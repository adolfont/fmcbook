%{{{ [vim] 
% vim:foldmarker=%{{{,%}}}
% vim:foldmethod=marker
% vim:foldcolumn=7
%}}}
%% fmcmain.tex
%% author: Thanos Tsouanas <thanos@tsouanas.org>
%% Copyright (c) 2016--2019 Thanos Tsouanas
%% All rights reserved.

%%{{{ chapter: Introduction 
\chapter Introdução.
\label{Introduction}%

%%{{{ chapintro 
\chapintro
Umas coisas nessa introdução não são pra fazer (muito) sentido.%
\footnote{Essa frase é uma dessas coisas.}
Se encontrar alguma notação, algum termo, símbolo, processo, etc.,
que tu não reconhece, continue lendo;
o importante é pegar uma idéia geral---os detalhes
são para os capítulos próximos.
%%}}}

%%{{{ Propositions vs. objects 
\section Proposições vs.~objetos.
\label{Propositions_vs_objects}%

\blah.
Olhando para matemática de longe podemos enxergar dois tipos principais:
\emph{proposições} (também \emph{afirmações}) e \emph{objetos} (também
\emph{individuais}).

\TODO $f : A \to B$, $A \subset B$, $x = y$: not always propositions.

\endsection
%%}}}

%%{{{ Errors 
\section Erros.
\label{Errors}%

%%{{{ Type errors 
\note Type errors.
\tdefined{type error}%
Um \dterm{type error} ocorre quando usamos uma expressão cujo tipo é
incompatível com o tipo esperado pelo contexto.
%%}}}

%%{{{ Logical 
\note De lógica.
%%}}}

%%{{{ Mathematical 
\note De matemática.
%%}}}

%%{{{ Semantic 
\note De semântica.
Isso acontece quando o que escrevemos realmente quis dizer algo, mas não é o que temos na nossa cabeça.
%%}}}

%%{{{ if_vs_since 
\note Se \vs como.
\label{if_vs_since}%
Considere as frases seguintes:
$$
\gather
\text{<<Se $\namedhole A$, $\namedhole B$.>>}\\
\text{<<Como $\namedhole A$, $\namedhole B$.>>}
\endgather
$$
Primeiramente observe que, em português, cada uma delas tem uma
palavra implícita logo após da virgula:
$$
\gather
\text{<<Se $\namedhole A$, ({\lthole}) $\namedhole B$.>>}\\
\text{<<Como $\namedhole A$, ({\lthole}) $\namedhole B$.>>}
\endgather
$$
Quais são?
Na primeira frase a palavra implícita é a ``então'', e na segunda a ``logo'':
$$
\gather
\text{<<Se $\namedhole A$, (então) $\namedhole B$.>>}\\
\text{<<Como $\namedhole A$, (logo) $\namedhole B$.>>}
\endgather
$$
Numa lida superficial as duas frases podem aparecer parecidas.
Mas são bem, bem diferentes!
%%}}}

%%{{{ x: explain_the_difference_between_if_and_since 
\exercise.
\label{explain_the_difference_between_if_and_since}%
Qual é a diferença entre as duas frases?

\solution
A frase
$$
\text{<<Se $\namedhole A$, (então) $\namedhole B$.>>}
$$
é uma afirmação que a proposição $A$ implica a proposição $B$.
Ou seja, não está afirmando que a proposição $A$ é verdade (nem que é falsa),
e também nada sobre a $B$.
No outro lado, a frase
$$
\text{<<Se $\namedhole A$, (então) $\namedhole B$.>>}
$$
é uma \emph{argumentação}.
Seu escritor já usa como fato conhecido que $A$ é verdade,
e alem disso, ele tá afirmando que $B$ também é verdade por causa disso.

\endexercise
%%}}}

%%{{{ Theses vs. hypotheses 
\note Teses \vs hipoteses.
``Tese'' vem da grega \emph{θέσις} e similarmente ``hipotese'' da
palavra \emph{ὑπόθεσις}.
\dterm{Tese} quis dizer \emph{posição},
nesse sentido também \emph{opinião}.
Tu tens uma tese sobre um assunto, e queres argumentar para defendê-la.
O prefixo ``ὑπο-'' (hipo-) denota uma idéia de ``a baixo de''.
O equivalente prefixo latino (e usado em português) é o ``sub-''.
\dterm{Hipoteses} então são \emph{su(b)posições}, ou seja,
afirmações ``a baixo'' da tese: as proposições em quais a tese depende.
%%}}}

\endsection
%%}}}

%%{{{ Definitions 
\section Definições.

\blah.
Tanto em matemática quanto fora de matemática, para facilitar nosso pensamento
e a comunicação com outras pessoas introduzimos novos termos, e novas notações
de certos conceitos, assim evitando a necessidade de descrever em todo detalhe
a mesma idéia.

%%{{{ From mind to paper 
\note De mente para papel.
O processo de definir algo começa na nossa cabeça, onde
identificamos---ou pelo menos, achamos que identificamos---um conceito
que consideramos interessante e que merece seu próprio nome, sua própria
notação, etc.
Depois disso começa o processo de \emph{traduzir} nossa idéia, do mundo
mental para uma linguagem, freqüentemente sendo uma linguagem natural
pouco enriquecida com notação, termos, convenções, etc., para atender
as necessidades de matemática.
Também precisamos de \emph{escolher um nome bonito} para nossa definição,
uma notação conveniente e útil.
%%}}}

%%{{{ Examples and nonexamples 
\note Exemplos e nãœxemplos.
Talvez já temos vários exemplos de objetos que satisfazem nossa definição,
ou nem sabemos se existem tais objetos!  Observe então que para definir
algo não é necessário---e com certeza nem suficiente!---mostrar exemplos
de objetos.
Mesmo assim, quando escrevemos um texto matemático e queremos ajudar nosso
leitor confirmar seu entendimento da nossa definição, podemos dar uns
exemplos ou nãœxemplos, mas é importante entender que a natureza deles
nunca é essencial para a definição, e que
\emph{eles não fazem parte da definição}.
É apenas uma ferramenta pedagógica.
%%}}}

\blah.
Dando uma definição de algum termo, notação, etc., precisamos deixar claro
em qual afirmação ela denota.
Considere como exemplo a noção de \emph{primos gêmeos} que aparece em
teoria dos números:

%%{{{ eg: eg_def_of_twin_primes 
\example.
\label{eg_def_of_twin_primes}%
Considere a definição:
\quote
<<Dois números $p,q$ são \dterm{primos gêmeos} sse $p,q$ são primos e $\abs{p-q} = 2$.>>
\endquote
Dados então dois números $a,b$, sabemos o que a afirmação
``$a,b$ são primos gêmeos''
significa:
$$
\text{$a,b$ são primos e $\abs{p-q} = 2$}.
$$
\endexample
%%}}}

%%{{{ context_of_a_definition 
\note Contexto.
\label{context_of_a_definition}%
Para definir qualquer coisa precisamos primeiramente deixar claro o
\dterm{contexto}.  No~\ref{eg_def_of_twin_primes} o contexto é:
$$
\align
p &\eqtype \text{um número} \\
q &\eqtype \text{um número}.
\intertext{No outro lado, se a definição fosse <<dois números primos $p,q$ são \dterm{primos gêmeos} sse $\abs{p-q} = 2$>> o contexto seria pouco diferente:}
p &\eqtype \text{um número primo} \\
q &\eqtype \text{um número primo}.
\endalign
$$
%%}}}

%%{{{ what_is_tijolo 
\note O que é tijolo?.
\label{what_is_tijolo}%
No meu primeiro semestre como professor no Brasil, em algum momento---%
não lembro porquê---um aluno na sua explicação usou a palavra ``tijolo''.
O problema é, que eu nunca tinha encontrado essa palavra antes; então
perguntei ao meu aluno:
\quote
<<O que é tijolo?>>
\endquote
Neste momento o aluno sentiu um desafio: como você explica o que é um tijolo para um gringo?
\footnote{O aluno não falava inglês---nem grego!---e logo a gente não tinha
uma linguagem ``fallback'' para usá-la e tirar minha dúvida.}
Ele precisou dar uma \emph{definição} dessa palavra.
A resposta dele foi
\quote
\emph{<<Tijolo é tijolo, ué!>>}
\endquote
\dots E isso não me ajudou muito.
%%}}}

%%{{{ Circular definition 
\note Definições circulares.
\tdefined{definição circular}%
A resposta do aluno acima é um exemplo duma \dterm{definição circular}.
$$
\tikzpicture
\node (word) at (0,0) {tijolo};
\draw[-Latex] (word.-45) arc (-150:150:6mm);
\endtikzpicture
$$
Tenho então essa questão pra ti.
\quote
\emph{<<O que é um conjunto?>>}
\endquote
Uma resposta razoável neste momento seria a seguinte:
\quote
\emph{<<Um conjunto é uma colecção de objetos.>>}
\endquote
E, se eu sei o que significa ``colecção'' eu vou entender
o que é um conjunto e vou ficar feliz; mas caso contrário, eu vou perguntar:
\quote
\emph{<<E o que é uma colecção?>>}
\endquote
Provavelmente aquele aluno que me ensinou o que é ``tijolo'' ia responder:
\quote
\emph{<<Uma colecção é um conjunto de objetos.>>}
\endquote
Aqui o problema é o mesmo com o ``tijolo'', só que um tiquinho menos óbvio,
pois o cíclo aqui pelo menos tem duas setinhas:
$$
\tikzpicture
\node[inner sep=2pt, outer sep=2pt] (word1) at (-1,0) {conjunto};
\node[inner sep=2pt, outer sep=2pt] (word2) at (1,0)  {colecção};
\draw (word1) edge[out=315,in=225,-Latex] (word2);
\draw (word2) edge[out=135,in=45, -Latex] (word1);
\endtikzpicture
$$
Pensando numa forma computacional, entendemos essa definição como um
programa cuja execução caiu num \emph{loop infinito}.
Como ele nunca termina, nos nunca sabemos se um objeto satisfaz
ou não essa definição.
%}}}

%%{{{ Recursive definitions 
\note Definições recursivas.
\label{recursive_definitions_teaser}%
Alguém pode pensar que o problema com as definições circulares é que a palavra
que estamos definindo apareceu na sua própria definição.
Isso \emph{não} é o caso!
Numa \dterm{definição recursiva} a palavra que queremos definir parece aparacer
dentro da sua própria definição, e mesmo assim, não estamos caindo num loop infinito,
e realmente conseguimos definir o que queremos.
Mas bora deixar esse assunto para depois, quando com pouco mais experiência
vamos trabalhar com recursão.
%%}}}

%%{{{ Errors in definitions 
\note Erros em definições.
Pode ser que para algum erro uma suposta definição acaba não definindo
nada pois seu texto não conseguiu descrever nenhum conceito.
%%}}}

\TODO Elaborate.

%%{{{ What is ``well-defined''? 
\note O que é ``bem-definido''?.
%%}}}

\TODO Explain and examples, point to fun chap.

%%{{{ The importance of definitions 
\note A importância das definições.
Superficialmente alguém pode pensar que ``não existe definição errada''.
Ficando no pé da letra seria difícil convencer esse alguém que ele não
tem razão.  Mas muitas vezes dando as definições ``certas'' é o que te
permite provar um teorema difícil que seria inatacável sem elas.
Uma definição deve ser escrita na maneira mais simples possível para entender e usar.
E deve capturar um conceito interessante.
Tendo as definições corretas, raciocinamos melhor,
e conseguimos formular nosso pensamento numa forma
curta e entendível.
Com prática, vamos conseguir identificar quando faria sentido definir
um termo novo, dar uma definição elegante e correta, e escolher
um nome bom, e se for útil uma notação conveniente também.
%%}}}

%%{{{ Comparison with programming 
\note Comparação com programação.
\tdefined{entry point}%
Enquanto programando, para muitos programadores a parte mais
desafiadora (e divertida) é \emph{inventar os nomes corretos}%
\footnote{Ou até \emph{descobrir os nomes escondidos},
dependendo do caso e do ponto de vista, para enfatisar!}
para partes dos seus programas.
Em muitas linguagens existe um \dterm{entry point} para teu programa, onde a execução começa.
Por exemplo, em C isso seria o corpo da função $\code{main}$.
Seria bizarro (no mínimo) tentar escrever um inteiro programa apenas usando os primitivos da C dentro dessa função $\code{main}$.
Felizmente as linguagens oferecem ferraments de abstracção para o programador---umas bem mais que outras---e assim começamos definindo nossos próprios conceitos: funções, variáveis, constantes, típos, etc.
%%}}}

\endsection
%%}}}

%%{{{ Theorems and friends 
\section Teoremas e seus amigos.

\TODO Elaborar.

\endsection
%%}}}

%%{{{ And what is ...?  And why ...? 
\section E o que é \dots?  E por que \dots?.

\note Uma criança ``chata''.

\note Geometria euclideana.

\endsection
%%}}}

%%{{{ Notation_of_fmcbook 
\section Notação desse texto.
\label{Notation_of_fmcbook}%

%%{{{ equal or equivalente 
\note Igual ou equivalente?.
Usamos os símbolos \sq{$=$} e \sq{$\iffsymbol$} para afirmar uma relação especifica entre as
coisas que aparecem nos dois lados deles.
Só que os \emph{tipos} de coisas são diferentes para cada símbolo.
O $=$ fica entre \emph{objetos}, o \sq{$\iffsymbol$} entre \emph{proposições} (afirmações).
\endgraf
Usamos $=$ para dizer que os objetos nos seus lados são \emph{iguais}, ou seja,
as coisas escritas nos seus dois lados, denotam o mesmo objeto.
Por exemplo ``$1+5$'' denota um número e ``$3$'' também denota um número, e escrevendo
$$
1 + 5 = 3
$$
estamos afirmando (erroneamente nesse caso!) que as duas expressões denotam o mesmo número.
Escrever $1 + 5 = 6$ seria uma afirmação correta.
Pronunciamos o $A = B$ como ``$A$ é igual ao $B$''.
\endgraf
Usamos $\iff$ para dizer que as proposições (afirmações) nos seus lados são
\emph{logicamente equivalentes}, ou seja, são ambas verdadeiras ou ambas falsas.
Escrevemos então
$$
\text{$p$ é primo e $p>2$}
\iff
\text{$p$ é um primo ímpar}
$$
e nesse caso essa é uma afirmação correta.
Note que não sabemos dizer qual é o caso aqui: são ambas verdadeiras, ou ambas falsas?
Não sabemos que número é denotado por a variável $p$, mesmo assim as afirmações
são equivalentes.
Note que isso nos permite escrever o símbolo \sq{$\iffsymbol$} entre proposições que não
tem nada a ver uma com outra.
Por exemplo, seria válido e correto escrever
$$
0 = 1
\iff
\text{existe número natural maior que todos os outros}
$$
mas esse tipo de afirmações raramente aparecem em matemática.
Pronunciamos o $A \iff B$ como ``$A$ é equivalente a $B$'' ou,
``$A$ se e somente se $B$'', usando a abreviação \dterm{sse}
para a frase ``se e somente se''.
%%}}}

%%{{{ x: which_is_if_and_which_is_only_if 
\exercise.
\label{which_is_if_and_which_is_only_if}%
Entendemos o \sq{$\impliessymbol$} como uma abreviação de
``implica'' e o \sq{$\impliedbysymbol$} como uma abreviação de
``é implicado por''.
Podemos ler as expressões seguintes assim também:
$$
\align
A \implies B & :\quad\text{se $A$ então $B$}\\
A \iff B     & :\quad\text{$A$ se e somente se $B$}
\endalign
$$
Podemos pronunciar o \sq{$\impliessymbol$} e o \sq{$\impliedbysymbol$}
apenas por uma das frases: ``se'' e ``somente se''.
Qual é qual?

\endexercise
%%}}}

%%{{{ by definition 
\note Por definição.
Peluma convenção a coisa sendo definida vai no lado esquerdo do símbolo
que decoramos com esse ``def'' e a sua definição fica no lado direito.
Então mesmo que nos símbolos \sq{$=$} e \sq{$\iffsymbol$} podemos trocar seus lados,
nos $\defeq$ e $\defiff$, não!
%%}}}

%%{{{ eg: with_and_without_def 
\example.
Qual a diferença entre as duas expressões?
$$
\align
\text{$n$ é ímpar} &\defiff \text{$n = 2k + 1$ para algum inteiro $k$}\\
\text{$n$ é ímpar} &\iff    \text{$n = 2k + 1$ para algum inteiro $k$}
\endalign
$$
A primeira linha \emph{é uma definição}.
Estamos \emph{definindo} o que significa ``ser ímpar'', dizendo como
traduzir a afirmação ``$n$ é ímpar'' em uma outra afirmação que
supostamente entendemos.
A segunda linha \emph{é uma afirmação}:
afirma que as duas proposições nos seus lados são equivalentes.
Ou seja, é algo que pode ser provado, ou refutado.
E para usar o \sq{$\iffsymbol$} com certeza seus dois lados precisam ser
afirmações bem-definidas.
\endexample
%%}}}

\blah.
\TODO
Explicar o resto dos ``parecidos'':
$\asseq$, $\eqass$, $\inteq$, $\synasseq$, $\semeq$,
$\defiff$, $\sugdefiff$, $\sugiff$, etc.

\endsection
%%}}}

%%{{{ Bound_and_free_variables 
\section Variáveis ligades e livres.
\label{Bound_and_free_variables}%
\tdefined{variável}[livre]%
\tdefined{variável}[ligada]%
\tdefined{variável}[capturada]%
\tdefined{variável}[dummy]%
\iisee{capturado}{variável, capturada}%
\iisee{dummy}{variável, dummy}%

\TODO Explicar.

\endsection
%%}}}

%%{{{ Sorts of numbers 
\section Tipos de números.
% cyclic definitions
% from reals to nats
% from nats to reals
\endsection
%%}}}

%%{{{ Sets, functions, relations 
\section Conjuntos, funções, relações.

\TODO Aridade.

\endsection
%%}}}

%%{{{ Programming vs. proving 
\section Programando vs.~provando.

\endsection
%%}}}

%%{{{ Problems 
\problems.

\endproblems
%%}}}

%%{{{ Further reading 
\further.

Matemática elementar:
\cite{simmonsprecalculus} (para uma revisão rápida);
\cite{langbasicmath} (para um estudo mais profundo).

Sobre geometria euclideana:
\cite{elements},
\cite{coxeterrevisited};
\cite{hartshorneeuclidbeyond}.

Sobre calculus:
\cite{spivakcalculus},
\cite{hardypuremath};
\cite{apostol1}~\&~\cite{apostol2},
\cite{loomissternberg}.

Sobre álgebra linear:
\cite{janichlinalg},
\cite{halmoslapb},
\cite{halmosfdvs}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Rational and irrational numbers 
\chapter Números racionais e irracionais.

%%{{{ Rationals and the pythagoreans 
\section Os racionais e os pitagoreanos.

\endsection
%%}}}

%%{{{ sqrt(2) is not rational 
\section O $\sqrt 2$ não é racional.

\endsection
%%}}}

%%{{{ But sqrt(2) surely is a number 
\section Mas o $\sqrt 2$ com certeza é um número.

\endsection
%%}}}

%%{{{ Irrational numbers 
\section Números irracionais.

\endsection
%%}}}

%%{{{ sqrt(3) is irrational 
\section O $\sqrt 3$ é irracional.

\endsection
%%}}}

%%{{{ A lemma 
\section Um lemma.

\endsection
%%}}}

%%{{{ What happens with sqrt(4) and sqrt(5) 
\section O que acontece com $\sqrt 4$ e $\sqrt 5$.

\endsection
%%}}}

%%{{{ A generalization theorem 
\section Um teorema de generalização.

\endsection
%%}}}

%%{{{ More irrational numbers 
\section Mais números irracionais.

\endsection
%%}}}

%%{{{ Algebraic and transcendental numbers 
\section Números algébricos e transcendentais.

\endsection
%%}}}

%%{{{ Problems 
\problems.

%%{{{ prob: transcedentalidade_of_one_of_epluspi_etimespi 
\problem.
\label{transcedentalidade_of_one_of_epluspi_etimespi}%
Pelo menos um dos $e+\pi$, $e\pi$ é transcendental.

\solution
Demonstramos usando reductio ad absurdum.
Suponha então que ambos são algébricos e
vamos chamá-los assim:
$$
\xalignat2
S &= e + \pi &
P &= e\pi.
\endxalignat
$$
Agora considere o polinômio
$$
f(x) = x^2 - Sx + P
$$
e observe que $e,\pi$ são raizes dele:
$$
\align
f(e)   &= e^2   - (e + \pi)e + e\pi   = 0 \\
f(\pi) &= \pi^2 - (e + \pi)\pi + e\pi = 0.
\endalign
$$
Chegamos assim na contradição que $e,\pi$
são algébricos, pois os coeficientes do $f$ são.

\endproblem
%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite{nivenirrational}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Languages 
\chapter Linguagens.

%%{{{ Numbers, numerals, digits 
\section Números, numerais, dígitos.
% dígito aka "algarismo"

\note.
\tdefined{número}%
\tdefined{numeral}%
\tdefined{dígito}%
\iisee{algarismo}{dígito}%
Aceitamos por enquanto como dado o conceito dos números que usamos
para contar:
$$
0, 1, 2, 3, \dots, 247, 248, 249, \dots
$$
Usando então apenas um \emph{alfabeto} composto de 10 símbolos
$$
\digit 0\ 
\digit 1\ 
\digit 2\ 
\digit 3\ 
\digit 4\ 
\digit 5\ 
\digit 6\ 
\digit 7\ 
\digit 8\ 
\digit 9
$$
e seguindo as regras bem-conhecidas do sistema decimal conseguimos
denotar qualquer um dos números, mesmo que tem uma infinidade deles!

Chamamos esses símbolos \dterm{dígitos} (ou \dterm{algarismos}),
e as palavras (ou ``strings'') que formamos justapondo esses dígitos que
representam os números, \dterm{numerais}.
Sem contexto, lendo o ``10'' existe já uma ambigüidade:
é o numeral $\numeral {10}$ ou o número dez?
Para apreciar essa diferença ainda mais, note que o numeral $\numeral {10}$,
pode representar outro número em outro contexto.
Por exemplo, no sistema binário, o numeral $\numeral {10}$
representa o número dois.
E a ambigüidade pode ser ainda maior lendo ``1'':
é o numeral $\numeral {1}$; o número um; ou o dígito~$\digit 1$?
Quando o contexto é suficiente para entender, não precisamos mudar a fonte
como acabei de fazer aqui, nem escrever explicitamente o que é.
Note que existem numerais bem diferentes para denotar esses números:
o numeral (romano) {XII}
e o numeral (grego) {ιβ} denotam o mesmo número: doze.

\blah.
Temos então umas pequenas linguágens que nos permitem descrever \emph{números}.
Não fatos sobre números.
Não operações que envolvem números.
Números.
Quais números?
Todos os números \emph{naturais}, cuja totalidade simbolizamos com $\nats$.

\endsection
%%}}}

%%{{{ Arithmetic expressions: syntax vs. semantics 
\section Expressões aritméticas: sintaxe vs.~semântica.
\label{arithmetic_expressions_syntax_vs_semantics}%

%%{{{ A first example expression 
\note.
\tdefined{precedência}%
Considere agora a expressão
$$
1 + 5 \ntimes 2
$$
que envolve os numerais $1$, $5$, e $2$,
e os símbolos de funções $+$ (adição) e $\ntimes$ (multiplicação).
O que ela representa?
A multiplicação de $1+5$ com $2$, ou a adição de $1$ com $5\ntimes 2$?
A segunda opção, graças a uma convenção que temos%
---e que você provavelmente já encontrou na vida.
Digamos que a $\ntimes$ ``pega mais forte'' do que a $+$,
então precisamos ``aplicá-la'' primeiro.
Mais formalmente, a $\ntimes$ tem uma \dterm{precedência} mais alta que a da $+$.
Quando não temos convenções como essa, usamos parenteses para tirar a ambigüidade
e deixar claro como parsear uma expressão.
Então temos
$$
(1 + 5) \ntimes 2 \neq 1 + 5 \ntimes 2 = 1 + (5 \ntimes 2).
$$
%%}}}

%%{{{ One more example; syntax-vs-semantics 
\note.
\tdefined{associatividade}[esquerda e direita]%
\tdefined{igualdade}[sintáctica]%
\tdefined{igualdade}[semântica]%
\sdefined {\sholed A = \sholed B}      {igualdade semântica}%
\sdefined {\sholed A \syneq \sholed B} {igualdade sintáctica}%
E a expressão
$$
1+5+2
$$
representa o quê?
Não seja tentado dizer ``tanto faz'', pois mesmo que as duas
possíveis interpretações
$$
(1+5) + 2
\qqqqtext{e}
1 + (5+2)
$$
\emph{denotam valores} iguais,
elas expressam algo diferente:
$$
\align
(1 + 5) + 2&: \quad\text{adicione o $1+5$ com o $2$};\\
1 + (5 + 2)&: \quad\text{adicione o $1$ com o $5+2$}.
\endalign
$$
Então\dots
$$
(1 + 5) + 2 \askeq 1 + (5 + 2)
$$
Como \emph{expressões} (a \emph{sintaxe}) são diferentes;
como \emph{valores} (a \emph{semântica}) são iguais,
pois denotam o mesmo objeto: o número oito.
Normalmente em matemática ligamos sobre as denotações das expressões,
e logo escrevemos igualdades como
$$
(1 + 5) + 2 = 6 + 2 = 8 = 1 + 7 = 1 + (5 + 2).
$$
Ou seja, o símbolo \sq{$=$} em geral denota \dterm{igualdade semântica}:
$A=B$ significa que os dois lados, $A$ e $B$, denotam o mesmo objeto.
Querendo representar \dterm{igualdade sintáctica}, as vezes usamos
outros símbolos.  Vamos usar o \sq{$\syneq$} agora, de modo que:
$$
\align
1 + 2 = 3
&\qqqtext{mas}
1 + 2 \synneq 3;\\
(1 + 5) + 2 = 1 + (5 + 2)
&\qqqtext{mas}
(1 + 5) + 2 \synneq 1 + (5 + 2);
\quad\text{etc.}
\endalign
$$

Voltando à expressão $1 + 5 + 2$, precisamos mais uma convenção
para atribuir uma associatividade esquerda ou direita.
Vamos concordar que $a + b + c$ representa a expressão
$((a + b) + c)$, ou seja, atribuimos em $+$ uma
\emph{associatividade esquerda}.

Mas $+$ não é uma operação associativa?
Sim, e isso quis dizer que como valores,
$$
((a + b) + c) = (a + (b + c)).
$$
Mas como expressões, são diferentes, e logo sem essa convenção,
$a + b + c$ não representaria nenhuma expressão de aritmética!
%%}}}

%%{{{ x: syneq or semeq? 
\exercise.
\label{syneq_or_semeq}%
Sejam $a,b,c$ números naturais.
Usando $=$ para igualdade semântica e $\syneq$ para igualdade
sintáctica, decida para cada uma das afirmações seguintes
se é verdadeira ou falsa:
\beginol
\li $a + b + c                \syneq  a + (b + c)$
\li $a + b + c                \syneq  (a + b) + c$
\li $a + b + c                =       a + (b + c)$
\li $a + b + c                =       (a + b) + c$
\li $2 \ntimes 0 + 3          =       0 + 3$
\li $2 \ntimes 0 + 3          \syneq  0 + 3$
\li $(2 \ntimes 0) + 3 + 0    =       1 + 1 + 1$
\li $2 \ntimes 0 + 3          \syneq  1 + 1 + 1$
\li $2 \ntimes 0 + 3          \syneq  2 \ntimes (0 + 3)$
\li $2 \ntimes 0 + 3          =       2 \ntimes (0 + 3)$
\li $2 \ntimes 0 + 3          \syneq  (2 \ntimes 0) + 3$
\li $1 + 2                    \syneq  2 + 1$
\endol

\solution
Temos:
\beginol
\li $a + b + c                \synneq a + (b + c)$
\li $a + b + c                \syneq  (a + b) + c$
\li $a + b + c                =       a + (b + c)$
\li $a + b + c                =       (a + b) + c$
\li $2 \ntimes 0 + 3          =       0 + 3$
\li $2 \ntimes 0 + 3          \synneq 0 + 3$
\li $(2 \ntimes 0) + 3 + 0    =       1 + 1 + 1$
\li $2 \ntimes 0 + 3          \synneq 1 + 1 + 1$
\li $2 \ntimes 0 + 3          \synneq 2 \ntimes (0 + 3)$
\li $2 \ntimes 0 + 3          \neq    2 \ntimes (0 + 3)$
\li $2 \ntimes 0 + 3          \syneq  (2 \ntimes 0) + 3$
\li $1 + 2                    \synneq 2 + 1$
\endol

\endexercise
%%}}}

%%{{{
\exercise.
Verdade ou falso?:
$$
A \syneq B \implies A = B
$$

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Derivation trees 
\section Arvores de derivação.

%%{{{ Parsing 
\note Parsing.
\tdefined{parsing}%
\tdefined{árvore}[sintáctica]%
\tdefined{árvore}[de derivação]%
Lendo uma expressão ``linear'' como a
``$1 + 5 \ntimes 2$''
nos a \dterm{parseamos} para revelar sua estrutura,
freqüentemente representada numa forma bidimensional, como uma
\dterm{árvore sintáctica}.
Temos então as árvores:
$$
1 + (5 \ntimes 2)
\quad\leadsto\quad
\gathered
\tikzpicture[scale=0.8]
\node [circle,draw] (z) {$+$}
  child {node [circle,draw] (a) {$1$}}
  child {node [circle,draw] (b) {$\vphantom+\ntimes$}
    child {node [circle,draw] (b1) {$5$}}
    child {node [circle,draw] (b2) {$2$}}
  };
\endtikzpicture
\endgathered
\qqqquad
(1 + 5) \ntimes 2
\quad\leadsto\quad
\gathered
\tikzpicture[scale=0.8]
\node [circle,draw] (z) {$\vphantom+\ntimes$}
  child {node [circle,draw] (a) {$+$}
    child {node [circle,draw] (a1) {$1$}}
    child {node [circle,draw] (a2) {$5$}}
  }
  child {node [circle,draw] (b) {$2$}};
\endtikzpicture
\endgathered
$$
Não vamos usar mais esse tipo de árvore sintáctica nessas notas.
%%}}}

%%{{{ Derivation trees 
\note Arvores de derivação.
\tdefined{árvore de derivação}%
Em vez, vamos usar \dterm{árvores de derivação} como essas:
$$
\xalignat2
&
\Proof {
\A {1}
          \A {5}       \A {2}
          \I2---------------- {$\ntimes$}
           {$(5 \ntimes 2)$}
\I2------------------------- {$+$}
      {$1 + (5 \ntimes 2)$}
}
&&
\Proof {
\A {1}    \A {5}
\I2------------- {$+$}
   {$(1 + 5)$}            \A {2}
   \I2-------------------------- {$\ntimes$}
        {$(1 + 5) \ntimes 2$}
}
\endxalignat
$$
Sendo esse nosso primeiro contato com árvores sintácticas, vamos explicar
em detalhe como as escrevemos.  Começamos então com a expressão (linear)
que queremos parsear:
$$
(1 + 5) \ntimes 2.
$$
Graças à sua parêntese, o ``operador principal'' (o mais ``externo'')
é o $\ntimes$.  Isso quis dizer que, no final das contas, essa expressão
representa uma multiplicação de duas coisas.
Exatamente por isso, reduzimos essa expressão em duas novas, escrevendo
uma linha em cima dela, onde temos agora dois lugares para botar essas
duas coisas.  No lado da linha, escrevemos sua ``justificativa''
$$
\AxiomC{$\hole$}
\AxiomC{$\hole$}
\RightLabel{$\holed \ntimes$}
\BinaryInfC{$(1 + 5) \ntimes 2$}
\DisplayProof
$$
e nos dois buracos que aparecem botamos as expressões que estão
nos lados desse $\ntimes$:
$$
\AxiomC{$\holed {(1 + 5)}$}
\AxiomC{$\holed {\vphantom(2}$}
\RightLabel{$\ntimes$}
\BinaryInfC{$(1 + 5) \ntimes 2$}
\DisplayProof
$$
Agora $2$ já é uma expressão \dterm{atômica} (ou seja, inquebrável),
mas a $(1 + 5)$ não é então repetimos o mesmo processo nela:
$$
\AxiomC{$\holed 1$}
\AxiomC{$\holed 5$}
\RightLabel{$\holed +$}
\BinaryInfC{$(1 + 5)$}
\AxiomC{${\vphantom(2}$}
\RightLabel{$\ntimes$}
\BinaryInfC{$(1 + 5) \ntimes 2$}
\DisplayProof
$$
Chegamos finalmente na árvore
$$
\AxiomC{$1$}
\AxiomC{$5$}
\RightLabel{$+$}
\BinaryInfC{$(1 + 5)$}
\AxiomC{${\vphantom(2}$}
\RightLabel{$\ntimes$}
\BinaryInfC{$(1 + 5) \ntimes 2$}
\DisplayProof
$$
que mostra como a expressão aritmética $(1 + 5) \ntimes 2$ na sua \dterm{raiz}
(ou \dterm{root}) é composta por os numeráis $1$, $5$, e $2$
que são as \dterm{folhas} (ou \dterm{leaves}) dessa árvore.
%%}}}

\endsection
%%}}}

%%{{{ Grammars and BNF notation 
\section Gramáticas e a notação BNF.
\label{BNF_notation}%
\tdefined{BNF}%
\tdefined{gramática}%
\iisee{Backus--Naur form}{BNF}%

%%{{{ A first try 
\note Uma primeira tentativa.
\label{BNF_a_first_try}%
Vamos começar diretamente com um exemplo de uso da
notação~\dterm{BNF}
(Backus\Backus{}--Naur\Naur{} form),
para descrever uma linguagem de expressões aritméticas, usando
a \dterm{gramática} seguinte:
%%}}}

%%{{{ g: ArEx_grammar_1 
\grammar ArEx (1).
\label{ArEx_grammar_1}%
$$
\align
\bnf{ArEx} &\bnfeq 0 \bnfor 1 \bnfor 2 \bnfor 3 \bnfor \dotsb \tag{1}\\
\bnf{ArEx} &\bnfeq (\bnf{ArEx} + \bnf{ArEx})                \tag{2}
\endalign
$$
%%}}}

%%{{{ Explanation 
\blah.
O que tudo isso significa?
A primeira linha, é uma regra dizendo:
uma expressão aritmética pode ser um dos
$0$, $1$, $2$, $3$, \dots.
A segunda linha é mais interessante: uma expressão aritmética pode começar
com o símbolo \sq{(},
depois ter uma expressão aritmética,
depois o símbolo \sq{+},
depois mais uma expressão aritmética,
e finalmente o símbolo \sq{)}.
A idéia é que o que aparece com ângulos é algo que precisa ser substituido,
com uma das opções que aparecem no lado direito de alguma regra que começa com ele.

Começando com o $\bnf{ArEx}$ ficamos substituindo até não aparece mais nada em ângulos.
Et voilà: neste momento temos criado uma expressão aritmética.
%%}}}

%%{{{ eg: BNF_first_example 
\example.
Use as regras (1)--(2) da~\ref{ArEx_grammar_1} acima para criar uma expressão
aritmética.
Comece usando a regra (2).
$$
\align
\bnf{ArEx}
&\leadstoby {(2)} (\bnf{ArEx} + \bnf{ArEx})\\
&\leadstoby {(1)} (\bnf{ArEx} + 3)\\
&\leadstoby {(2)} ((\bnf{ArEx} + \bnf{ArEx}) + 3)\\
&\leadstoby {(1)} ((128 + \bnf{ArEx}) + 3)\\
&\leadstoby {(1)} ((128 + 0) + 3)
\endalign
$$
\endexample
%%}}}

%%{{{ eg: BNF_direct_example 
\example.
Use a mesma gramática (agora sem restricção) para criar uma expressão aritmética.
$$
\align
\bnf{ArEx}
&\leadstoby {(1)} 17
\endalign
$$
\endexample
%%}}}

%%{{{ x: BNF_with_goal 
\exercise.
Mostre como usar a~\ref{ArEx_grammar_1} para gerar a expressão aritmética
$((1 + (2 + 2)) + 3)$.

\solution
Uma solução é a seguinte:
$$
\align
\bnf{ArEx}
&\leadstoby {(2)} (\bnf{ArEx} + \bnf{ArEx})\\
&\leadstoby {(1)} (\bnf{ArEx} + 3)\\
&\leadstoby {(2)} ((\bnf{ArEx} + \bnf{ArEx}) + 3)\\
&\leadstoby {(2)} ((\bnf{ArEx} + (\bnf{ArEx} + \bnf{ArEx})) + 3)\\
&\leadstoby {(1)} ((1 + (\bnf{ArEx} + \bnf{ArEx})) + 3)\\
&\leadstoby {(1)} ((1 + (2 + \bnf{ArEx})) + 3)\\
&\leadstoby {(1)} ((1 + (2 + 2)) + 3)
\endalign
$$

\endexercise
%%}}}

% doesn't have to be the same expression for the same <name> 

%%{{{ Q: problems_of_first_BNF
\question.
Quais são uns defeitos dessa primeira tentativa?
O que podemos fazer para a melhorar?
\spoiler.
%%}}}

%%{{{ A: problems_of_first_BNF_answer 
\blah Resposta.
Umas deficiências são:

\beginol
\li A linguagem gerada por essa gramática não é suficiente para representar expressões que envolvem outras operações, como $-$, $\ntimes$, $\div$, etc.
\li A regra (1) tem uma infinitade de casos (graças aos \sq{$\dotsb$}).
\li As regras e os nomes escolhidos não refletem bem nossa idéia.
\endol
%%}}}

%%{{{ x: solve_first_problem_of_ArEx 
\exercise.
\label{solve_first_problem_of_ArEx}%
Apenas alterando a segunda regra da~\ref{ArEx_grammar_1}, resolva a primeira deficiência.

\hint
Falta só adicionar 3 mais casos na segunda regra, imitando para os outros operadores o caso do $+$.

\solution
Temos:
$$
\align
\bnf{ArEx} &\bnfeq 0 \bnfor 1 \bnfor 2 \bnfor 3 \bnfor \dotsb \tag{1}\\
\bnf{ArEx}
&\bnfeq (\bnf{ArEx} + \bnf{ArEx})\tag{2}\\
&\bnfOR (\bnf{ArEx} - \bnf{ArEx})\\
&\bnfOR (\bnf{ArEx} \ntimes \bnf{ArEx})\\
&\bnfOR (\bnf{ArEx} \div \bnf{ArEx})
\endalign
$$

\endexercise
%%}}}

%%{{{ A second try 
\note Uma segunda tentativa.
A solução que encontramos no~\ref{solve_first_problem_of_ArEx}
não é a coisa mais elegante do mundo.
Tem muita repetição que podemos evitar, definindo uma nova regra em nossa gramática:
%%}}}

%%{{{ g: ArEx_grammar_2 
\grammar ArEx (2).
\label{ArEx_grammar_2}%
$$
\align
\bnf{ArEx} &\bnfeq 0 \bnfor 1 \bnfor 2 \bnfor 3 \bnfor \dotsb \tag{1}\\
\bnf{ArEx} &\bnfeq (\bnf{ArEx} \bnf{BinOp} \bnf{ArEx})\tag{2}\\
\bnf{BinOp} &\bnfeq + \bnfor - \bnfor \ntimes \bnfor \div\tag{3}
\endalign
$$
%%}}}

\blah.
Bem melhor!
Mas ainda a gramática não refleta bem nossa idéia.
Podemos melhorá-la, com mais regras e com nomes melhores
que deixam mais claras nossas intenções:

%%{{{ g: ArEx_grammar_3 
\grammar ArEx (3).
\label{ArEx_grammar_3}%
$$
\align
\bnf{ArEx}  &\bnfeq \bnf{Num} \bnfor \bnf{OpEx} \tag{0}\\
\bnf{Num}   &\bnfeq 0 \bnfor 1 \bnfor 2 \bnfor 3 \bnfor \dotsb \tag{1}\\
\bnf{OpEx}  &\bnfeq (\bnf{ArEx} \bnf{BinOp} \bnf{ArEx})\tag{2}\\
\bnf{BinOp} &\bnfeq + \bnfor - \bnfor \ntimes \bnfor \div\tag{3}
\endalign
$$
%%}}}

\blah.
Falta achar um jeito para remover esses ``$\dotsb$'' ainda,
mas vamos deixar isso para depois (\ref{remove_dots_from_ArEx_grammar}).

%%{{{ Nat_grammar 
\grammar Nat.
\label{Nat_grammar}%
$$
\bnf{Nat} \bnfeq 0 \bnfor S \bnf{Nat}
$$
%%}}}

%%{{{ x: generate_some_nats_from_grammar 
\exercise.
\label{generate_some_nats_from_grammar}%
Quais são umas das palavras que podes gerar com a~\ref{Nat_grammar}?
Podemos usar sua linguagem como numerais para os naturais?

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Metalanguages 
\section Metalinguagens.
\label{Metalanguages}%

%%{{{ metalanguage 
\note.
\label{metalanguage}%
\tdefined{metalinguagem}%
\tdefined{linguagem-objeto}%
Já encontramos o conceito de linguagem como um objeto de estudo.
Logo vamos estudar bem mais linguagens, de lógica matemática,
estudar linguágens de programação, etc.
É preciso entender que enquanto estudando uma linguagem,
esse próprio estudo acontece também usando uma (outra) linguagem.
Aqui usamos por exemplo português, provando propriedades, dando definições,
afirmando relações, etc., de outras linguagens que estudamos,
como da aritmética, de lógica matemática, de programação, etc.
Para enfatizar essa diferença e para tirar certas ambigüidades,
chamamos \dterm{linguagem-objeto} a linguagem que estudamos,
e \dterm{metalinguagem} a linguagem que usamos para falar
sobre a linguagem-objeto.
Note que todos os símbolos \sq{$\iffsymbol$}, \sq{$\impliessymbol$}, e \sq{$\impliedbysymbol$}
fazem parte da \emph{metalinguagem}, e não é para confundir com os
\sq{${\liff}$}, \sq{${\limplies}$}, e \sq{${\limplied}$} que geralmente usamos
como símbolos de certas \emph{linguagens} de lógica.
%%}}}

%%{{{ metavariables 
\note.
\label{metavariables}%
\tdefined{metavariável}%
Imagine que você trabalha como programador e teu chefe lhe pediu
fazer uma mudança no código de todos os teus programas escritos na linguagem de
programação C.
Ele disse:
<<Em todo programa teu $\Pi$, substitua cada variável $\alpha$ de tipo $\tau$
que aparece no código fonte por para $\alpha\code{\_of\_}\tau$.>>
<<Por exemplo,>> ele continuou abrindo o programa no seu editor,
<<essa variável aqui $\code{i}$ que é de tipo $\code{int}$,
precisa ser renomeada para $\code{i\_of\_int}$;
e essa $\code{count}$ também para $\code{count\_of\_int}$;
e essa $\code{mean}$ de tipo $\code{float}$, para $\code{mean\_of\_float}$,
etc.>>
\endgraf
Nesse pedido---obviamente sem noção, algo muito comum em pedidos de chefes
de programadores---aparecem duas ``espécies'' de variáveis diferentes:
as $\Pi$, $\alpha$, e $\tau$ são variáveis de uma espécie;
as $\code{i}$, $\code{i\_of\_int}$,
$\code{count}$, $\code{count\_of\_int}$,
$\code{mean}$, e $\code{mean\_of\_float}$
de outra.
Chamamos $\Pi$, $\alpha$ e $\tau$ \dterm{metavariáveis},
pois elas pertencem na metalinguagem,
e não na linguagem-objeto,
que nesse exemplo é a linguagem de programação C.
Observe que a metavariável $\Pi$ denota programas escritas na linguagem-objeto (C)
a metavariável $\alpha$ denota variáveis de C,
e a metavariável $\tau$ denota tipos da C.
%%}}}

\endsection
%%}}}

%%{{{ Abbreviations and syntactic sugar 
\section Abreviações e açúcar sintáctico.

%%{{{ x: ArEx_outer_parentheses_missing 
\exercise.
\label{ArEx_outer_parentheses_missing}%
Tente gerar a expressão
$$
(1 + 5) \ntimes 2
$$
usando a~\ref{ArEx_grammar_2}.

\solution
Não tem como!

\endexercise
%%}}}

%%{{{ Abbreviations 
\note Abreviações.
\tdefined{abreviação}%
Seguindo nossa~\ref{ArEx_grammar_2}, cada vez que escrevemos um operador binário
começamos e terminamos com \sq{$($} e \sq{$)$} respectivamente.
Logo, ``$1 + 2$'' nem é uma expressão gerada por essa gramática!
Mas como é tedioso botar as parenteses mais externas, temos a convenção
de omiti-las.
Logo, consideramos a ``$1 + 2$'' como uma \dterm{abreviação} da expressão aritmética ``$(1 + 2)$''.
Então qual é o primeiro caráter da $1 + 2$?  É sim o \sq{$($},
pois consideramos o $1+2$ apenas como um nome que usamos na
metalinguagem para denotar a expressão aritmética $(1+2)$,
que pertence na linguagem-objeto.
%%}}}

%%{{{ beware: abbr_not_always_shorter 
\beware.
\label{abbr_not_always_shorter}%
Não se iluda com a palavra ``abreviação'' que usamos aqui:
uma expressão pode ser mais curta do que uma das suas abreviações!
Nosso motivo não é preguiça de escrever expressões mais longas,
mas sim ajudar nossos olhos humanos a parsear.
%%}}}

%%{{{ Syntactic sugar 
\note Açúcar sintáctico.
\tdefined{açúcar sintáctico}%
Querendo enriquecer uma linguagem com um novo conceito, uma nova operação,
etc., parece que precisamos aumentar sua sintaxe para adicionar certos
símbolos e formas para corresponder nessas novas idéias.
Mas isso não é sempre necessário.
Por exemplo, suponha que trabalhamos com a linguagem da~\ref{ArEx_grammar_3},
e queremos usá-la com sua interpretação canônica, onde suas expressões aritméticas
geradas denotam realmente as operações que conhecemos desde pequenos.
Agora, queremos adicionar uma operação unária $S$, escrita na forma prefixa,
onde a idéia é que $Sn$ denota o sucessor de $n$ (o próximo inteiro).
Nesse caso, em vez de realmente alterar a sintaxe da nossa linguagem,
definimos como \dterm{açúcar sintáctico} o uso de $S$ tal que, para qualquer
expressão aritmética $\alpha$, o $S\alpha$ denota a expressão $(\alpha + 1)$.
Por exemplo, $S4$ é apenas uma abreviação para o $(4 + 1)$,
e $SS4$ só pode denotar o $((4 + 1) + 1)$.%
\footnote{Percebeu que esse $\alpha$ aqui é uma metavariável?}
Açúcar sintáctico é muito usado em linguagens de programação,
para adular os programadores (que ganham assim um mecanismo
``doce'' para usar nos seus programas) sem mexer e complicar
a linguagem de verdade.
%%}}}

%%{{{ x: for_while_sugar 
\exercise.
\label{for_while_sugar}%
Mostre como um $\code{while}$ loop pode ser implementado como
açúcar sintáctico numa linguagem que tem $\code{for}$ loops
mas não $\code{while}$ loops,
e vice versa.

\endexercise
%%}}}

%%{{{ x: recursion_loop_sugar 
\exercise.
\label{recursion_loop_sugar}%
Mostre como um $\code{for}$ loop no estilo da linguagem C
pode ser implementado sem usar nenhum dos loops disponíveis
em C (for, while, do-while).

\hint
Recursão.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Problems 
\problems.

%%{{{ decimal_numerals_BNF_problem
\problem.
\label{decimal_numerals_BNF_problem}%
Usando BNF, defina uma gramática para a linguagem de todos os
numerais que representam os naturais no sistema decimal.
Embuta-la na gramática das expressões aritméticas
para eliminar os ``$\dotsb$''.

\endproblem
%%}}}

%%{{{ remove_dots_from_ArEx_grammar 
\problem.
\label{remove_dots_from_ArEx_grammar}%
Com base a~\ref{ArEx_grammar_3} defina uma gramática que gera a mesma linguagem,
sem usar ``$\dotsb$''.

\hint
Já resolveu o~\ref{decimal_numerals_BNF_problem}?

\endproblem
%%}}}

%%{{{ ArEx_fact_grammar 
\problem.
\label{ArEx_with_factorial}%
Aumente tua gramática do~\ref{remove_dots_from_ArEx_grammar} para
gerar expressões aritméticas que usam o operador unitário (e postfixo)
do factorial, que denotamos com $!$, escrevendo por exemplo
$8!$ para o factorial de $8$.
Note que não usamos parenteses para aplicar o factorial:
$$
((2 + 3!)! \ntimes 0!!)
$$

\endproblem
%%}}}

%%{{{ ArEx_fact_vars_grammar 
\problem.
\label{ArEx_fact_vars_grammar}%
Aumenta tua gramática do~\ref{ArEx_with_factorial} para
gerar expressões aritméticas que usam as variáveis
$$
x,y,z,
x',y',z',
x'',y'',z'',
x''',y''',z''',
\dotsc
$$

\endproblem
%%}}}

%%{{{ Polish_notation 
\problem Notação polonesa.
\label{Polish_notation}%
\tdefined{Polonesa}[notação]%
\iiseealso{Polonesa!notação}{Łukasiewicz}%
{\Lukasiewicz[notação]}%
Demonstre que não podemos simplesmente apagar as parenteses
da nossa gramática de $\bnf{ArEx}$ sem perder uma propriedade
importantíssima da nossa linguagem (qual?).
Experimente com a gramática
$$
\align
\bnf{PolArEx}  &\bnfeq \bnf{Num} \bnfor \bnf{OpEx} \tag{0}\\
\bnf{Num}      &\bnfeq 0 \bnfor 1 \bnfor 2 \bnfor 3 \bnfor \dotsb \tag{1}\\
\bnf{OpEx}     &\bnfeq \bnf{BinOp} \bnf{PolArEx} \bnf{PolArEx}\tag{2}\\
\bnf{BinOp}    &\bnfeq + \bnfor - \bnfor \ntimes \bnfor \div\tag{3}
\endalign
$$
Escreva uns dos seus termos.
Supondo que cada símbolo de $\bnf{Num}$ é apenas um símbolo
(por exemplo o \sq{$15$} é um símbolo atômico e não algo composto
dos \sq{$1$} e \sq{$5$}),
observe que com essa notação (chamada \dterm{notação Polonesa} ou
\dterm{notação Łukasiewicz}) não precisamos de parenteses!
Como escreverias nessa linguagem as expressões correspondentes às:
$$
1 + 2;
\qquad
3\ntimes(2 + 4) + 6;
\qquad
2 \ntimes 3 + 3 \ntimes (7 + 8\ntimes 2)\,?
$$

\endproblem
%%}}}

%%{{{ g: NatList_grammar 
\grammar.
\label{NatList_grammar}%
$$
\align
\bnf{L} &\bnfeq [\,] \bnfor (\bnf{Nat} :: \bnf{L})\\
\intertext{onde $\bnf{Nat}$ é o}
\bnf{Nat} &\bnfeq 0 \bnfor S\bnf{Nat}
\endalign
$$
da~\ref{Nat_grammar}.
%%}}}

%%{{{ NatList_grammar_problem 
\problem.
\label{NatList_grammar_problem}%
Escreva umas expressões geradas por a~\ref{NatList_grammar} e ache um possível
uso dessa gramática: o que podemos representar com essa linguagem?

\endproblem
%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[Cap.~4]{alicebook}.
\cite[Cap.~2]{curryfoundations}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: The language of propositional logic 
\chapter A linguagem de lógica proposicional.

%%{{{ Propositions 
\section Proposições.

\note.
Considere as seguinte proposições:
\beginol
\li Se $x < y$ e $y < z$ então $z < x$.
\li O $\sqrt 2$ é irracional.
\li O $3$ é um múltiplo de $10$.
\li O $5$ é um divisor dos $25$ e $26$.
\li O $n$ é menor de $8$ ou maior de $4$.
\endol

\TODO Complete the section.

\endsection
%%}}}

%%{{{ Its syntax 
\section Sua sintaxe.

\note Dados.
Um conjunto de símbolos
$$
\zolvars = \set{ \lsym p_0, \lsym p_1, \lsym p_2, \dotsc }
$$
chamados \dterm{variáveis proposicionais}.

\TODO
Começar com duas definições erradas:
uma sem parens outra com conectivos apenas entre atômicas.

\blah.
Finalmente chegamos na definição correta do que é uma fórmula:

%%{{{ df: propositional_formula 
\definition Fórmula.
\label{propositional_formula}%
\tdefined{fórmula}[proposicional]
\beginul
\li Se $p$ é uma variável proposicional, então $p$ é uma fórmula.
\li Se $F$ é uma fórmula, então $\lnot F$ é uma fórmula.
\li Se $F,G$ são fórmulas, então:
\item{--} $(F \limplies G)$ é uma fórmula;
\item{--} $(F \lor G)$ é uma fórmula;
\item{--} $(F \land G)$ é uma fórmula.
\endul
Nada mais é uma fórmula.
Uma fórmula que consiste em apenas uma variável proposicional é chamada
\dterm{fórmula atômica}.
%%}}}

%%{{{ g: zolang_grammar 
\grammar.
\label{zolang_grammar}%
Escrevemos
$$
\align
F &\bnfeq A \bnfor \lnot F \bnfor (F \limplies F) \bnfor (F \land F) \bnfor (F \lor F)\\
\intertext{onde $A$ denota as fórmulas atômicas da $\zolang$, ou seja as variáveis proposicionais:}
A &\bnfeq \lsym p_0 \bnfor \lsym p_1 \bnfor \lsym p_2 \bnfor \dotsb
\endalign
$$
%%}}}

%%{{{ x: metavar_vs_vats_in_propositional_formula 
\exercise.
No texto da \ref{propositional_formula}, identifique todas as metavariáveis
e todas as variáveis (veja~\refn{Metalanguages}, \refn{metavariables}).

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Its semantics 
\section Sua semântica.

\blah.
Definimos então a \emph{sintaxe} da nossa linguagem.
Mas por enquanto nenhuma das suas expressões válidas
tem significado!
A gente deixou claro o que é uma fórmula, mas não
o que ela \emph{denota}.
Nesse capítulo não vamos definir formalmente alguma
\emph{semântica} para nossa linguagem.
Pelo contrário, usando exemplos e umas explicações
\emph{informais}, eu vou dar uma primeira idéia do que
todas essas fórmulas significam.
O importante é conseguir traduzir uma afirmação escrita
em portugues numa fórmula dessa linguagem, pois assim
ficará mais clara a \emph{estrutúra lógica} que tá
escondida atrás das palavras (e suas ambigüidades)
da linguagem natural.
Depois de bastante trabalho vamos voltar para a questão
de \emph{definir formalmente uma semântica}
para essa linguagem.
Essa tarefa vai nos preocupar nos capítulos
\refn{Mathematical_logic}, \refn{Denotational_semantics},
\refn{Intuitionistic_logic}, \refn{Proof_theory}.
Por enquanto, deixe pra lá!

\TODO Exemplos de fórmulas e seus significados intencionados.

\endsection
%%}}}

%%{{{ Syntactic sugar 
\section Açúcar sintáctico e convenções.

%%{{{ limplied_liff_abbr 
\note Açúcar sintáctico.
\label{limplied_liff_abbr}%
Se $F,G$ são fórmulas, usamos as seguintes abreviações:
$$
\align
(F \liff G)     &\sugareq ((F \limplies G) \land (G \limplies F))\\
(F \limplied G) &\sugareq (G \limplies F)
\endalign
$$
%%}}}

%%{{{ x: second_character_of_limplied_abbr 
\exercise.
\label{second_character_of_limplied_abbr}%
Qual é o segundo caráter da fórmula $(A \limplied B)$?

\hint
Lembre-se que aqui $A,B$ são apenas \emph{metavariáveis}
que denotam algumas fórmulas, sobre quais não sabemos nada mais
fora do fato que são fórmulas (bem formadas).

\solution
O primeiro caráter da fórmula $B$.

\endexercise
%%}}}

%%{{{ Parentheses 
\note Parenteses.
Nos permitimos ``esquecer'' as parenteses mais externas
duma fórmula.
$$
F \limplies G \abbrdefeq (F \limplies G).
$$
%%}}}

%%{{{ Associativities 
\note Associatividades.
Atribuimos às $\land$ e $\lor$ uma associatividade à esquerda,
e a $\limplies$ uma associatividade à direita.
Pela semântica desejada a primeira escolha é arbitraria,
pois a conjunção e a disjunção são operações \emph{associativas}.
Mas a implicação não é.  Nossa escolha então importa!
%%}}}

%%{{{ x: limplies_is_not_associative 
\exercise.
Verifique com um exemplo que realmente, em geral
$$
A \limplies (B \limplies C)
\qqtext{não é equivalente à}
(A \limplies B) \limplies C.
$$

\endexercise
%%}}}

%%{{{ Precedences 
\note Precedências.
Não vamos escolher nenhuma das $\land$, $\lor$ para considerá-la
mais forte, ou seja, \emph{nunca} vamos escrever algo do tipo
$$
F \lor G \land H.
$$
Por outro lado é comum considerar que elas têm precedência contra
a $\limplies$: com as
$$
F \limplies G \land H
\qqtext{e}
F \lor G \limplies H
$$
denotamos as fórmulas
$$
(F \limplies (G \land H))
\qqtext{e}
((F \lor G) \limplies H)
$$
respectivamente.
Mesmo assim, eu vou tentar botar essas parenteses quando considero
que ajudam na leitura da fórmula!
%%}}}

\endsection
%%}}}

%%{{{ Its limitations 
\section Suas limitações.
\label{ZOL_limitations}%

%%{{{ related propositions seem unrelated 
\note.
Considere a afirmação
\quote
Se Igor é brasileiro ele toca violão.
\endquote
Qual é a melhor maneira para traduzir essa afirmação na
nossa linguagem de lógica proposicional?
Estamos procurando então uma \emph{fórmula} da $\zolang$
que poderia representar essa afirmação.
Podemos usar a fórmula seguinte:
$$
(P_0 \limplies P_1)
$$
mas precisamos ainda declarar quais são as proposições
denotadas por as variáveis proposicionais que usamos ($P_0$ e $P_1$).
A escolha é óbvia:
$$
\align
P_0 &:\ \text{Igor é brasileiro}\\
P_1 &:\ \text{Igor toca violão}
\endalign
$$
Note aqui que $P_0$ não poderia ser ``ele toca violão'', pois
na afirmação original esse ``ele'' refere ao Igor, então seria
errado mudar isso para o indefinido e ambiguo ``ele''.
Tudo bem até agora, mas como vamos traduzir as frases:
\beginol
\li Se Thanos é brasileiro ele toca violão.
\li Se Igor é brasileiro ele toca piano.
\li Se Igor é grego ele toca violão.
\endol
Note que cada uma dessas proposições afirma algo muito parecido
com a original, e mesmo assim o melhor jeito que temos
para representar cada uma delas, é:
$$
\align
&(P_2 \limplies P_3)\\
&(P_0 \limplies P_4)\\
&(P_5 \limplies P_1)
\endalign
$$
O problema é que perdemos muita informação nessa traduação,
e olhando apenas para essas fórmulas não conseguimos ver
as conexões que alguem vê lendo as afirmações escritas na
lingua natural acima.
%%}}}

%%{{{ zolang_is_way_too_poor_for_some_propositions 
\note.
Até pior, vamos tentar traduzir a afirmação seguinte:
\quote
Todo brasileiro que fala grego toca piano.
\endquote

\question.
Qual é a melhor forma que você pode traduzir essa proposição para a linguagem
$\zolang$?
\spoiler.
%%}}}

%%{{{ a_wrong_translation_to_zolang 
\note.
Uma tentativa errada seria pensar numa fórmula como
$$
((B \land G) \limplies P)
$$
onde escolhendo as proposições denotadas por nossos
$B$, $G$, e $P$, acabamos falando algo sem sentido:
$$
\align
B &: \text{todo brasileiro}\\
G &: \text{alguém que fala grego}\\
P &: \text{ele toca piano}
\endalign
$$
ou algo parecido com isso.
Agora pare e resolva o exercício seguinte:
%%}}}

%%{{{ x: what_is_wrong_with_this_translation_to_zolang 
\exercise.
Qual o problema com essa tradução?

\endexercise
%%}}}

%%{{{ we accept the best is the worst 
\note.
Infelizmente temos que aceitar que a melhor tradução que conseguimos
é denotar a afirmação inteira por alguma variável proposicional.
Ou seja, pelos olhos da $\zolang$, essa é uma afirmação atômica.
%%}}}

%%{{{ x: universal_proposition_boils_down_to_pvar_in_zolang 
\exercise.
\label{universal_proposition_boils_down_to_pvar_in_zolang}%
Para um exemplo ``mais matemático'', considere a afirmação
\quote
Para todo inteiro $n$, se $n$ é primo e $n>2$, então $n+2$ é primo.
\endquote
Qual é a melhor tradução dela que conseguimos na linguagem $\zolang$?

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Problems 
\problems.

%%{{{ prob: zolang_Polish 
\problem.
\label{zolang_Polish}%
Defina a linguagem $\zolang$ usando notação Polonesa~(\ref{Polish_notation}).

\endproblem
%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[Cap.~1]{velleman};
\cite[Cap.~1]{corilascar1};
\cite[Cap.~1]{bellmachover}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: The language of predicate logic 
\chapter A linguagem de lógica de predicados.

%%{{{ Its syntax 
\section Sua sintaxe.
\label{FOL_syntax}%

%%{{{ the alphabet 
\note O alfabeto.
Pelas limitações da linguagem da lógica proposicional que encontramos
já na~\refn{ZOL_limitations} faz sentido adicionar pelo menos os dois
símbolos que correspondem nos quantificadores ``para todo'' e ``existe'',
alem do resto dos símbolos que já temos:
$$
\lnot, \limplies, \land, \lor, \forall, \exists
$$
\endgraf
O que mais vamos precisar?
Com certeza precisamos uma nova infinidade de símbolos para \emph{variáveis}
$$
\lsym x_0, \lsym x_1, \lsym x_2, \dots
$$
Essas variáveis não tem nada a ver com as variáveis proposicionais,
pois elas não denotam proposições, mas individuais (objetos).
\endgraf
Que mais?
Faria sentido permitir símbolos de \emph{nomes} ou \emph{constantes}
para denotar certos individuais.  Por exemplo, estudando números,
$3$ e $\pi$ são constantes, símbolos que assim que determinar uma
linguagem, eles vão sempre denotar o mesmo objeto.
Observe que não faz sentido falar <<existe $3$ tal que\dots>>
nem <<para todo $3$ \dots>>.  Nossa sintaxe deve proibir essas
abominagens.%
\footnote{Mesmo assim, já aconteceu na turma dum amigo meu
corrigindo provas de cálculo ver a frase ``$\forall 3 > 0$''.
Um aluno que, enquanto colando na prova, provavelmente pensou
que seu colega tinha errado no ``$\forall \epsilon > 0$''.
Depois dele, muitos mais alunos acabaram entregando prova com
``$\forall 3 > 0$''.  Ai ai\dots}
Adicionamos então símbolos para constantes
$$
c,d,e,\dots
$$
\endgraf
Que mais?
Bem, se é para conseguir \emph{formular afirmações sobre individuais},
vamos precisar símbolos para \emph{predicados} que recebem argumentos.
E com eles vamos substituir os símbolos de variáveis proposicionais.
Já discutimos (\refn{ZOL_limitations}) que uma das limitações que
queremos atender com essa nova linguagem é que afirmações bem parecidas
acabam sendo denotadas por fórmulas que não tem nada em comum:
nossa melhor tradução das afirmações ``$8$ é múltiplo de $2$''
e ``$10$ é múltiplo de $3$'' é algo do tipo $\lsym p_0$ para uma e
$\lsym p_1$ para a outra.
Não serve.  Queremos conseguir usar algo do tipo $P(8,2)$ para uma
e $P(10,3)$ para a outra, onde o $P$ \emph{é o mesmo símbolo},
preservando assim a conexão entre as afirmações.
Jogamos fora então todos os símbolos de variáveis proposicionais
para usar símbolos de \emph{predicados}:
$$
P, Q, R, \dots
$$
e bora botar a virgula \sq{$,$} também para separar os argumentos.
\endgraf
Algo mais?
Sim, precisamos de uma última coisa.
Símbolos para denotar \emph{funções}.
Eles nos permitem apontar para algum individual dados outros.
Por exemplo <<a mãe da Bárbara>>; ou $\lsym x_0 + \sin(\pi)$
que seria <<a soma do $\lsym x_0$ com o seno do $\pi$>>, etc.
Aqui a gente usaria símbolos como $\lsym{mother}$, $+$, $\ntimes$,
$\sin$, $\cos$, nos números.
Vamos adicionar então símbolos de \emph{funções}
$$
f, g, h, \dots
$$
e pronto.
Então o alfabéto duma linguagem FOL parece assim:
$$
\def\symsnames##1##2{\tunderbrace{\;\vphantom {g_g} ##1\;} {##2}}
\symsnames {\lnot\ \limplies\ \land\ \lor\ \forall\ \exists\;} {lógica}\ 
\symsnames {(\ )\ ,\;} {puntuação}\ 
\symsnames {\lsym x_0\ \lsym x_1\ \lsym x_2\ \dots\;} {variáveis}\ 
\symsnames {c\ d\ e\ \dots\;} {constantes}\ 
\symsnames {f\ g\ h\ \dots\;} {funções}\ 
\symsnames {P\ Q\ R\ \dots\;} {predicados}.
$$
%%}}}

%%{{{ givens_for_a_FOL 
\note Os dados para uma linguagem de FOL.
Um conjunto infinito de símbolos de variáveis
$$
\folvars  = \set{\lsym x_0, \lsym x_1, \lsym x_2, \lsym x_3, \dotsc}.
$$
Conjuntos de símbolos de constantes, de funções, e de predicados:
$$
\folcons,\quad
\folfuns,\quad
\folpreds.
$$
Vamos separar os símbolos de funções por \dterm{aridade},
ou seja, por a quantidade de argumentos que ele necessita ``consumir''.
Similarmente para os símbolos de predicados, escrevendo assim
$\folfuns_n$ e $\folpreds_n$, para o conjunto de símbolos de funções
e de predicados de aridade $n$ respectivamente.%
%%}}}

%%{{{ remark: nullary functions as constants 
\remark.
Podemos usar funções de aridade $0$ como constantes,
e assim nem precisamos um conjunto especial para esses símbolos.
Mesmo assim, não vamos fazer isso aqui.
Questão de gosto.%
\footnote{Mentira.
Tem uns detalhes inessenciais neste momento sobre essa escolha.
Vamos discutir isso no~\ref{Mathematical_logic}.}
%%}}}

%%{{{ remark: alternative approach with arity metafunction 
\remark.
Alternativamente, podemos deixar os símbolos de aridades
diferentes juntos e exigir uma função $\folarity$ que
atribua a cada deles sua aridade.
Por exemplo, numa FOL que usariamos para cálculo, faria
sentido ter símbolos $\lsym +,\lsym{cos},\lsym{<}$ entre outros, com aridades
$\folarity(\lsym{+}) = 2$, $\folarity(\lsym{cos}) = 1$,
$\folarity(\lsym{<}) = 2$, etc.
As duas abordagens são equivalentes:
$$
\align
f \in \folfuns_n  &\iff f \in \folfuns  \mland \folarity(f) = n\\
P \in \folpreds_n &\iff P \in \folpreds \mland \folarity(P) = n.
\endalign
$$
Vamos discutir mais sobre isso no~\ref{Mathematical_logic}.
%%}}}

%%{{{ eg: FOL_example_number_theory 
\example.
\label{FOL_example_number_theory}%
Para estudar teoria dos números alguém poderia escolher essa linguagem:
$$
\align
\folcons    &= \set{\lsym 0, \lsym 1, \lsym 2, \dots} \\
\folfuns_1  &= \set{{-}} \\
\folfuns_2  &= \set{{+}, {\cdot}, \lsym {gcd}} \\
\folpreds_1 &= \set{\lsym{Prime}, \lsym{Even}, \lsym{Odd}, \lsym{IsZero}} \\
\folpreds_2 &= \set{{=}, {<}, {\leq}, {\divides}}
\endalign
$$
Note que aqui o símbolo \sq{$-$} foi escolhido para ter aridade $1$.
O usuário dessa linguagem vai usá-lo para representar a operação
unária de negação de números, para formas termos como os:
$-1$, $-(1 + x)$, etc.
\endexample
%%}}}

%%{{{ eg: FOL_example_people 
\example.
\label{FOL_example_people}%
Para estudar pessoas e suas relações uma linguagem poderia ser:
$$
\align
\folcons    &= \set{\lsym{Thanos}, \lsym{Ramile}, \lsym{Eva}, \lsym{Sam}, \lsym{Maroui}, \lsym{Jebinos}} \\
\folfuns_1  &= \set{\lsym{mother}, \lsym{father}} \\
\folpreds_1 &= \set{\lsym{Male}, \lsym{Female}, \lsym{Adult}, \lsym{Mother}, \lsym{Father}, \lsym{Brazilian}, \lsym{Greek}} \\
\folpreds_2 &= \set{=, \lsym{Loves}, \lsym{SiblingOf}, \lsym{MotherOf}, \lsym{FatherOf}}
\endalign
$$
Qual a diferença entre os símbolos $\lsym{mother}$ e $\lsym{Mother}$?
Ambos são símbolos de aridade $1$, mas $\lsym{mother}$ é um símbolo de função
e $\lsym{Mother}$ é um símbolo de predicado.
O que isso quis dizer?
Suponha que $p$ é qualquer objeto do meu mundo (vamos pensar em pessoas).
A expressão $\lsym{mother}(p)$ vai acabar denotando um objeto do meu mundo
também.  A intenção do criador dessa linguagem provavelmente foi que
$\lsym{mother}(p)$ denota a mãe de $p$.
Similarmente, $\lsym{mother}(\lsym{mother}(p))$ denota a mãe da mãe
da pessoa $p$.  E por aí vai.
No outro lado, a expressão $\lsym{Mother}(p)$ não denota pessoa, mas
sim uma afirmação \emph{sobre} a pessoa $p$.  Adivinhando novamente
a intenção do criador, a proposição $\lsym{Mother}(p)$ afirma que
a pessoa $p$ \emph{é uma mãe}.
E o símbolo $\lsym{MotherOf}$?
Como ele tem aridade $2$, ele precisa de $2$ objetos, e assim
que recebé-los ele denota uma afirmação (pois é símbolo de \emph{predicado}).
Aqui a idéia é que $\lsym{MotherOf}(p,q)$ denota a afirmação
<<$p$ é a mãe de $q$>>.
\endexample
%%}}}

%%{{{ eg: full_FOL_example 
\example.
Tomamos
$$
\xalignat2
\bigparen{\;\folcons =\;}\quad
\folfuns_0   &= \set{\lsym f^0_0, \lsym f^0_1, \lsym f^0_2, \lsym f^0_3, \dotsc} & \folpreds_0  &= \set{\lsym P^0_0, \lsym P^0_1, \lsym P^0_2, \lsym P^0_3, \dotsc}\\
\folfuns_1   &= \set{\lsym f^1_0, \lsym f^1_1, \lsym f^1_2, \lsym f^1_3, \dotsc} & \folpreds_1  &= \set{\lsym P^1_0, \lsym P^1_1, \lsym P^1_2, \lsym P^1_3, \dotsc}\\
\folfuns_2   &= \set{\lsym f^2_0, \lsym f^2_1, \lsym f^2_2, \lsym f^2_3, \dotsc} & \folpreds_2  &= \set{\lsym P^2_0, \lsym P^2_1, \lsym P^2_2, \lsym P^2_3, \dotsc}\\
             &\eqvdots                                                                   &              &\eqvdots                                                                  
\endxalignat
$$
onde temos denotado a aridade de cada símbolo como um ``exponente''.
\endexample
%%}}}

%%{{{ Equality 
\remark Igualdade.
Note que podemos considerar o símbolo de igualdade \sq{$=$} como símbolo
da lógica, botando junto com os
$$
\lnot, \limplies, \land, \lor, \forall, \exists, =
$$
e nesse caso falamos que temos uma FOL \emph{com igualdade}.
Ou podemos considerar \sq{$=$} como mais um predicado,
cuja existência ou não na linguagem depende no usuário,
e---ainda mais importante---cuja \emph{interpretação}
também depende no usuário.
Nesse primeiro encontro com lógica e fórmulas, vamos considerar
que $=$ é um símbolo de predicado de aridade $2$, cujo significado
é sempre afirmar que seus $2$ argumentos \emph{denotam o mesmo objeto},
e que sempre faz parte do $\folpreds_2$.
Quando a gente voltar para estudar lógica matemática no
\ref{Mathematical_logic}, vamos discutir mais sobre isso.
Por enquanto não importa!
%%}}}

%%{{{ Terms vs. formulae 
\note Terms \vs fórmulas.
Não vamos dar diretamente uma definição de quando uma expressão é uma fórmula.
Em vez disso, vamos primeiro definir o que são os \emph{termos} duma FOL.
A idéia é que o termos representam os individuais (objetos) do nosso universo.
Se estamos estudando pessoas, cada termo vai acabar apontando (denotando)
uma pessoa.  Estudando cálculo, os termos denotariam números reais, etc.
Um termo então é um caso especifico de fórmula?
Não!  Temos um ``type error'' se pensar assim!
Os termos denotam objetos.
As fórmulas denotam proposições (afirmações) (possivelmente \emph{sobre}
objetos).
Talvez uns exemplos ajudam.
%%}}}

%%{{{ eg: terms_vs_formulas_example 
\example.
Estudando cálculo, as expressões seguintes são termos:
$$
\xalignat7
 &0
&&\pi
&&x
&&-1
&&1/2
&&\sin(\pi/x)
&&x\sin(\pi/3) + y\cos(\pi^2)
\endxalignat
$$
Por outro lado, as expressões seguintes são fórmulas:
$$
\xalignat4
&
\gathered
{0 < 1} \land {x < 0} \\
{x^2 = 0} \limplies {x = 0}
\endgathered
&&
\gathered
\lnot\exists y (y^2 > 4) \\
x^2 + y^2 = 1
\endgathered
&&
\gathered
\forall x (0 \leq x^2 0) \\
\exists x \forall y (x + y = 0)
\endgathered
&&
\gathered
\forall y \exists y (x + y = 0) \\
\forall z \paren{{z = 0} \lor \forall w \lnot (w + z = w)}
\endgathered
\endxalignat
$$
Uns dos termos chamamos de atômicos e similarmente umas das fórmulas
chamamos de atômicas.  Tente agora (antes de ver a definição) adivinhar
quais desses termos são atômicos e quais dessas fórmulas são atômicas.
\endexample
%%}}}

%%{{{ df: FOL_term 
\definition Termo.
\label{FOL_term}%
\tdefined{FOL}[termo]%
\beginul
\li Se $x \in \folvars$ então $x$ é um termo.
\li Se $c \in \folcons$ então $c$ é um termo.
\li Se $f \in \folfuns_n$ e $t_1,\dotsc,t_n$ são termos, então $f(t_1,\dotsc,t_n)$ é um termo.
\endul
Nada mais é um termo.
Denotamos o conjunto de termos com $\folterms$.
Resumindo esquematicamente a definição, temos:
$$
\align
x \in \folvars &\implies x \in \folterms\\
c \in \folcons &\implies c \in \folterms\\
\rightbrace{
\aligned
f &\in \folfuns_n\\
t_1,\dotsc,t_n &\in \folterms
\endaligned
}
&\implies f(t_1,\dotsc,t_n) \in \folterms\\
\endalign
$$
%%}}}

%%{{{ df: FOL_atomic_formula 
\definition Fórmula atômica.
\label{FOL_atomic_formula}%
\tdefined{FOL}[fórmula atômica]%
\beginul
\li Se $P \in \folpreds_n$ e $t_1,\dotsc,t_n$ são termos,
então $P(t_1,\dotsc,t_n)$ é uma \dterm{fórmula atômica}.
\endul
%%}}}

%%{{{ df: FOL_formula 
\definition Fórmula.
\label{FOL_formula}%
\tdefined{FOL}[fôrmula]%
\beginul
\li Se $A$ é uma fórmula atômica, então $A$ é uma fórmula.
\li Se $F$ é uma fórmula, então $\lnot F$ é uma fórmula.
\li Se $F,G$ são fórmulas, então:
\item{-} $(F \limplies G)$ é uma fórmula;
\item{-} $(F \lor G)$ é uma fórmula;
\item{-} $(F \land G)$ é uma fórmula.
\li Se $F$ é uma fórmula e $x$ é uma variável, então:
\item{-} $\forall x F$ é uma fórmula;
\item{-} $\exists x F$ é uma fórmula.
\endul
%%}}}

%%{{{ Practical abuse of BNF for FOL 
\grammar FOL.
\label{FOL_grammar}%
Seguindo uma práctica comum, escrevemos apenas
$$
\align
F &\bnfeq
\mathit{A}
\bnfor \lnot F
\bnfor (F \limplies F)
\bnfor (F \land F)
\bnfor (F \lor F)
\bnfor \forall v F
\bnfor \exists v F
\endalign
$$
onde $A$ denota fórmulas atômicas e $v$ denota qualquer variável da nossa FOL.
%%}}}

%%{{{ x: BNF_for_FOL 
\exercise.
\label{BNF_for_FOL}%
Supondo que $\bnf{At}$ pode ser substituito por qualquer fórmula atômica duma FOL (e por nada mais),
defina umas gramáticas em BNF para gerar a linguagem das suas fórmulas bem formadas.

\solution
Aqui uma solução:
$$
\align
\bnf{F}     &\bnfeq \bnf{At} \bnfor \lnot \bnf{F} \bnfor (\bnf{F} \bnf{Bin} \bnf{F}) \bnfor \bnf{Q}\bnf{Var}\bnf{F}\\
\bnf{Bin}   &\bnfeq \lor \bnfor \land \bnfor \limplies\\
\bnf{Q}     &\bnfeq \forall \bnfor \exists\\
\bnf{Var}   &\bnfeq x_0 \bnfor x_1 \bnfor x_2 \bnfor \dotsb\\
\intertext{Como já encontramos, um fácil jeito para evitar os ``$\dotsb$'' seria usar:}
\bnf{Var}   &\bnfeq x \bnfor \bnf{Var}'
\endalign
$$

\endexercise
%%}}}

%%{{{ Q: What do we need in order to have a FOL language? 
\question.
O que precisamos especificar para ter uma linguagem FOL?
%%}}}

%%{{{ A: pick symbols and their arities 
\blah Resposta.
Olhando cuidadosamente para a sua sintaxe, é claro que precisamos
deixar claro quais são os símbolos de variáveis, constantes,
funções, e predicados, que vamos usar, e suas aridades para
os símbolos de funções e predicados.
%%}}}

\endsection
%%}}}

%%{{{ Its semantics 
\section Sua semântica.

%%{{{ blah: don't worry about it yet 
\blah.
Tanto como na lógica proposicional, não vamos nos preocupar
neste momento para definir formalmente uma semântica para
as linguagens de lógica da primeira ordem.
Para conseguir isso, precisamos ganhar muita experiência
com conjuntos (\ref{Sets}), funções (\ref{Functions}),
e relações (\ref{Relations}), e uma certa
\emph{maturidade matemática} que vai chegando durante
nossos estudos.
Finalmente no~\ref{Mathematical_logic} vamos voltar
nessa questão.
Mesmo assim, precisamos dar pelo menos uma primeira idéia
da semântica da FOL, mesmo sem rigidez.
%%}}}

%%{{{ Interpretations 
\note Interpretações.
\label{Interpretations}%
\tdefined{interpretação}%
Dada uma linguagem de FOL, para suas fórmulas ganharem
significado, precisamos deixar claro:
\beginul
\li Qual é o \dterm{universo}, ou seja, todos os objetos
onde as variáveis (e constantes) tomam seus valores.
Todos os nossos termos vão acabar denotando objetos
desse universo.
\li Para cada \emph{símbolo de função}, qual é a \emph{função mesmo}
que ele representa no universo escolhido.
\li Para cada \emph{símbolo de predicado}, qual é a \emph{relação mesmo}
que ele representa no universo escolhido.
\endul
Assim que der tudo isso, digamos que temos uma \dterm{interpretação}
da linguagem.
%%}}}

%%{{{ Definition of truth 
\note Definição de verdade.
Mas o que significa que uma fórmula é verdadeira?
Tendo uma interpretação (\refn{Interpretations})%
---ou seja, assim que especificar tudo isso---se numa fórmula
não aparecem variáveis livres, podemos investigar já sua veracidade,
testando a correspondente afirmação na interpretação.
Se aparecem variáveis livres, tendo uma atribuição de objetos
nelas também podemos decidir sua veracidade.
Essa curta explicação informal deve servir por enquanto,
junta com os exemplos abaixo.
No~\ref{Mathematical_logic} vamos ver tudo formalmente e com carinho.
Paciência.
%%}}}

%%{{{ eg: interpretting_formulas_example; mother_of_all 
\example.
\label{interpretting_formulas_exercise}%
\label{mother_of_all}%
Considere as fórmulas
\beginol
\li $\forall x (P(x) \limplies Q(x))$;
\li $\exists x \forall y R(x,y)$.
\li $\forall y \exists x R(x,y)$.
\endol
Escolhendo que o universo é feito por todas as pessoas
(tanto vivas quanto mortas) e que $P$ e $Q$ são os predicados de
``ser pai'' e ``ser homem'', a primeira fórmula vira-se verdade:
realmente cada pai é um homem.  Escolhendo interpretar o $R(u,v)$
como ``$u$ é a mãe de $v$'', a segunda frase se-traduza como
``existe pessoa que é mãe de todos'' (que é falso),
mas a terceira diz ``toda pessoa tem mãe'' (que é verdadeiro).
\endexample
%%}}}

%%{{{ x: interpretting_formulas_exercise
\exercise.
\label{interpretting_formulas_exercise}%
Para cada uma das fórmulas abaixo, quando possível,
ache uma interpretação que a satisfaz e uma que não.
\beginol
\li $\forall x \forall y \paren{R(x,y) \land \lnot R(y,x)}$;
\li $\forall x \forall z \exists y \paren{R(x,y) \land R(y,z)}$;
\li $\exists x \exists y \exists z Q(f(x,y),z)$.
\endol

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Translations to and from FOL 
\section Traduzindo de e para FOL.
\label{FOL_translations}%

\TODO Exemplos de matemática, pessoas, etc.

\endsection
%%}}}

%%{{{ Syntactic sugar and conventions 
\section Açúcar sintáctico e convenções.

%%{{{ Non-limitations 
\note Não-limitações.
Numa primeira olhada a linguagem pode parecer limitada
para expressar umas afirmações que encontramos o tempo
todo em matemática:
$$
\gathered
\text{``existe único $x$ tal que \dots''} \\
\text{``para todo número primo $p$, \dots''} \\
\text{``existe $x\in A$ tal que \dots''} \\
\text{``para todo $x\in A$, \dots''} \\
\text{``existe único $x\in A$ tal que \dots''}
\endgathered
$$
etc.
Podemos expressar essas afirmações numa linguagem de FOL?
Se não, vamos precisar aumentar nossa linguagem
com novos quantificadores, mas felizmente isso
não é necessário.  Podemos realmente escrever
todas essas afirmações e logo basta só descrever
como, e definir mais \emph{acúcar sintáctico}.
Trabalhe nos exercícios seguintes para ver como.
%%}}}

%%{{{ x: forall_x_in_A_sugar 
\exercise.
\label{forall_x_in_A_sugar}%
Ache uma fórmula de linguagem de FOL equivalente à
$\lforall {x \in A} {\phi(x)}$, onde $\phi(x)$ é
uma fórmula que envolve o $x$.  Podes supor que
tua linguagem tem o símbolo \sq{$\in$} nos seus predicados.

\hint
Só para ajudar, suponha que o universo é feito
por todas as pessoas da terra, e que $A$ é o conjunto
de todos os alunos.
E só para ficar mais concreto ainda, suponha
que a fórmula $\phi(x)$ quis dizer que
<<$x$ é uma pessoa legal>>.
O desafio é conseguir escrever a afirmação
$$
\text{<<todo aluno é legal>>}
$$
O problema é que minha linguagem me permite dizer
$$
\forall x {\lthole}
$$
ou seja
$$
\text{<<toda pessoa, \dots>>}
\text{<<para toda pessoa $x$, $\psi(x)$>>}
$$
etc., mas não <<para todo aluno $x$, $\psi(x)$>>.
O que você precisa afirmar \emph{para toda pessoa $x$} mesmo,
tal que a afirmação inteira vai acabar sendo equivalente a
$$
\text{<<todo aluno é legal>>}?
$$

\hint
Tu tens que afirmar algo para toda pessoa $x$.
Em vez de afirmar que $x$ é legal, afirme uma implicação:
afirme que
$$
\text{se $x$ {\lthole}, então {\lthole}}.
$$

\solution
$$
\lforall {x \in A} {\phi(x)}
\iff
\forall x \paren{ x\in A \limplies \phi(x) }
$$

\endexercise
%%}}}

%%{{{ x: exists_x_in_A_sugar 
\exercise.
\label{exists_x_in_A_sugar}%
Similarmente para a $\lexists {x \in A} {\phi(x)}$.

\hint
A idéia é parecida com o~\ref{forall_x_in_A_sugar},
mas cuidado, pois é fácil errar!

\hint
Se eu quiser afirmar que existe \emph{um aluno} $x$ tal que $\phi(x)$,
mas eu posso apenas afirmar que existe \emph{uma pessoa} $x$ tal que $\psi(x)$, como eu posso escolher esse $\psi(x)$ para conseguir dizer o que eu quero?
Observe que afirmando que existe aluno $x$ tal que $\phi(x)$,
é a mesma coisa de afirmar que existe pessoa $x$ tal que $\phi(x)$ e\dots
mais uma coisa!
Qual?

\solution
$$
\lexists {x \in A} {\phi(x)}
\iff
\lexists x \paren{ x\in A \land \phi(x) }
$$

\endexercise
%%}}}

%%{{{ x: unique_x_sugar 
\exercise.
\label{unique_x_sugar}%
Similarmente para
$\sunique x \phi(x)$ e uma da $\lunique {x \in A} {\phi(x)}$.
Lemos o ``$\unique{}$'' como ``existe único''.

\endexercise
%%}}}

%%{{{ x: is_this_sugar_good_for_unique_1 
\exercise.
\label{is_this_sugar_good_for_unique_1}%
$
\sunique x \phi(x)
\askiff
\exists u \forall y \paren{ \phi(y) \liff y = u }
$

\endexercise
%%}}}

%%{{{ x: is_this_sugar_good_for_unique_2 
\exercise.
\label{is_this_sugar_good_for_unique_2}%
$
\sunique x \phi(x)
\askiff
\exists x \bigparen{\phi(x)
\land
\forall y \paren{ \phi(y) \limplies \phi(x)}}
$

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Back to the metalanguage 
\section De volta para a metalinguagem.

%%{{{ x: square_of_odd_is_odd 
\exercise.
\label{square_of_odd_is_odd}%
Considere a afirmação:
\quote
<<Todos os quadrados de ímpares são ímpares.>>
\endquote
Usando a notação encontrada nesse capítulo, escreva a afirmação em tal forma
que sua estrutura lógica é claramente exposta.

\hint
$\lforall {n \in \ints} {\dots?\dots}$.

\hint
$\lforall {n \in \ints} {\text{$n$ ímpar} \askiff \text{$n^2$ ímpar}}$.

\solution
$\lforall {n \in \ints} {\text{$n$ ímpar} \implies \text{$n^2$ ímpar}}$.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Its limitations 
\section Suas limitações.

\blah.
Para a maioria das afirmações que encontramos em matemática normalmente
a FOL é suficiente.  Mesmo assim, ela tem suas limitações tanto
para expressar certas proposições matemáticas, quanto para certas afirmações
que encontramos com freqüência na nossa vida.
Mas vou deixar essas preocupações para os problemas.

\endsection
%%}}}

%%{{{ Problems 
\problems.

%%{{{ prob: folang_Polish 
\problem.
\label{folang_Polish}%
Defina a linguagem FOL usando notação Polonesa~(\ref{Polish_notation}).

\endproblem
%%}}}

%%{{{ limitation_of_fol_in_math 
\problem.
\label{limitation_of_fol_in_math}%
Ache uma afirmação matemática que FOL não é capaz para traduzir bem.

\endproblem
%%}}}

%%{{{ modal_temporal_logics 
\problem.
\label{limitation_of_fol_not_in_math}%
Pense em outras afirmações que aparecem freqüentemente na nossa fala
que FOL seria pobre para traduzir bem.

\endproblem
%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[Cap.~2]{velleman};
\cite[Cap.~3]{corilascar1};
\cite[Cap.~2--3]{bellmachover}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Proofs 
\chapter Demonstrações.
\label{Proofs}%

%%{{{ intro 
\chapintro
Em matemática, para cada afirmação precisamos saber:
\beginol
\li como matá-la;
\li como usá-la.
\endol
``Matar'' aqui, quis dizer \emph{provar}.
Vamos pegar emprestada muita da terminologia de \emph{jogos}
e de \emph{programação} para nos ajudar comunicar certas idéias.
Para realmente aprender como provar teoremas,
existe apenas um caminho: \emph{provando}.
E vamos fazer isso no resto do texto mesmo.
Nosso objectivo aqui \emph{não é} estudar profundamente estratégias
de prova num contexto abstrato, mas apenas introduzir umas
idéias e estabelecer uma terminologia e metodologia para falar
sobre provas no resto do texto.
%%}}}

%%{{{ Proofs as games 
\section Provas como jogos.

%%{{{ lorenzen dialogue games 
\note.
Existem várias maneiras de usar jogos para estudar provas.
Num dos mais comuns, é selecionada uma afirmação e dois jogadores
estão jogando um \emph{contra} o outro:
um acredita na afirmação e está tentando prová-la;
o outro não, e está tentando refutá-la.
Muitas variações disso existem e correspondem principalmente
em alterações da ``lógica por trás''.
%%}}}

%%{{{ one-player game 
\note.
Mas aqui vamos usar terminologia de jogos numa maneira
diferente, onde o jogo é jogado só por você mesmo,
como um jogo de Solitaire ou de Minesweeper.%
\footnote{%
Podes visualizar esses jogos como jogos de 2 jogadores
onde teu oponente só joga uma vez (e joga primeiro) escolhendo
a ordem das cartas no caso de Solitaire ou onde botar as minas no
caso de Minesweeper.  Após disso, quem joga é apenas você.
}
Tu estás jogando com um ou mais álvos, onde cada alvo é uma afirmação
matemática que tu estás querendo matá-la (provar).
Para conseguir isso, tu tens na tua disposição:
certas \emph{armas}: os seus dados (hipoteses),
definições, teoremas, etc., e finalmente \emph{a própria lógica},
que é representada aqui por \emph{as próprias regras do jogo}.
O jogo é feito numa maneira que se não roubar
(ou seja, se seguir as regras),
então tua prova realmente estabelece a veracidade dos teus álvos.
%%}}}

\TODO REPL analogy.

%%{{{ where's the compiler? 
\note Cadê o compilador?.
Um dos maiores problemas em nossos primeiros contatos com
matemática \emph{de verdade}, é ``roubar sem querer''.
Em programação, o compilador assume bastante um papel de
regulador que não nos permite roubar.
O desafio em matemática é que, escrevendo uma prova estamos assumindo
o papel tanto do programador quanto do compilador.
No início isso pode aparecer uma carga muito pesada,
mas praticando acaba sendo algo natural.
No mesmo sentido, o programador iniciante ``briga'' com o compilador
o tempo todo, e com mais experiência ele assume (conscientemente ou não)
cada vez mais um papel de compilador mental também, e acaba brigando
cada vez menos com o compilador da sua máquina.
%%}}}

%%{{{ the game and its board 
\note O jogo e seu tabuleiro.
Podemos pensar que o jogo acontece em duas partes.
A primeira parte é a \proofstyle{\proofname}.
É aqui que o jogador (você) joga, onde cada movimento
é escrever uma frase mais nessa parte.
A segunda parte é a tabela de Dados/Alvos.
O enunciado do teorema que queres provar cria o contexto da prova,
ou seja, ele está deixando claro quais são os \emph{dados},
e qual (ou quais) os \emph{alvos}.
Com cada movimento (frase escrita na parte \proofstyle{\proofname}),
a tabela dos Dados/Alvos muda para refletir a situação atual
do jogo.  Novos dados podem ser adicionados, uns álvos podem
ser matados, outros nascidos.  O jogo termina quando não tem
mais nenhum alvo vivo.
\endgraf
As partes do jogo e seu tabuleiro parecem assim então:
\endgraf\medskip\noindent
\hbox to \hsize{
\vtop{
\halign to .3\hsize{##\hfil\cr
\proofstyle{\proofname.}\cr
\cr
\cr
\cr
}
}
\vtop{
\gg
\givens
\git {}
\git {}
\gim {\hskip3cm}
\goals
\gim {\hskip3cm}
\endgg
}
}
%%}}}

%%{{{ eg: x odd => x^2 odd 
\example.
Nesse exemplo encontramos uma prova de um teorema sobre inteiros.
Neste momento apenas siga essa prova, movimento-por-movimento,
para entender a idéia desse jogo e nada mais.
A afirmação que queremos demonstrar é a seguinte:
\quote
<<Todos os quadrados de ímpares, são ímpares.>>
\endquote
Já que tu trabalhou no~\ref{square_of_odd_is_odd} (né?), entendes bem a forma do teu alvo:
$$
\lforall {n \in \ints} {\text{$n$ ímpar} \implies \text{$n^2$ ímpar}}
$$
Bora começar jogar então!

\endgraf\bigskip\noindent
\hbox to \hsize{
\vtop{
\halign to .333\hsize{#\hfil\cr
\proofstyle{\proofname.}\cr
}
}
\hfill
\vtop{
\gg
\givens
\gim {\phantom{\lexists {k\in\ints} {x = 2k+1}}}
\goals
\gim {\lforall {n \in \ints} {\text{$n$ ímpar} \implies \text{$n^2$ ímpar}}}
\endgg
}
}
\endgraf\bigskip\noindent
\hbox to \hsize{
\vtop{
\halign to .333\hsize{#\hfil\cr
\proofstyle{\proofname.}\cr
\alert{Seja $x$ inteiro.}\cr
}
}
\hfill
\vtop{
\gg
\givens
\gim {\alert{x \in \ints}}
\gim {\phantom{\lexists {k\in\ints} {x = 2k+1}}}
\goals
\gim {\coloredcancel{red}{\lforall {n \in \ints} {\text{$n$ ímpar} \implies \text{$n^2$ ímpar}}}}
\gim {\alert{\text{$x$ ímpar} \implies \text{$x^2$ ímpar}}}
\gim {\hphantom{\lforall {n \in \ints} {\text{$n$ ímpar} \implies \text{$n^2$ ímpar}}}}
\endgg
}
}
\endgraf\bigskip\noindent
\hbox to \hsize{
\vtop{
\halign to .333\hsize{#\hfil\cr
\proofstyle{\proofname.}\cr
Seja $x$ inteiro.\cr
\alert{Suponha $x$ ímpar.}\cr
}
}
\hfill
\vtop{
\gg
\givens
\gim {x \in \ints}
\git {\alert{$x$ ímpar}}
\gim {\phantom{\lexists {k\in\ints} {x = 2k+1}}}
\goals
\gim {\faded{\lforall {n \in \ints} {\text{$n$ ímpar} \implies \text{$n^2$ ímpar}}}}
\gim {\coloredcancel{red}{\text{$x$ ímpar} \implies \text{$x^2$ ímpar}}}
\git {\alert{$x^2$ ímpar}}
\endgg
}
}
\endgraf\bigskip\noindent
\hbox to \hsize{
\vtop{
\halign to .333\hsize{#\hfil\cr
\proofstyle{\proofname.}\cr
Seja $x$ inteiro.\cr
Suponha $x$ ímpar.\cr
\alert{Seja $k\in\ints$ tal que $x = 2k+1$.}\cr
}
}
\hfill
\vtop{
\gg
\givens
\gim {x \in \ints}
\git {$x$ ímpar}
\gim {\lexists {k\in\ints} {x = 2k+1}}
\gim {\alert{k \in \ints}}
\gim {\alert{x = 2k + 1}}
\goals
\gim {\faded{\lforall {n \in \ints} {\text{$n$ ímpar} \implies \text{$n^2$ ímpar}}}}
\gim {\faded{\text{$x$ ímpar} \implies \text{$x^2$ ímpar}}}
\git {$x^2$ ímpar}
\endgg
}
}
\endgraf\bigskip\noindent
\hbox to \hsize{
\vtop{
\halign to .333\hsize{#\hfil\cr
\proofstyle{\proofname.}\cr
Seja $x$ inteiro.\cr
Suponha $x$ ímpar.\cr
Seja $k\in\ints$ tal que $x = 2k+1$.\cr
\alert{Calculamos:}\cr
\phantom{a}\cr
\alert{\quad$\aligned x^2 &= (2k+1)^2 = 4k^2 + 4k + 1 \\&= 2(2k^2+2k) + 1\endaligned$}\cr
\phantom{a}\cr
}
}
\hfill
\vtop{
\gg
\givens
\gim {x \in \ints}
\git {$x$ ímpar}
\gim {\lexists {k\in\ints} {x = 2k+1}}
\gim {k \in \ints}
\gim {x = 2k + 1}
\gim {\alert{x^2 = 2(2k^2 + 2k) + 1}}
\goals
\gim {\faded{\lforall {n \in \ints} {\text{$n$ ímpar} \implies \text{$n^2$ ímpar}}}}
\gim {\faded{\text{$x$ ímpar} \implies \text{$x^2$ ímpar}}}
\git {$x^2$ ímpar}
\gim {\lexists {a\in\ints} {x^2 = 2a + 1}}
\endgg
}
}
\endgraf\bigskip\noindent
\hbox to \hsize{
\vtop{
\halign to .333\hsize{#\hfil\cr
\proofstyle{\proofname.}\cr
Seja $x$ inteiro.\cr
Suponha $x$ ímpar.\cr
Seja $k\in\ints$ tal que $x = 2k+1$.\cr
Calculamos:\cr
\phantom{a}\cr
\quad$\aligned x^2 &= (2k+1)^2 = 4k^2 + 4k + 1 \\&= 2(2k^2+2k) + 1\endaligned$\cr
\phantom{a}\cr
\alert{Como $(2k^2+2k)\in\ints$, temos que $x^2$ é ímpar.}\cr
}
}
\hfill
\vtop{
\gg
\givens
\gim {x \in \ints}
\git {$x$ ímpar}
\gim {\lexists {k\in\ints} {x = 2k+1}}
\gim {k \in \ints}
\gim {x = 2k + 1}
\gim {x^2 = 2(2k^2 + 2k) + 1}
\goals
\gim {{\faded{\lforall {n \in \ints} {\text{$n$ ímpar} \implies \text{$n^2$ ímpar}}}}}
\gim {{\faded{\text{$x$ ímpar} \implies \text{$x^2$ ímpar}}}}
\git {{\faded{$x^2$ ímpar}}}
\gim {\coloredcancel{red}{\lexists {a\in\ints} {x^2 = 2a + 1}}}
\endgg
}
}
\endgraf\bigskip\noindent
Matamos todos os alvos, então podemos concluir que o que queriamos
provar, foi provado (ou seja: é um teorema mesmo).
\endexample
%%}}}

%%{{{ remark: the text above is terrible 
\remark.
O texto que a prova acabou sendo é \emph{terrível}.
Parece escrito por um robô que não entende nada.
Não vamos escrever provas nesse jeito.
Em vez disso, o texto ``real e humano'' que corresponde
nessa prova seria algo do tipo:
\quotepar
Seja $x$ inteiro ímpar,
e logo seja $k\in\ints$ tal que $x = 2k + 1$.
Preciso mostrar que $x^2$ é ímpar também.
Calculamos:
$$
x^2 = (2k+1)^2 = 4k^2 + 4k + 1 = 2(2k^2+2k) + 1.
$$
Como $2k^2+2k\in\ints$, logo $x^2$ é ímpar.
\endquote
Mesmo assim, é importante entender o ``backend'' da prova,
em termos da tabela ``Dados/Alvos''.
Então quando tu vai escrever tuas próprias provas,
pelo menos no início, podes aproveitar um rascunho
para fazer teu ``bookkeeping'', escrevendo e apagando
coisas nele com cada frase que escreveu na tua prova.
Com mais experiência, esse processo vai virar automático
e subconsciente.
%%}}}

\endsection
%%}}}

%%{{{ Attacking the logical structure of a proposition 
\section Atacando a estrutura logical duma proposição.

\blah.
Enquanto nosso alvo não é atómico, podemos atacá-lo numa maneira direita, ``batendo na lógica'' mesmo.
Similarmento, dados alvos não atómicos podemos usá-los na nossa demonstração baseados só na lógica.

%%{{{ x: how_to_use_and_how_to_attack_each_connective 
\exercise.
\label{how_to_use_and_how_to_attack_each_connective}%
Até agora encontramos como usar os $\exists,\land$ e como atacar os $\forall,\exists,\limplies$.
Para cada um dos conectivos que ainda não achamos como usar ou atacar, pense em:
o que tu podes escrever na tua demonstração; o que efeito tem nos dados; e o que nos alvos.
$$
\vbox{\halign{
\hfil#\hfil             &\qquad #\quad\hfil               & \qquad #\hfil\cr
                        & {\bf Usar}                      & {\bf Atacar}\cr
\tablethickrule
$\sforall x \phi(x)$    & $?^{\phantom?}$                 & <<Seja $u$.>>\cr
                        &                                 & Novos dados: $u$\cr
                        &                                 & Novo alvo: $\phi(u)$\cr
\tablerule
$\sexists x \phi(x)$    & <<Seja $u$ tal que $\phi(u)$.>> & --\cr
                        & Novos dados: $u$, $\phi(u)$     & Efeito nos dados: --\cr
                        & Efeito nos alvos: --            & Novo alvo: $\phi(u)$ (eu escolho o $u$)\cr
\tablerule
$\phi \land \psi$       & --                              & ?\cr
                        & Novos dados: $\phi$, $\psi$     &  \cr
                        & Efeito nos alvos: --            &  \cr
\tablerule
$\phi \lor \psi$        & ?                               & ?\cr
                        &                                 &  \cr
                        &                                 &  \cr
\tablerule
$\phi \limplies \psi$   & ?                               & <<Suponha $\phi$.>>\cr
                        &                                 & Novo dado: $\phi$\cr
                        &                                 & Novo alvo: $\psi$\cr
\tablerule
$\lnot \phi$            & ?                               & ?\cr
}}
$$

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Proofs by cases 
\section Provas por casos.

\blah.
Suponha que está tentando provar uma afirmação.
Para matar esse monstro, em qualquer momento da tua prova,
você pode separar em casos, e mostrar como matá-lo
em cada um deles.
Quando decidir atacar nessa maneira precisa tomar certos cuidados.

%%{{{ our new goals 
\note Nossos novos alvos.
\label{case_split_clones_goal}%
O alvo tá sendo clonado igualzíssimo para cada um dos casos.
%%}}}

%%{{{ remark: seems weird choice to case split 
\remark.
Mas, peraí.
A gente quer matar um monstro $G$.
Depois desse passo de separar em, sei lá, 4 casos,
agora nosso objectivo é matar 4 cópias desse monstro,
uma em cada caso.
Se fosse cada um desses novos monstros pelo menos
um pouquinho mais fraco o motivo de separar em casos
faria sentido.  Mas, como eu acabei de dizer,
em cada caso temos que matar um clono de $G$.
Não uma versão diferente de $G$.  O mesmo $G$!
%%}}}

%%{{{ Q: why case split? 
\question.
Por que separar em casos então e multiplicar nossos alvos?
%%}}}
\spoiler.

%%{{{ A: the monsters don't get weaker, but we get stronger 
\blah Resposta.
Não é que teus novos alvos são mais fracos---pois eles não são---mas
é você mesmo que fica mais forte em cada um deles.
Em cada caso, ganhas mais uma arma:
o dado que o próprio caso te oferece para matar esse mesmo alvo.
%%}}}

%%{{{ Don't forget a case 
\note Não deixar nenhum caso por fora.
Uma maneira de ter certeza que não esqueceu nada, é escolher uma
propriedade $A$ e separar nos dois casos complementares:
$A$ ou não $A$.
Para um exemplo de como errar, suponha que queremos provar
que para todo inteiro $n$, o $n(n-1)$ é um múltiplo de $3$.
Consideramos dois casos:
\beginol
\li Caso $n = 3k$   para algum $k\in\ints$.
\li Caso $n = 3k+1$ para algum $k\in\ints$.
\endol
Em cada um deles, é fácil provar que realmente $n(n-1)$ é
um múltiplo de $3$.  Mas claramente temos um erro aqui,
pois, como um contraexemplo tome o inteiro $2$ e calcule:
$5(5-1) = 20$, e com certeza $20$ não é um múltiplo de $3$.
O problema é que em nossa separação em casos a gente não
considerou todas as possibilidades!
Esquecemos um terceiro caso:
\quote
Caso contrário.
\endquote
Como aprendemos nos capítulos~\refn{Number_theory_divisibility}
e~\refn{Number_theory_congruences}, a única possibilidade que deixamos,
esse ``caso contrário'' é equivalente ao:
\quote
Caso $n = 3k+2$  para algum $k\in\ints$.
\endquote
Uma separação em casos correta então seria considerar todos os:
\beginol
\li Caso $n = 3k$   para algum $k\in\ints$.
\li Caso $n = 3k+1$ para algum $k\in\ints$.
\li Caso $n = 3k+2$ para algum $k\in\ints$.
\endol
E com essa separação, felizmente, não podemos provar
essa afirmação errada, pois no terceiro caso, não temos como
matar nosso alvo!
%%}}} 

\endsection
%%}}}

%%{{{ Implication 
\section Implicação.

%%{{{ Understand 
\note Entender.
Pensando no que uma implicação realmente é, vamos visualizá-la como uma premissa:
$$
\text{<<Prometo que $B$ com a condição $A$.>>}
$$
E o que é prometido caso que a condição $A$ não for verdadeira?
\emph{Nada!}
É importante entender essa parte, e talvez essa piada conhecida ajuda:
\quotepar
Um filho tá gritando e seu pai vire e fala pra ele:
\emph{``se tu continuar gritando, eu vou bater em ti!''}
O filho, com medo, imediatemente fica calado, e logo após seu pai bate nele.
\endquote
A pergunta para pensar é: \emph{o pai mentiu?}
Em matemática entendemos a implicação numa forma que não culpa esse pai
de mentiroso.%
\footnote{relaxe que tu podes culpar o pai para outras coisas se quiser}
Entendemos a implicação
$$
\text{<<se $\namedhole A$ então $\namedhole B$>>}
$$
como uma promessa.
Aqui o pai não prometeu nada no caso que seu filho parasse de gritar!
Nesse exemplo bobo então, a afirmação do pai é verdadeira \dterm{vacuamente}
como a gente fala:
ou seja, como não aconteceu a \emph{premissa},
não tem como culpá-lo de mentiroso.
%%}}}

%%{{{ What did I gain? 
\note O que eu ganhei?.
\tdefined{modus ponens}%
Escrevendo como regra de inferência,
$$
\Proofm {
\A  {\phi \implies \psi}
\A                         {\phi}
\I2------------------------------- {}
              {\psi}
}
$$
O nome dessa regra é \dterm{modus monens}.
%%}}}

\note Como eu mato?.

\endsection
%%}}}

%%{{{ Conjunction 
\section Conjunção.

\endsection
%%}}}

%%{{{ Universal 
\section Universal.

\endsection
%%}}}

%%{{{ Existential 
\section Existencial.

\endsection
%%}}}

%%{{{ Equivalence 
\section Equivalência.

\endsection
%%}}}

%%{{{ Disjunction 
\section Disjunção.

\endsection
%%}}}

%%{{{ Negation 
\section Negação.

\TODO Botando negações pra dentro.

\TODO Negando fórmulas atômicas.

\endsection
%%}}}

%%{{{ Igualdade 
\section Igualdade.

%%{{{ Laws 
\note Leis.
Aceitamos como parte da nossa lógica que a igualdade é:
\dterm{reflexiva}, \dterm{simétrica}, e \dterm{transitiva}:
$$
\Proof {
\I0---------------- {Refl}
{$\alpha = \alpha$}
}
\qquad
\Proof {
\A {$\alpha = \beta$}
\I1------------------ {Sym}
 {$\beta = \alpha$}
}
\qquad
\Proof {
\A {$\alpha = \beta$}
\A                       {$\beta = \gamma$}
\I2---------------------------------------- {Trans}
           {$\alpha = \gamma$}
}
$$
Alem disso, aceitamos a \dterm{lei de substituição:}
\emph{em qualquer fórmula ou qualquer termo podemos
substituir um subtermo por um igual
sem mudar o significado da fórmula ou termo}.
%%}}}

%%{{{ What did I gain? 
\note O que eu ganhei?.
Ganhando como dado o $\alpha = \beta$, tu agora podes
substituir $\alpha$ por $\beta$ e vice versa em qualquer
contexto que eles aparecem!
%%}}}

%%{{{ How to attack? 
\note Como atacar?.
Simples: pega um lado, e calcule até chegar no outro!
Às vezes fica difícil enxergar um caminho direto de $\alpha$
pra $\beta$; nesse caso tente pegar um lado até chegar num ponto $\gamma$; depois pega o outro lado e se conseguir chegar no mesmo ponto $\gamma$, teu alvo já era!
%%}}}

\endsection
%%}}}

%%{{{ Reductio ad absurdum 
\section Reductio ad absurdum.

\endsection
%%}}}

%%{{{ Uniqueness proofs 
\section Provas de unicidade.

\endsection
%%}}}

%%{{{ Common errors and fallacies 
\section Erros comuns e falácias.
\label{Fallacies}%

%%{{{ Proof by repeating the definition 
\note Prova por repetição da definição.
Imagine que u tá querendo demonstrar que $2x + 8$ é ímpar, onde ímpar quis dizer
Para apreciar quão inútil 
Imagine um advogado defendendo um cara suspeito 
\quote
<<Meu cliente é inocente, porque ele não matou a vítima.>>
\endquote
Ninguém deveria considerar essa frase como um argumento convincente
e válido da inocência do acusado.
Nesse contexto, ``$x$ é inocente'' \emph{significa}
``$x$ não matou a vítima''.
É \emph{exatamente a mesma afirmação}, expressada com outras palavras.
Ou seja, traduzindo o argumento do advogado, percebemos que o que ele falou mesmo foi:
\quote
<<Meu cliente não matou a vítima, porque ele não matou a vítima.>>
\endquote
ou
\quote
<<Meu cliente é inocente, porque ele é inocente.>>
\endquote
dependendo de qual direção da tradução escolhemos aplicar.
Esse advogado não deveria ter muito sucesso no seu futuro assim!%
\footnote{Infelizmente muitas pessoas caem por esse tipo de argumento
na vida real, onde políticos, pastores, e advogados como o não-tão-fictício
do meu exemplo, ``argumentam'' em maneiras erradas para convencer seus
ouvidores (que não estudaram matemática).}
%%}}}

%%{{{ Forget one of the branches 
\note Esquecer um dos ramos.
Lembre-se o modus ponens:
$$
\Proofm {
\A  {\phi \implies \psi}
\A                           {\phi}
\I2--------------------------------- {M.P.}
                 {\psi}
}
$$
Que nos permite inferir a proposição $\psi$,
pelas \emph{duas} proposições
\beginol
\li $\phi \implies \psi$;
\li $\phi$.
\endol
É comum esquecer sobre uma das duas e mesmo assim tentar
inferir (a partir da outra) a mesma conclusão $\psi$.
Estudando matemática é mais freqüente esquecer a $\phi$;
na vida real qualquer uma das duas pode acabar sendo ``esquecida''.
%%}}}

%%{{{ Denying the antecedent 
\note Refutação do antecedente.
%%}}}

%%{{{ Let and prove vs. Prove that all 
\note Seja e demonstre \vs demonstre que todos.
%%}}}

\TODO complete and provide math and life examples.

\endsection
%%}}}

%%{{{ Wrong; now what? 
\section Deu errado; e agora?.

\TODO Erro na prova não é suficiente para dizer que o teorema é errado.

\TODO Conseqüência de teorema errado não é suficiente para concluir que
a conseqüência é errada também.

\endsection
%%}}}

%%{{{ Problems 
\problems.

%%{{{ prob: change_order_of_quantifiers_one_way 
\problem.
Sem saber qual afirmação é denotada por $\phi(x,y)$, demonstre as equivalências:
$$
\align
\forall x \sforall y \phi(x,y)
\askiff
\forall y \sforall x \phi(x,y).
\endalign
$$
Podes demonstrar ou refutar a outra?

\endproblem
%%}}}

%%{{{ prob: change_order_of_quantifiers_one_way 
\problem.
Sem saber qual afirmação é denotada por $\phi(x,y)$, demonstre \emph{uma} das duas direções da equivalência
$$
\forall x \sexists y \phi(x,y)
\askiff
\exists y \sforall x \phi(x,y).
$$
Podes demonstrar ou refutar a outra?

\endproblem
%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[Cap.~3]{velleman}

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Recursion_induction 
\chapter Recursão; indução.
\label{Recursion_induction}%
\iisee{recursão}{recursão}%

%%{{{ First examples 
\section Primeiros exemplos.

\TODO Fibonacci e Lucas.

%%{{{ df: fibonacci 
\definition Os números Fibonacci.
\label{fibonacci}%
\tdefined{Fibonacci}[seqüência]%
Definimos os \emph{números Fibonacci}\Fibonacci[seqüência]\tdefined{Fibonacci}[números]{}
recursivamente assim:
$$
\align
    F_0     &= 0 \\
    F_1     &= 1 \\
    F_{n+2} &= F_{n+1} + F_n.
\endalign
$$
%%}}}

\TODO Computando seus valores.

%%{{{ x: lucas 
\exercise Os números Lucas.
\label{lucas}%
\tdefined{Lucas}[números]%
Os números Lucas\Lucas[números]\tdefined{Lucas}[números]{} são definidos similarmente:
$$
\align
L_0     &= 2\\
L_1     &= 1\\
L_{n+2} &= L_{n+1} + L_n.
\endalign
$$
Calcule o valor $L_{12}$.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Sums and products, formally 
\section Somatórios e produtórios formalmente.

\TODO Definições recursivas de somatórios e produtórios.

\endsection
%%}}}

%%{{{ The principle of finite induction 
\section O princípio da indução finita (PIF).

%%{{{ ax: FIP 
\axiom Princípio da indução finita (PIF).
\label{FIP}%
\tdefined{PIF}%
\iiseealso{PIF}{indução}%
\iisee{princípio}[da indução finita]{indução}%
\tdefined{indução}%
Seja $P(n)$ uma propriedade de naturais.
Se $P(0)$ e, para todo $k\in\nats$,
$P(k)$ implica $P(k+1)$,
então $P(n)$ é verdade para todo $n\in\nats$.
%%}}}

%%{{{ FIP schematically 
\note.
Esquematicamente o PIF:
$$
\rightbrace{
\aligned
\text{\proofpartstyle{Base:}}\quad            & P(0)\\
\text{\proofpartstyle{Passo Indutivo:}}\quad  & \lforall {k\in\nats} {P(k)\limplies P(k+1)}\quad
\endaligned
}
\implies
\lforall {n\in\nats} {P(n)}.
$$
%%}}}

%%{{{ eg: gauss_child 
\example.
\label{gauss_child}%
Prove que
$$
    1 + 2 + \cdots + n = \frac { n (n+1) } 2
$$
para todo $n\in\nats$.

\solution
Por indução, verificamos que a propriedade
$$
P(n)
\defiff
1 + 2 + \cdots + n = \frac { n (n+1) } 2
$$
é válida para todo $n$.
Primeiramente provamos a base
$$
P(0)
\iff
\underbrace{1 + 2 + \cdots + 0}_{\text{somatório vazio}}
= \frac { 0 (0+1) } { 2 }.
$$
Realmente, o lado esquerdo é um somatório vazio,
logo $0$, e o lado direito é o número $0(0+1)/2 = 0$ também.
Concluimos que $P(0)$.
\endgraf
Seja $k\in\nats$ tal que $P(k)$, ou seja,
$$
1 + 2 + \cdots + k = \frac { k (k+1) } 2.\tag{H.I.}
$$
Calculamos:
$$
\alignat 3
P(k+1)
&\iff& 1 + 2 + \cdots + (k+1)        &= \frac { (k+1) (k+2) } 2 \\
&\iff& 1 + 2 + \cdots + k + (k+1)    &= \frac { (k+1) (k+2) } 2 \\
&\iff& \frac { k (k+1) } 2  + (k+1)  &= \frac { (k+1) (k+2) } 2 \by {pela H.I.}
&\iff& k \cancel{(k+1)} + 2 \cancel{(k+1)} &= \cancel{(k+1)} (k+2) \\
&\iff& k + 2                         &= k + 2.
\endalignat
$$
\endexample
%%}}}

%%{{{ x: sum_of_cubes_formula 
\exercise.
\label{sum_of_cubes_formula}%
Prove que
$$
    1 + 8 + 27 + \cdots + n^3 = \paren{\frac { n (n+1) } { 2 } }^2
$$
para todo $n\in\nats$.

\hint
Lembre que o somatório vazio é $0$.

\endexercise
%%}}}

%%{{{ x: sum_of_negative_powers_of_two_formula 
\exercise.
\label{sum_of_negative_powers_of_two_formula}%
Observando os valores de:
$$
\align
    1
    +
    \frac 1 2
    &= 2 - \frac 1 2\\
    1
    +
    \frac 1 2
    +
    \frac 1 4
    &= 2 - \frac 1 4\\
    1
    +
    \frac 1 2
    +
    \frac 1 4
    +
    \frac 1 8
    &= 2 - \frac 1 8,
\intertext{adivinhe uma fórmula geral para o somatório}
    1 + \frac 1 2 + \frac 1 4 + \cdots + \frac 1 {2^n} &= \text{?}
\endalign
$$
e prove que ela é válida para todo $n\in\nats$.

\endexercise
%%}}}

%%{{{ x: one_minus_sum_of_1_over_n_formula 
\exercise.
\label{one_minus_sum_of_1_over_n_formula}%
Calculando os valores de:
$$
    \paren{1 - \frac 1 2},
   \qquad 
    \paren{1 - \frac 1 2}
    \paren{1 - \frac 1 3},
   \qquad
    \paren{1 - \frac 1 2}
    \paren{1 - \frac 1 3}
    \paren{1 - \frac 1 4},
$$
adivinhe uma fórmula geral para o produtório
$$
\Prod_{i=2}^n\paren{ 1 - \frac 1 i}
=
    \paren{1 - \frac 1 2}
    \paren{1 - \frac 1 3}
    \paren{1 - \frac 1 4}
\dotsb
    \paren{1 - \frac 1 n}
$$
e prove que ela é válida para todo inteiro $n \geq 2$.

\endexercise
%%}}}

%%{{{ x: sum_of_squares_formula 
\exercise.
\label{sum_of_squares_formula}%
Prove que para todo $n \in\nats$,
$$
\Sum_{i=1}^n i^2
= \frac {n^3} 3 + \frac {n^2} 2 + \frac n 6.
$$

\endexercise
%%}}}

%%{{{ x: sum_of_cubes_and_gauss_formula 
\exercise.
\label{sum_of_cubes_and_gauss_formula}%
Prove que para todo $n \in\nats$,
$$
\align
\Sum_{i=1}^n i^3 &= \paren{\Sum_{i=1}^n i}^2\\
\text{ou seja,}\qquad
1^3 + 2^3 + \dotsb + n^3 &= \paren{ 1 + 2 + 3 + \dotsb + n }^2.
\endalign
$$

\endexercise
%%}}}

%%{{{ x: sum_of_threes_and_fives 
\exercise.
\label{sum_of_threes_and_fives}%
Qualquer número inteiro positivo $n \geq 8$ pode ser escrito
como somatório de $3$'s e $5$'s.

\endexercise
%%}}}

%%{{{ x 
\exercise.
Seja
$$
P(n) \defiff 1 + 2 + \dotsb + n = \frac 1 8 \paren{2n + 1}^2.
$$
\item{(1)} Prove que para todo $k\in\nats$, se $P(k)$ então $P(k+1)$.
\item{(2)} Critique a sentença: ``\emph{Logo, por indução temos que $P(n)$ é válido para todo $n\in\nats$.}''
\item{(3)} Mudando o ``$=$'' para ``$>$'' ou ``$<$'', defina um novo predicado $P'(n)$, válido para todo $n\in\nats$, e prove a validade dele por indução.

\endexercise
%%}}}

%%{{{ x fibonacci 
\exercise.
Prove que para todo $n\in\nats$,
$$
\Sum_{i=0}^n F_i = F_{n+2} - 1,
$$
onde $F_n$ o $n$-ésimo número Fibonacci.

\endexercise
%%}}}

%%{{{ x fibonacci 2 
\exercise.
Prove que para todo $n\in\nats$,
$$
\Sum_{i=1}^n F_i^2 = F_n F_{n+1},
$$
onde $F_n$ o $n$-ésimo número Fibonacci.

\endexercise
%%}}}

%%{{{ x: n_over_succ_n_formula 
\exercise.
\label{n_over_succ_n_formula}%
Prove que para todo inteiro $n \geq 1$.
$$
    \frac 1 {1 \cdot 2} +
    \frac 1 {2 \cdot 3} +
    \frac 1 {3 \cdot 4} + \cdots + 
    \frac 1 {n (n+1)}
    =
    \frac n {n+1}
$$

\endexercise
%%}}}

%%{{{ x: squares_smaller_than_powers_of_two_induction 
\exercise.
\label{squares_smaller_than_powers_of_two_induction}%
Prove que para todo inteiro $n \geq 5$,
$$
    n^2 < 2^n.
$$

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ When one base is not enough 
\section Quando uma base não é suficiente.

%%{{{ prop: lucas_altdef_first_attempt 
\proposition.
\label{lucas_altdef_first_attempt}%
Para todo inteiro $n \geq 1$,
seja $\ell : \nats\setminus\set0\to\nats$ a função definida pela equação
$$
    \ell(n) = F_{n-1} + F_{n+1},
$$
onde $F_n$ é o $n$-ésimo número \Fibonacci{}Fibonacci (veja~\ref{fibonacci}).
Queremos mostrar que para todo $n \geq 1$, $L_n = \ell(n)$,
onde $L_n$ é o $n$-ésimo número \Lucas{}Lucas (veja~\ref{lucas}).
\wrongproof.
Nos vamos provar por indução que \emph{para todo $n \geq 1$, $L_n = \ell(n)$}.
Vamos primeiramente verificar que para $n=1$, realmente temos $L_n = \ell(n)$:
\compute
\ell(1) &= F_0 + F_2      \by {def.~de $\ell(n)$}
        &= 0 + F_1 + F_0  \by {def.~de $F_n$}
        &= 0 + 1 + 0      \by {def.~de $F_n$}
        &= 1              \\
        &= L_1.           \by {def.~de $L_n$}
\intertext{Seja $k\in\nats$ com $k\geq 2$, tal que $L_{k-1} = \ell(k-1)$.
Realmente temos}
L_k
&= L_{k-1} + L_{k-2}                        \by {def.~de $L_n$}
&= \ell(k-1) + \ell(k-2)                    \by {H.I.}
&= (F_{k-2} + F_k) + (F_{k-3} + F_{k-1})    \by {def.~de $\ell(n)$}
&= (F_{k-2} + F_{k-3}) + (F_k + F_{k-1})    \by {ass.~e com.~de $+$}
&= F_{k-1} + F_{k+1}                        \by {def.~de $F_n$}
&= \ell(k).                                 \by {def.~de $\ell(n)$}
\endcompute
que termina nossa prova.
\mistaqed
%%}}}

%%{{{ x: lucas_altdef_find_error 
\exercise.
\label{lucas_altdef_find_error}%
Na prova acima roubamos.
Ache onde e explique como, e pense numa solução.

\endexercise
%%}}}

%%{{{ lucas_altdef_final 
\proposition.
\label{lucas_altdef_final}%
Com a notação da~\ref{lucas_altdef_first_attempt},
para todo $n\geq 1$, $\ell(n) = L_n$.
\proof.
Nos vamos provar por indução que \emph{para todo $n \geq 1$, $L_n = \ell(n)$}.
Vamos primeiramente verificar que para $n=1$ e $n=2$, realmente temos $L_n = \ell(n)$.
Para $n=1$:
\compute
\ell(1) &= F_0 + F_2      \by {def.~de $\ell(n)$}
        &= 0 + F_1 + F_0  \by {def.~de $F_n$}
        &= 0 + 1 + 0      \by {def.~de $F_n$}
        &= 1              \\
        &= L_1.           \by {def.~de $L_n$}
\endcompute
E para $n=2$:
$$
\xalignat2
\computed
      L_2 &= L_1 + L_0  \by {def.~de $L_n$}
          &= 1 + 2      \by {def.~de $L_n$}
          &= 3          
\endcomputed
&&
\computed
\ell(2) &= F_1 + F_3          \by {def.~de $\ell(n)$}
        &= 1 + F_2 + F_1      \by {def.~de $F_n$}
        &= 1 + 1 + 1          \\
        &= 3.
\endcomputed
&
\endxalignat
$$
Seja $k\in\nats$ com $k\geq 3$ tal que
$$
L_{k-1} = \ell(k-1)
\qquad
\text{e}
\qquad
L_{k-2} = \ell(k-2)
$$
(nossas \emph{duas} hipoteses indutivas).
Vamos provar que $L_k = \ell(k)$.
Realmente temos
\compute
L_k
&= L_{k-1} + L_{k-2}                        \by {def.~de $L_n$}
&= \ell(k-1) + \ell(k-2)                    \by {H.I.}
&= (F_{k-2} + F_k) + (F_{k-3} + F_{k-1})    \by {def.~de $\ell(n)$, $k\geq3$}
&= (F_{k-2} + F_{k-3}) + (F_k + F_{k-1})    \by {ass.~e com.~de $+$}
&= F_{k-1} + F_{k+1}                        \by {def.~de $F_n$, $k\geq3$}
&= \ell(k),                                 \by {def.~de $\ell(n)$}
\endcompute
que termina nossa prova.
\qed
%%}}}

%%{{{ x: new_proof_of_sum_of_threes_and_fives_with_three_bases 
\exercise.
\label{new_proof_of_sum_of_threes_and_fives_with_three_bases}%
Ache uma nova prova do~\ref{sum_of_threes_and_fives} por indução
com três bases.

\hint
$k = (k-3) + 3$.

\solution
Seja $k\geq 8 + 3 = 11$ tal que $k-1$, $k-2$, e $k-3$
podem ser escritos como somatórios de $3$'s e $5$'s (H.I.).
Temos
\compute
k &= (k-3) + 3      \\
  &= (3x + 5y) + 3  \quad\text{para alguns $x,y\in\nats$} \by {pela H.I.}
  &= 3(x+1) + 5y.
\endcompute
Como precisamos a veracidade da proposição para o valor $k-3$,
devemos mostrar as $3$ bases, para os inteiros $8$, $9$, e $10$:
$$
\alignat 2
8  &= 3 + 5     &&= 3\ntimes 1 + 5\ntimes 1\\
9  &= 3 + 3 + 3 &&= 3\ntimes 3 + 5\ntimes 0\\
10 &= 5 + 5     &&= 3\ntimes 0 + 5\ntimes 2.
\endalignat
$$

\endexercise
%%}}}

%%{{{ two_ways_to_organize_inductive_step 
\note Duas maneiras de organizar tua demonstração.
\label{two_ways_to_organize_inductive_step}%
Ok, vamos supor que tu tá tentando demonstrar algo da forma
$$
\lforall {n \in \nats} {\phi(n)}
$$
por indução, e que tu decidiu usar duas bases
(obviamente a $\phi(0)$ e a $\phi(1)$).
Como seria teu passo indutivo?
Tem duas maneiras boas para proceder agora:
\crproofalt{Maneira 1:}
<<Seja $k\in\nats$ tal que $\phi(k-1)$\fact{H.I.1} e $\phi(k-2)$\fact{H.I.2}.
Vou demonstrar que $\phi(k)$.>>
Nessa maneira, preciso tomar cuidado que nenhum inteiro menor que $k-2$ aparece
em algum canto errado, pois não sei nada sobre eles; até pior pode ser
que aparecem objetos que nem são definidos.
\crproofalt{Maneira 2:}
<<Seja $k\in\nats$ tal que $\phi(k)$\fact{H.I.1} e $\phi(k+1)$\fact{H.I.2}.
Vou demonstrar que $\phi(k+2)$.>>
E agora preciso tomar o mesmo cuidado, só que agora com inteiros
menores que~$k$.
\endgraf
\emph{Ambas as maneiras são corretas} e bem escritas e bem entendíveis
e tudo mais---e dá pra variar também, não são
únicas~(\ref{third_way_to_organize_inductive_step}).
Qual vamos escolher?  Depende de gosto e as vezes do contexto também.
Na maioria das vezes eu vou favorecer a primeira:
meus olhos gostam da associação dos ``(H.I.$i$)'' com os $\phi(k-i)$.
Na mesma linha de pensar, na segunda maneira as hipoteses indutivas são as
$\phi(k)$ e $\phi(k+1)$, e o alvo seria o $\phi(k+2)$;
então a (H.I.2) parece mais com o alvo do que com a (H.I.1).
Ou seja: \emph{nos meus olhos}, os dados e o alvo ficam mais arrumados
na maneira 1.
Mas como falei: ambas corretas; questão de gosto; então consulte teus
próprios olhos.
%%}}}

%%{{{ x: third_way_to_organize_inductive_step 
\exercise.
\label{third_way_to_organize_inductive_step}%
Qual seria a terceira ``óbvia'' maneira?
Com que inteiros tem que tomar cuidado se escolhê-la?

\solution
<<Seja $k\in\nats$ tal que $\phi(k-1)$\fact{H.I.1} e $\phi(k)$\fact{H.I.2}.
Vou demonstrar que $\phi(k+1)$.>>
Nessa maneira, preciso tomar cuidado com inteiros menores de $k-1$.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Many variables 
\section Muitas variáveis.

%TODO explain that it's just one more tool to attack theorems
%TODO XXX Maybe refer to a weaker result from "irrationality"?
%%{{{ lemma: odd_to_any_power_is_odd 
\lemma.
\label{odd_to_any_power_is_odd}%
Para todo $n\in\nats$, e todo ímpar $k\in\ints$, $k^n$ é ímpar.
\proof.
Seja $k\in\ints$ ímpar, então $k=2a+1$ para um $a\in\ints$.%
\footnote{%
Aqui consideramos a seguinte definição de ``ímpar'':
\emph{um inteiro $n$ é \dterm{ímpar} sse existe inteiro $k$ tal que $n = 2k+1$.}
}
Vamos provar por indução que para todo $n\in\nats$, $k^n$ é ímpar.
Se $n=0$, imediatamente $k^0 = 1$ e é ímpar ($1 = 2\ntimes 0 + 1$).
Suponha que para algum $t\in\nats$, $k^t$ é ímpar, ou seja $k^t = 2b+1$ para um $b\in\ints$.
Falta provar que $k^{t+1}$ também é ímpar.
Calculando,
\compute
k^{t+1}
&= k k^t               \by {definição de exponenciação}
&= (2a + 1) (2b + 1)   \by {hipoteses}
&= 4ab + 2a + 2b + 1   \\
&= 2(2ab + a + b) + 1.
\endcompute
Logo, como $2ab + a + b\in\ints$, $k^{t+1}$ é ímpar.
\qed
%%}}}

\endsection
%%}}}

%%{{{ Strong induction 
\section O princípio da indução finita forte (PIFF).
\label{Strong_induction}%

\blah.
O seguinte princípio parece mais forte que o PIF.
Na verdade, nos naturais, os dois princípios são equivalentes:

%%{{{ thm: COVIP 
\label{COVIP}%
\theorem Princípio da indução finita forte (PIFF).
\tdefined{PIFF}
\iiseealso{PIFF}{indução}
\tdefined{indução}[forte]
\iisee{princípio}[da indução finita forte]{indução forte}
Seja $P(n)$ uma propriedade de naturais.
Se para todo $k\in\nats$,
a hipótese que $P(i)$ é verdade para todo $i<k$
implica que $P(k)$ também é,
então $P(n)$ é verdade para todo $n\in\nats$.
%%}}}

%%{{{ note: PIFF in symbols 
\note.
Esquematicamente o PIFF:
$$
\lforall
    {k\in\nats}
    {\vphantom{\bigg(}\Big(\lforall {i < k} {P(i)}\Big) \limplies P(k)}
\implies
\lforall
    {n\in\nats}
    {P(n)}.
$$
%%}}}

\endsection
%%}}}

%%{{{ The well-ordering principle 
\section O princípio da boa ordem (PBO).
\label{The_wellordering_principle}%

%%{{{ df: minimum_first_encounter 
\definition Elemento mínimo.
\label{minimum_first_encounter}%
\tdefined{mínimo}%
\sdefined {\min {\sholed A}} {mínimo do $A$}%
Seja $A$ um conjunto ordenado.
Um elemento $m\in A$ é chamado
\dterm{(elemento) mínimo do $A$}
sse
$m$ é menor de todos os outros elementos do $A$.
Quando o conjunto $A$ possui elemento mínimo,
escrevemos $\min A$ para denotá-lo:
$$
m = \dsym{\min A} \defiff m\in A \;\land\; \lforall {a\in A} {a \neq m \limplies m < a}.
$$
Note que necessariamente o mínimo dum conjunto $A$ pertence no $A$.
%%}}}

%%{{{ remark: we_must_prove_uniqueness_of_min 
\remark.
\label{we_must_prove_uniqueness_of_min}%
Para justificar a definição do símbolo $\min A$, \emph{devemos} provar o
seguinte:
%%}}}

%%{{{ x: uniqueness_of_minimum 
\exercise Unicidade de mínimo.
\label{uniqueness_of_minimum}%
Um conjunto não pode ter mais que um elemento mínimo.

\hint
Suponha que tem dois mínima diferentes
e aplicando a definição de ``mínimo''
e propriedades de $<$,
chega numa contradição.

\hint
Pela transitividade, $a<b$ e $b<a$ implicam uma contradição.

\endexercise
%%}}}

%%{{{ x: ordered_singleton_set_has_minimum 
\exercise.
\label{ordered_singleton_set_has_minimum}%
Seja $U$ um conjunto unitário ordenado.
Prove que ele tem elemento mínimo.

\endexercise
%%}}}

%%{{{ x: finite_nonempty_subset_of_poset_has_minimum 
\exercise.
\label{finite_nonempty_subset_has_minimum}%
Seja $A$ um conjunto ordenado, e um subconjunto finito $A_0\finsubset A$,
com $A_0\neq\emptyset$.
O $A_0$ possui elemento mínimo.

\hint
Indução no tamanho do $A_0$.

\endexercise
%%}}}

%%{{{ thm: WOP 
\theorem Princípio da boa ordem (PBO).
\label{WOP}%
\tdefined{PBO}%
\tdefined{princípio}[da boa ordem]%
\iiseealso{PBO}{princípio da boa ordem}%
Cada subconjunto não vazio do\/ $\nats$ possui mínimo.
\sketch.
Seja $P(n)$ a propriedade que cada subconjunto $A\subset\nats$
que possui elementos menores ou iguais a $n$ tem mínimo.
Vamos mostrar por indução que para todo $n$, $P(n)$.
\qes
%%}}}

%%{{{ x: which_orders_are_wellorders 
\exercise.
\label{which_orders_are_wellorders}%
Quais dos $\ints$, $\rats$, $\rats_{>0}$, $\rats_{\geq0}$, $\reals$,
satisfázem a propriedade de boa ordem?

\endexercise
%%}}}

%%{{{ x: which_subsets_are_well_ordered 
\exercise.
\label{which_subsets_are_well_ordered}%
Seja $a\in\reals$.
Quais dos $\rats_{\geq a}$, $\reals_{\geq a}$,
e $\set{ 2^{-n} \st n \in\nats, n \leq a}$
satisfázem a propriedade de boa ordem?

\endexercise
%%}}}

%%{{{ thm: no_int_between_0_and_1 
\theorem.
\label{no_int_between_0_and_1}%
Não existe inteiro $k$ tal que\/ $0 < k < 1$.
\sketch.
Suponha que existe um tal inteiro $k$.
Então o conjunto $C=\set{c\in\ints\st 0 < c < 1}$ de todos os ``contraexemplos''
não é vazio.
Aplique o PBO para tomar seu menor elemento, e ache um outro contraexemplo,
ainda menor, chegando assim numa contradição.
\qes
%%}}}

%%{{{ x: no_int_between_0_and_1_by_induction 
\exercise.
\label{no_int_between_0_and_1_by_induction}%
Prove o \ref{no_int_between_0_and_1} usando indução.

\hint
Nenhum inteiro negativo satisfaz $0 < m < 1$.
Então para provar que nenhum inteiro fica estritamente entre $0$ e $1$, basta provar
que todos os não-negativos $n$ satisfazem $n=0$ ou $n\geq 1$

\hint
Seja
$
P(n) \defiff \text{$n=0$ ou $n\geq1$}
$.

\hint
A base é trivial.

\hint
Para o passo indutivo, tomando um $k\in\nats$ tal que $P(k)$, separa tua prova
em dois casos, dependendo da razão que o $P(k)$ seja verdade.

\endexercise
%%}}}

%%{{{ x: if_ab_is_1_then_what 
\exercise.
\label{if_ab_is_1_then_what}%
Sejam $a,b\in\ints$ com $ab=1$.
Prove que $a=\pm1$ e $b=\pm1$.

\endexercise
%%}}}

%%{{{ thm: PIF_set_form 
\theorem Indução, forma com conjuntos.
\label{PIF_set_form}%
\tdefined{indução}[forma com conjuntos]%
Seja $A\subset\nats$ tal que $0\in A$ e $n+1\in A$ para todo $n\in A$.
$A=\nats$.
\sketch.
Caso contrário, existeriam ``contraexemplos'', ou seja, naturais que não pertencem ao $A$.
Aplique a PBO para escolher o menor tal contraexemplo, e chega num absurdo.
\qes
%%}}}

%%{{{ x: shifted_WOP 
\exercise.
\label{shifted_WOP}%
Prove que se um subconjunto $A$ de inteiros tem elementos maiores que um número fixo $n_0$,
então existe o $\min\set{a\in A\st n_0 < a}$.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Problems 
\problems.

%%{{{ prob: products_in_disguise 
\problem.
\label{products_in_disguise}%
Seja $h : \nats\to\nats$.
Defina recursivamente as funções $t : \nats \to \nats$ e $T : \nats^2 \to \nats$ que satisfazem:
$$
\align
t(n)   &= h(0)h(1)\dotsb h(n-1)     = \Prod\limits_{i=0}^{n-1} h(i);\\
T(m,n) &= h(m)h(m+1)\dotsb h(m+n-1) = \Prod\limits_{i=m}^{m+n-1} h(i).
\endalign
$$

\hint
Depois de definir confira tuas definições seguindo elas para calcular uns valores.
Por exemplo, $t(2)$ e $T(5,2)$ devem dar os resultados
$$
\xalignat2
t(2) &= h(0)h(1)
&
T(5,2) &= h(5)h(6).
\endxalignat
$$

\hint
Mesmo que a função $T$ tem aridade 2, escolhendo bem,
tu não precisarás escrever 4 equações, mas apenas 2.

\solution
Definimos
$$
\xalignat2
t      &\eqtype \nats\to\nats   &  T        &\eqtype \nats^2\to\reals\\
t(0)   &= 1                     &  T(m,0)   &= 1                     \\
t(n+1) &= h(n) \ntimes t(n)     &  T(m,k+1) &= h(m+k) \ntimes T(m,k).  
\endxalignat
$$
Tendo definido primeiro a $T$, podemos definir a $t$ assim:
$$
t(n) = T(0,n).
$$

\endproblem
%%}}}

%%{{{ prob: victors_mistake 
\problem.
\label{victors_mistake}%
Tentando resolver o~\ref{products_in_disguise},
% STUDENT: Victor
um aluno definiu corretamente a $t$ e depois a usou
na sua definição de $T$, assim:
$$
T(m,n) = {t(m+n)}/{t(m)}.
$$
Qual o problema com essa definição?
(Suponha como conhecida uma definição recursiva da
operação $/$ de divisão inteira.)

\hint
Qual é o contradomínio da $h$?

\hint
$0\in\nats$.

\hint
O que acontece se $h(i) = 0$ para algum $i \in \nats$?

\solution
Se $h(i) = 0$ para algum $i \in \nats$,
o $t(j)=0$ para todo $j>i$.
Assim, a expressão
${t(m+n)}/{t(m)}$ não é definida para qualquer $m>i$.
Observe que a solução seria certa se
o contradomínio da $h$ fosse o $\nats\setminus\set0$.

\endproblem
%%}}}

%%{{{ prob: every_finite_set_of_reals_has_min_and_max 
\problem.
\label{every_finite_set_of_reals_has_min_and_max}%
Cada conjunto finito e não vazio $A\subset\reals$ possui
elemento mínimo $\min A$ e máximo $\max A$.

\hint
Indução no número de elementos do $A$.

\endproblem
%%}}}

%%{{{ prob: triminos 
\problem Triminôs.
\label{triminos}%

\endproblem
%%}}}

%%{{{ prob: induction_iff_strong_induction 
\problem.
\label{induction_iff_strong_induction}%
\ii{PIF}%
\ii{PIFF}%
$\text{PIF} \iff \text{PIFF}$.

\endproblem
%%}}}

%%{{{ prob: where_is_the_base_of_strong_induction 
\problem Cadê a base da indução forte?.
\label{where_is_the_base_of_strong_induction}%
Seguindo o teorema acima, parece que não precisamos provar uma ``base''
na indução forte.
Critique a seguinte afirmação:
``\emph{Quando quero provar um teorema da forma
$\forall n P(n)$
usando indução, eu preciso mostrar uma(s) base(s)
$P(0), P(1), \dotsc, P(b)$
e depois provar o $P(k+1)$,
dado apenas umas $b+1$ hipoteses:
$P(k), P(k-1), \dotsc, P(k-b)$.
No outro lado, usando indução forte eu preciso mostrar menos
coisas: não tenho que mostrar nenhuma base;
e, alem disso, no meu esforço para provar o $P(k+1)$,
eu não vou ter apenas umas poucas hipoteses, mas
todos os $P(i)$ para $i<k+1$.
Como os dois princípios são equivalentes no $\nats$,
eu vou sempre usar indução forte.}''

\hint
Quantos $i\in\nats$ satisfazem $i < 0$?

\endproblem
%%}}}

%%{{{ prob: ackermann_function 
\problem.
\label{ackermann_function}%
Considere a função recursiva $\alpha : \nats^2 \to \nats$ definida pelas equações:
$$
\align
\alpha(0,x)     &= x+1                      \tag{K1}\\
\alpha(n+1,0)   &= \alpha(n,1)              \tag{K2}\\
\alpha(n+1,x+1) &= \alpha(n,\alpha(n+1, x)))\tag{K3}  
\endalign
$$
\beginil
\item{(i)} Calcule o valor $\alpha(3,2)$, indicando para cada passo qual equação foi usada.
\item{(ii)} Prove que para todo $x\in\nats$, $\alpha(1,x) = x + 2$.
\item{(iii)} Prove que para todo $x\in\nats$, $\alpha(2,x) = 2x + 3$.
\endil
A função $\alpha$ é conhecida como função de \Ackermann{}Ackermann,
e vamos encontrá-la novamente bem depois, no~\ref{Theory_of_recursive_functions}.

\endproblem
%%}}}

%%{{{ prob: quot_rem_eq_prob 
\problem.
\label{quot_rem_eq_prob}%
Considere as funções $q$, $r$, e $t$ definidas recursivamente:
$$
\xalignat3
q       &\eqtype \nats \to \nats   & r      &\eqtype \nats \to \nats   &  t          &\eqtype \nats^2 \to \bools     \\
q(0)    &=       0\phantom{666}    & r(0)   &=       0\phantom{666}    &  t(0,   0)  &=       \True          \\
q(1)    &=       0\phantom{666}    & r(1)   &=       1\phantom{666}    &  t(0,  Sn)  &=       \False         \\
q(2)    &=       0\phantom{666}    & r(2)   &=       2\phantom{666}    &  t(Sm,  0)  &=       \False         \\
q(n+3)  &=       q(n) + 1          & r(n+3) &=       r(n)              &  t(Sm, Sn)  &=       t(m,n)             
\endxalignat
$$
O que cada função calcula?

\hint
Calcule os valores $q(11)$, $q(12)$, $r(11)$, e $r(12)$.

\solution
Temos:
\beginul
\li $q(n) = \bigg\lfloor{\dfrac n 3}\bigg\rfloor$.
\li O $r(n)$ é o resto da divisão do $n$ por $3$.
\li A $t$ decida se suas entradas são iguais ou não.
\endul

\endproblem
%%}}}

%%{{{ prob: horses_and_birthdays 
\problem Cavalos e aniversários.
\label{horses_and_birthdays}%
Vamos provar o seguinte:
\quote
<<Para todo $n$ natural, em qualquer conjunto de $n$ pessoas, só tem pessoas com o mesmo dia de aniversário.>>
\endquote
\proofstyle{Suposta demonstração.}
\quote\it
<<Por indução no $n$.
\crproofpart{Base.}
Trivial: em qualquer conjunto de $0$ pessoas, só tem pessoas com o mesmo aniversário, pois não tem nenhuma pessoa e logo não tem como achar pessoas de aniversários diferentes.
\crproofpart{Passo indutivo.}
Seja $k$ natural tal que \emph{em qualquer conjunto de $k$ pessoas, só tem pessoas com o mesmo dia de aniversário}.
Seja $A$ conjunto de $k+1$ pessoas:
$$
A = \set{ p_0, p_1, \dotsc, p_{k-1}, p_k }.
$$
Considere os conjunto
$$
\align
A'  &= \set{ p_0, p_1, \dotsc, p_{k-1} } \\
A'' &= \set{      p_1, \dotsc, p_{k-1}, p_k }.
\endalign
$$
Ambos os $A', A''$ têm $k$ pessoas, e logo pela hipótese indutiva todos os membros de $A'$ têm o mesmo aniversário entre si; e também todos os membros de $A''$ têm o mesmo aniversário entre si.
Como a pessoa $p_1$ está no $A'$, todos os membros de $A'$ têm o mesmo aniversário com o $p_1$.
Mas a pessoa $p_1$ também etsá no $A''$, e logo todos os membros de $A''$ têm o mesmo aniversário com o $p_1$.
Ou seja:
todos os $p_0, p_1, \dotsc, p_{k-1}, p_k$ têm aniversario no mesmo dia.>>
\endquote
Numa maneira parecida podemos demonstrar várias afirmações doidas, como por exemplo a seguinte:
\quote
<<Para todo $n$ natural, em qualquer conjunto de $n$ cavalos, só tem cavalos da mesma cor.>>
\endquote
Obviamente o que ``demonstramos'' é errado, e logo na demonstração existe pelo menos um erro---%
caso contrário seria uma indicação que o princípio da indução não é válido!
Qual é?

\endproblem
%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

Mais informações sobre indução e indução forte,
veja o~\cite[Cap.~6]{velleman}.
Sobre o princípio da boa ordem e indução,
veja o~\cite[\S\S1.4--1.5]{babybm}

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Enumerative_combinatorics 
\chapter Combinatória enumerativa.
\label{Enumerative_combinatorics}%

%%{{{ Counting principles 
\section Princípios de contagem.

%%{{{ Informally 
\note Informalmente.
Queremos contar todas as maneiras possíveis para algo acontecer,
certas configurações, certos objetos ser escolhidos, ou ordenados, etc.
Baseamos nossas idéia em dois princípios de contagem:
da \emph{adição} e da \emph{multiplicação}.
\endgraf
{O princípio da adição, informalmente:}
Se podemos agrupar todos esses objetos em grupos \emph{distintos},
tais que cada objeto pertence em \emph{exatamente um} grupo,
o número total dos objetos é igual o somatório dos tamanhos dos grupos.
\endgraf
{O princípio da multiplicação, informalmente:}
Se cada configuração pode ser descrita completamente em $n$ passos,
onde para o primeiro passo temos $a_1$ opções,
para o segundo passo temos $a_2$ opções, etc., e
\emph{em cada passo a quantidade das opções disponíveis
não depende nas escolhas anteriores},
então existem em total $a_1a_2\dotsb a_n$ configurações possíveis.
%%}}}

%%{{{ principle: principle_of_addition 
\principle da adição.
\label{principle_of_addition}%
\tdefined{princípio}[da adição]
Seja $A$ conjunto finito, e $A_1,\dotsc,A_n$ subconjuntos dele tais que cada elemento $a\in A$, pertence em \emph{exatamente} um dos $A_i$.
Logo,
$$
|A| = \Sum_{i=1}^n |A_i|.
$$
%%}}}

%%{{{ principle: principle_of_multiplication 
\principle da multiplicação.
\label{principle_of_multiplication}%
\tdefined{princípio}[da multiplicação]
Sejam $A_1,\dotsc,A_n$ conjuntos finitos.
Logo
$$
|A_1\times\dotsb\times A_n| = |A_1|\dotsb|A_n|.
$$
%%}}}

%%{{{ eg 
\example.
De quantas maneiras podemos escrever um string de tamanho $3$\dots
\item{(i)} Usando o alfabeto
$$
\set{\txt A, \txt B, \txt C, \dotsc, \txt X, \txt Y, \txt Z}?
$$
\item{(ii)} Usando o mesmo alfabeto, mas proibindo o mesmo caractere se repetir no string?

\solution
Consideramos a formação de cada string em passos, caractere a caractere.
Temos 3 posições para colocar os caracteres:
$
\underline{\phantom{\txt Z}}
\;
\underline{\phantom{\txt Z}}
\;
\underline{\phantom{\txt Z}}
\;
$.
\endgraf
Para a questão (i), temos:
$26$ maneiras para escolher o primeiro caractere,
$26$ para o segundo, e
$26$ para o último:
$$
\underbrace{
\underline{\phantom{\txt Z}}
}_{26}
\;
\underbrace{
\underline{\phantom{\txt Z}}
}_{26}
\;
\underbrace{
\underline{\phantom{\txt Z}}
}_{26}
\;.
$$
A escolha em cada passo não é afeitada por as escolhas dos passos anteriores.
Logo, pelo princípio da multiplicação tem
$$
26\ntimes 26\ntimes 26 = 26^3
$$
strings possíveis.
\endgraf
Para a questão (ii), temos:
$26$ maneiras para escolher o primeiro caractere,
$25$ para o segundo (todos menos aquele que escolhemos no passo anterior), e
$24$ para o último (similarmente):
$$
\underbrace{
\underline{\phantom{\txt Z}}
}_{26}
\;
\underbrace{
\underline{\phantom{\txt Z}}
}_{25}
\;
\underbrace{
\underline{\phantom{\txt Z}}
}_{24}
\;.
$$
Agora a escolha em cada passo realmente \emph{é afeitada} por as escolhas
dos passos anteriores!
Por exemplo, se no primeiro passo escolher o caractere $\txt C$, para
o segundo passo as opções incluem o caractere $\txt A$; 
mas se no primeiro passo escolher o caractere $\txt A$, as opções para o segundo
mudam: não temos essa opção mais.
\emph{Mesmo assim, podemos usar o princípio da multiplicação!}
Por quê?
As escolhas dos passos anteriores afeitam \emph{quais} são as escolhas do passo atual,
mas não afeitam \emph{quantas} elas são!
Por isso, chegamos no resultado aplicando mais uma vez o princípio da multiplicação:
temos
$$
26\ntimes 25\ntimes 24
$$
maneiras possíveis.
\endexample
%%}}}

%%{{{ x: 4 gifts for 3 kids 
\exercise.
Temos $4$ presentes e queremos dar para $3$ crianças tal que cada criança vai
receber apenas um presente.
\item{(i)} De quantas maneiras podemos disribuir os presentes para as crianças?
\item{(ii)} O que muda se as crianças são $4$?  Explique.

\endexercise
%%}}}

%%{{{ x: in how many ways can we write strings of length 2 using ABCD 
\exercise.
De quantas maneiras podemos escrever strings de tamanho $2$ usando o alfabeto
$$
\set{\txt A, \txt B, \txt C, \txt D},
$$
tais que as letras aparecem em ordem que concorda com a do alfabeto?
Por exemplo os string $\txt A \txt C$, $\txt B \txt B$, e $\txt C \txt D$ são aceitáveis,
mas os $\txt D \txt C$ e $\txt B \txt A$, não.

\hint
Cuidado: aqui a \emph{quantidade} das opções da segunda escolha, depende sim na escolha
anterior!

\hint
Separa os strings possíveis em colecções e conta os strings de cada colecção separadamente,
somando no final (princípio de adição) para achar o resultado.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Permutations and combinations 
\section Permutações e combinações.
\label{Permutations_and_combinations}%

%%{{{ Q: in how many ways can we choose r from n? 
\question.
De quantas maneiras podemos escolher $r$ objetos de $n$?
%%}}}

\blah.
Essa questão é bastante ambígua;
por exemplo:
Os $n$ objetos são todos distintos?
Podemos repetir o mesmo objeto na nossa escolha?

%%{{{ df: comb_perm_totperm 
\definition.
\label{comb_perm_totperm}%
\sdefined {\totperm {\sholed n}} {o número de permutações (totais) de $n$ objetos}%
\sdefined {\perm {\sholed n} {\sholed r}} {o número de $r$-permutações de $n$ objetos}%
\sdefined {\comb {\sholed n} {\sholed r}} {o número de $r$-combinações de $n$ objetos}%
Usamos os símbolos:
$$
\align
\totperm n &:\quad\text{o número de permutações totais de $n$ objetos}\\
\perm n r  &:\quad\text{o número de $r$-permutações de $n$ objetos}\\
\comb n r  &:\quad\text{o número de $r$-combinações de $n$ objetos}
\endalign
$$
Onde entendemos que:
\beginol
\li os $n$ objetos são distíntos;
\li não podemos repeti-los.
\endol
Observe que as permutações totais são apenas casos especiais de $r$-permutações.
Na literatura encontramos $r$-permutações também com o nome \dterm{arranjos},
mas nos vamos evitar esse termo aqui para evitar confusão.
%%}}}

%%{{{ prop: total_permutations 
\proposition Permutações totais.
\label{total_permutations}%
\tdefined{permutação}[total]%
{\iisee{arranjo}{permutação}}%
$$
\totperm n = {n!}.
$$
%%}}}

%%{{{ prop: permutations 
\proposition Permutações.
\tdefined{permutação}
$$
\perm n r = \frac {n!} {(n-r)!}.
$$
%%}}}

%%{{{ prop: combinations 
\proposition Combinações.
\tdefined{combinação}
$$
\comb n r = \frac {n!} {(n-r)!\stimes r!}.
$$
%%}}}

%%{{{ eg: 10_friends_car_trip 
\example.
\label{10_friends_car_trip}%
10 amigos têm vontade viajar com um carro de 5 vagas.
De quantas maneiras diferentes 5 deles podem entrar no carro?
Considere que o que diferencia mesmo a configuração são apenas a posição
do motorista e do copiloto.

\solution
Vamos ver dois jeitos diferentes para contar essas configurações:
\endgraf
\proofstyle{\indent Jeito 1:}
Escrevendo
$$
\comb {10} 1
\ntimes
\comb 9 1
\ntimes
\comb 8 3
$$
já é meio auto-explicativo: formamos cada configuração em passos:
{(i)}      escolher o motorista;
{(ii)}     escolher o copiloto;
{(iii)}    escolher os passangeiros de trás.
\endgraf
\proofstyle{\indent Jeito 2:}
Outra método para formar cada configuração seria:
{(i)}      escolher os 5 que vão entrar no carro;
{(ii)}     escolher qual vai ser o motorista;
{(iii)}    escolher qual vai ser o copiloto.
pensando assim chegamos no cálculo
$$
\tunderbrace{\comb {10} 5} {(i)}
\ntimes
\tunderbrace{\comb 5 1} {(ii)}
\ntimes
\tunderbrace{\comb 4 1} {(iii)}.
$$
\endgraf
Olhando para os dois cálculos
$$
\comb {10} 1 \ntimes \comb 9 1 \ntimes \comb 8 3
\askeq
\comb {10} 5 \ntimes \comb 5 1 \ntimes \comb 4 1
$$
não é óbvio que seus valores são iguais.
Calculamos
$$
\alignat2
\comb {10} 1 \ntimes \comb 9 1 \ntimes \comb 8 3
&= 10 \ntimes 9 \ntimes \frac {8!} {5!\stimes3!}
&&= \frac {10!} {5!\stimes3!}
\\
\comb {10} 5 \ntimes \comb 5 1 \ntimes \comb 4 1
&= \frac {10!} {5!\stimes 5!} \ntimes 5 \ntimes 4
&&= \frac {10!} {5!\stimes 3!}
\endalignat
$$
e respondemos (felizmente) que em total temos
$$
\frac {10!} {5!\stimes3!}
= \frac{10 \ntimes 9 \ntimes 8\ntimes7\ntimes6} { 3! }
= 10 \ntimes 9 \ntimes 8\ntimes7
= 5040
$$
configurações diferentes.
\endexample
%%}}}

\endsection
%%}}}

%%{{{ Permutations in a circle 
\section Permutações cíclicas.

%%{{{ eg: circle_dance_of_8 
\example.
\label{circle_dance_of_8}%
$8$ pessoas querem dançar uma dança em qual
todos precisam formar um ciclo pegando as mãos
(e olhando para o interior do ciclo).
Em quantas configurações diferentes essa dança pode começar?

\solution
Vamos resolver esse problema seguindo duas idéias bem diferentes:
\endgraf
\proofstyle{\indent Idéia~1.}
Consideramos primeiro a questão:
``\emph{de quantas maneiras podemos permutar as $8$ pessoas numa ordem?}''
Respondemos $8!$, o número das permutações totais de $8$ objetos
(sabendo que hipercontamos para o problema original).
Mas podemos calcular que cada resposta do problema original,
corresponde em exatamente $8$ respostas do problema novo
(uma para cada ``circular shift'').
Então basta só dividir a ``hiperconta'' por $8$, e chegamos
no resultado final: $8! / 8$, ou seja, $7!$.
\endgraf
\proofstyle{\indent Idéia~2.}
\emph{Fixamos uma pessoa como ``determinante'' da configuração;}
a idéia sendo que para comparar duas configurações nos vamos
começar com o determinante, e depois comparar em ordem fixa
o resto da configuração
(por exemplo indo cada vez de uma pessoa
para quem tá no lado direito dela).
Assim, para cada permutação total das 7 outras pessoas,
temos uma permutação circular das 8 e vice-versa,
ou seja, a resposta final é $7!$.
\endexample
%%}}}

%%{{{ fig for circle_dance_of_8 
\midinsert
\hfil
\tikzpicture[scale=0.8]%%{{{
\draw (0,0) circle (2cm);
\foreach \t in {0,45,90,135,180,225,270,315}
    \node[circle,fill=white] (a\t) at (\t:2cm) {$\phantom{p_0}$};
\node[circle,fill=white] at (a0)   {$p_0$};
\node[circle,fill=white] at (a45)  {$p_1$};
\node[circle,fill=white] at (a90)  {$p_2$};
\node[circle,fill=white] at (a135) {$p_3$};
\node[circle,fill=white] at (a180) {$p_4$};
\node[circle,fill=white] at (a225) {$p_5$};
\node[circle,fill=white] at (a270) {$p_6$};
\node[circle,fill=white] at (a315) {$p_7$};
\endtikzpicture
%%}}}
\hfil
\tikzpicture[scale=0.8]%%{{{
\draw (0,0) circle (2cm);
\foreach \t in {0,45,90,135,180,225,270,315}
    \node[circle,fill=white] (a\t) at (\t:2cm) {$\phantom{a_0}$};
\node[circle,fill=white] at (a315)  {$p_0$};
\node[circle,fill=white] at (a0)    {$p_1$};
\node[circle,fill=white] at (a45)   {$p_2$};
\node[circle,fill=white] at (a90)   {$p_3$};
\node[circle,fill=white] at (a135)  {$p_4$};
\node[circle,fill=white] at (a180)  {$p_5$};
\node[circle,fill=white] at (a225)  {$p_6$};
\node[circle,fill=white] at (a270)  {$p_7$};
\endtikzpicture
%%}}}
\hfil
\endgraf\centerline{Uma configuração do~\refn{circle_dance_of_8} representada em dois jeitos diferentes no papel.}
\endinsert
%%}}}

\blah.
Generalizando concluimos que:

%%{{{ prop: permutations_in_circle 
\proposition.
\label{permutations_in_circle}%
As configurações circulares diferentes de $n$ objetos, $n>0$ são
$$
(n-1)!.
$$
%%}}}

%%{{{ x: circle_dance_of_8_inorout 
\exercise.
\label{circle_dance_of_8_inorout}%
O que mudará na contagem do~\ref{circle_dance_of_8},
se cada dançador pode olhar ou para o interior ou para o exterior do círculo?

\hint
Começando com a mesma resposta ($7!$) do~\ref{circle_dance_of_8},
claramente nos hipocontamos---mas quanto?

\hint
Considere uma configuração do~\ref{circle_dance_of_8}.
Com quantas configurações do problema atual ela corresponde?

\endexercise
%%}}}

%%{{{ x: circle_dance_of_8_couples 
\exercise.
\label{circle_dance_of_8_couples}%
O que mudará na contagem do~\ref{circle_dance_of_8},
se temos $4$ mulheres e $4$ homens e as regras da dança
mandam alternar os sexos na configuração?

\hint
Construa cada configuração em passos.

\hint
Primeiramente, esqueça os homens (ou as mulheres)
e coloca as $4$ mulheres (ou os $4$ homens)
num ciclo.
De quantas maneiras pode escolher o resto para
entrar no círculo?

\endexercise
%%}}}

%%{{{ x: 8_bead_bracelet 
\exercise.
Temos $8$
miçangas
diferentes, e queremos pôr todas
numa
corrente
para criar uma pulseira.
Quantas maneiras diferentes temos para o criar?

\hint
Se tu achar o problema igual com o~\ref{circle_dance_of_8},
tu hipercontarás\dots Quanto?

\hint
Veja a figura.
Pode explicar por que as três representações
correspondem na mesma configuração?
\topinsert
\centerline{
\tikzpicture[scale=0.8]%%{{{
\draw (0,0) circle (2cm);
\foreach \t in {0,45,90,135,180,225,270,315}
    \node[circle,fill=white] (a\t) at (\t:2cm) {$\phantom{a_0}$};
\node[circle,fill=red!33]       at (a0)   {$a_0$};
\node[circle,fill=green!33]     at (a45)  {$a_1$};
\node[circle,fill=blue!33]      at (a90)  {$a_2$};
\node[circle,fill=cyan!33]      at (a135) {$a_3$};
\node[circle,fill=magenta!33]   at (a180) {$a_4$};
\node[circle,fill=yellow!33]    at (a225) {$a_5$};
\node[circle,fill=orange!33]    at (a270) {$a_6$};
\node[circle,fill=brown!33]     at (a315) {$a_7$};
\endtikzpicture
%%}}}
\hfil
\tikzpicture[scale=0.8]%%{{{
\draw (0,0) circle (2cm);
\foreach \t in {0,45,90,135,180,225,270,315}
    \node[circle,fill=white] (a\t) at (\t:2cm) {$\phantom{a_0}$};
\node[circle,fill=red!33]       at (a315)  {$a_0$};
\node[circle,fill=green!33]     at (a0)    {$a_1$};
\node[circle,fill=blue!33]      at (a45)   {$a_2$};
\node[circle,fill=cyan!33]      at (a90)   {$a_3$};
\node[circle,fill=magenta!33]   at (a135)  {$a_4$};
\node[circle,fill=yellow!33]    at (a180)  {$a_5$};
\node[circle,fill=orange!33]    at (a225)  {$a_6$};
\node[circle,fill=brown!33]     at (a270)  {$a_7$};
\endtikzpicture
%%}}}
\hfil
\tikzpicture[scale=0.8]%%{{{
\draw (0,0) circle (2cm);
\foreach \t in {0,45,90,135,180,225,270,315}
    \node[circle,fill=white] (a\t) at (\t:2cm) {$\phantom{a_0}$};
\node[circle,fill=red!33]       at (a315)  {$a_0$};
\node[circle,fill=green!33]     at (a270)  {$a_1$};
\node[circle,fill=blue!33]      at (a225)  {$a_2$};
\node[circle,fill=cyan!33]      at (a180)  {$a_3$};
\node[circle,fill=magenta!33]   at (a135)  {$a_4$};
\node[circle,fill=yellow!33]    at (a90)   {$a_5$};
\node[circle,fill=orange!33]    at (a45)   {$a_6$};
\node[circle,fill=brown!33]     at (a0)    {$a_7$};
\endtikzpicture
%%}}}
}
\botcaption{}
\emph{Apenas uma} das configurações da pulseira, representada em três desenhos.
\endcaption
\endinsert

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Together or separated 
\section Juntos ou separados.

%%{{{ x: dinner_of_8_with_couple 
\example.
\label{dinner_of_8_with_couple}%
Suponha que $8$ pessoas $A,B,C,D,E,F,G,H$ querem sentar num bar
mas $C$ e $D$ querem sentar juntos.
De quantas maneiras isso pode acontecer?

\solution
\emph{Vamos imaginar que $C$ e $D$ são uma pessoa, chamada $CD$.}
Nos perguntamos de quantas maneiras as 7 pessoas $A,B,CD,E,F,G,H$ podem sentar
numa mesa de bar com $7$ banquinhos.
A resposta é os permutações totais de tamanho 7, ou seja, $7!$.
Mas para cada configuração desse problema,
correspondem \emph{duas} configurações do problema original, porque os
$C$ e $D$ podem sentar em duas ordens diferentes juntos.
A resposta final:
$7! \ntimes 2$.
\endexample
%%}}}

%%{{{ x: 8_persons_are_sitting_on_a_bar 
\exercise.
Suponha que 8 pessoas $A,B,C,D,E,F,G,H$ querem jantar numa mesa de bar.
Em quantas configurações diferentes eles podem sentar se\dots:
\item{(1)} os $C$ e $D$ e $E$ querem sentar juntos;
\item{(2)} os $F$ e $G$ não podem sentar juntos;
\item{(3)} as duas restricções (1) e (2).

\hint
\item{(1)} Como no \ref{dinner_of_8_with_couple},
           considere o problema onde $C$, $D$, e $E$ são uma pessoa só.
\item{(2)} Conte o complementar e subtraia do total sem restricção;
\item{(3)} Conte as configurações em quais $C$, $D$, e $E$ sentam juntos e subtraia
           as configurações onde, alem disso, $F$ e $G$ também sentam juntos.

\solution
(1) Como no \ref{dinner_of_8_with_couple}, traduzimos o problema para um onde
$C$, $D$, e $E$, são uma pessoa---vamos chamá-la de $CDE$---e as
$6$ pessoas $A,B,CDE,F,G,H$ querem jantar numa mesa de bar com 6 banquinhos.
Cada solução desse problema corresponde em tantas configurações quantas as $3$ pessoas
$C$, $D$, $E$ podem sentar numa ordem, ou seja $\totperm 3$ configurações.
A resposta final:
$$
\totperm 6 \ntimes \totperm 3 = 6!\stimes3! = 6!\stimes 6
$$
\endgraf
(2) Contamos o complementar:
todas as maneiras onde $F$ e $G$ sentam juntos ($7!\ntimes 2$),
e o tiramos de todas as maneiras sem restricção ($8!$):
$$
\totperm 8 - \totperm 7 \ntimes \totperm 2
= 8! - 7!\ntimes 2! = 7!(8 - 2)
= 7!\stimes 6
$$
(3) Já achamos quantas maneiras tem onde $C$, $D$, e $E$ sentam juntos: $6!\stimes6$.
Disso, precisamos subtrair as configurações onde $F$ e $G$ também sentam juntos:
para satisfazer as duas restricções, consideramos as $5$ ``pessoas''
$A,B,CDE,FG,H$, quais podem sentar numa mesa de bar de tamanho $5$ de
$$
\totperm 5 \stimes \totperm 3 \stimes \totperm 2
= 5! \stimes 3! \stimes 2!
= 5! \stimes 6 \stimes 2
= 6! \stimes 2
$$
maneiras.
A resposta final então é
$$
6!\stimes6 - 6!\stimes2 = 6!(6-2) = 6! \stimes 4.
$$

\endexercise
%%}}}

\blah.
Generalizando:

%%{{{ prop: total_permutations_with_consecutives_restriction 
\proposition.
O número das permutações totais de $m$ objetos distintos com a restricção que
certos $c$ deles tem que estar consecutivos é
$$
(m-c+1)! \stimes c!.
$$
%%}}}

\endsection
%%}}}

%%{{{ Permutations of things not all distinct 
\section Permutações de objetos não todos distintos.

%%{{{ Q: in how many ways can we permute n not-all-distinct objects? 
\question.
De quantas maneiras podemos permutar $n$ objetos se
eles não são todos distíntos?
%%}}}

%%{{{ eg: pessimissimo 
\example.
\label{pessimissimo}%
Conte todas as palavras feitas por permutações das 12 letras da palavra
$$
\txt{PESSIMISSIMO}.
$$

\solution
Vamos contar em dois jeitos diferentes:
\endgraf
\proofstyle{Idéia 1:}
Construimos cada palavra possível ``em passos'',
usando o princípio da multplicação para achar o número total.
$$
\alignat 2
\text{Começamos com 12 espaços:}
\qquad&
\underline{\phantom {\txt M}} \ 
\underline{\phantom {\txt I}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt I}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt I}} \ 
\underline{\phantom {\txt P}} \ 
\underline{\phantom {\txt O}} \ 
\underline{\phantom {\txt E}} \ 
\underline{\phantom {\txt M}}
\\
\text{escolhemos onde colocar o ${\txt P}$:}
\qquad&
\underline{\phantom {\txt M}} \ 
\underline{\phantom {\txt I}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt I}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt I}} \ 
          {         {\txt P}} \ 
\underline{\phantom {\txt O}} \ 
\underline{\phantom {\txt E}} \ 
\underline{\phantom {\txt M}}
&\qquad&
\text{tivemos $\comb {12} 1$ opções;}
\\
\text{depois o ${\txt E}$:}
\qquad&
\underline{\phantom {\txt M}} \ 
\underline{\phantom {\txt I}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt I}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt I}} \ 
          {         {\txt P}} \ 
\underline{\phantom {\txt O}} \ 
          {         {\txt E}} \ 
\underline{\phantom {\txt M}}
&\qquad&
\text{tivemos $\comb {11} 1$ opções;}
\\
\text{depois os 4 ${\txt S}$:}
\qquad&
\underline{\phantom {\txt M}} \ 
\underline{\phantom {\txt I}} \ 
          {         {\txt S}} \ 
          {         {\txt S}} \ 
\underline{\phantom {\txt I}} \ 
          {         {\txt S}} \ 
          {         {\txt S}} \ 
\underline{\phantom {\txt I}} \ 
          {         {\txt P}} \ 
\underline{\phantom {\txt O}} \ 
          {         {\txt E}} \ 
\underline{\phantom {\txt M}}
&\qquad&
\text{tivemos $\comb {10} 4$ opções;}
\\
\text{depois os 3 ${\txt I}$:}
\qquad&
\underline{\phantom {\txt M}} \ 
          {         {\txt I}} \ 
          {         {\txt S}} \ 
          {         {\txt S}} \ 
          {         {\txt I}} \ 
          {         {\txt S}} \ 
          {         {\txt S}} \ 
          {         {\txt I}} \ 
          {         {\txt P}} \ 
\underline{\phantom {\txt O}} \ 
          {         {\txt E}} \ 
\underline{\phantom {\txt M}}
&\qquad&
\text{tivemos $\comb 6 3$ opções;}
\\
\text{depois os 2 ${\txt M}$:}
\qquad&
          {         {\txt M}} \ 
          {         {\txt I}} \ 
          {         {\txt S}} \ 
          {         {\txt S}} \ 
          {         {\txt I}} \ 
          {         {\txt S}} \ 
          {         {\txt S}} \ 
          {         {\txt I}} \ 
          {         {\txt P}} \ 
\underline{\phantom {\txt O}} \ 
          {         {\txt E}} \ 
          {         {\txt M}}
&\qquad&
\text{tivemos $\comb 3 2$ opções;}
\\
\text{e finalmente o ${\txt O}$:}
\qquad&
          {         {\txt M}} \ 
          {         {\txt I}} \ 
          {         {\txt S}} \ 
          {         {\txt S}} \ 
          {         {\txt I}} \ 
          {         {\txt S}} \ 
          {         {\txt S}} \ 
          {         {\txt I}} \ 
          {         {\txt P}} \ 
          {         {\txt O}} \ 
          {         {\txt E}} \ 
          {         {\txt M}}
&\qquad&
\text{tivemos $\comb 1 1$ opção.}
\endalignat
$$
Pelo princípio da multiplicação, a resposta é o produto
$$
\align
\underbrace{\comb {12} 1}_{\dsize {\txt P}}
\underbrace{\comb {11} 1}_{\dsize {\txt E}}
\underbrace{\comb {10} 4}_{\dsize4{\txt S}}
\underbrace{\comb {6}  3}_{\dsize3{\txt I}}
\underbrace{\comb {3}  2}_{\dsize2{\txt M}}
\underbrace{\comb {1}  1}_{\dsize {\txt O}}
&=
\frac
{12!}
{\cancel{11!}\stimes 1!}
\frac
{\cancel{11!}}
{\cancel{10!}\stimes 1!}
\frac
{\cancel{10!}}
{\cancel{6!}\stimes 4!}
\frac
{\cancel{6!}}
{\cancel{3!}\stimes 3!}
\frac
{\cancel{3!}}
{\cancel{1!}\stimes 2!}
\frac
{\cancel{1!}}
{0!\stimes 1!}\\
&=
\frac
{12!}
{1!
\stimes 1!
\stimes 4!
\stimes 3!
\stimes 2!
\stimes 1!
}
=
\frac
{12!}
{
4!
\stimes 3!
\stimes 2!
}.
\endalign
$$
\endgraf
\proofstyle{Idéia 2:}
Contamos as maneiras se todas as letras fossem distintas,
por exemplo marcando cada letra com índices:
$$
{\txt P}_1\ 
{\txt E}_1\ 
{\txt S}_1\ 
{\txt S}_2\ 
{\txt I}_1\ 
{\txt M}_1\ 
{\txt I}_2\ 
{\txt S}_3\ 
{\txt S}_4\ 
{\txt I}_3\ 
{\txt M}_2\ 
{\txt O}_1\,.
$$
Sabemos que são $12!$ e que
assim temos \emph{hipercontado} para nosso problema.
Por exemplo, a palavra 
$
{\txt M}
{\txt I}
{\txt S}
{\txt S}
{\txt I}
{\txt S}
{\txt S}
{\txt I}
{\txt P}
{\txt O}
{\txt E}
{\txt M}
$
corresponde em várias palavras do problema novo;
escrevemos três delas aqui como exemplos:
$$
{\txt M}\ 
{\txt I}\ 
{\txt S}\ 
{\txt S}\ 
{\txt I}\ 
{\txt S}\ 
{\txt S}\ 
{\txt I}\ 
{\txt P}\ 
{\txt O}\ 
{\txt E}\ 
{\txt M}
\ 
\transto
\ 
\brace{
\gathered
{\txt M}_1\ 
{\txt I}_1\ 
{\txt S}_1\ 
{\txt S}_2\ 
{\txt I}_2\ 
{\txt S}_3\ 
{\txt S}_4\ 
{\txt I}_3\ 
{\txt P}_1\ 
{\txt O}_1\ 
{\txt E}_1\ 
{\txt M}_2
\\
{\txt M}_2\ 
{\txt I}_1\ 
{\txt S}_1\ 
{\txt S}_2\ 
{\txt I}_2\ 
{\txt S}_3\ 
{\txt S}_4\ 
{\txt I}_3\ 
{\txt P}_1\ 
{\txt O}_1\ 
{\txt E}_1\ 
{\txt M}_1
\\
{\txt M}_2\ 
{\txt I}_1\ 
{\txt S}_4\ 
{\txt S}_3\ 
{\txt I}_2\ 
{\txt S}_2\ 
{\txt S}_1\ 
{\txt I}_3\ 
{\txt P}_1\ 
{\txt O}_1\ 
{\txt E}_1\ 
{\txt M}_1
\\
\vdots
\endgathered
\quad\qquad
}
\ \text{\dots quantas?}
$$
Mas é fácil calcular quanto hipercontamos:
\emph{cada} palavra do problema original corresponde em exatamente tantas palavras
quantas as maneiras de permutar cada grupo de letras ``subindicadas'' entre si,
ou seja:
$$
\underbrace{1!}_{{\txt P}} \ntimes
\underbrace{1!}_{{\txt E}} \ntimes
\underbrace{4!}_{{\txt S}} \ntimes
\underbrace{3!}_{{\txt I}} \ntimes
\underbrace{2!}_{{\txt M}} \ntimes
\underbrace{1!}_{{\txt O}}
$$
maneiras.
Para responder então, basta dividir o número da ``hipercontagem'' por esse:
$$
\frac
{12!}
{4!\stimes 3!\stimes 2!}.
$$
\moveqedup
\endexample
%%}}}

%%{{{ x: choices_may_depend_on_past_ones_but_not_their_quantity 
\exercise.
\label{choices_may_depend_on_past_ones_but_not_their_quantity}%
Escolhendo outra ordem de colocar as letras
na \proofstyle{Idéia 1} do~\ref{pessimissimo}
nossas opções em cada passo seriam diferentes.
Explique porque podemos usar o princípio da multiplicação mesmo assim.

\hint
Presta atenção na frase
``\emph{em cada passo a quantidade das opções disponíveis
não depende nas escolhas anteriores}''.

\solution
O imporante é que em cada passo, qual das nossas disponíveis opções
será escolhida, não vai afeitar a quantidade das nossas opções no passo seguinte.
Isso é realmente valido nesse caso.
Se escolher colocar as letras em outra ordem, por exemplo a
$
{\txt S},
{\txt E},
{\txt I},
{\txt P},
{\txt O},
{\txt M}
$, teriamos quantidades diferentes para cada passo sim,
\emph{mas}\/:
cada uma das nossas escolhas, não afeitaria a quantidade das escolhas próximas.
Com essa ordem, chegamos no mesmo resultado (com um cálculo que de longe aparece diferente):
$$
\align
\underbrace{\comb {12} 4}_{\dsize4{\txt S}}
\underbrace{\comb {8}  1}_{\dsize {\txt E}}
\underbrace{\comb {7}  3}_{\dsize3{\txt I}}
\underbrace{\comb {4}  1}_{\dsize {\txt P}}
\underbrace{\comb {3}  1}_{\dsize {\txt O}}
\underbrace{\comb {2}  2}_{\dsize2{\txt M}}
&=
\frac
{12!}
{\cancel{8!}\stimes 4!}
\frac
{\cancel{8!}}
{\cancel{7!}\stimes 1!}
\frac
{\cancel{7!}}
{\cancel{4!}\stimes 3!}
\frac
{\cancel{4!}}
{\cancel{3!}\stimes 1!}
\frac
{\cancel{3!}}
{\cancel{2!}\stimes 1!}
\frac
{\cancel{2!}}
{0!\stimes 2!}\\
\vphantom{
\underbrace{\comb {12} 4}_{\dsize4{\txt S}}
\underbrace{\comb {8}  1}_{\dsize {\txt E}}
\underbrace{\comb {7}  3}_{\dsize3{\txt I}}
\underbrace{\comb {4}  1}_{\dsize {\txt P}}
\underbrace{\comb {3}  1}_{\dsize {\txt O}}
\underbrace{\comb {2}  2}_{\dsize2{\txt M}}
}
&=
\frac
{12!}
{4!
\stimes 1!
\stimes 3!
\stimes 1!
\stimes 1!
\stimes 2!
}\\
&=
\frac
{12!}
{
4!
\stimes 3!
\stimes 2!
}.
\endalign
$$

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Binomial coefficients 
\section Binomial e seus coeficientes.

%%{{{ thm: binomial_theorem 
\theorem Binomial.
\label{binomial_theorem}%
\ii{teorema}[binomial]%
\iisee{binomial}[teorema]{teorema binomial}%
Sejam $x,y\in\ints$ e $n\in\nats$.
$$
\align
(x+y)^n
&= \binom n 0 x^n + \binom n 1 x^{n-1}y + \dotsb + \binom n {n-1} xy^{n-1} + \binom n n y^n\\
&= \Sum_{i=0}^n \binom n i x^{n-i}y^i.
\endalign
$$
\sketch.
Queremos achar quantas vezes o termo $x^{n-r}y^r$ aparece na expansão do binomial.
Escrevendo
$$
(x+y)^n = \underbrace{(x+y)(x+y)\dotsb(x+y)}_{\text{$n$ vezes}}
$$
observamos que para cada das $\comb n r$ maneiras de escolher $r$ dos termos acima,
corresponde um termo $x^{n-r}y^r$:
``escolha quais dos termos do produto vão oferecer seu $y$
(o resto dos termos oferecerá seus $x$'s)''.
Isso justifica os coeficientes $\binom n r$.
Por exemplo, para $n=7$ e $r=4$, a escolha
$$
(x+y)^7
=
(x+y)
\underbrace{(x+y)}_{\text{``$y$''}}\,
(x+y)
\underbrace{(x+y)}_{\text{``$y$''}}
\underbrace{(x+y)}_{\text{``$y$''}}\,
(x+y)
\underbrace{(x+y)}_{\text{``$y$''}}
$$
corresponde no produto
$xyxyyxy = x^3y^4$, e cada diferente escolha das $\binom 7 4$
correspondará com uma maneira diferente para formar o $x^3y^4$.
\qes
%%}}}

\endsection
%%}}}

%%{{{ Number of subsets 
\section Número de subconjuntos. 
\label{Number_of_subsets}%

%%{{{ Q: how many subsets of a finite set? 
\question.
Quantos subconjuntos dum conjunto finito existem?
%%}}}

%%{{{ Idea 1: subset_count_using_strings 
\note Idéia 1.
\label{subset_count_using_strings}%
Começamos com um exemplo de um conjunto $A$ de tamanho 6:
$$
A = \set{a, b, c, d, e, f}.
$$
Uns subconjuntos de $A$ são os:
$$
\set{a,d,e},
\qquad
\emptyset,
\qquad
\set{a},
\qquad
\set{b,c,e,f},
\qquad
A,
\qquad
\set{f},
\qquad
\dotsc
$$
Queremos contar todos os subconjuntos de $A$.
Vamos \emph{traduzir o problema} de contar os subconjuntos do $A$
para um problema que envolve $n$-tuplas de dois símbolos ``0'' e ``1'', ``sim'' e ``não'', ``$\in$'' e ``$\notin$'', etc.
(Obviamente \emph{quais} são esses símbolos não afeita nada; o que importa é
que são dois símbolos distintos.)
Podemos associar agora cada dessas tuplas (ou strings) de tamanho $n$ para um
subconjunto de $A$, e vice-versa, chegando numa correspondência entre as duas
colecções de objetos.
Naturalmente associamos, por exemplo,
$$
\def\Y{1}
\def\N{0}
\underbrace{
\matrix
a  & b  & c  & d  & e  & f \\
\Y & \N & \N & \Y & \Y & \N\\
\N & \N & \N & \N & \N & \N\\
\Y & \N & \N & \N & \N & \N\\
\N & \Y & \Y & \N & \Y & \Y\\
\Y & \Y & \Y & \Y & \Y & \Y\\
\N & \N & \N & \N & \N & \Y\\
\vdots&
\vdots&
\vdots&
\vdots&
\vdots&
\vdots
\endmatrix
}_{\text{Strings de tamanho 6 do alfabeto $\set{\N,\Y}$}}
\quad\bitrans\quad
\underbrace{
\matrix
\format
\c\\
\\
\set{a,d,e}\\
\emptyset\\
\set{a}\\
\set{b,c,e,f}\\
A\\
\set{f}\\
\vdots
\endmatrix
}_{\text{Subconjuntos de $A$}}
$$
e verificamos que realmente cada configuração do problema original de subconjuntos
corresponde exatamente numa configuração do problema novo dos strings e vice-versa.
\endgraf
\emph{O que ganhamos?}
Sabemos como contar todos esses strings: são $2^6$.
Concluimos que os subconjuntos do $A$ são $2^6$ também.
%%}}}

\blah.
Generalizando essa idéia chegamos no resultado:

%%{{{ prop: number_of_subsets_of_finite_set_as_power 
\proposition.
\label{number_of_subsets_of_finite_set_as_power}%
Seja $A$ conjunto finito.
$$
\card{\pset A} = 2^{\card A}.
$$
%%}}}

%%{{{ Idea 2: subset_count_by_grouping 
\note Idéia 2.
\label{subset_count_by_grouping}%
Um outro jeito para contar todos os subconjuntos dum dado conjunto $A$, seria
os separar em grupos baseados no seu tamanho.
Assim, percebos que esses subconjuntos são naturalmente divididos em $n+1$ colecções:
subconjuntos com $0$ elementos, com $1$ elemento, \dots, com $n$ elementos.
\endgraf
\emph{O que ganhamos?}
Sabemos como contar os elementos de cada uma dessas colecções:
para formar um subconjunto de tamanho $r$, precisamos escolher $r$ dos $n$ elementos,
ou seja, existem $\comb n r$ subconjuntos de tamanho $r$.
Agora, pelo princípio da adição basta apenas somar:
são
$\Sum_{i=0}^n \comb n i$.
\endgraf
\emph{Qual o problema?}
Comparando essa solução com a do item~\refn{subset_count_using_strings},
aqui temos a dificuldade de realmente calcular todos os $n$ números $\comb n i$
para os somar.
O~\ref{sum_of_all_binomial_coefficients} mostre que na verdade,
não é nada dificil calcular o somatório diretamente sem nem
calcular nenhum dos seus termos separadamente!
%%}}}

%%{{{ prop: number_of_subsets_of_finite_set_as_sum 
\proposition.
\label{number_of_subsets_of_finite_set_as_sum}%
Seja $A$ conjunto finito.
$$
\card{\pset A} = \Sum_{i=0}^n \comb n i,\qquad\text{onde $n = \card A$}.
$$
%%}}}

\blah.
Combinando as duas proposições chegamos num resultado interessante:

%%{{{ cor: sum_of_binom_coefs 
\corollary.
\label{sum_of_binom_coefs}%
Para todo $n\in\nats$,
$$
\Sum_{i=0}^n \binom n i
= \binom n 0 + \binom n 1 + \dotsb + \binom n {n-1} + \binom n n
= 2^n
$$
%%}}}

%%{{{ x: sum_of_all_binomial_coefficients 
\exercise.
\label{sum_of_all_binomial_coefficients}%
Esqueça o corolário e prove que:
$$
\alignat 2
\Sum_{i=0}^n \binom n i
&= \binom n 0 + \binom n 1 + \binom n 2 + \dotsb + \binom n n
&&= 2^n\\
\Sum_{i=0}^n (-1)^i \binom n i
&=\binom n 0 - \binom n 1 + \binom n 2 - \dotsb + (-1)^n \binom n n
&&= 0
\endalignat
$$

\hint
Teorema binomial~\refn{binomial_theorem}.

\hint
Cada somatório é apenas um caso especial do teorema binomial.

\hint
Toma $x,y \asseq 1$ no teorema para resolver o primeiro.

\hint
Toma $x \asseq 1$ e $y \asseq -1$ para resolver o segundo.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Pascal's triangle 
\section O triângulo de Pascal.

%%{{{ The first powers of the binomial 
\note As primeiras potências do binomial.
Calculamos:
$$
\align
(x+y)^0 &= 1\\
(x+y)^1 &= x   + y\\
(x+y)^2 &= x^2 + 2 xy    + y^2\\
(x+y)^3 &= x^3 + 3 x^2y  + 3 xy^2     + y^3\\
(x+y)^4 &= x^4 + 4 x^3y  + 6 x^2y^2   + 4xy^3      + y^4\\
(x+y)^5 &= x^5 + 5 x^4y  + 10 x^3y^2  + 10 x^2y^3  + 5 xy^4     + y^5\\
(x+y)^6 &= x^6 + 6 x^5y  + 15 x^4y^2  + 20 x^3y^3  + 15 x^2y^4  + 6 xy^5    + y^6\\
(x+y)^7 &= x^7 + 7 x^6y  + 21 x^5y^2  + 35 x^4y^3  + 35 x^3y^4  + 21 x^2y^5 + 7 xy^6    + y^7\\
(x+y)^8 &= x^8 + 8 x^7y  + 28 x^6y^2  + 56 x^5y^3  + 70 x^4y^4  + 56 x^3y^5 + 28 x^2y^6 + 8 xy^7 + y^8
\endalign
$$
%%}}}

%%{{{ pascal_triangle 
\note O triângulo de Pascal.
\label{pascal_triangle}%
\tdefined{triângulo}[de Pascal]
Tomando os coeficientes acima criamos o triângulo seguinte,
conhecido como \emph{triângulo de \Pascal[triângulo]{}Pascal}:%
$$
\matrix
\format
\;\c\; &
\;\c\; &
\;\c\; &
\;\c\; &
\;\c\; &
\;\c\; &
\;\c\; &
\;\c\; &
\;\c\; &
\;\c\; &
\;\c\; \\
1\\
1&1\\
1&2&1\\
1&3&3&1\\
1&4&6&4&1\\
1&5&10&10&5&1\\
1&6&15&20&15&6&1\\
1&7&21&35&35&21&7&1\\
1&8&28&56&70&56&28&8&1\\
\;\vdots\;&
\phantom{00}&
\phantom{00}&
\phantom{00}&
\phantom{00}&
\phantom{00}&
\phantom{00}&
\phantom{00}&
\phantom{00}&
\ddots
\endmatrix
$$
%%}}}

\blah.
Observando o triângulo, percebemos que com umas exceções---quais?---cada
número é igual à soma de dois números \emph{na linha em cima}:
aquele que fica na mesma posição, e aquele que fica na posição anterior.
(Consideramos os ``espaços'' no triângulo como se fossem $0$'s.)

%%{{{ x: write this formally 
\exercise.
Escreva essa relação formalmente.

\hint
O $\binom a b$ está na linha $a$, na posição $b$
(começando contar com 0).

\solution
Temos as equações:
$$
\rightbrace{
\aligned
\binom 0 0          &= 1\\
\binom 0 r          &= 0\\
\binom n r          &= \binom {n-1} r + \binom {n-1} {r-1}
\endaligned
}
\quad
\text{equivalentemente}
\quad
\leftbrace{
\aligned
\binom 0     0      &= 1\\
\binom 0     {r+1}  &= 0\\
\binom {n+1} {r+1}  &= \binom n {r+1} + \binom n r.
\endaligned
}
$$

\endexercise
%%}}}

%%{{{ thm: combinations_recursive_equation 
\theorem.
\label{combinations_recursive_equation}%
Para todos inteiros positivos $n$ e $r$ positivos temos:
$$
\comb n r           = \comb {n-1} r + \comb {n-1} {r-1}.
$$
\sketch.
Lembramos que $\comb n r$ é o número das maneiras que podemos
escolher $r$ de $n$ objetos.
Fixe um dos $n$ objetos e denota-lo por $s$,
para agir como ``separador'':
separamos as maneiras de escolher em dois grupos:
aquelas que escolhem (entre outros) o $s$ e aquelas que não o escolhem.
Contamos cada colecção separadamente e somamos (princípio da adição)
para achar o resultado:
$$
\comb n r
= \underbrace{\comb {n-1} r}_{\text{escolhas sem $s$}}
+ \underbrace{\comb {n-1} {r-1}}_{\text{escolhas com $s$}}.
$$
\qes
%%}}}

%%{{{ x 
\exercise.
Prove o~\ref{combinations_recursive_equation} para todos os $n,r\in\nats$
com $0<r<n$, usando como definição do símbolo $\comb n r$ a
$$
\comb n r = \frac {n!} {(n-r)!\stimes r!}.
$$

\hint
Prove diretamente usando apenas a definição de fatorial.

\solution
Sejam $r,n\in\nats$ com $0<r<n$.
Calculamos:
$$
\alignat 4
\intertext{$\comb n r = \comb {n-1} r + \comb {n-1} {r-1}$}
&\iff\quad& \frac {n!} {(n-r)!\stimes r!} &= \frac {(n-1)!} {(n-1-r)!\stimes r!}              &\!\!{}+{}\ & \frac {(n-1)!} {(n-1-(r-1))!\stimes (r-1)!} &\qquad&\qquad\\
&\iff\quad& n! &= \frac {(n-1)!\stimes(n-r)!\stimes r!} {(n-r-1)!\stimes r!}                  &\!\!{}+{}\ & \frac {(n-1)!\stimes(n-r)!\stimes r!} {(n-r)!\stimes (r-1)!}\\
&\iff\quad& n! &= \frac {(n-1)!\stimes(n-r)!\stimes\cancel{r!}} {(n-r-1)!\stimes \cancel{r!}} &\!\!{}+{}\ & \frac {(n-1)!\stimes\cancel{(n-r)!}\stimes r!} {\cancel{(n-r)!}\stimes (r-1)!}\\
&\iff\quad& n! &= \frac {(n-1)!\stimes(n-r)\!\cancel{\stimes!\stimes}} {\cancel{(n-r-1)!}}    &\!\!{}+{}\ & \frac {(n-1)!\stimes r\cancel{\stimes!\stimes}} {\cancel{(r-1)!}}\\
&\iff\quad& n! &= {(n-1)!\stimes(n-r)} &\!\!{}+{}\ & {(n-1)!\stimes r} \\
&\iff\quad& n! &= {(n-1)!\stimes((n-r) + r)}\\
&\iff\quad& n! &= {(n-1)!\stimes n}\\
&\iff\quad& n! &= n!
\endalignat
$$

\endexercise
%%}}}

%%{{{ x 
\exercise.
\emph{Redefina} o símbolo $\comb n r$ para todo $n,r\in\nats$
recursivamente com
$$
\align
\comb 0 0          &= 1\\
\comb 0 r          &= 0\\
\comb n r          &= \comb {n-1} r + \comb {n-1} {r-1},
\endalign
$$
e prove que para todo $n,r\in\nats$,
$\comb n r = \dfrac {n!} {(n-r)!\stimes r!}$\,.

\hint
Indução.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Counting recursively 
\section Contando recursivamente.

%%{{{ x: sequences_of_twos_and_threes 
\exercise.
\label{sequences_of_twos_and_threes}%
Defina uma função $f : \nats\to\nats$ que conta as seqüências feitas por os números 2 e 3 com soma sua entrada.
Quantas seqüências de $2$'s e $3$'s existem cujos termos somam em $17$?

\hint
Recursão.

\hint
Separe as seqüências em dois grupos: aquelas que começam com 2, e aquelas que começam com 3.

\hint
Cuidado com a ``base'' $f(0)$.  Quantas seqüências de 2 e 3, somam em $0$?

\hint
Para calcular o valor de $f(17)$, \emph{não} use a definição recursiva ``top-down'',
mas ``bottom-up'': calcule os valores em seqüência linear
$f(0), f(1), f(2), \dotsc$ até o valor desejado.

\endexercise
%%}}}

%%{{{ x: sequences_of_twos_and_threes_restricted 
\exercise.
\label{sequences_of_twos_and_threes_restricted}%
Defina uma função $g : \nats\to\nats$ que conta as seqüências feitas por os números 2 e 3 com soma sua entrada, em quais aparecem os dois números (2 e 3).
Quantas seqüências de $2$'s e $3$'s existem cujos termos somam em $18$?

\hint
Use a $f$ do~\ref{sequences_of_twos_and_threes}.

\hint
Quando $g(n) \neq f(n)$?

\hint
Considere os casos:
(1) $n$ não pode ser escrito nem como $n = 2 + 2 + \dotsb + 2$, nem como $n = 3 + 3 + \dotsb + 3$;
(2) $n$ pode ser escrito como $n = 2 + 2 + \dotsb + 2$, e como $n = 3 + 3 + \dotsb + 3$ também;
(3) nenhum dos casos (1)--(2).

\hint
$
g(n) =
\knuthcases{
\cdots\vphantom{f(n)}\cr
\cdots\vphantom{f(n)}\cr
\cdots\vphantom{f(n)}
}
$

\endexercise
%%}}}

%%{{{ x: infinite_city_1 
\exercise Dirigindo na cidade infinita (sem destino).
\label{infinite_city_1}%
No ``meio'' duma ``cidade infinita'', tem um motorista no seu carro.
Seu carro tá parado numa intersecção onde tem 3 opções:
virar esquerda; dirigir reto; virar direita.
No seu depósito tem $a$ unidades de combustível,
e sempre gasta $1$ para dirigir até a próxima intersecção.
De quantas maneiras diferentes ele pode dirigir até seu combustível acabar?
(Veja na figura, dois caminhos possíveis com $a=12$.)
\noindent
\midinsert
\noindent
\centerline{
\hfill
\tikzpicture[scale=0.666]%%{{{
%
\foreach \i in {-4,-3,-2,-1,0,1,2,3,4}
  \draw [-] (\i,-2.5) -- (\i,4.5);
\foreach \j in {-2,-1,0,1,2,3,4}
  \draw [-] (-4.5,\j) -- (4.5,\j);
\draw[rounded corners,line width=2mm,color=blue!40] (0,0) -- (0,1) -- (0,2) -- (-1,2) -- (-1,1) -- (-1,0) -- (-1,-1) -- (-2,-1) -- (-3,-1) -- (-3,0) -- (-3,1) -- (-2,1) -- (-2,2);
\draw[rounded corners,line width=2mm,color=green!40] (0,0) -- (1,0) -- (2,0) -- (3,0) -- (3,1) -- (3,2) -- (3,3) -- (3,4) -- (4,4) -- (4,3) -- (4,2) -- (3,2) -- (2,2);
\node[circle,fill=gray!20] (CR)  at (0,0) {$C$};
%
\endtikzpicture
%%}}}
\hfill
\tikzpicture[scale=0.666]%%{{{
%
\foreach \i in {-4,-3,-2,-1,0,1,2,3,4}
  \draw [-] (\i,-2.5) -- (\i,4.5);
\foreach \j in {-2,-1,0,1,2,3,4}
  \draw [-] (-4.5,\j) -- (4.5,\j);
\draw[rounded corners,line width=2mm,color=blue!40] (0,0) -- (-1.8,0) -- (-1.8,2);
\draw[rounded corners,line width=2mm,color=cyan!60] (0,0) -- (4,0) -- (4,2) -- (-3, 2) -- (-3,3) -- (-2,3) -- (-2,2);
\draw[rounded corners,line width=2mm,color=green!40] (0,0) -- (0,-1) -- (-2.1,-1) -- (-2.1,2);
\node[circle,fill=gray!20] (CR)  at (0,0) {$C$};
\node[circle,fill=gray!20] (DN)  at (-2,2) {$D$};
%
\endtikzpicture
%%}}}
\hfill
}
%\caption{Fig.~1}
\endgraf\centerline{Caminhos possíveis para os exercícios~\refn{infinite_city_1} e~\refn{infinite_city_2} respectivamente.}
%\endcaption
\endinsert

\hint
Sem recursão!

\hint
Em cada intersecção tem $3$ opções: $\mathtt L$, $\mathtt F$, $\mathtt R$.

\solution
Em cada das $a$ intersecções que ele encontra ele tem $3$ opções.
Logo, ele pode seguir $3^a$ caminhos diferentes dirigindo até seu combustível acabar.

\endexercise
%%}}}

%%{{{ x: infinite_mountain 
\exercise Dirigindo na montanha infinita.
\label{infinite_mountain}%
No ``meio'' duma montanha de altura infinita, tem um motorista no seu carro.
Seu carro tá parado numa intersecção onde tem 4 opções:
dirigir subindo (gasta $4$ unidades de combutível);
dirigir descendo (gasta $1$);
dirigir na mesma altura clockwise (gasta $2$);
dirigir na mesma altura counter-clockwise (gasta $2$).
No seu depósito tem $a$ unidades de combistível.
De quantas maneiras diferentes ele pode dirigir até seu combustível acabar?
\ignore{
\midinsert
\tikzpicture[scale=2]
\axis[
hide axis,
domain=0:1,
y domain=0:-2*pi,
xmin=-1.5, xmax=1.5,
ymin=-1.5, ymax=1.5, zmin=-1.2, zmax=-1.2,
samples=10,
samples y=40,
z buffer=sort,
]
\addplot3[mesh,gray]
({1.1*x*cos(deg(y))},{1.1*x*sin(deg(y))},{-x});
\endaxis
\endtikzpicture
\endinsert
}

\hint
Recursão.

\hint
Seja $f(a)$ o número de caminhos diferentes que o motorista pode seguir com $a$ unidades de combustível.

\hint
Separa todos os caminhos possíveis em 3 grupos, dependendo na primeira escolha do motorista.
Conta o número de caminhos em cada grupo separadamente (recursivamente!),
e e use o princípio da adição para contar quantos são todos.

\endexercise
%%}}}

%%{{{ x: infinite_city_2 
\exercise Dirigindo na cidade infinita (com destino).
\label{infinite_city_2}%
No ``meio'' duma ``cidade infinita'', tem um motorista no seu carro.
Seu carro tá parado numa intersecção onde tem 4 opções:
dirigir na direção do norte; do leste; do sul; do oeste.
No seu depósito tem $c$ unidades de combustível
e sempre gasta $1$ para dirigir até a próxima intersecção.
De quantas maneiras diferentes ele pode dirigir até chegar no teu destino,
que fica numa distância $y$ unidades para norte e $x$ para leste?
Considere que números negativos representam descolamento para a direção oposta.
(Veja na figura onde o carro $C$ tem destino $D$, ou seja, seu descolamento
desejado é de $x=-2$, $y=2$.)

\hint
Recursão.

\hint
Seja $f(a,x,y)$ o número de caminhos diferentes que acabam com descolamento total de $y$ unidades para norte e $x$ para leste, para um motorista que tem $a$ unidades de combustível no seu carro.

\hint
Separa todos os caminhos possíveis em 4 grupos, dependendo na primeira escolha do motorista.
Conta o número de caminhos em cada grupo separadamente (recursivamente!),
e e use o princípio da adição para contar quantos são todos.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Solutions of equations in integers 
\section Soluções de equações em inteiros.

\endsection
%%}}}

%%{{{ Combinations with repetitions 
\section Combinações com repetições. 

\endsection
%%}}}

%%{{{ The inclusion--exclusion principle 
\section O princípio da inclusão--exclusão.
\label{Inclusion_exclusion_principle}%

%%{{{ x: 42_passengers_on_a_plane 
\exercise.
\label{42_passengers_on_a_plane}%
42 passangeiros estão viajando num avião.
\beginul
\li 11 deles não comem beef.
\li 10 deles não comem peixe.
\li 12 deles não comem frango.
\li Os passangeiros que não comem nem beef nem frango são 6.
\li O número de passangeiros que não comem nem beef nem peixe, é o mesmo com o número de passangeiros que não comem nem peixe nem frango.
\li Os passangeiros que não comem nada disso são 3.
\li Os passangeiros que comem tudo são 22.
\endul
Quantos são os passangeiros que não comem nem beef nem peixe?

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Elementary probability 
\section Probabilidade elementar.

\endsection
%%}}}

%%{{{ Derrangements 
\section Desarranjos.

\endsection
%%}}}

%%{{{ The pigeonhole principle 
\section O princípio da casa dos pombos.

\endsection
%%}}}

%%{{{ Generating functions and recurrence relations 
\section Funções geradoras e relações de recorrência.

\endsection
%%}}}

%%{{{ Problems 
\problems.

%%{{{ prob 
\problem.
Uma turma de 28 alunos tem 12 mulheres e 16 homens.
\beginol
\li De quantas maneiras podemos escolher 5 desses alunos, para formar um time de basquete?
(Considere que as posições de basquete não importam).
\li De quantas maneiras podemos escolher 6 desses alunos, para formar um time de volei, tal que o time tem pelo menos 4 homens?
(Considere que as posições de volei não importam).
\li De quantas maneiras podemos escolher 11 desses alunos, para formar um time de futebol, tal que o time tem exatamente 3 mulheres, e um homem para goleiro?
(Considere que a única posição de futebol que importa é do goleiro.)
\li De quantas maneiras podemos escolher 3 times, um para cada esporte, sem restricção de sexo?
\endol

\endproblem
%%}}}

%%{{{ prob 
\problem.
Uma noite, depois do treino 3 times (uma de basquete, uma de vólei, e uma de
futebol), foram beber num bar que foi reservado para eles.
Como os jogadores de cada time querem sentar juntos,
o dono arrumou duas mesas cíclicas, uma com 5 e outra com 6 cadeiras, e 11 cadeiras no bar.
\endgraf
De quantas maneiras diferentes eles podem sentar?
(Considere que nas mesas cíclicas o que importa é apenas quem tá no lado de quem, mas no bar o que importa é a posição da cadeira mesmo.)

\endproblem
%%}}}

%%{{{ prob 
\problem.
Considere os inteiros $1,2,\dotsc, 30$.
Quantas das suas $30!$ permutações totais têm a propriedade que
não aparecem múltiplos de $3$ consecutivamente?

\hint
Construa cada configuração em passos e use o princípio da multiplicação.

\hint
Coloque os não-múltiplos de 3 primeiramente numa ordem, deixando espaços entre-si
para os múltiplos de 3.

\hint
Escolhe 10 dos 21 lugares possíveis para colocar os múltiplos de 3.

\solution
Primeiramente vamos esquecer os múltiplos de 3.
O resto dos (20) números pode ser permutado de
$20!$ maneiras.
Para qualquer dessa maneira, temos $\comb {21} {10}$
opções para escolher em quais $10$ das $20+1$ possíveis posições vamos colocar os múltiplos de 3,
e para cada escolha, correspondem $10!$ diferentes permutações dos múltiplos de 3 nessas $10$ posições.
Finalmente,
$$
\underbrace{\phantom(20!\phantom)}_{\text{ordena os não-múltiplos}}\ntimes \underbrace{\comb {21} {10}}_{\text{escolhe as posições dos múltiplos}}\ntimes \underbrace{\phantom(10!\phantom)}_{\text{escolhe a ordem dos múltiplos}}
$$
das $30!$ permutações têm a propriedade desejada.

\endproblem
%%}}}

%%{{{ prob 
\problem.
Numa turma de $28$ alunos
precisamos formar duas comissões de $5$ e $6$ membros.
Cada comição tem seu presidente, seu vice-presidente, e seus membros normais.
De quantas maneiras podemos formar essas comissões\dots
\beginol
\li\dots sem restricções (cada um aluno pode participar nas duas comissões simultaneamente)?
\li\dots se nenhum aluno pode participar simultaneamente nas duas comissões?
\li\dots se os dois (únicos) irmãos entre os alunos não podem participar na mesma comissão,
e cada aluno pode participar simultaneamente nas duas?
\endol

\endproblem
%%}}}

%%{{{ prob: nikos 
\problem.
\label{nikos}%
Na figura abaixo temos um mapa (as linhas correspondem em ruas).
Nikos quer caminhar do ponto $A$ para o ponto $B$, \emph{o mais rápido possível}.
\beginol
\li De quantas maneiras ele pode chegar?
\li Se ele precisa passar pelo ponto $S$?
\li Se ele precisa passar pelo ponto $S$ mas quer evitar o ponto $N$?
\endol
\midinsert
\noindent
\tikzpicture[scale=0.666]%%{{{
%
\foreach \i in {0,1,2,3,4,5,6,7,8,9}
  \foreach \j in {0,1,2,3,4,5,6,7,8}
    \node (a\i) at (\i,\j) {};
\foreach \i in {0,1,2,3,4,5,6,7,8,9}
  \draw [-] (\i,0) -- (\i,8);
\foreach \j in {0,1,2,3,4,5,6,7,8}
  \draw [-] (0,\j) -- (9,\j);
\draw [rounded corners,line width=2mm,color=green!50] (0,0) -- (0,2) -- (3,2) -- (3,4) -- (7,4) -- (7,5) -- (8,5) -- (8,7) -- (9,7) -- (9,8);
\node[circle,fill=gray!20]  (SW)    at (-0.3,-0.3) {$A$};
\node[circle,fill=gray!20]  (NE)    at (9.3,8.3)   {$B$};
\node[circle,             inner sep=2pt,fill=green!30] (nice)  at (3,2.5)     {{\niness S}};
\node[star,star points=17,inner sep=2pt,fill=red!30]   (boom)  at (6.5,5)     {{\niness N}};
%
\endtikzpicture
%%}}}
\tikzpicture[scale=0.666]%%{{{
%
\foreach \i in {0,1,2,3,4,5,6,7,8,9}
  \foreach \j in {0,1,2,3,4,5,6,7,8}
    \node (a\i) at (\i,\j) {};
\foreach \i in {0,1,2,3,4,5,6,7,8,9}
  \draw [-] (\i,0) -- (\i,8);
\foreach \j in {0,1,2,3,4,5,6,7,8}
  \draw [-] (0,\j) -- (9,\j);
\draw [rounded corners,line width=2mm,color=red!50] (0,0) -- (0,2) -- (3,2) -- (3,4) -- (5,4) -- (5,5) -- (7,5) -- (7,7) -- (8,7) -- (8,8) -- (9,8);
\node[circle,fill=gray!20] (SW)  at (-0.3,-0.3) {$A$};
\node[circle,fill=gray!20] (NE)  at (9.3,8.3) {$B$};
\node[circle,             inner sep=2pt,fill=green!30] (nice)  at (3,2.5)     {{\niness S}};
\node[star,star points=17,inner sep=2pt,fill=red!30]   (boom)  at (6.5,5)     {{\niness N}};
%
\endtikzpicture
%%}}}
\endgraf\centerline{Um caminho aceitável e um inaceitável no caso (3) do \ref{nikos}.}
\endinsert

\endproblem
%%}}}

%%{{{ prob 
\problem.
Num jogo de lotéria, tem os números de $1$ até $60$:
$$
\matrix
    01&02& 03 &04 &05 &06 &07 &08 &09 &10\\
    11&12& 13 &14 &15 &16 &17 &18 &19 &20\\
    21&22& 23 &24 &25 &26 &27 &28 &29 &30\\
    31&32& 33 &34 &35 &36 &37 &38 &39 &40\\
    41&42& 43 &44 &45 &46 &47 &48 &49 &50\\
    51&52& 53 &54 &55 &56 &57 &58 &59 &60
\endmatrix
$$
Os organizadores do jogo, escolhem aleatoriamente 6 números
deles (sem repetições).
Esses 6 números são chamados ``a megasena''.
Um jogador marca pelo menos 6 números na sua
lotéria e se conseguir ter marcados todos os 6 da megasena, ganha.

(Marcando mais que 6 números,
as chances do jogador aumentam, mas o preço da lotéria aumenta também.)

(1)
Um jogador marcou $6$ números.
Qual a probabilidade que ele ganhe?

(2)
Uma jogadora marcou $9$ números.
Qual a probabilidade que ela ganhe?

(3)
Generalize para um jogo com $N$ números, onde $w$ deles são escolhidos,
e com um jogador que marcou $m$ números, sendo $w\leq m \leq N$.

\solution
(1)
Apenas uma escolha é a certa, então a probabilidade de ganhar é:
    $$
    \dfrac 1 {\comb {60} 6}
    = \dfrac{6!\stimes 54!} {60!}
    = \dfrac {6!} {55 \ntimes 56 \ntimes 57 \ntimes 58 \ntimes 59 \ntimes 60}
    = \dfrac {1} {11\ntimes 14\ntimes 19\ntimes 29\ntimes 59\ntimes 10}
    = \dfrac 1 {50063860}\,.
    $$
(2)
Para ganhar, com certeza acertamos nos 6 números da megasena,
então temos que contar todas as maneiras de escolher os 3 outros números dos 9 que escolhemos:
    $$
    \dfrac {\comb {60-6} {9-6}} {\comb {60} 9}
    = \dfrac {\comb {54} 3} {\comb {60} 9}
    = \dfrac {54!\stimes \cancel{51!}\stimes 9!} {\cancel{51!} \stimes 3!\stimes 60!}
    = \dfrac {4\ntimes 5 \ntimes 6 \ntimes 7 \ntimes 8 \ntimes 9} {55\ntimes 56\ntimes 57\ntimes 58\ntimes 59 \ntimes 60}
    = \dfrac 3 {1787995}\,.
    $$
(3)
Generalizando a solução do (2), a probabilidade é
$$
\align
\frac
{\comb {N-w} {m-w}}
{\comb N m}
&=
\frac
{(N-w)! \stimes (N-m)! \stimes m!}
{((N-w)-(m-w))! \stimes (m-w)! \stimes N!}\\
&=
\frac
{(N-w)! \stimes (N-m)! \stimes m!}
{((N\cancel{{}-{}w}-m\cancel{{}+w}))! \stimes (m-w)! \stimes N!}\\
&=
\frac
{(N-w)! \stimes \cancel{(N-m)!} \stimes m!}
{\cancel{(N-m)!} \stimes (m-w)! \stimes N!}\\
&=
\frac
{(N-w)! \stimes m!}
{(m-w)! \stimes N!}\\
&=
\Prod_{i=0}^{w-1}
\frac
{m-i}
{N-i}\,.
\endalign
$$

\endproblem
%%}}}

%%{{{ prob: aleco_bego 
\problem.
\label{aleco_bego}%
Aleco e Bego são dois sapos.
Eles estão na frente de uma escada com 11 degraus.
No 6o degrau, tem Cátia, uma cobra, com fome.
Aleco pula 1 ou 2 degraus para cima.
Bego, 1, 2 ou 3.  E ele é tóxico: se Cátia comê-lo, ela morre na hora.
\midinsert
\tikzpicture[scale=0.666]%%{{{
%
\node[star,star points=17,fill=red!30,inner sep=3pt]    (boom) at (6.75,6.25) {\phantom{\niness C}};
\node[                                             ]    (catia) at (6.666,6.333) {{\niness C}};
\node[circle,fill=green!40]  (aleco) at (-0.333,0.5) {{\niness A}};
\node[circle,fill=blue!30]   (bego)  at (-1.75,0.5) {{\niness B}};
\draw [->,color=green!50,line width=1mm] (aleco) to [bend left=70] (2.333,2);
\draw [->,color=blue!50,line width=1mm] (bego)  to [bend left=66] (1.666,1);
\draw [->,color=green!50,line width=1mm] (aleco) to [bend left=60] (1.333,1);
\draw [->,color=blue!50,line width=1mm] (bego)  to [bend left=62] (2.666,2);
\draw [->,color=blue!50,line width=1mm] (bego)  to [bend left=60] (3.5,3);
\foreach \i in {1,2,3,4,5,6,7,8,9,10,11} {
  \path[fill=gray!10]
    (\i,\i) -- (\i,\i-1) -- (15,\i-1) -- (15,\i) -- (\i,\i);
  \node[circle,fill=black,inner sep=0pt] (b\i) at (\i,\i)   {};
  \node[circle,fill=black,inner sep=0pt] (e\i) at (\i+1,\i) {};
  \node[circle,fill=black,inner sep=0pt] (d\i) at (\i,\i-1) {};
  \node[                  inner sep=0pt] (s\i) at (\i+0.5,\i) {};
  \draw [-,line width=0.2mm] (b\i) -- (e\i);
  \draw [-,line width=0.2mm] (b\i) -- (d\i);
  \node[                  inner sep=0pt] (t\i) at (\i+0.5,\i-0.3) {\i};
}
\draw [-] (-3,0) -- (1,0);
\draw [-] (12,11) -- (15,11);
%\foreach \j in {0,1,2,3,4,5,6,7,8}
%  \draw [-] (0,\j) -- (9,\j);
%  \draw [line width=2mm,color=green!50] (0,0) -- (0,2) -- (3,2) -- (3,4) -- (7,4) -- (7,5) -- (8,5) -- (8,7) -- (9,7) -- (9,8);
%\node[circle,fill=gray!20]  (SW)    at (-0.3,-0.3) {$A$};
%\node[circle,fill=gray!20]  (NE)    at (9.3,8.3)   {$B$};
%\node[circle,fill=green!30] (nice)  at (3,2.5)     {{\niness S}};
%\node[circle,fill=red!30]   (boom)  at (6.5,5)     {{\niness N}};
%
\endtikzpicture
%%}}}
%\caption{Fig.~2}
\endgraf\centerline{Os dois sapos do~\ref{aleco_bego} e suas possibilidades para começar.}
%\endcaption
\endinsert
\item{(1)} Por enquanto, Cátia está dormindo profundamente.
\itemitem{a.} De quantas maneiras Aleco pode subir a escada toda?
\itemitem{b.} De quantas maneiras Bego pode subir a escada toda?
\item{(2)} Cátia acordou!
\itemitem{a.} De quantas maneiras Aleco pode subir a escada toda?
\itemitem{b.} De quantas maneiras Bego pode subir a escada toda?
\item{(3)} Bego começou subir a escada\dots{}
Qual é a probabilidade que Cátia morra?
(Considere que antes de começar,
ele já decidiu seus saltos e não tem percebido a existência da cobra.)
\ignore{
\item{(4)} O que muda na questão (3) se ao invés de decidir seu caminho desde o
início, Bega decida cada vez aleatoriamente (com probabilidades iguais) qual
dos 3 possíveis saltos ele vai fazer?
\item{(5)}
Generalize o problema (4)~para o caso onde a escada
tem uma infinidade de degraus e Cátia fica no degrau $k$.
}

\hint
Recursão.

\hint
Sejam $a(n)$ e $b(n)$ o número de maneiras que Aleco e Bego
podem subir uma escada de $n$ degraus, respectivamente.

\hint
Grupe as maneiras em colecções (para aplicar o princípio da adição),
olhando para o primeiro salto.

\solution
Sejam $a(n)$ e $b(n)$ o número de maneiras que Aleco e Bego
podem subir uma escada de $n$ degraus, respectivamente.
Cada maneira do Aleco pode começar com 2 jeitos diferentes:
salto de 1 degrau, ou salto de 2 degraus.
Cada maneira do Bego pode começar com 3 jeitos diferentes:
salto de 1, de 2, ou de 3 degraus.
Observe que, por exemplo, se Bego começar com um pulo de 2
degraus, falta subir uma escada de $n-2$ degraus.
Pelo princípio da adição então, temos as equações recursivas:
$$
\xalignat 2
a(n) &= a(n-1) + a(n-2)                & b(n) &= b(n-1) +  b(n-2) +  b(n-3)
\intertext{validas para $n\geq 2$ e $n \geq 3$ respectivamente.
Devemos definir os casos básicos de cada função recursiva:
$n=0,1$ para a $a(n)$, e $n=0,1,2$ para a $b(n)$:}
     &                                 & b(0) &= 1\qquad\explanation{fica}\\
a(0) &= 1 \qquad\explanation{fica}     & b(1) &= 1\qquad\explanation{pula $1$}\\
a(1) &= 1 \qquad\explanation{pula $1$} & b(2) &= 2\qquad\explanation{pula $1+1$; ou pula $2$}\\
a(n) &= a(n-1) +  a(n-2)               & b(n) &= b(n-1) +  b(n-2) +  b(n-3)
\endxalignat
$$
Calculamos os 11 primeiros valores:
$$
\matrix
a:\quad& \overbrace {1}^{a(0)}, & 1, & 2, & 3, & 5, & \phantom08,  & 13, & 21, & 34, & \phantom055,  & \phantom089,  & \overbrace {144}^{a(11)}, &\dotsc\\
b:\quad& \underbrace{1}_{b(0)}, & 1, & 2, & 4, & 7, & 13,          & 24, & 44, & 81, & 149, & 274, & \underbrace{504}_{b(11)}, &\dotsc
\endmatrix
$$
Agora temos tudo que precisamos para responder facilmente nas questões do problema.
\endgraf
\item{(1)} Precisamos apenas os valores $a(11)$ e $b(11)$:
\itemitem{a.} De $a(11) = 144$ maneiras.
\itemitem{b.} De $b(11) = 504$ maneiras.
\item{(2)} Usamos ``$n\to m$'' para ``pula diretamente do degrau $n$ para o degrau $m$'' e ``$n\transto m$'' para ``vai do degrau $n$ para o degrau $m$ pulando num jeito''.
\itemitem{a.} Para conseguir subir, Aleco necessariamente precisa chegar no degrau 5, saltar até o degrau 7, e depois continuar até o degrau 11.  Formamos cada maneira então em passos, e usando o princípio da multiplicação achamos que Aleco tem
$$
\underbrace{a(5)}_{0 \transto 5} \ntimes
\underbrace{\phantom(1\phantom)}_{5 \to 7} \ntimes
\underbrace{a(4)}_{7 \transto 11}
=
8 \ntimes 1 \ntimes 5
= 40
$$
maneiras de subir a escada toda.
\itemitem{b.} 
Para o Bego a situação não é tão simples, porque ele pode evitar a cobra de vários jeitos.
Vamos agrupá-los assim:
(i)   aqueles onde ele pulou a cobra com salto de tamanho 2;
(ii)  aqueles onde ele pulou a cobra com salto de tamanho 3 desde o degrau 5;
(iii) aqueles onde ele pulou a cobra com salto de tamanho 3 desde o degrau 4.
Contamos as maneiras em cada grupo como na questão anterior, e no final as somamos (princípio da adição) para achar a resposta final: Bego tem
$$
\overbrace{
\underbrace{b(5)}_{0 \transto 5} \ntimes
\underbrace{\phantom(1\phantom)}_{5 \to 7} \ntimes
\underbrace{b(4)}_{7 \transto 11}
}^{\text{grupo (i)}}
+
\overbrace{
\underbrace{b(5)}_{0 \transto 5} \ntimes
\underbrace{\phantom(1\phantom)}_{5 \to 8} \ntimes
\underbrace{b(3)}_{8 \transto 11}
}^{\text{grupo (ii)}}
+
\overbrace{
\underbrace{b(4)}_{0 \transto 4} \ntimes
\underbrace{\phantom(1\phantom)}_{4 \to 7} \ntimes
\underbrace{b(4)}_{7 \transto 11}
}^{\text{grupo (iii)}}
=
13 \ntimes 7 + 
13 \ntimes 4 + 
7 \ntimes 7 
=
192
$$
maneiras de subir a escada toda.
\item{(3)}
Pela definição, a probabilidade que Cátia morra é a fracção
$$
\frac
{\text{todas as maneiras em quais Bego pisou no degrau 6}}
{\text{todas as maneiras possíveis}}\,,
$$
ou seja,
$$
\frac
{504-192}
{504}
=
\frac
{312}
{504}
=
\frac
{156}
{252}
=
\frac
{78}
{126}
=
\frac
{39}
{63}
=
\frac
{13}
{21}
\,.
$$

\endproblem
%%}}}

%%{{{ prob: band_maker 
\problem.
\label{band_maker}%
Temos $6$ músicos disponíveis, onde cada um toca:
\medskip
\halign{
\hfil# & #\hfil &\quad \hfil# & #\hfil\cr
Alex:       &violão, guitarra, baixo& Daniel:     &guitarra\cr
Bill:       &bateria                & Eduardo:    &piano, teclado, violão, fláuto\cr
Claudia:    &saxofone, clarineto    & Fagner:     &guitarra, baixo, teclado\cr
}
\medskip
\noindent
(Considere que uma banda precisa \emph{pelo menos um membro},
todos os membros duma banda \emph{precisam tocar pelo menos algo na banda},
e que cada banda é diferenciada pelos músicos e
suas funções.
Por exemplo: uma bande onde Alex toca o violão (apenas) e Bill a bateria,
é diferente duma banda onde
Alex toca o violão \emph{e} a guitarra, e Bill a bateria,
mesmo que seus membros podem ser os mesmos.

\item{(1)}
Quantas bandas diferentes podemos formar?
\item{(2)}
Quantas bandas diferentes podemos formar com a restricção que nenhum
músico tocará mais que um instrumento na banda (mesmo se em geral sabe tocar mais)?
\item{(3)}
Quantas bandas diferentes podemos formar onde todos os
músicos fazem parte da banda?

\solution
(1):
$2^{14}-1$: para cada músico e cada instrumento, temos 2 opções: ``sim'' ou ``não''.
Tiramos $1$ porque hipercontamos (a ``banda vazia'').
\endgraf\medskip\noindent
(2):
Cada músico que toca $i$ instrumentos tem $i+1$ opções (a extra $+1$ corresponde no ``não participar na banda''):
podemos formar $4 \ntimes 2 \ntimes 3 \ntimes 2 \ntimes 5 \ntimes 4 - 1$ bandas, onde de novo tiramos 1 para excluir a ``banda vazia''.
\endgraf\medskip\noindent
(3):
Cada músico que toca $i$ instrumentos tem $2^i - 1$ opções (tirando a opção de ``não tocar nada'').  Então podemos formar $7\ntimes 1 \ntimes 3 \ntimes 1 \ntimes 15 \ntimes 7$ bandas.

\endproblem
%%}}}

%%{{{ prob 
\problem.
De quantas maneiras podemos escrever um string ternário
(usando o alfabeto $\set{0, 1, 2}$)
de tamanho 7,
tais que \emph{não aparece neles o substring $00$}.
\endgraf
Por exemplo:
$$
\align
0112220                                           &\qquad\text{é um string aceitável;}\\
2\underline{00}1\underline{0\overline0}\overline0 &\qquad\text{não é.}
\endalign
$$

\hint
Recursão.

\hint
Seja $a(n)$ o número dos strings ternários de tamanho $n$ tais que não aparece
neles o substring ${00}$.

\hint
Defina a $a(n)$ e depois calcule o $a(7)$, calculando em ordem os
$a(0),a(1),\dotsc,a(7)$.

\solution
Seja $a(n)$ o número dos strings ternários de tamanho $n$ tais que não aparece
neles o substring ${00}$.
Queremos achar o $a(7)$.
\endgraf
Observe que:
$$
\align
    a(0) &= 1 \qqqquad\explanation{o string vazio: ``$\,$''}\\
    a(1) &= 3 \qqqquad\explanation{os strings: ``$0$'', ``$1$'', e ``$2$''}\\
    a(n) &=
      \underbrace{a(n-1)}_{1\ldots}
    + \underbrace{a(n-1)}_{2\ldots}
    + \underbrace{a(n-2)}_{{01}\ldots}
    + \underbrace{a(n-2)}_{{02}\ldots}\\
         &= 2a(n-1) + 2a(n-2)\\
         &= 2(a(n-1) + a(n-2))
\endalign
$$
Então calculamos os primeiros $8$ termos da seqüência:
$$
1,\quad 3,\quad 8,\quad 22,\quad 60,\quad 164,\quad 448,\quad \underbrace{1224}_{a(7)}.
$$

\endproblem
%%}}}

%%{{{ prob: pessimissimo 
\problem.
\label{pessimissimo}%
Contar todas as palavras feitas por permutações das 12 letras da palavra
$$
\txt{PESSIMISSIMO}
$$
onde\dots
\item{(1)}
A palavra começa com $\txt P$.
\item{(2)}
Todos os $\txt I$ aparecem \emph{juntos}.
\item{(3)}
Os $\txt M$ aparecem \emph{separados}.
\item{(4)}
Nenhum dos $\txt S$ aparece ao lado de outro $\txt S$.

\hint
Para o (4), seria diferente se a restricção fosse
``os $\txt S$ não aparecem todos juntos''.

\solution
(1):
Como somos obrigados começar a palavra com ${\txt P}$,
precisamos apenas contar as permutações das letras da palavra
$
\txt{ESSIMISSIMO}
$,
que sabemos que são
$$
\frac
{11!}
{4!\stimes3!\stimes 2!}.
$$
\endgraf\medskip\noindent
(2):
Podemos considerar que temos apenas um $I$:
$
\dfrac
 {10!}
 {4!\stimes  2!}
$
\endgraf\medskip\noindent
(3):
Contamos em quantas palavras eles aparecem juntos,
e usando princípio da adição, os subtraimos das permutações sem restricção.
$$
\underbrace{
\,
\dfrac
 {12!}
 {4!\stimes  3!\stimes  2!}
\,
}_{\text{todas}}
 -
\underbrace{
\,
\dfrac
 {11!}
 {4!\stimes  3!}
\,
}_{\text{$\txt M$ juntos}}
$$
\endgraf\medskip\noindent
(4):
Construimos cada dessas palavras em passos.
Primeiramente escolhemos uma das permutações da palavra sem os ${\txt M}$'s:
$$
\phantom{\underline{\phantom{{\txt M}}}}*
\phantom{\underline{\phantom{{\txt M}}}}*
\phantom{\underline{\phantom{{\txt M}}}}*
\phantom{\underline{\phantom{{\txt M}}}}*
\phantom{\underline{\phantom{{\txt M}}}}*
\phantom{\underline{\phantom{{\txt M}}}}*
\phantom{\underline{\phantom{{\txt M}}}}*
\phantom{\underline{\phantom{{\txt M}}}}*
\phantom{\underline{\phantom{{\txt M}}}}
$$
(temos 
$
\dfrac
{8!}
{3!\stimes 2!}
$
opções).
\endgraf
\medskip
No próximo passo escolemos em qual das $9$ posições possíves colocamos os $M$:
$$
\underline{\phantom{{\txt M}}}*
\underline{\phantom{{\txt M}}}*
\underline{\phantom{{\txt M}}}*
\underline{\phantom{{\txt M}}}*
\underline{\phantom{{\txt M}}}*
\underline{\phantom{{\txt M}}}*
\underline{\phantom{{\txt M}}}*
\underline{\phantom{{\txt M}}}*
\underline{\phantom{{\txt M}}}
$$
Pelo princípio da multiplicação então, temos
$
\dfrac
{8!}
{3!\stimes 2!}
\cdot
\comb 9 4
$
palavras que satisfazem essa restricção.

\endproblem
%%}}}

%%{{{ prob 
\problem.
De quantas maneiras podemos escrever um string usando o alfabeto
de 26 letras
$$
\txt A, \txt B, \txt C, \dotsc, \txt X, \txt Y, \txt Z,
$$
tais que as vogais aparecem na ordem estrita alfabética, e as consoantes na órdem oposta?
(As vogais sendo as letras $\txt A$, $\txt E$, $\txt I$, $\txt O$, $\txt U$, $\txt Y$.)
{Por exemplo:}
$$
\align
\txt{TEDUCY}    &\qquad\text{é um string aceitável};\\
\txt{DETUCY}    &\qquad\text{não é ($\txt D \not> \txt T$)};\\
\txt{TEDUCA}    &\qquad\text{não é ($\txt U \not< \txt A$)}.
\endalign
$$
\item{(1)} \dots se os strings são de tamanho 26 e os vogais aparecem todos juntos;
\item{(2)} \dots se os strings são de tamanho 12 e aparecem todos os vogais;
\item{(3)} \dots se os strings são de tamanho 3;
\item{(4)} \dots se os strings são de tamanho $\ell$, com $0\leq\ell\leq 26$.

\solution
(1)
Como a ordem das consoantes e das vogais é predeterminada e as vogais devem aparecer juntas,
a única escolha que precisamos fazer é onde colocar as vogais, e temos $21$ possíveis posições.
Então existem $21$ tais strings.
\endgraf\medskip\noindent
(2)
$$
\underbrace{\comb {20} 6}_{\text{\eightrm consoantes}},
\underbrace{\comb {12} 6}_{\text{\eightrm suas posições}}.
$$
\endgraf\medskip\noindent
(3)
Separamos todos os strings que queremos contar em quatro grupos e contamos cada um separadamente:
$$
{
\overbrace{
\underbrace{\comb {20} 3}_{\text{as c.}}
}^{\text{3 c., 0 v.}}
}
+
{
\overbrace{
\underbrace{\comb {20} 2}_{\text{as c.}}
\underbrace{\comb 6 1}_{\text{a v.}}
\underbrace{\comb 3 2}_{\text{pos.~c.}}
}^{\text{2 c., 1 v.}}
}
+
\overbrace{
\underbrace{\comb {20} 1}_{\text{a c.}}
\underbrace{\comb 6 2}_{\text{as v.}}
\underbrace{\comb 3 1}_{\text{pos.~c.}}
}^{\text{1 c., 2 v.}}
+
\overbrace{
\underbrace{\comb 6 3}_{\text{as v.}}
}^{\text{0 c., 3 v.}}.
$$
Podemos descrever o resultado numa forma mais uniforme e mais fácil para generalizar:
$$
\Sum_{i=0}^3
\tunderbrace{\comb {20} {3-i}} {as $3-i$ c.}
\tunderbrace{\comb 6 i} {as $i$ v.}
\tunderbrace{\comb 3 i} {pos.~v.}
=
\Sum_{\Sb c+v=3\\ c,v\in\nats\endSb}
\tunderbrace{\comb {20} c} {as c.}
\tunderbrace{\comb 6 v} {as v.}
\tunderbrace{\comb 3 v} {pos.~v.}
$$
\endgraf\medskip\noindent
(4)
Seguindo a última forma do (3), temos
$$
\Sum_{i=0}^{\ell}
\tunderbrace{\comb {20} {\ell-i}} {as $\ell-i$ c.}
\tunderbrace{\comb 6 i} {as $i$ v.}
\tunderbrace{\comb {\ell} i} {pos.~v.}
$$
maneiras.  O somatório pode ser escrito também assim:
$$
\Sum
\bigg\{
\tunderbrace{\comb {20} c} {as c.}
\tunderbrace{\comb 6 v} {as v.}
\tunderbrace{\comb {\ell} v} {pos.~v.}
\ \Big|\ 
c+v=\ell, \ 0\leq c \leq 20, \ 0\leq v \leq 6, \ c,v\in\nats
\bigg\}.
$$
Note que como o conjunto acima é finito,
a adição é comutativa e associativa; logo, nosso somatório é bem-definido.

\endproblem
%%}}}

%%{{{ prob: roulette_multiple_balls 
\problem.
\label{roulette_multiple_balls}%
Numa roleta dum cassino tem ``pockets'' (ou ``casas'') numerados com:
$$
00, 0, 1, 2, \dotsc, 36
$$
e cada um deles é suficientemente profundo para caber até 8 bolinhas.
O crupiê joga 8 bolinas na roleta no mesmo tempo.
De quantas maneiras elas podem cair nos pockets se\dots
\item{(1)}\dots as bolinhas são distintas e não importa sua ordem dentro um pocket.
\item{(2)}\dots as bolinhas são todas iguais.
\endgraf

\solution
\noindent
(1) São permutações com repetições: $38 ^ 8$.
\endgraf
\noindent
(2) São combinações com repetições: $\comb {38 + 8 - 1} 8 = \comb {45} 8$.

\endproblem
%%}}}

%%{{{ prob 
\problem.
De quantas maneiras podemos escrever um string usando
letras do alfabeto $\set{\txt A, \txt B, \txt C, \txt D}$,
tais que \emph{cada letra é usada exatamente duas vezes
mas não aparece consecutivamente no string}?
Por exemplo:
$$
\align
\txt{ABADCDBC}                      &\qquad\text{é um string aceitável;}\\
\txt{ABAC$\underline{\txt{DD}}$BC}  &\qquad\text{não é.}
\endalign
$$

\hint
Inclusão--exclusão.

\hint
Considere as propriedades:
$$
\xalignat 4
 \alpha  &: \text{aparece o $\txt{AA}$}
&\beta   &: \text{aparece o $\txt{BB}$}
&\gamma  &: \text{aparece o $\txt{CC}$}
&\delta  &: \text{aparece o $\txt{DD}$}.
\endxalignat
$$

\solution
Seja $N$ o número de permutações totais das létras
e defina as 4 propriedades
$$
\xalignat 4
 \alpha  &: \text{aparece o $\txt{AA}$}
&\beta   &: \text{aparece o $\txt{BB}$}
&\gamma  &: \text{aparece o $\txt{CC}$}
&\delta  &: \text{aparece o $\txt{DD}$}.
\endxalignat
$$
Procuramos o número dos strings de tamanho 8 que não tenham nenhuma dessas 4 propriedades.
Assim que calcular os $N(\alpha),\dotsc,N(\alpha,\beta,\gamma,\delta)$
o princípio da inclusão--exclusão, vai nos dar o número que procuramos.
\endgraf
Observamos que
$$
\gather
N(\alpha) =N(\beta) =N(\gamma) =N(\delta)\\
N(\alpha,\beta) =N(\alpha,\gamma) = \dotsb = N(\gamma,\delta)\\
N(\alpha,\beta,\gamma) = \dotsb = N(\beta,\gamma,\delta).
\endgather
$$
\endgraf
Calculamos os
$$
\align
N
&= \frac {8!} {2!\stimes 2!\stimes 2!\stimes 2!} = 2520\\
N(\alpha)
&= \frac {7!} {2!\stimes 2!\stimes 2!} = \frac {7!} 8 = 7\ntimes 6 \ntimes 5 \ntimes 3 = 630\\
N(\alpha,\beta)
&= \frac {6!} {2!\stimes 2!} = \frac {6!} 4 = 180 \\
N(\alpha,\beta,\gamma)
&= \frac {5!} {2!} = \frac {5!} 2 = 60 \\
N(\alpha,\beta,\gamma,\delta)
&= {4!} = 24.
\endalign
$$
\endgraf
Para responder, temos
$$
\multline
    N
    - \comb 4 1 N(\alpha)
    + \comb 4 2 N(\alpha,\beta)
    - \comb 4 3 N(\alpha,\beta,\gamma)
    + N(\alpha,\beta,\gamma,\delta)\\
    =
    2520 - 4\ntimes 630 + 6\ntimes 180 - 4\ntimes 60 + 24
    =
    864
\endmultline
$$
tais permutações.

\endproblem
%%}}}

%%{{{ prob: parity_respecting_strings_mutual_recursion 
\problem.
\label{parity_respecting_strings_mutual_recursion}%
De quantas maneiras podemos escrever um string binário
(usando o alfabeto $\set{0, 1}$) de tamanho 12,
tais que: 
\beginol
\li os $0$'s aparecem apenas em grupos maximais de tamanho par;
\li os $1$'s aparecem apenas em grupos maximais de tamanho ímpar.
\endol
Por exemplo:
$$
\align
{000000111001}                         &\qquad\text{é um string aceitável;}\\
{100\underline{11}001\underline{000}1} &\qquad\text{não é.}
\endalign
$$

\hint
Separe os strings em dois grupos, aqueles que terminam em $0$ e aqueles que terminam em $1$,
e conta os strings de cada grupo usando recursão.

\hint
Sejam $a(n)$ e $b(n)$ o número de strings binários de tamánho $n$ que terminam em $0$ e em $1$ respectivamente.

\endproblem
%%}}}

%%{{{ prob: xyzzy_lemmings 
\problem.
\label{xyzzy_lemmings}%
\def\MM{\ensuremath{\mathtt{M}}}%
\def\FB{\ensuremath{\mathtt{F}}}%
\def\ST{\ensuremath{\mathtt{B}}}%
Xÿźźÿ o Mago Bravo decidiu matar todos os lemmings que ele guarda no seu quintal.
Seus feitiços são os:
\beginul
\li ``magic missile'', que mata 2 lemmings simultaneamente, e gasta 1 ponto ``mana'';
\li ``fireball'', que mata 3 lemmings simultaneamente, e gasta 2 pontos mana.
\endul
Alem dos feitiços, Xÿźźÿ pode usar seu bastão para matar
os lemmings (que não custa nada, e mata 1 lemming com cada batida).
\endgraf
Suponha que o mago \emph{nunca} lançará um feitiço que mataria mais lemmings do
que tem (ou seu quintal vai se queimar).
Ele tem $m$ pontos mana e existem $n$ lemmings no seu quintal.
Em quantas maneiras diferentes ele pode destruir todos os lemmings se\dots
\beginol
\li os lemmings são indistinguíveis?
\li os lemmings são distinguíveis?
\li os lemmings são distinguíveis e cada vez que Xÿźźÿ mata um usando seu bastão,
ele \emph{ganha} um ponto de mana?
\endol
(Para os casos que os lemmings são distinguíveis,
o mago escolhe também \emph{quais} dos lemmings ele matará cada vez.)

\hint
Recursão.

\hint
Seja $f(m,n)$ o número de maneiras que Xÿźźÿ pode matar todos os $n$ lemmings,
começando com $m$ pontos de mana.

\endproblem
%%}}}

\endproblems
%%}}}

%%{{{ History 
\history.

Pascal não foi o primeiro de estudar o ``triângulo aritmético'',
cuja existência e sua relação com o teorema binomial já eram
conhecidas desde uns séculos antes do seu nascimento.
Mesmo assim, seu estudo
\emph{``Traité du triangle arithmétique,
avec quelques autres petits traitez
sur la mesme matière''},
publicado no ano \yearof{1654} (depois da sua morte)
popularizou o triângulo e suas diversas aplicações e
propriedades~(\cite{pascaltriangle}).

\endhistory
%%}}}

%%{{{ Further reading 
\further.

Veja o~\cite{nivencount}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Number_theory_divisibility 
\chapter Teoria dos números I: divisibilidade.
\label{Number_theory_divisibility}%

%%{{{ Factorization 
\section Fatorização.

%%{{{ Q: given a positive integer n, how can we break it to construction blocks? 
\question.
Dado um inteiro positivo $n$, como podemos ``quebrá-lo'' em blocos de construção?
%%}}}

%%{{{ what is our cement? 
\note.
Vamos primeiramente responder nessa questão com outra:
\emph{Qual seria nosso ``cimento''?}
Tome como exemplo o número $n=28$.
Usando $+$ para construí-lo com blocos, podemos quebrá-lo:
$$
\align
28 &= 16 + 12.
\intertext{E agora quebramos esses dois blocos:}
   &= \overbrace{10 + 6}^{16} + \overbrace{11 + 1}^{12};
\intertext{e esses:}
   &= \overbrace{3 + 7}^{10} + \overbrace{3 + 3}^{6} + \overbrace{4 + 7}^{11} + 1
\intertext{e o $1$ não é mais ``quebrável''.
Nesse quesito, ele é um bloco atômico, um ``tijolo''.
Repetimos esse processo até chegar num somatório cujos termos são todos tijolos:}
 &= \tunderbrace{1 + 1 + 1 + 1 + \dotsb + 1} {$28$ termos}.
\endalign
$$
O leitor é convidado pensar sobre as próximas observações:
\beginol
\li
Começando com qualquer inteiro positivo $n$,
depois um \emph{finito} número de passos, o processo termina:
nenhum dos termos que ficam pode ser quebrado.
\li
Existe apenas um tipo de bloco atômico: o $1$.
Podemos então formar qualquer número $n$ começando com $n$ tijolos ($n$ $1$'s)
e usando a operação $+$ para os juntar.
\li
Não faz sentido considerar o $0$ como tijolo, pois escrevendo o $1$ como
$$
1 = 1 + 0 \qqqqtext{ou}
1 = 0 + 1
$$
não conseguimos o ``quebrar'' em peças menores.  Pelo contrário,
ele aparece novamente, da mesma forma, no lado direito.
\endol
%%}}}

%%{{{ x: partitioning_restricted_best_strategy 
\exercise.
\label{partitioning_restricted_best_strategy}%
Qual é a melhor estratégia para desconstruir o $n$ em $1$'s conseguindo
o menor número de passos possível?  Quantos passos precisa?
Suponha que em cada passo tu tens que escolher apenas \emph{um} termo
(não atômico) e decidir em quais duas partes tu o quebrarás.

\hint
Olha na forma final do somatório.
O que acontece em cada passo?

\solution
Todas as estratégias são iguais: em cada passo, um $+$ é adicionado,
e todas terminam no mesmo somatório com $n$ $1$'s e $n-1$ $+$'s.
Então começando com qualquer número $n$, depois de $n-1$ passos chegamos
na sua forma $n = 1+1+\dotsb +1$.

\endexercise
%%}}}

%%{{{ x 
\exercise.
Prove formalmente tua resposta no~\ref{partitioning_restricted_best_strategy}.

\hint
Como nos livramos dos pontos informais ``$\dotsb$''?

\hint
Indução.

\hint
Seja $steps(x)$ o número de passos necessários para quebrar o $x$ em $1$'s.

\endexercise
%%}}}

%%{{{ times in stead of plus 
\note ``$\,\ntimes\,$'' ao invés de ``$\,+\,$''.
Vamos agora usar como cimento a operação $\ntimes$,
ilustrando o processo com o número $2016$:
\goodbreak
$$
\align
2016
&= 12 \ntimes 168
\intertext{e repetimos\dots}
&= \overbrace{4\ntimes 3}^{12} \ntimes \overbrace{28 \ntimes 6}^{12}
\intertext{e agora vamos ver:
o $4$ pode ser quebrado sim ($2\ntimes2$), mas o $3$?
Escrever $3 = 3\ntimes 1$ com certeza não é um jeito aceitável para quebrar o $3$
em blocos de construção ``mais principais'': o lado direto é mais complexo!
Quebrando com $\ntimes$ então, o $3$ é um bloco atômico, um tijolo!
Continuando:}
&= \overbrace{2\ntimes 2}^{4}{} \ntimes 3 \ntimes (7\ntimes 4) \ntimes (2\ntimes3)\\
&= 2\ntimes 2 \ntimes 3 \ntimes 7 \ntimes \overbrace{2\ntimes2}^4{} \ntimes 2\ntimes3
\intertext{onde todos os fatores são atômicos.
Podemos construir o número $2016$ então assim:}
2016 &= 2\ntimes 2 \ntimes 3 \ntimes 7 \ntimes 2\ntimes2 \ntimes 2\ntimes3,
\endalign
$$
usando os tijolos 2, 3, e 7, e a operação de multiplicação.
Nos vamos definir formalmente esses tijolos (são os \ii{primo}[informalmente]\dterm{primos},~\ref{prime}),
e estudar suas propriedades.
\endgraf
Ilustrando com o mesmo número $2016$, um outro caminho para processar seria o seguinte:
$$
\align
2016
&= 48 \ntimes 42 \\
&= \overbrace{8 \ntimes 6}^{48} \ntimes \overbrace{6\ntimes 7}^{42}\\
&= \overbrace{2\ntimes 4}^{8} \ntimes \overbrace{2\ntimes 3}^{6} \ntimes \overbrace{2\ntimes 3}^{6}{}\ntimes 7\\
&= 2 \ntimes \overbrace{2\ntimes 2}^{4}{} \ntimes 2\ntimes 3 \ntimes 2\ntimes 3\ntimes 7
\intertext{então no final temos:}
2016&= 2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes 3 \ntimes 2 \ntimes 3 \ntimes 7.
\endalign
$$
%%}}}

%%{{{ x: fundamental_theorem_of_arithmetic_omen 
\exercise.
\label{fundamental_theorem_of_arithmetic_omen}%
O que tu percebes sobre as duas desconstruções?:
$$
\align
2016 &= 2\ntimes 2 \ntimes 3 \ntimes 7 \ntimes 2\ntimes2 \ntimes 2\ntimes3;\\
2016 &= 2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes 3 \ntimes 2 \ntimes 3 \ntimes 7.
\endalign
$$

\solution
Esquecendo a ordem que os fatores parecem, são iguais:
cada construção precisa os mesmos blocos atômicos (o $2$, o $3$, e o $7$),
e cada um deles foi usado o mesmo número de vezes:
$2016 = 2^5 3^2 7$.

\endexercise
%%}}}

%%{{{ x: factorize_some_integers 
\exercise.
\label{factorize_some_integers}%
Fatorize os inteiros $15$, $16$, $17$, $81$, $100$, $280$, $2015$, e $2017$
em fatores primos.

\solution
Calculamos:
$$
\alignat 4
15   &= 3 \ntimes 5 \qquad&  17   &= 17          \qquad& 100  &= 2^2\ntimes 5^2           \qquad& 2015 &= 5\ntimes 13\ntimes 31  \\
16   &= 2^4         \qquad&  81   &= 3^4         \qquad& 280  &= 2^3 \ntimes 5 \ntimes 7  \qquad& 2017 &= 2017.
\endalignat
$$

\endexercise
%%}}}

%%{{{ codeit: program_factor_naive 
\codeit FactorNaive.
\label{program_factor_naive}%
Escreva um programa que mostra para cada entrada, uma fatorização em primos.
Execute teu programa para verificar tuas respostas no~\ref{factorize_some_integers}.
\endcodeit
%%}}}

%%{{{ Q: how many different construction blocks for times? 
\question.
Usando adição, nos precisamos apenas um tipo de tijolo para construir qualquer
inteiro positivo: o $1$.
Usando a multiplicação nos já percebemos que vários tipos são necessários; mas quantos?
%%}}}

%%{{{ A: soon 
\note Resposta (Euclides).
Essa pergunta e sua resposta não são triviais!
Recomendo para ti, tentar responder e \emph{provar} tua afirmação.
Logo vamos encontrar a resposta (de Euclides)
que é um dos teoremas mais famosos e importantes na história de matemática
(\ref{primes_is_infinite}).
%%}}}

\blah.
No fim do capítulo chegamos no resultado principal
que esclarecerá o~\ref{fundamental_theorem_of_arithmetic_omen}:
o Teorema Fundamental de Aritmética (\refn{fundamental_theorem_of_arithmetic}),
ilustrado (parcialmente) já por \Euclid{}Euclides
(circa~\yearof{300}~a.C.)~nos seus \Euclid[Elementos]\emph{Elementos}
de Euclides\Euclid~\cite{elements}
e provado completamente e formalmente por \Gauss{}Gauss
(no ano \yearof{1798}) no seu
\emph{Disquisitiones Arithmeticæ}\Gauss[Disquisitiones Arithmiticæ]~\cite{disquisitiones}.

\endsection
%%}}}

%{{{ Divisibility 
\section Divisibilidade.

%%{{{ df: divides 
\definition Divisibilidade.
\label{divides}%
\tdefined{divide}%
\tdefined{divisor}%
\tdefined{multiplo}%
\tdefined{divisível}%
\sdefined {\sholed a\divides \sholed b} {$a$ divide $b$}%
Sejam $a,b\in\ints$.
Digamos que \dterm{o $a$ divide o $b$} (ou \dterm{o $b$ é divisível por $a$}), sse existe $b = ak$ para algum $k\in\ints$.
Nesse caso, escrevemos $a\divides b$.
Em símbolos:
$$
a\divides b \defiff \lexists {k\in\ints} {b = ak}.
$$
Os \dterm{divisores} do $a$ são todos os inteiros $d$ tais que $d \divides a$.
Naturalmente, usamos a notação $a\ndivides b$ quando $a$ não divide $b$.
%%}}}

%%{{{ eg 
\example. $3 \divides 12$, porque $12 = 3 \ntimes 4$ e $4\in\ints$, mas
$8 \ndivides 12$, porque nenhum inteiro $u$ satisfaz $12 = 8u$.
\endexample
%%}}}

%%{{{ x: divides_properties 
\exercise Propriedades da divisibilidade.
\label{divides_properties}%
Sejam $a,b,x,y,m\in\ints$.
Prove que:
\beginol
\li[1_is_the_bottom_of_divides] $1 \divides a$
\li[0_is_the_top_of_divides] $a \divides 0$
\li $a \divides b \implies a \divides bx$
\li $a \divides b \implies a \divides -b \mland -a \divides b$
\li $a \divides b \mland a \divides c \implies a \divides b + c$
\li $a \divides b \mland a \divides c \implies a \divides bx + cy$
\li $a \divides b \mland b \neq 0 \implies \abs a \leq \abs b$
\li se $m\neq0$ então: $a \divides b \!\iff\! ma \divides mb$.
\endol

\hint
Aplique a definição do $\divides$.

\endexercise
%%}}}

%%{{{ x: divides_is_almost_a_partial_order 
\exercise Mais propriedades da divisibilidade.
\label{divides_is_almost_a_partial_order}%
Para todos $a,b,c\in\ints$,
$$
\alignat 2
&a \divides a                                           \called{reflexividade}\\
&a \divides b \mland b \divides c \implies a \divides c \called{transitividade}\\
&a \divides b \mland b \divides a \implies \abs a = \abs b.
\intertext{
Se $a,b\in\nats$, a terceira propriedade fica mais forte:
}
&a \divides b \mland b \divides a \implies a = b        \called{antissimetria}.
\endalignat
$$

\endexercise
%%}}}

%%{{{ prop: wrong_property_of_product_dividing_common_multiple 
\proposition.
\label{wrong_property_of_product_dividing_common_multiple}%
Sejam $a,b,m\in\ints$.  Se $a \divides m$ e $b \divides m$, então $ab \divides m$.
\wrongproof.
Como $a\divides m$, pela definição de $\divides$, existe $u\in\ints$ tal que
$a = mu$.  Similarmente, como $b\divides m$, existe $v\in\ints$ tal que
$b = mv$.  Multiplicando as duas equações por partes, temos
$$
ab = (mu)(mv) = m(umv),
$$
e como $umv\in\ints$, $ab \divides m$.
\mistaqed
%%}}}

%%{{{ x: find the error and prove that it is false 
\exercise.
Ache o erro na prova acima e \emph{prove} que a proposição é falsa!

\hint
Presta atenção na definição do $\divides$.

\hint
Procure um contraexemplo onde $a$ e $b$ tem um fator em comun.

\solution
O erro fica na aplicação da definição de $a \divides b$\thinspace:
ao invés de $\lexists {k\in\ints} {b = ak}$,
a prova usou $\lexists {k\in\ints} {a = bk}$.
\endgraf
Para ver que a proposição realmente é falsa, considere o contraexemplo seguinte:
$$
a = 6,\qquad
b = 15,\qquad
m = 30.
$$
Realmente temos
$6  \divides 30$ e 
$15 \divides 30$,
mas
$6\ntimes 15 = 90 \ndivides 30$.

\endexercise
%%}}}

\blah.
Nos encontramos a ``versão correta'' da proposição falsa acima no
item~\refn{wrong_property_of_product_dividing_common_multiple}
depois (\ref{product_of_coprimes_divides_common_multiple}).

%%{{{ x: implications_with_divisibility_of_linear_combinations 
\exercise.
\label{implications_with_divisibility_of_linear_combinations}%
Sejam $a,b,c\in\ints$.
Para cada afirmação abaixo, prove-a ou desprove-a:
$$
\alignat2
\text{(i)}   &\qquad& a \divides \phantom1b + c\phantom1                          &\implies a \divides b \mland a \divides c\\
\text{(ii)}  &\qquad& a \divides b + c \mland a \divides \phantom1b - c\phantom2  &\implies a \divides b                    \\
\text{(iii)} &\qquad& a \divides b + c \mland a \divides \phantom1b + 2c          &\implies a \divides b                    \\
\text{(iv)}  &\qquad& a \divides b + c \mland a \divides 2b + 2c                  &\implies a \divides b                    \\
\text{(v)}   &\qquad& a \divides b + c \mland a \divides 2b + 3c                  &\implies a \divides 3b + 2c\,.
\endalignat
$$

\solution
A (ii) é falsa: um contraexemplo seria o $a = 2$, $b = c = 1$.
Realmente, temos
$$
2 \divides 1 + 1 = 2 \mland 2 \divides 1 - 1 = 0,
\qqtext{mas}
2\ndivides 1.
$$
\endgraf
A (iii) é verdadeira:
$$
\rightbrace{
\aligned
        a\divides b + c \implies a\divides 2b + 2c\\
                                 a\divides \phantom1b + 2c
\endaligned
}
\implies
a \divides \munderbrace{(2b + 2c) - (b + 2c)} {\dsize b}.
$$

\endexercise
%%}}}

%%{{{ df: prime 
\definition Primo.
\label{prime}%
\tdefined{primo}%
\tdefined{composto}%
\iiseealso{composto}{primo}%
\iiseealso{primo}{composto}%
Seja $p\in\nats$, com $p \geq 2$.
Chamamos o $p$ \dterm{primo} sse $p$ é divisível apenas por $\pm 1$ e $\pm p$.
Caso contrário, ele é \dterm{composto}.
%%}}}

%%{{{ x: zero_and_one_prime_or_composite 
\exercise.
O $0$ é primo?  Composto?
O $1$ é primo?  Composto?

\solution
Nenhum dos dois é nem primo nem composto: a definição começa declarando
$p$ como um natural tal que $p \geq 2$.
Logo, não é aplicável nem para o 0 nem para o 1.

\endexercise
%%}}}

%%{{{ x: 2_is_the_only_even_prime 
\exercise.
\label{2_is_the_only_even_prime}%
2 é o único primo par.

\endexercise
%%}}}

%%{{{ x 
\exercise.
Usando uma fórmula de lógica, defina diretamente o que significa que
um $n\in\nats\setminus\set 1$ é composto.

\solution
Seja $n\in\nats$.
$$
\namedrel{Composite}(n) \defiff
\lexists {a,b\in\nats\setminus\set{0,1}} { n = ab }.
$$

\endexercise
%%}}}

%%{{{ x: first_primes 
{\input knuthprimes
\example.
\label{first_primes}%
Os primeiros 31 primos são os \primes{31}.
\endexample
}
%%}}}

%%{{{ x: in_primes_divides_means_equals 
\exercise.
\label{in_primes_divides_means_equals}%
Sejam $p$, $q$ primos, com $p\divides q$.
Mostre que $p=q$.

\endexercise
%%}}}

%%{{{ x: every_composite_number_is_divisible_by_a_prime 
\exercise.
\label{every_composite_number_is_divisible_by_a_prime}%
Seja $b$ composto.  Prove que $b$ tem um divisor primo $d\leq \sqrt b$.

\endexercise
%%}}}

%%{{{ codeit: program_factor 
\codeit factor.
\label{program_factor}%
Use o~\ref{every_composite_number_is_divisible_by_a_prime}
para melhorar teu programa do~\ref{program_factor_naive}.
\endcodeit
%%}}}

\endsection
%%}}}

%%{{{ The division algorithm 
\section O algoritmo da divisão.

%%{{{ lemma: euclidean_division 
\lemma Divisão de Euclides.
\label{euclidean_division}%
\Euclid[lema da divisão]%
\iisee{divisão}{Euclides}%
Dados inteiros $a$ e $b$ com $b>0$, existem inteiros $q$ e $r$ tais que:
$$
a = bq + r,
\qquad
0\leq r < b.
\eqdef{division_eq}
$$
Alem disso, os $q$ e $r$ são \emph{determinados unicamente}.
\sketch.
\endgraf
\proofstyle{Existência:}
Considera a seqüência infinita:
$$
\ldots,~
-3b + r,~
-2b + r,~
-b + r,~
r,~
b + r,~
2b + r,~
3b + r,~
\ldots
$$
Observe que ela tem elementos não-negativos e, aplicando a PBO, considera o menor deles.
\endgraf
\proofstyle{Unicidade:}
    Suponha que $a=bq+r=bq'+r'$
    para alguns $q,r,q',r'\in\ints$ tais que satisfazem as restricções
    $0\leq r < b$ e $0\leq r' < b$.
    Mostre que $r=r'$ e $q=q'$.
\qes
%%}}}

\blah.
Por causa dessa existência e unicidade, podemos definir:

%%{{{ df: division 
\definition Divisão.
\label{division}%
\tdefined{divisão}%
\tdefined{quociente}[divisão]%
\tdefined{resto}[divisão]%
\sidx[see]{quociente}{divisão} 
Dados $a,b\in\ints$ com $b>0$, chamamos os inteiros $q$ e $r$ que satisfazem
a~\eqref{division_eq}
Chamamos o $q$ o \dterm{quociente} e o $r$ o
\dterm{resto} da divisão de $a$ por $b$.
%%}}}

%%{{{ x: n_divides_exactly_one_of_n_consecutive_integers 
\exercise.
\label{n_divides_exactly_one_of_n_consecutive_integers}%
Seja $n\in\nats$ positivo.  Se $a_0,a_1,\dotsc,a_{n-1}$ são $n$ inteiros consecutivos,
então $n\divides a_i$ para um único $i\in\set{0,\dots,n-1}$.

\hint
Seja $a=a_0$.  Assim $a_i = a + i$.

\hint
Divida o $a$ por $n$ e, olhando para o resto $r$,
ache o certo $i$ tal que $n\divides a_i$.

\hint
Para a unicidade, ache o resto da divisão de $n$ por o aleatório $a_j$.

\endexercise
%%}}}

%%{{{ x 
\exercise.
Prove que para todo $n\in\ints$, se $3\ndivides n$
então $3 \divides n^2 - 1$.

\hint
Ou fatorize o $n^2-1$ e use o~\ref{n_divides_exactly_one_of_n_consecutive_integers},
ou considere os dois casos possíveis dependendo dos restos da divisão de $n$ por $3$.

\endexercise
%%}}}

%%{{{ df: closed_under_addition 
\definition Conjunto fechado sobre $+$.
\label{closed_under_addition}%
    Seja $A$ conjunto de números que satisfaz a propriedade:
    $$
    a,b \in A \implies a+b \in A.
    $$
    Digamos que $A$ é \dterm{fechado} sobre $+$.
%%}}}

%%{{{ x 
\exercise.
O $\emptyset$ e o $\set{0}$ são fechados sobre $+$.

\endexercise
%%}}}

%%{{{ x 
\exercise.
Generalize a noção acima para definir a noção
``conjunto fechado sobre $f$'',
onde $f$ é uma operação no $A$ de aridade qualquer.

\endexercise
%%}}}

%%{{{ x 
\exercise.
Quais dos conjuntos abaixo são fechados sobre $+$,
quais sobre $-$, e quais sobre $\cdot$?
$$
\aligned
    U &= \set{0}\\
    W &= \set{0,1}\\
    P &= \set{1,2,4,8,16,\dotsc}\\
    I &= \set{1,1/2,1/4,1/8,1/16,\dotsc}
\endaligned
\quad
\aligned
    A &= \set{0,4,6,10,12,16,18,22,24,\dotsc}\\
    B &= \set{0,2,4,6,8,10,12,\dotsc}\\
    C &= \set{\dotsc,-9,-6,-3,0,3,6,9,\dotsc}\\
    D &= \set{\dotsc,-8,-5,-2,1,4,7,10,\dotsc}.
\endaligned
$$

\endexercise
%%}}}

%%{{{ x 
\exercise.
Defina os conjuntos infinitos do exercício anterior sem usar ``$\ldots$\!''.

\endexercise
%%}}}

%%{{{ x 
\exercise.
O $\rats$ é fechado sobre quais das quatro operações binárias: $+$, $-$, $\cdot$, $\div$?
E o $\rats\setminus\set0$?

\endexercise
%%}}}

%%{{{ x 
\exercise.
Prove que se um conjunto é fechado sobre $-$, ele tem que ser fechado sobre $+$ também, mas não o converso!

\endexercise
%%}}}

\blah.
Um conjunto de inteiros fechado sobre $-$ (e $+$),
não tem muita liberdade na ``forma'' dele.
O teorema seguinte mostra a forma geral de todos eles.

%%{{{ x: form_of_closed_under_minus 
\exercise.
\label{form_of_closed_under_minus}%
Seja $S\subset\ints$, com $S\neq\emptyset$,
$S$ fechado sobre $-$ (e logo, sobre $+$ também).
Prove que $S=\set 0$ ou $S$ possui um mínimo elemento positivo $m$
e $S = \setst {km} {k \in\ints}$.

\endexercise
%%}}}

%%{{{ x: form_of_closed_under_minus_without_disjunction 
\exercise.
Sem usar disjunção, escreva uma frase equivalente com a conclusão do
\ref{form_of_closed_under_minus}, e explique porque ela é equivalente.

\hint
Existe $n\in\nats$ tal que $S = \setst {kn} {k\in\ints}$.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ The greatest common divisor 
\section O máximo divisor comum.
\label{The_greatest_common_divisor}%

%%{{{ df: a_gcd 
\definition.
\label{a_gcd}%
Sejam $a,b\in\ints$.
O inteiro $d$ é \dterm{um máximo divisor comum (m.d.c.)} dos $a$~e~$b$,
sse $d$~é~um divisor comum e um multiplo de todos os divisores comuns.
Em símbolos:
\endgraf\vskip 1ex\noindent
\line{\hfill
$
d = \dsym{\gcd a b}
\defiff
\tunderbrace {
d \divides a
\;\land\;
d \divides b
} {divisor comun}
\;\land\;
\tunderbrace {
\lforall c {c\divides a \;\land\; c\divides b \implies c\divides d}
} {``máximo''}.
$
\hfil\mistake}
%%}}}

%%{{{ x 
\exercise.
A~\ref{a_gcd} tem um erro: o símbolo $\gcd a b$ não foi bem-definido!
O que precisamos provar para definir realmente o símbolo $\gcd a b$?

\solution
Duas coisas:
\endgraf
\proofstyle{Existência:}
\emph{para todos inteiros $a$, $b$, existe inteiro $d$ que satisfaz as relações acima.}
\endgraf
\proofstyle{Unicidade:}
\emph{se $d$, $d'$, são inteiros que satisfazem essas relações, então $d=d'$.}

\endexercise
%%}}}

%%{{{ prop 
\proposition.
Sejam $a,b\in\ints$.  Se $d,d'\in\ints$ são máximos divisores comum
dos $a$ e $b$, então $d=\pm d'$.
\sketch.
Aplicamos a definição de m.d.c.~para cada um dos $d$ e $d'$,
para chegar em $d\divides d'$ e $d'\divides d$.
\qes
\proof.
Suponha que $d,d'$ são m.d.c.'s de $a$ e $b$.
Como $d$ é um m.d.c., todos os divisores em comum dos $a$ e $b$ o dividem.
Mas, como $d'$ é um divisor em comum, então $d'\divides d$.
Simetricamente concluimos que $d\divides d'$.
Logo $d = \pm d'$ (por~\ref{divides_is_almost_a_partial_order}).
\qed
%%}}}

%%{{{ cor 
\corollary.
Sejam $a,b\in\ints$.
Existe único $d\in\nats$ tal que $d$ é um m.d.c.~de $a$ e~$b$.
%%}}}

\blah.
Agora podemos definir o símbolo $\gcd a b$:

%%{{{ df: gcd 
\definition O máximo divisor comum.
\label{gcd}%
\tdefined{mdc}%
\tdefined{divisor}[máximo comum]%
\sdefined {\gcd {\sholed a} {\sholed b}} {o máximo divisor comum de $a$ e $b$}%
\iisee{mdc}{divisor, máximo comum}%
Sejam $a,b\in\ints$.
$$
d = \dsym{\gcd a b}
\defiff
\tunderbrace {
d \divides a
\;\land\;
d \divides b
} {divisor comun}
\;\land\;
\tunderbrace {
d\in\nats
\;\land\;
\lforall c {\paren{c\divides a \mland c\divides b} \implies c\divides d}
} {o máximo}
$$
%%}}}

%%{{{ thm: gcd_as_linear_combination & gcd_divides_any_linear_combination 
\theorem.
\label{gcd_as_linear_combination}%
\label{gcd_divides_any_linear_combination}%
\tdefined{combinação linear}%
Sejam $a,b\in\ints$.
Então existe $d\in\nats$ que satisfaz a definição de $\gcd a b$,
ele pode ser escrito como \dterm{combinação linear}
dos $a$ e $b$, com coeficientes inteiros; ou seja,
$$
d = sa + tb,
\qquad
\text{para alguns $s,t\in\ints$}.
$$
Alem disso, o $\gcd a b$ divide qualque combinação linear dos $a$ e $b$.
\sketch.
Considere o conjunto $L$ de todas as combinações lineares.
Prove que existe $n_0\in\nats$ tal que $L = \set{ kn_0 \st k\in\ints }$.
Verifique que $\gcd a b = n_0$.
\qes
%%}}}

%%{{{ x 
\exercise.
Verifique se a forma do $\gcd a b$ como combinação linear dos $a$ e $b$
é unicamente determinada.

\hint
Não é.  Mostre um contraexemplo.

\solution
Toma $3$ e $4$.  Temos $\gcd 4 3 = 1$, mas:
$$
\aligned
1 &= (-2)\ntimes 4 + 3\ntimes 3\\
1 &= \phantom{(-}4\phantom{)}\ntimes 4 - 5\ntimes 3.
\endaligned
$$

\endexercise
%%}}}

%%{{{ prop: gcd_of_comparable 
\proposition.
\label{gcd_of_comparable}%
$a\divides b \implies \gcd a b = a$.
Especificamente, $\gcd a 0 = a$.
\sketch.
Precisamos apenas verificar as condições da definição de m.d.c., que seguem por
as propriedades de $\divides$ que já provamos.
\qes
%%}}}

%%{{{ x: gcd_signs 
\exercise.
\label{gcd_signs}%
$
\gcd a b
=
\gcd a {-b}
=
\gcd {-a} {b}
=
\gcd b a
$.

\endexercise
%%}}}

%%{{{ x: gcd_of_two_is_gcd_of_one_plus_sum 
\exercise.
\label{gcd_of_two_is_gcd_of_one_plus_sum}%
Sejam $a,b\in\ints$.
Prove que
$$
\gcd a b = \gcd a {a+b}.
$$

\hint
Lembre a definição de m.d.c.\,.

\hint
Talvez as propriedades seguintes são úteis:
\beginul
\li para todos $x,y\in\nats$, $x\divides y \mland y\divides x \implies x = y$;
\li para todos $a,x,y\in\ints$, $a\divides x \mland a\divides y \implies a \divides {x+y}$.
\endul

\solution
\proofstyle{Idéia 1:}
Sejam $d = \gcd a b$ e $d' = \gcd a {a + b}$.
Pela definição, $d$ é divisor comum dos $a$ e $b$,
então $d\divides a $ e $d\divides b$, e logo $d \divides a + b$.
Temos então que $d$ é um divisor comum dos $a$ e $a + b$, e, pela definição de mdc,
como $d' = \gcd a {b+c}$, temos $d'\divides d$.
Similarmente, $d\divides d'$.
Então $|d| = |d'|$ e como ambós são naturais (parte da definição de $\gcd x y$), temos:
$$
\gcd a b = d = d' = \gcd a {a + b}.
$$
\endgraf
\proofstyle{Idéia 2:}
Seja $d = \gcd a b$.  Vamos mostrar que $d = \gcd a {a + b}$.
Pela definição, $d\geq0$ e é divisor comum dos $a$ e $b$,
então $d\divides a$ e $d\divides b$, e logo $d \divides a + b$.
Temos então que $d\geq0$ e é um divisor comum dos $a$ e $a + b$, e, pela definição de mdc,
falta só provar que cada divisor comum deles divide o $d$.
Seja $c\in\ints$ tal que $c\divides a$ e $c \divides {a+b}$.
Logo, $c\divides a - (a+b)=-b$.  Concluimos que $c\divides b$, então
$c$ é um divisor comum dos $a$ e $b$, então $c\divides d$ pela definição do $d$
como m.d.c.~dos $a$ e $b$.

\endexercise
%%}}}

%%{{{ lemma: euclid_lemma 
\lemma Lema de Euclides.
\label{euclid_lemma}%
\Euclid[lema]%
Sejam $a,b\in\ints$ e $p$ primo.
Se $p \divides ab$, então $p\divides a$ ou $p\divides b$.
\sketch.
Suponha que $p\ndivides a$.  Logo o $\gcd a p = 1$ pode ser escrito como combinação linear de $a$ e $p$:
$$
1 = as + pt,    \qquad\text{para uns $s,t\in\ints$}.
$$
Multiplica os dois lados por $b$, e explica por que necessariamente $p\divides b$.
\qes
\proof.
Suponha que $p\ndivides a$.  Logo o $\gcd a p = 1$ pode ser escrito como combinação linear de $a$ e $p$,
ou seja, existem $s,t\in\ints$ tais que:
$$
\align
1 &= as + pt.
\intertext{Multiplicando os dois lados por $b$, temos:}
b &= asb + ptb.
\endalign
$$
Observe que como $p\divides ab$, segue que $p\divides asb$ (por~\ref{divides_properties}).
Obviamente $p\divides ptb$ também.
Logo, $p\divides asb + ptb = b$.
\qed
%%}}}

%%{{{ thm: coprime_with_a_part_of_a_product_must_divide_the_other_part_to_divide_the_product 
\theorem.
\label{coprime_with_a_part_of_a_product_must_divide_the_other_part_to_divide_the_product}%
Se $\gcd d a = 1$ e $d \divides ab$, então $d \divides b$.
\sketch.
A prova é practicamente a mesma com aquela do~\ref{euclid_lemma}:
lá nós precisamos da primalidade do $p$ apenas para
concluir que $\gcd a p = 1$.
Aqui temos diretamente a hipótese $\gcd a d = 1$.
\qes
\proof.
Seja $a,b,d\in\ints$, tais que
$\gcd d a = 1$ e $d \divides ab$.
Como $\gcd a d = 1$, podemos escrevê-lo como combinação linear dos $a$ e $d$:
$$
1 = sa + td,\qquad\text{para alguns $s,t\in\ints$}.
$$
Multiplicando por $b$, ganhamos
$$
b = sab + tdb,
$$
e argumentando como na prova do~\ref{euclid_lemma}
concluimos que $d \divides b$.
\qed
%%}}}

%%{{{ cor: product_of_coprimes_divides_common_multiple 
\corollary.
\label{product_of_coprimes_divides_common_multiple}%
Se $a\divides m$, $b\divides m$, e $\gcd a b = 1$, então $ab\divides m$.
\proof.
Como $a\divides m$, temos $m = au$ para algum $u\in\ints$.
Mas $b\divides m=au$, e como $\gcd b a = 1$, temos $b\divides u$
(por~\ref{coprime_with_a_part_of_a_product_must_divide_the_other_part_to_divide_the_product}).
Então $bv = u$ para algum $v\in\ints$.
Substituindo, $m = au = a(bv) = (ab)v$, ou seja, $ab \divides m$.
\qed
%%}}}

%%{{{ thm: primes_is_infinite 
\theorem Euclid.
\label{primes_is_infinite}%
\Euclid[infinidade de primos]%
Existe uma infinidade de primos.
\sketch.
Para qualquer conjunto finito de primos
$P = \set{p_1,\dotsc,p_n}$, considere o número
$p_1\dotsb p_n + 1$ e use-o para achar um primo fora do $P$.
\qes
\proof.
Para qualquer conjunto finito de primos
$P = \set{p_1,\dotsc,p_n}$,
observe que o número $p=p_1\dotsb p_n + 1$ não é divisivel por nenhum dos $p_i$'s
(porque $p_i\divides p$ e $p_i\divides p_1\dotsb p_n$ implicam
$p\divides 1$, absurdo).
Então, como $p\geq 2$, ou o $p$ é primo e $p\not\in P$,
ou $p$ é divisivel por algum primo $q \not\in P$
(por~\ref{every_composite_number_is_divisible_by_a_prime}).
Nos dois casos, existe pelo menos um primo fora do $P$.
\qed
%%}}}

\endsection
%%}}}

%%{{{ The Euclidean algorithm 
\section O algoritmo de Euclides.

%%{{{ Idea 
\note Idéia.
Sejam $a,b$ inteiros positivos.
Como achamos o $\gcd a b$?
Nos vamos aplicar o lemma da divisão~(\refn{euclidean_division}) repetetivamente,
até chegar em resto $0$:
$$
\matrix
\format
\r\;    &\;\c\;  & \; \c \;                   & \l      & \;\c\; & \c      & \qquad\qquad\l          \\
a       &   =    & b                          & q_0     &  +     & r_0,    & 0\leq r_0 < b           \\
b       &   =    & r_0                        & q_1     &  +     & r_1,    & 0\leq r_1 < r_0         \\
r_0     &   =    & r_1                        & q_2     &  +     & r_2,    & 0\leq r_2 < r_1         \\
r_1     &   =    & r_2                        & q_3     &  +     & r_3,    & 0\leq r_3 < r_2         \\
        & \vdots &                            &         &        &         & \hfil\vdots\hfil        \\
r_{n-3} &   =    & r_{n-2}                    & q_{n-1} &  +     & r_{n-1},& 0\leq r_{n-1} < r_{n-2} \\
r_{n-2} &   =    & \boxed{\mathstrut r_{n-1}} & q_n     &  +     & \munderbrace {r_n} {0},     & 0 = r_n < r_{n-1}.      
\endmatrix
$$
O $\gcd a b$ estará na posição marcada acima.
Vamos agora descrever o algoritmo formalmente, e provar
(informalmente e formalmente) sua corretude!
%%}}}

%%{{{ algorithm: euclidean_algorithm 
\algorithm Euclides.
\label{euclidean_algorithm}%
\tdefined{algoritmo}[de Euclides]%
\Euclid[algoritmo]%
\endgraf
\noindent%
{\def\Euclid{\algorithmstyle{Euclid}}%
\centerline{$\Euclid(a,b)$}
{\hrule width \hsize height 1pt\relax}
\vskip4pt
\algospec
 INPUT: $a,b\in\nats$
OUTPUT: $\gcd a b$
\endspec
\beginol
\li Se $b=0$, retorna $a$.
\li Retorna $\Euclid(b,r)$, onde $r = a \bmod b$.
\endol
{\hrule width \hsize height 1pt\relax}
}
%%}}}

%%{{{ eg: euclidean_algorithm_example 
\example.
\label{euclidean_algorithm_example}%
Ache o $\gcd {101} {73}$ com o algoritmo de Euclides.

\solution
Sabendo que os dois números são primos, fica imediato que eles são coprimos
entre si também: a reposta é 1.
\endgraf
Aplicando o algoritmo de Euclides, para achar o $\gcd {101} {73}$, dividimos o $101$ por $73$:
$$
\alignat 2
101 &= 73       \ntimes \tunderbrace {\phantom 1} {quociente} + \tunderbrace {\phantom{28}} {resto},      &\qquad&0 \leq \tunderbrace {\phantom{28}} {resto} < 73
\intertext{e sabemos que assim reduziremos o problema para o alvo de achar o $\gcd {73} {\text{resto}}$.  Pensando, achamos os valores:}
101 &= 73       \ntimes \tunderbrace {1} {quociente} + \tunderbrace {28} {resto},      &\quad&0 \leq \tunderbrace {28} {resto} < 73 
\intertext{ou seja, $\gcd {101} {73} = \gcd {73} {28}$.  Então, repetimos:}
73  &= 28       \ntimes \tunderbrace {2} {quociente} + \tunderbrace {17} {resto},      &&0 \leq \tunderbrace {17} {resto} < 28
\intertext{ou seja, $\gcd {73} {28} = \gcd {28} {17}$.  Repetimos:}
28  &= 17       \ntimes \tunderbrace {1} {quociente} + \tunderbrace {11} {resto},      &&0 \leq \tunderbrace {11} {resto} < 17
\intertext{ou seja, $\gcd {28} {17} = \gcd {17} {11}$.  Repetimos:}
17  &= 11       \ntimes \tunderbrace {1} {quociente} + \tunderbrace {6}  {resto},      &&0 \leq \tunderbrace {6} {resto} < 11
\intertext{ou seja, $\gcd {17} {11} = \gcd {11} 6$.  Repetimos:}
11  &= 6        \ntimes \tunderbrace {1} {quociente} + \tunderbrace {5}  {resto},      &&0 \leq \tunderbrace {5} {resto} < 6
\intertext{ou seja, $\gcd {11} 6 = \gcd 6 5$.  Repetimos:}
6   &= 5        \ntimes \tunderbrace {1} {quociente} + \tunderbrace {1}  {resto},      &&0 \leq \tunderbrace {1} {resto} < 5
\intertext{ou seja, $\gcd 6 5 = \gcd 5 1$.  Como $\gcd 5 1 = 1$, nem precisamos repetir, mas vamos mesmo assim:}
5   &= \boxed 1 \ntimes \tunderbrace {5} {quociente} + \tunderbrace {0} {resto}.      &&
\endalignat
$$
Mais compactamente, os passos são:
$$
\matrix
\format
\r  & \c    & \c       & \l        & \l & \c    & \l  & \c     & \c & \c       & \c & \c    & \c & \c     & \r            & \c    & \l          \\
101 & {}={} & 73       & {}\ntimes{} & 1  & {}+{} & 28, & \qquad & 0  & {}\leq{} & 28 & {}<{} & 73 & \qquad & \gcd{101}{73} & {}={} & \gcd{73}{28}\\
73  & {}={} & 28       & {}\ntimes{} & 2  & {}+{} & 17, &        & 0  & {}\leq{} & 17 & {}<{} & 28 &        & \gcd{73 }{28} & {}={} & \gcd{28}{17}\\
28  & {}={} & 17       & {}\ntimes{} & 1  & {}+{} & 11, &        & 0  & {}\leq{} & 11 & {}<{} & 17 &        & \gcd{28 }{17} & {}={} & \gcd{17}{11}\\
17  & {}={} & 11       & {}\ntimes{} & 1  & {}+{} & 6,  &        & 0  & {}\leq{} & 6  & {}<{} & 11 &        & \gcd{17 }{11} & {}={} & \gcd{11}{6 }\\
11  & {}={} & 6        & {}\ntimes{} & 1  & {}+{} & 5,  &        & 0  & {}\leq{} & 5  & {}<{} & 6  &        & \gcd{11 }{6 } & {}={} & \gcd{6 }{5 }\\
6   & {}={} & 5        & {}\ntimes{} & 1  & {}+{} & 1,  &        & 0  & {}\leq{} & 1  & {}<{} & 5  &        & \gcd{6  }{5 } & {}={} & \gcd{5 }{1 }\\
5   & {}={} & \boxed 1 & {}\ntimes{} & 5  & {}+{} & 0   &        &    &          &    &       &    &        & \gcd{5  }{1 } & {}={} & \gcd{1 }{0 } = \boxed 1.
\endmatrix
$$
\moveqedup
\endexample
%%}}}

%%{{{ 
\remark.
\def\Euclid{\algorithmstyle{Euclid}}%
Podemos utilizar o algoritmo de Euclides para achar o $\gcd a b$
onde $a,b\in\ints$ também,
graças ao~\ref{gcd_signs}:
$(a,b) = (\abs a, \abs b) = \Euclid(\abs a, \abs b)$.
%%}}}

%%{{{ x: find_a_couple_of_gcds 
\exercise.
\label{find_a_couple_of_gcds}%
Usando o algoritmo de Euclides, ache os:
(i) $\gcd {108} {174}$; 
(ii) $\gcd {2016} {305}$.

\solution
(i) Para o $\gcd {108} {174} = \gcd {174} {108}$ calculamos:
$$
\matrix
\format
\r  & \c    & \c       & \l        & \l & \c    & \l    & \c     & \c & \c       & \c & \c    & \c & \c     & \r             & \c    & \l            \\
174 & {}={} & 108      & {}\ntimes{} & 1  & {}+{} &{66},  & \qquad & 0  & {}\leq{} & 66 & {}<{} & 108& \qquad & \gcd{174}{108} & {}={} & \gcd{108}{66 }\\
108 & {}={} & 66       & {}\ntimes{} & 1  & {}+{} &{42},  &        & 0  & {}\leq{} & 42 & {}<{} & 66 &        &                & {}={} & \gcd{66 }{42 }\\
66  & {}={} & 42       & {}\ntimes{} & 1  & {}+{} &{24},  &        & 0  & {}\leq{} & 24 & {}<{} & 42 &        &                & {}={} & \gcd{42 }{24 }\\
42  & {}={} & 24       & {}\ntimes{} & 1  & {}+{} &{18},  &        & 0  & {}\leq{} & 18 & {}<{} & 24 &        &                & {}={} & \gcd{24 }{18 }\\
24  & {}={} & 18       & {}\ntimes{} & 1  & {}+{} &{6 },  &        & 0  & {}\leq{} & 6  & {}<{} & 18 &        &                & {}={} & \gcd{18 }{6  }\\
18  & {}={} & \boxed 6 & {}\ntimes{} & 3  & {}+{} &{0 }   &        &    &          &    &       &    &        &                & {}={} & \gcd{6  }{0  } = \boxed 6.
\endmatrix
$$
\endgraf
\noindent
(ii) Calculamos:
$$
\matrix
\format
\r  & \c    & \c       & \l        & \l & \c    & \l     & \c     & \c & \c       & \c & \c    & \c & \c     & \r              & \c    & \l            \\
2016& {}={} & 305      & {}\ntimes{} & 6  & {}+{} &{186},  & \qquad & 0  & {}\leq{} &186 & {}<{} &305 & \qquad & \gcd{2016}{305} & {}={} & \gcd{305}{186}\\
305 & {}={} & 186      & {}\ntimes{} & 1  & {}+{} &{119},  &        & 0  & {}\leq{} &119 & {}<{} &186 &        &                 & {}={} & \gcd{186}{119}\\
186 & {}={} & 119      & {}\ntimes{} & 1  & {}+{} &{67 },  &        & 0  & {}\leq{} &67  & {}<{} &119 &        &                 & {}={} & \gcd{119}{67 }\\
119 & {}={} & 67       & {}\ntimes{} & 1  & {}+{} &{52 },  &        & 0  & {}\leq{} &52  & {}<{} &67  &        &                 & {}={} & \gcd{67 }{52 }\\
67  & {}={} & 52       & {}\ntimes{} & 1  & {}+{} &{15 },  &        & 0  & {}\leq{} &15  & {}<{} &52  &        &                 & {}={} & \gcd{52 }{15 }\\
52  & {}={} & 15       & {}\ntimes{} & 3  & {}+{} &{7  },  &        & 0  & {}\leq{} &7   & {}<{} &15  &        &                 & {}={} & \gcd{15 }{7  }\\
15  & {}={} & 7        & {}\ntimes{} & 2  & {}+{} &{1  },  &        & 0  & {}\leq{} &1   & {}<{} &7   &        &                 & {}={} & \gcd{7  }{1  }\\
7   & {}={} & \boxed 1 & {}\ntimes{} & 7  & {}+{} &{0  }   &        &    &          &    &       &    &        &                 & {}={} & \gcd{1  }{0  } = \boxed 1.
\endmatrix
$$
%$$
%\matrix
%\format
%\r  & \c    & \c       & \l        & \l & \c    & \l     & \c     & \c & \c       & \c & \c    & \c & \c     & \r              & \c    & \l            \\
%    & {}={} &          & {}\ntimes{} &    & {}+{} &{   },  & \qquad & 0  & {}\leq{} &    & {}<{} &    & \qquad & \gcd{    }{   } & {}={} & \gcd{   }{   }\\
%    & {}={} &          & {}\ntimes{} &    & {}+{} &{   },  &        & 0  & {}\leq{} &    & {}<{} &    &        &                 & {}={} & \gcd{   }{   }\\
%    & {}={} & \boxed 1 & {}\ntimes{} &    & {}+{} &{   }   &        &    &          &    &       &    &        &                 & {}={} & \gcd{   }{   } = .
%\endmatrix
%$$

\endexercise
%%}}}

%%{{{ codeit: implement_euclidean_algorithm 
\codeit.
\label{implement_euclidean_algorithm}%
Implemente o algoritmo de Euclides e verifique tuas soluções nos exercícios anteriores.
\endcodeit
%%}}}

%%{{{ codeit: implement_verbose_euclidean_algorithm 
\codeit.
\label{implement_verbose_euclidean_algorithm}%
Implemente um modo ``verbose'' no teu programa
do~\ref{implement_euclidean_algorithm},
onde ele mostra todas as equações e desigualdades, e não apenas o resultado final.
\endcodeit
%%}}}

%%{{{ lemma: euclid_gcd_lemma 
\lemma Euclides.
\label{euclid_gcd_lemma}%
Se $a,b\in\ints$ com $b > 0$, então $\gcd a b = \gcd b r$,
onde $r$ o resto da divisão de $a$ por $b$.
\wrongproof.
Dividindo o $a$ por $b$, temos $a = bq + r$.
Vamos mostrar que qualquer inteiro $d$ satisfaz a equivalência:
$$
\align
d \divides a
\mland
d \divides b
&\iff
d \divides b
\mland
d \divides r.\\
\intertext{Realmente, usando as propriedades~\refn{divides_properties}, temos:}
d \divides a
\mland
d \divides b
&\implies
d\divides \moverbrace {a - bq} {\dsize r}\\
d\divides \munderbrace {bq + r} {\dsize a}
&\impliedby
d \divides b
\mland
d \divides r.
\endalign
$$
Isso mostra que os divisores em comum dos $a$ e $b$, e dos $b$ e $r$ são os mesmos,
ou, formalmente:
$$
\set{c\in\ints\st c\divides a \mland c\divides b}
=
\set{c\in\ints\st c\divides b \mland c\divides r}.
$$
Logo,
\compute
\gcd a b
&= \max\set{c\in\ints\st c\divides a \mland c\divides b}    \by {def.~$\gcd a b$}
&= \max\set{c\in\ints\st c\divides b \mland c\divides r}    \by {provado acima}
&= \gcd b r                                                 \by {def.~$\gcd b r$}
\endcompute
que mostra a corretude do algoritmo.
\mistaqed
%%}}}

%%{{{ x: what_is_the_problem_with_euclid_gcd_lemma 
\exercise.
\label{what_is_the_problem_with_euclid_gcd_lemma}%
Qual é o problema com a prova do~\ref{euclid_gcd_lemma}?

\solution
A definição do maior divisor comum $(a,b)$ não foi
``o maior divisor comum dos $a$ e $b$''.
Lembre-se a~\ref{gcd}.
Veja também o~\ref{gcd_alternative_definition}.

\endexercise
%%}}}

%%{{{ thm: euclidean_algorithm_correctness 
\theorem Algorítmo de Euclides.
\label{euclidean_algorithm_correctness}%
O~\ref{euclidean_algorithm} é correto.
\proof.
Precisamos provar duas coisas: \emph{terminação\/}\/ e \emph{corretude}.
\endgraf
\proofstyle{Corretude.}
Se o algoritmo precisou $n$ passos, temos que verificar:
Temos
$$
\gcd a b
= \gcd b {r_0}
= \gcd {r_0} {r_1}
= \gcd {r_1} {r_2}
= \dotsb
= \gcd {r_{n-1}} {r_n}
= \gcd {r_n} 0
= r_n.
$$
Todas as igualdades exceto a última seguem por causa do~\ref{euclid_gcd_lemma};
a última por causa da~\ref{gcd_of_comparable}.
\endgraf
\proofstyle{Terminação.}
Note que a seqüência de restos $r_0, r_1, \ldots$ é estritamente
decrescente, e todos os seus termos são não negativos:
$$
0\leq \dotsb < r_2 < r_1 < r_0 < b.
$$
Logo, essa seqüência não pode ser infinita.
Realmente, o tamanho dela não pode ser maior que $b$,
então depois de no máximo $b$ passos, o algorítmo terminará.
\qed
%%}}}

%%{{{ x: euclidean_algorithm_proof_why_informal 
\exercise.
\label{euclidean_algorithm_proof_why_informal}%
Nenhuma das duas partes da prova do~\ref{euclidean_algorithm_correctness}
é completamente formal.  Explique porque.
(Veja também os~\refs{euclidean_algorithm_correctness_formal_proof_by_induction}--\refn{euclidean_algorithm_correctness_formal_proof_by_wop}.)

\hint
${}\dotsb{}$

\hint
${}\dotsb{}$

\solution
São os ``${}\dotsb{}$'' mesmo!

\endexercise
%%}}}

%%{{{ Steps in Euclid's algorithm 
\note Passos do algoritmo de Euclides.
Como o exercício seguinte mostra, o algoritmo de Euclides
é bem mais eficiente do que nós mostramos acima:
depois dois passos, as duas entradas, nos piores dos casos,
são reduzidas para metade.
%%}}}

%%{{{ x: less_steps_in_euclid
\exercise.
\label{less_steps_in_euclid}%
Se $a \geq b$, então $r < a/2$, onde $r$ o resto da divisão de $a$ por $b$.

\hint
Separe os casos: ou $b > a/2$ ou $b \leq a/2$.

\hint
Qual seria o resto em cado caso?

\hint
Num caso, dá para achar exatamente o resto.
No outro, use a restricção que o resto satisfaz.

\solution
\case{Caso $b > a/2$:}
Então $r = a-b < a/2$.
\case{Caso $b < a/2$:}
Então $r < b < a/2$.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ The extended Euclidean algorithm 
\section O algoritmo estendido de Euclides.

%%{{{ How do we find the coefs of the linear combination 
\note.
Nos já provamos que o m.d.c.~$\gcd a b$ de dois inteiros $a$ e $b$
pode ser escrito como uma combinação linear deles, mas como podemos
realmente \emph{achar}\/ inteiros $s,t\in\ints$ que satisfazem a
$$
\gcd a b = as + bt,     \qquad s,t\in\ints?
$$
Surpresamente a resposta já está ``escondida'' no mesmo algoritmo de Euclides!
%%}}}

%%{{{ algorithm: extended_euclidean_algorithm 
\algorithm Algoritmo estendido de Euclides.
\label{extended_euclidean_algorithm}%
\Euclid[algoritmo estendido]%
\tdefined{algoritmo}[estendido de Euclides]%
\algospec
 INPUT: $a,b\in\ints$, $b>0$
OUTPUT: $s,t\in\ints$ tais que $\gcd a b = as + bt$.
\endspec
%%}}}

%%{{{ eg: write_a_gcd_as_a_linear_combination 
\example.
\label{write_a_gcd_as_a_linear_combination}%
Escreva o $\gcd {101} {73}$ como combinação linear dos $101$ e $73$.

\solution
Primeiramente, precisamos aplicar o algoritmo de Euclides para achar o m.d.c.,
como no~\ref{euclidean_algorithm_example},
mas vamos também resolver cada equação por o seu resto:
$$
\matrix
\format
\r  & \c    & \c       & \l          & \l & \c    & \l & \c           & \r & \c    & \c & \c    &\c & \c         & \c  \\
101 & {}={} & 73       & {}\ntimes{} & 1  & {}+{} & 28 & \qquad\qquad &28  & {}={} &101 & {}-{} &   &{}       {} & 73 \\
73  & {}={} & 28       & {}\ntimes{} & 2  & {}+{} & 17 &              &17  & {}={} &73  & {}-{} & 2 &{}\ntimes{} & 28 \\
28  & {}={} & 17       & {}\ntimes{} & 1  & {}+{} & 11 &              &11  & {}={} &28  & {}-{} &   &{}       {} & 17 \\
17  & {}={} & 11       & {}\ntimes{} & 1  & {}+{} & 6  &              &6   & {}={} &17  & {}-{} &   &{}       {} & 11 \\
11  & {}={} & 6        & {}\ntimes{} & 1  & {}+{} & 5  &              &5   & {}={} &11  & {}-{} &   &{}       {} & 6  \\
6   & {}={} & 5        & {}\ntimes{} & 1  & {}+{} & 1  &              &1   & {}={} &6   & {}-{} &   &{}       {} & 5  \\
5   & {}={} & \boxed 1 & {}\ntimes{} & 5  & {}+{} & 0. &              &    &       &    &       &    &          &     \\
\endmatrix
$$
Utilizando as equações no lado direto, de baixo para cima, calculamos:
$$
\def\hl#1{\underline{#1}}
\alignat 2
1 &= \hl6 - \hl5                                           &\quad&\text{(6 e 5)   }\\
  &= \hl6 - (\hl{11} - \hl6)
   = \hl6 - \hl{11} + \hl6
   = -\hl{11} + 2\ntimes \hl6                                   &&\text{(11 e 6)  }\\
  &= -\hl{11} + 2\ntimes (\hl{17} - \hl{11})
   = -\hl{11} + 2\ntimes \hl{17} - 2\ntimes \hl{11}
   = 2\ntimes \hl{17} - 3\ntimes \hl{11}                        &&\text{(17 e 11) }\\
  &= 2\ntimes \hl{17} - 3\ntimes (\hl{28} - \hl{17})
   = 2\ntimes \hl{17} - 3\ntimes \hl{28} + 3\ntimes 17
   = -3\ntimes \hl{28} + 5\ntimes \hl{17}                       &&\text{(28 e 17) }\\
  &= -3\ntimes \hl{28} + 5\ntimes (\hl{73} - 2\ntimes \hl{28})
   = -3\ntimes \hl{28} + 5\ntimes \hl{73} - 10\ntimes \hl{28}
   = 5\ntimes \hl{73} -13\ntimes \hl{28}                        &&\text{(73 e 28) }\\
  &= 5\ntimes \hl{73} -13\ntimes (\hl{101} - \hl{73})
   = 5\ntimes \hl{73} -13\ntimes \hl{101} + 13\ntimes \hl{73}
   = -13\ntimes \hl{101} + 18\ntimes \hl{73}                    &&\text{(101 e 73)}
\endalignat
$$
No lado direto mostramos nosso progresso, no sentido de ter conseguido
escrever o m.d.c.~como combinação linear de quais dois números.
Sublinhamos os inteiros que nos interessam para não perder nosso foco.
Em cada nova linha, escolhemos o menor dos dois números sublinhados,
e o substituimos por a combinação linear que temos graças ao algoritmo de Euclides.
Obviamente, essa notação e metodologia não tem nenhum sentido matematicamente
falando.  Serve apenas para ajudar nossos olhos humanos.
\endgraf
Achamos então $s,t\in\ints$ que satisfazem a equação $1 = sa + tb$:
são os $s = -13$ e $t = 18$.
\endexample
%%}}}

%%{{{ x: more_gcds_as_linear_combinations 
\exercise.
\label{more_gcds_as_linear_combinations}%
Usando o algoritmo estendido de Euclides, escreve:
(i) o $\gcd {108} {174}$ como combinação linear dos 108 e 174; 
(ii) o $\gcd {2016} {305}$ como combinação linear dos 2016 e 305.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ The sieve of Eratosthenes 
\section O crivo de Eratosthenes.
\label{Sieve_of_Eratosthenes}%

%%{{{ Q: How can we find all primes up to a given bound? 
\question.
Como podemos achar todos os primos até um dado limitante $b\in\nats$?
%%}}}

%%{{{ A: answer_by_eratosthenes 
\note Resposta.
\label{answer_by_eratosthenes}%
\def\co##1{\phantom{##1}}%
\def\ci##1{\underline{##1}}%
\Eratosthenes[crivo]%
Eratosthenes (276--194 a.C.)~conseguiu responder com sua metodo conhecida como
o \dterm{crivo de Eratosthenes}.
Antes de descrever o seu algoritmo formalmente, vamos aplicar sua idéia
para achar todos os primos menores ou iguais que $b=128$.
Primeiramente liste todos os números de $2$ até $b=128$:
$$
\matrix
\format
~\r  &~\r  &~\r   &~\r   &~\r   &~\r   &~\r   &~\r   &~\r   &~\r   &~\r   &~\r   &~\r   &~\r   &~\r   &~\r   \\
   {   }&   {  2}&   {   3}&   {   4}&   {   5}&   {   6}&   {   7}&   {   8}&   {   9}&   {  10}&   {  11}&   {  12}&   {  13}&   {  14}&   {  15}&   {  16}\\
   { 17}&   { 18}&   {  19}&   {  20}&   {  21}&   {  22}&   {  23}&   {  24}&   {  25}&   {  26}&   {  27}&   {  28}&   {  29}&   {  30}&   {  31}&   {  32}\\
   { 33}&   { 34}&   {  35}&   {  36}&   {  37}&   {  38}&   {  39}&   {  40}&   {  41}&   {  42}&   {  43}&   {  44}&   {  45}&   {  46}&   {  47}&   {  48}\\
   { 49}&   { 50}&   {  51}&   {  52}&   {  53}&   {  54}&   {  55}&   {  56}&   {  57}&   {  58}&   {  59}&   {  60}&   {  61}&   {  62}&   {  63}&   {  64}\\
   { 65}&   { 66}&   {  67}&   {  68}&   {  69}&   {  70}&   {  71}&   {  72}&   {  73}&   {  74}&   {  75}&   {  76}&   {  77}&   {  78}&   {  79}&   {  80}\\
   { 81}&   { 82}&   {  83}&   {  84}&   {  85}&   {  86}&   {  87}&   {  88}&   {  89}&   {  90}&   {  91}&   {  92}&   {  93}&   {  94}&   {  95}&   {  96}\\
   { 97}&   { 98}&   {  99}&   { 100}&   { 101}&   { 102}&   { 103}&   { 104}&   { 105}&   { 106}&   { 107}&   { 108}&   { 109}&   { 110}&   { 111}&   { 112}\\
   {113}&   {114}&   { 115}&   { 116}&   { 117}&   { 118}&   { 119}&   { 120}&   { 121}&   { 122}&   { 123}&   { 124}&   { 125}&   { 126}&   { 127}&   { 128.}
\endmatrix
$$
Agora começa com o primeiro número na lista, o $2$, e apaga todos os maiores múltiplos dele:
$$
\matrix
\format
~\r &~\r &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r   \\
   {   }&   {  2}&   {   3}&\co{   4}&   {   5}&\co{   6}&   {   7}&\co{   8}&   {   9}&\co{  10}&   {  11}&\co{  12}&   {  13}&\co{  14}&   {  15}&\co{  16}\\
   { 17}&\co{ 18}&   {  19}&\co{  20}&   {  21}&\co{  22}&   {  23}&\co{  24}&   {  25}&\co{  26}&   {  27}&\co{  28}&   {  29}&\co{  30}&   {  31}&\co{  32}\\
   { 33}&\co{ 34}&   {  35}&\co{  36}&   {  37}&\co{  38}&   {  39}&\co{  40}&   {  41}&\co{  42}&   {  43}&\co{  44}&   {  45}&\co{  46}&   {  47}&\co{  48}\\
   { 49}&\co{ 50}&   {  51}&\co{  52}&   {  53}&\co{  54}&   {  55}&\co{  56}&   {  57}&\co{  58}&   {  59}&\co{  60}&   {  61}&\co{  62}&   {  63}&\co{  64}\\
   { 65}&\co{ 66}&   {  67}&\co{  68}&   {  69}&\co{  70}&   {  71}&\co{  72}&   {  73}&\co{  74}&   {  75}&\co{  76}&   {  77}&\co{  78}&   {  79}&\co{  80}\\
   { 81}&\co{ 82}&   {  83}&\co{  84}&   {  85}&\co{  86}&   {  87}&\co{  88}&   {  89}&\co{  90}&   {  91}&\co{  92}&   {  93}&\co{  94}&   {  95}&\co{  96}\\
   { 97}&\co{ 98}&   {  99}&\co{ 100}&   { 101}&\co{ 102}&   { 103}&\co{ 104}&   { 105}&\co{ 106}&   { 107}&\co{ 108}&   { 109}&\co{ 110}&   { 111}&\co{ 112}\\
   {113}&\co{114}&   { 115}&\co{ 116}&   { 117}&\co{ 118}&   { 119}&\co{ 120}&   { 121}&\co{ 122}&   { 123}&\co{ 124}&   { 125}&\co{ 126}&   { 127}&\co{ 128}
\endmatrix
$$
Toma o próximo número que está ainda na lista, o $3$, e faça a mesma coisa:
$$
\matrix
\format
~\r &~\r &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r   \\
   {   }&   {  2}&   {   3}&\co{   4}&   {   5}&\co{   6}&   {   7}&\co{   8}&\co{   9}&\co{  10}&   {  11}&\co{  12}&   {  13}&\co{  14}&\co{  15}&\co{  16}\\
   { 17}&\co{ 18}&   {  19}&\co{  20}&\co{  21}&\co{  22}&   {  23}&\co{  24}&   {  25}&\co{  26}&\co{  27}&\co{  28}&   {  29}&\co{  30}&   {  31}&\co{  32}\\
\co{ 33}&\co{ 34}&   {  35}&\co{  36}&   {  37}&\co{  38}&\co{  39}&\co{  40}&   {  41}&\co{  42}&   {  43}&\co{  44}&\co{  45}&\co{  46}&   {  47}&\co{  48}\\
   { 49}&\co{ 50}&\co{  51}&\co{  52}&   {  53}&\co{  54}&   {  55}&\co{  56}&\co{  57}&\co{  58}&   {  59}&\co{  60}&   {  61}&\co{  62}&\co{  63}&\co{  64}\\
   { 65}&\co{ 66}&   {  67}&\co{  68}&\co{  69}&\co{  70}&   {  71}&\co{  72}&   {  73}&\co{  74}&\co{  75}&\co{  76}&   {  77}&\co{  78}&   {  79}&\co{  80}\\
\co{ 81}&\co{ 82}&   {  83}&\co{  84}&   {  85}&\co{  86}&\co{  87}&\co{  88}&   {  89}&\co{  90}&   {  91}&\co{  92}&\co{  93}&\co{  94}&   {  95}&\co{  96}\\
   { 97}&\co{ 98}&\co{  99}&\co{ 100}&   { 101}&\co{ 102}&   { 103}&\co{ 104}&\co{ 105}&\co{ 106}&   { 107}&\co{ 108}&   { 109}&\co{ 110}&\co{ 111}&\co{ 112}\\
   {113}&\co{114}&   { 115}&\co{ 116}&\co{ 117}&\co{ 118}&   { 119}&\co{ 120}&   { 121}&\co{ 122}&\co{ 123}&\co{ 124}&   { 125}&\co{ 126}&   { 127}&\co{ 128}
\endmatrix
$$
Repeta o processo (o próximo agora seria o $5$) até não tem mais números para tomar.
Os números que ficarão são todos os primos até o $128$:
$$
\matrix
\format
~\r &~\r &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r   \\
   {   }&   {  2}&   {   3}&\co{   4}&   {   5}&\co{   6}&   {   7}&\co{   8}&\co{   9}&\co{  10}&   {  11}&\co{  12}&   {  13}&\co{  14}&\co{  15}&\co{  16}\\
   { 17}&\co{ 18}&   {  19}&\co{  20}&\co{  21}&\co{  22}&   {  23}&\co{  24}&\co{  25}&\co{  26}&\co{  27}&\co{  28}&   {  29}&\co{  30}&   {  31}&\co{  32}\\
\co{ 33}&\co{ 34}&\co{  35}&\co{  36}&   {  37}&\co{  38}&\co{  39}&\co{  40}&   {  41}&\co{  42}&   {  43}&\co{  44}&\co{  45}&\co{  46}&   {  47}&\co{  48}\\
   { 49}&\co{ 50}&\co{  51}&\co{  52}&   {  53}&\co{  54}&\co{  55}&\co{  56}&\co{  57}&\co{  58}&   {  59}&\co{  60}&   {  61}&\co{  62}&\co{  63}&\co{  64}\\
\co{ 65}&\co{ 66}&   {  67}&\co{  68}&\co{  69}&\co{  70}&   {  71}&\co{  72}&   {  73}&\co{  74}&\co{  75}&\co{  76}&   {  77}&\co{  78}&   {  79}&\co{  80}\\
\co{ 81}&\co{ 82}&   {  83}&\co{  84}&\co{  85}&\co{  86}&\co{  87}&\co{  88}&   {  89}&\co{  90}&   {  91}&\co{  92}&\co{  93}&\co{  94}&\co{  95}&\co{  96}\\
   { 97}&\co{ 98}&\co{  99}&\co{ 100}&   { 101}&\co{ 102}&   { 103}&\co{ 104}&\co{ 105}&\co{ 106}&   { 107}&\co{ 108}&   { 109}&\co{ 110}&\co{ 111}&\co{ 112}\\
   {113}&\co{114}&\co{ 115}&\co{ 116}&\co{ 117}&\co{ 118}&   { 119}&\co{ 120}&   { 121}&\co{ 122}&\co{ 123}&\co{ 124}&\co{ 125}&\co{ 126}&   { 127}&\co{ 128}
\endmatrix
$$
Tomando o $7$:
$$
\matrix
\format
~\r &~\r &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r   \\
   {   }&   {  2}&   {   3}&\co{   4}&   {   5}&\co{   6}&   {   7}&\co{   8}&\co{   9}&\co{  10}&   {  11}&\co{  12}&   {  13}&\co{  14}&\co{  15}&\co{  16}\\
   { 17}&\co{ 18}&   {  19}&\co{  20}&\co{  21}&\co{  22}&   {  23}&\co{  24}&\co{  25}&\co{  26}&\co{  27}&\co{  28}&   {  29}&\co{  30}&   {  31}&\co{  32}\\
\co{ 33}&\co{ 34}&\co{  35}&\co{  36}&   {  37}&\co{  38}&\co{  39}&\co{  40}&   {  41}&\co{  42}&   {  43}&\co{  44}&\co{  45}&\co{  46}&   {  47}&\co{  48}\\
\co{ 49}&\co{ 50}&\co{  51}&\co{  52}&   {  53}&\co{  54}&\co{  55}&\co{  56}&\co{  57}&\co{  58}&   {  59}&\co{  60}&   {  61}&\co{  62}&\co{  63}&\co{  64}\\
\co{ 65}&\co{ 66}&   {  67}&\co{  68}&\co{  69}&\co{  70}&   {  71}&\co{  72}&   {  73}&\co{  74}&\co{  75}&\co{  76}&\co{  77}&\co{  78}&   {  79}&\co{  80}\\
\co{ 81}&\co{ 82}&   {  83}&\co{  84}&\co{  85}&\co{  86}&\co{  87}&\co{  88}&   {  89}&\co{  90}&\co{  91}&\co{  92}&\co{  93}&\co{  94}&\co{  95}&\co{  96}\\
   { 97}&\co{ 98}&\co{  99}&\co{ 100}&   { 101}&\co{ 102}&   { 103}&\co{ 104}&\co{ 105}&\co{ 106}&   { 107}&\co{ 108}&   { 109}&\co{ 110}&\co{ 111}&\co{ 112}\\
   {113}&\co{114}&\co{ 115}&\co{ 116}&\co{ 117}&\co{ 118}&\co{ 119}&\co{ 120}&   { 121}&\co{ 122}&\co{ 123}&\co{ 124}&\co{ 125}&\co{ 126}&   { 127}&\co{ 128}
\endmatrix
$$
Tomando o $11$:
$$
\matrix
\format
~\r &~\r &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r   \\
   {   }&   {  2}&   {   3}&\co{   4}&   {   5}&\co{   6}&   {   7}&\co{   8}&\co{   9}&\co{  10}&   {  11}&\co{  12}&   {  13}&\co{  14}&\co{  15}&\co{  16}\\
   { 17}&\co{ 18}&   {  19}&\co{  20}&\co{  21}&\co{  22}&   {  23}&\co{  24}&\co{  25}&\co{  26}&\co{  27}&\co{  28}&   {  29}&\co{  30}&   {  31}&\co{  32}\\
\co{ 33}&\co{ 34}&\co{  35}&\co{  36}&   {  37}&\co{  38}&\co{  39}&\co{  40}&   {  41}&\co{  42}&   {  43}&\co{  44}&\co{  45}&\co{  46}&   {  47}&\co{  48}\\
\co{ 49}&\co{ 50}&\co{  51}&\co{  52}&   {  53}&\co{  54}&\co{  55}&\co{  56}&\co{  57}&\co{  58}&   {  59}&\co{  60}&   {  61}&\co{  62}&\co{  63}&\co{  64}\\
\co{ 65}&\co{ 66}&   {  67}&\co{  68}&\co{  69}&\co{  70}&   {  71}&\co{  72}&   {  73}&\co{  74}&\co{  75}&\co{  76}&\co{  77}&\co{  78}&   {  79}&\co{  80}\\
\co{ 81}&\co{ 82}&   {  83}&\co{  84}&\co{  85}&\co{  86}&\co{  87}&\co{  88}&   {  89}&\co{  90}&\co{  91}&\co{  92}&\co{  93}&\co{  94}&\co{  95}&\co{  96}\\
   { 97}&\co{ 98}&\co{  99}&\co{ 100}&   { 101}&\co{ 102}&   { 103}&\co{ 104}&\co{ 105}&\co{ 106}&   { 107}&\co{ 108}&   { 109}&\co{ 110}&\co{ 111}&\co{ 112}\\
   {113}&\co{114}&\co{ 115}&\co{ 116}&\co{ 117}&\co{ 118}&\co{ 119}&\co{ 120}&\co{ 121}&\co{ 122}&\co{ 123}&\co{ 124}&\co{ 125}&\co{ 126}&   { 127}&\co{ 128}
\endmatrix
$$
E podemos já parar aqui, certos que os números que ainda ficam na lista, são todos os primos desejados.
%%}}}

%%{{{ x: why? 
\exercise.
Por quê?

\endexercise
%%}}}

%%{{{ x: eratosthenian_algorithm 
\exercise.
\label{eratosthenian_algorithm}%
Escreva formalmente o algoritmo do Eratosthenes.

\endexercise
%%}}}

%%{{{ codeit: implement_eratosthenian_algorithm 
\codeit.
\label{implement_eratosthenian_algorithm}%
Implemente o algoritmo de Eratosthenes e use-o para achar todos os primos até o $1024$.
\endcodeit
%%}}}

\endsection
%%}}}

%%{{{ The fundamental theorem of arithmetic 
\section O teorema fundamental da aritmética.

%%{{{ thm: fundamental_theorem_of_arithmetic 
\theorem fundamental da aritmética (Euclides, Gauss).
\label{fundamental_theorem_of_arithmetic}%
\ii{teorema}[fundamental da aritmética]%
\Gauss{}%
\Euclid{}%
Todo $n\in\nats$ com $n > 1$, pode ser escrito como um produtório de primos.
Essa expressão é única se desconsiderar a ordem dos fatores do produtório.
\proof.
Seja $n\in\nats$ com $n > 1$.
\endgraf
\proofstyle{Existência:}
\ii{indução}[forte]
Usamos indução forte (veja~\refn{Strong_induction}).
Caso que $n$ seja primo,
trivialmente ele mesmo é o produtório de primos (produtório de tamanho 1).
Caso contrário, $n = ab$, para uns $a,b\in\nats$ com $1<a<n$ e $1<b<n$,
logo sabemos (hipoteses indutivas) que cada um deles pode ser
escrito na forma desejada:
$$
\alignat 2
a &= p_1p_2\dotsb p_{k_a},          &\quad& \text{para alguns $p_i$'s primos;}\\
b &= q_1q_2\dotsb q_{k_b},          &\quad& \text{para alguns $q_j$'s primos.}
\endalignat
$$
Então temos
$$
n = ab = (p_1p_2\dotsb p_{k_a})(q_1q_2\dotsb )
       = p_1p_2\dotsb p_{k_a}q_1q_2\dotsb q_{k_b}
$$
que realmente é um produtório de primos.
\endgraf
\proofstyle{Unicidade:}
Suponha que para alguns primos $p_i$'s e $q_j$'s, e uns $s,t\in\nats$, temos:
$$
\align
n &= p_1 p_2 \dotsc p_s,\\
n &= q_1 q_2 \dotsc q_t.
\endalign
$$
Vamos mostrar que $s = t$ e que para todo $i\in\set{1,\dotsc,s}$,  $p_i = q_j$.
Temos
$$
p_1 p_2 \dotsc p_s = q_1 q_2 \dotsc q_t,
$$
e $p_1$ é primo que divide o lado esquerdo, então divide também o lado direito:
$$
p_1 \divides q_1 q_2 \dotsc q_t.
$$
Pelo Lema de Euclides\Euclid~\ref{euclid_lemma}, $p_1\divides q_{j_1}$ para algum $j_1$.
Mas o $q_{j_1}$, sendo um dos $q_j$'s, também é primo.
Logo $p_1 = q_{j_1}$ (veja~\ref{in_primes_divides_means_equals}).
Cancelando o $p_1$, temos:
$$
p_2 \dotsc p_s = q_1 q_2 \dotsc q_{j_1 - 1} q_{j_1 + 1} q_t,
$$
Agora repetimos até um dos dois lados não ter mais fatores primos.
Necessariamente, isso vai acontecer ``simultaneamente'' nos dois lados
(caso contrário teriamos um produtório
de primos igual com 1, impossível), ou seja: $s = t$.
Note que as equações $p_i = q_{j_i}$ mostram a unicidade desejada.
\qed
%%}}}

\blah.
Graças o teorema fundamental da aritmética podemos definir a:

%%{{{ df: canonical_representation_of_ints 
\definition Representação canónica de inteiros.
\label{canonical_representation_of_ints}%
\tdefined{representação canónica}[de inteiros]%
Seja $0\neq n\in\ints$.
Sua \dterm{representação canónica} é o produtório
$$
n =
(\pm 1)
\Prod_{i=1}^k
p_i^{a_i}
=
(\pm 1)
p_1^{a_1}
p_2^{a_2}
\dotsb
p_k^{a_k},
$$
onde os $p_1 < p_2 < \cdots < p_k$'s são primos, e $a_i\in\nats_{>0}$ para $i=1,\dotsc,k$.
\endgraf
\label{canonical_complete_representation}%
Observe que se relaxar a restricção nos exponentes tal que $a_i\in\nats$,
cada $n\in\ints$ ($n\neq 0$) pode ser representado (também únicamente) como o produtório
$$
n =
(\pm 1)
\Prod_{i=0}^k
p_i^{a_i}
=
(\pm 1)
p_0^{a_0}
p_1^{a_1}
\dotsb
p_k^{a_k},
$$
onde agora os $p_0 < p_1 < \cdots < p_k$ são \emph{todos os $k+1$ primeiros primos},
sendo então $p_0 = 2$, e $p_k$ o maior primo divisor do $n$.
Chamamos essa forma a \dterm{representação canónica completa} do $n$.
(Veja também o~\ref{encoding_of_finite_sequences}.)
%%}}}

%%{{{ x: canonical_representation_with_int_exponents 
\exercise.
\label{canonical_representation_with_int_exponents}%
O que acontece se relaxar a restricção nos exponentes ainda mais?:
$a_i\in\ints$.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Open problems 
\section Problemas em aberto.
\label{Open_problems_in_number_theory}%

%%{{{ conjecture: goldbach_conjecture 
\conjecture Goldbach.
\label{goldbach_conjecture}%
\Goldbach{}
%%}}}

%%{{{ conjecture: twin_primes_conjecture 
\conjecture Twin primes.
\label{twin_primes_conjecture}%
%%}}}

%%{{{ conjecture: legendre_conjecture 
\conjecture Legendre.
\label{legendre_conjecture}%
\Legendre{}
%%}}}

%%{{{ conjecture: collatz_conjecture
\conjecture Collatz.
\label{collatz_conjecture}%
\Collatz[conjectura]{}
%%}}}

\endsection
%%}}}

%%{{{ Problems 
\problems.

%%{{{ prob: p_divides_comb_p_r 
\problem.
\label{p_divides_comb_p_r}%
Para todo $p$ primo, e todo $r\in\set{1,\dotsc,p-1}$,
$$
p \divides \comb p r.
$$
O que acontece se $r=0$ ou $r \geq p$?

\hint
$\comb p r \in\ints$, $r < p$, e $p-r < p$.

\endproblem
%%}}}

%%{{{ prob 
\problem.
(Generalização do~\ref{implications_with_divisibility_of_linear_combinations}.)
Para quais $u,v\in\ints$, a afirmação
$$
a \divides b + c \mland a \divides ub + vc \implies a \divides xb + yc \quad \text{para todos $x,y\in\ints$}
$$
é válida?

\endproblem
%%}}}

%%{{{ prob 
\problem.
Prove que para todo $n\in\nats$, $\gcd {F_n} {F_{n+1}} = 1$,
onde $F_n$ é o $n$-ésimo termo da seqüência Fibonacci\Fibonacci[seqüência]{}~(\ref{fibonacci}).

\hint
Tu já resolveu o~\ref{gcd_of_two_is_gcd_of_one_plus_sum}, certo?

\solution
Vamos provar o pedido por indução.
Para $n=0$ temos
$$
    \gcd {F_0} {F_1} = \gcd 0 1 = 1.
$$
Seja $k\in\nats$ tal que $\gcd {F_k} {F_{k+1}} = 1$.
Precisamos mostrar que $\gcd {F_{k+1}} {F_{k+2}} = 1$.
Calculando,
\compute
\gcd {F_{k+1}} {F_{k+2}}
    &= \gcd {F_{k+1}} {F_{k+1} + F_k}   \by {pela definição da $F_n$}
    &= \gcd {F_{k+1}} {F_k}             \by {pelo~\ref{gcd_of_two_is_gcd_of_one_plus_sum}, com $a\asseq F_{k+1},\ b\asseq F_k$}
    &= \gcd {F_k} {F_{k+1}}             \by {propriedade de mdc}
    &= 1.                               \by {pela hipótese indutiva}
\endcompute

\endproblem
%%}}}

%%{{{ prob 
\problem.
Seja $n\in\nats$, $n>1$.
Entre $n$ e $n!$ existe primo.

\hint
Olha para o $n!-1$.

\hint
Se $n!-1$ não é primo, toma um dos seus primos divisores, $p$.

\hint
Necessariamente $p > n$.

\endproblem
%%}}}

%%{{{ prob 
\problem.
Seja $n\in\nats$.
Ache $n$ consecutivos números compostos.

\hint
$!$

\hint
$m!+2$.

\hint
$m!+3$\dots

\hint
$m!+m$.

\endproblem
%%}}}

%%{{{ prob 
\problem.
Existe uma infinidade de primos ``da forma $4n+3$'', ou seja, o conjunto
$$
\set{4n+3 \st n\in\nats,\ \text{$4n+3$ primo}}
$$
é infinito.

\hint
Esquecendo o $2$, todos os primos são da forma $4n+1$ ou $4n+3$.
Suponha que $p_1, p_2,\dotsc, p_k$ ($k\in\nats$)
são todos os primos da segunda forma.

\hint
O que Euclides faria?

\hint
Tente achar (criar) um número da mesma forma tal que nenhum dos $p_i$ o divide.

\hint
$N = 4p_1p_2\dotsb p_k - 1$.

\hint
$N$ não pode ter apenas divisores da forma $4n+1$.

\endproblem
%%}}}

%%{{{ gcd_alternative_definition 
\problem {Definição alternativa de m.d.c.}.
\label{gcd_alternative_definition}%
Uma definição alternativa do m.d.c.~é a seguinte:
{\it Sejam $a,b\in\ints$.
O m.d.c.~dos $a$ e $b$ é o maior dos divisores em comum de $a$ e $b$.}
Ache um problema com essa definição, corrige-o, e depois compare
com a~\ref{gcd}.

\hint
O que acontece se $a=b=0$?
O que acontece se pelo menos um dos $a$ e $b$ não é o $0$?

\solution
Se $a=b=0$, o símbolo $\gcd a b$ não é definido,
porque todo $n\in\nats$ é um divisor em comum,
mas como o $\nats$ não tem um elemento máximo,
não existe o maior deles.
\endgraf
Precisamos restringir a definição para ser aplicável
apenas nos casos onde pelo menos um dos $a$ e $b$
não é o $0$ (escrevemos isso curtamente: $ab\neq 0$).
Assim, quando a nova definição é aplicável, ela realmente
defina o mesmo número, fato que segue pelas propriedades:
$$
\align
\gcd x 0 = 0 &\implies x = 0\\
x \divides y \mland y \neq 0 &\implies \abs x \leq \abs y.
\endalign
$$

\endproblem
%%}}}

%%{{{ prob 
\problem Contando os passos.
O que muda no~\ref{partitioning_restricted_best_strategy}
se em cada passo podemos quebrar todos os termos que aparecem?
Qual é a melhor estratégia, e quantos passos são necessários?

\hint
Tente quebrar o $10$ usando várias estratégias.
O que tu percebes?

\hint
Qual é o maior termo e como ele muda depois cada passo?

\solution
Agora a estratégia ótima seria quebrar cada termo ``no meio''.
Assim, para o $10$ temos:
$$
\align
10 &= 5 + 5\\
   &= (2 + 3) + (2 + 3)\\
   &= [(1 + 1) + (1 + 2)] + [(1 + 1) + (1 + 2)]\\
   &= 1 + 1 + 1 + 1 + 1 + 1 + 1 + 1 + 1 + 1
\endalign
$$
em apenas $4$ pássos.
Depois cada passo, se o maior termo fosse o $m$, agora é o $\ceil {\frac m 2}$.
Precisamos tantos passos quantas vezes que podemos dividir o $n$ por $2$ até
chegar na unidade $1$: precisamos $\ceil {\log_2(n)}$ passos.

\endproblem
%%}}}

%%{{{ prob: WOP_iff_PFI 
\problem.
\label{WOP_iff_PFI}%
$\text{PBO} \iff \text{PIF}$.

\hint
Nos já provamos a direção \lrdir.
Para provar a \rldir, considere o predicado
``todos os conjuntos $A$ com $k\in A$ para algum natural $k\leq n$ têm mínimo'',
ou o ``todos os conjuntos $A$ com $n\in A$ têm mínimo''.

\hint
Prove que todos os naturais satisfazem o predicado que tu consideraste.
(Para um dos dois, tu precisará indução \emph{forte}.)

\endproblem
%%}}}

%%{{{ prob: euclidean_algorithm_correctness_formal_proof_by_induction 
\problem.
\label{euclidean_algorithm_correctness_formal_proof_by_induction}%
\def\Euclid{\algorithmstyle{Euclid}}%
Como tu percebeu resolvendo o~\ref{euclidean_algorithm_proof_why_informal},
nenhuma das duas partes da prova do~\ref{euclidean_algorithm_correctness}
foi formal.
Prove completamente formalmente as duas partes usando indução.

\hint
Precisa expressar o alvo na forma $\lforall n {P(n)}$ para um certo predicado $P$.

\hint
\def\Euclid{\algorithmstyle{Euclid}}%
``\emph{Para todo $x\in\ints$, o $\Euclid(x,n)$ termina com o resultado certo}.''

\hint
O que significaria $P(0)$?  $P(b)$?

\hint
Ser forte é coisa boa.

\solution
\def\Euclid{\algorithmstyle{Euclid}}%
Seja o predicado
$$
P(n) \defiff \lforall {x\in\ints} {\text{$\Euclid(x,n)$ termina com $\gcd x n$}}
$$
Vamos provar que $\lforall {n\in\nats} {P(n)}$ por indução forte.
Seja $k\in\nats$ tal que $P(i)$ é válido para todo $i<k$ (hipótese indutiva).
Precisamos provar o $P(k)$, ou seja, que
\emph{para todo $x\in\ints$, $\Euclid(x,k)$ termina e $\Euclid(x,k) = \gcd x k$}.
Seja $x\in\ints$, e aplica o $\Euclid(x,k)$ para um passo.
Se $k=0$, a computação termina imediatamente com o resultado $x$, que é correto
(\refn{gcd_of_comparable}).
Se $k>0$, o algoritmo manda reduzir sua computação para a computação do $\Euclid(k,r)$,
onde $r = x \bmod k < k$.  Seguindo o~\ref{euclid_gcd_lemma} $\gcd x k = \gcd k r$, então
falta verificar que o $\Euclid(k,r)$ termina mesmo com $\gcd k r$,
que é verdade pela hipótese indutiva porque $r < k$ e logo $P(r)$ é válido.

\endproblem
%%}}}

%%{{{ prob: euclidean_algorithm_correctness_formal_proof_by_wop 
\problem.
\label{euclidean_algorithm_correctness_formal_proof_by_wop}%
Prove completamente formalmente as duas partes
do~\ref{euclidean_algorithm_correctness} usando o princípio da boa ordem.

\hint
Considera as duas partes separamente:
qual conjunto é o não vazio em cada parte?

\hint
Vai pelo absurdo.

\hint
O que seria um contraxemplo para cada parte?
\emph{O que acontece se existem contraexemplos?}

\hint
{%
\def\Euclid{\algorithmstyle{Euclid}}%
Sobre sua terminação:
Considere o menor $m$ tal que o $\Euclid(x,m)$ não termina
para algum $x\in\ints$.
}

\hint
{%
\def\Euclid{\algorithmstyle{Euclid}}%
Sobre sua corretude:
Considere o menor $m$ tal que o $\Euclid(x,m)$
termina com resultado errado par algum $x\in\ints$.
Mas mostre primeiro a terminação.
}

\solution
{%
\def\Euclid{\algorithmstyle{Euclid}}%
Provamos cada parte separamente:
\endgraf
\smallskip
\proofstyle{Terminação.}
Para chegar num absurdo, suponha que existem contraexemplos:
\emph{inteiros $c\geq0$, tais que o $\Euclid(a,c)$
não termina para algum $x\in\ints$.}
Seja $m$ o menor deles (PBO):
$$
m = \min\set{c \in\nats \st \lexists {x\in\ints} {\text{\Euclid(x,c) não termina}}}.
$$
Logo, para algum certo $a\in\ints$, temos que $\Euclid(a,m)$ não termina.
Com certeza $m\neq 0$, porque nesse caso o algoritmo termina imediatamente.
Logo $m > 0$ e aplicando o $\Euclid(a,m)$ para apenas um passo
a sua computação é reduzida no computação do $\Euclid(m,r)$,
onde $r = a \bmod m < m$, \emph{e agora precisamos mostrar que o
$\Euclid(m,r)$ termina para chegar num absurdo}.
Pela escolha do $m$ como \emph{mínimo} dos contraexemplos,
o $r$ não pode ser contraexemplo também.
Em outras palavras, o $\Euclid(x,r)$ realmente termina para qualquer $x$,
então para $x=m$ também, que foi o que queriamos provar.
\endgraf
\smallskip
\proofstyle{Corretude.}
Para chegar num absurdo, suponha que existem contraexemplos:
\emph{inteiros $c\geq0$, tais que o $\Euclid(x,c)$
acha resultado errado para algum $x\in\ints$.}
Seja $m$ o menor desses contraexemplos (PBO):
$$
m = \min\set{c \in\nats \st \lexists {x\in\ints} {\Euclid(x,c) \neq \gcd x c}}.
$$
Logo, para algum certo $a\in\ints$, temos $\Euclid(a,m) \neq \gcd a m$.
Esse $m$ não pode ser $0$, porque nesse caso o algoritmo retorna sua primeira entrada $a$;
resultado correto por causa do~\ref{gcd_of_comparable}.
Então $m>0$.
Aplicamos para um passo o $\Euclid(a,m)$.
Como $m\neq 0$, o algoritmo manda realizar o segundo passo:
retornar o que $\Euclid(m,r)$, onde $r = a \bmod m < m$.
(E sabemos que o $\Euclid(m,r)$ vai retornar algo, porque
já provamos a terminação do algoritmo para todas as suas possíveis entradas!)
Para concluir, observe:
\compute
\Euclid(m,r) 
&= \Euclid(a,m)     \by {pelas instruções do algoritmo}
&\neq \gcd a m      \by {escolha dos $m$ e $a$}
&= \gcd m r.        \by {pelo~\ref{euclid_gcd_lemma}}
\endcompute
Então $\Euclid(m,r) \neq \gcd m r$ e achamos um contraexemplo (o $r$)
menor que o mínimo (o $m$)---absurdo!
}

\endproblem
%%}}}

%%{{{ prob: encoding_of_finite_sequences 
\problem Codificação de seqüências finitas.
\label{encoding_of_finite_sequences}%
Seja $S$ o conjunto de seqüências finitas de números naturais.
Descreva uma método para ``codificar'' os elementos de $S$
com os elementos de $\nats\setminus\set0$.
Tua metodo deve ser uma \emph{revertível}, no sentido que
cada seqüência finita
$$
s = \tup{s_0,s_1,\dotsc,s_{k_s}}\in S
$$
deve corresponder em exatamente um número natural $n_s\in\nats\setminus\set0$,
e, dado esse número $n_s\in\nats_{>0}$, deveria ser possível ``extrair''
a seqüência $s$ cuja codificação é o $n_s$.
Não se preocupe se existem naturais que não são codificações de nenhuma
seqüência.

\hint
Use o teorema fundamental da aritmética~(\refn{fundamental_theorem_of_arithmetic}).

\hint
Seja $p_i$ o $i$-ésimo primo ($p_0 = 2$, $p_1 = 3$, $p_2 = 5$, \dots).
Como podemos escrever o aleatório $n\in\nats$?

\hint
Olha nos exponentes na forma
$
n =
p_0^{a_0}
p_1^{a_1}
p_2^{a_2}
\cdots
p_{k_n}^{a_{k_n}}
$.

\hint
Teste tua codificação nas seqüências $\tup{1,3}$ e $\tup{1,3,0}$.
Como essas seqüências são diferentes, suas codificações devem ser diferentes também.
E a seqüência vazia $\tup{}\in S$?  

\solution
Seja
$$
p_0 < p_1 < p_2 < p_3 < \dotsb
$$
a seqüência infinita dos primos.  (Assim, $p_0 = 2$, $p_1 = 3$, $p_2 = 5$, etc.)
Seja
$$
\tup{s_0, s_1, \dotsc, s_{n-1}} \in S
$$
uma seqüência de naturais de tamanho $n$.
Vamos codificá-la com o inteiro
$$
c_s
= \Prod_{i=0}^{n-1} p_i^{s_i + 1}
= p_0^{s_0 + 1} p_1^{s_1 + 1} p_2^{s_2 + 1} \cdots p_{n-1}^{s_{n-1} + 1}.
$$
(Note que a seqüência vazia ($n=0$) correponde no número $1\in\nats_{>0}$.)
\endgraf
Conversamente, dado um número $c\in\nats_{>0}$ que codifica uma seqüência,
como podemos ``decodificar'' a seqüência que corresponda com ele?
Graças o teorema fundamental da aritmética~(\refn{fundamental_theorem_of_arithmetic}),
temos
$$
c = p_0^{a_0} p_1^{a_1} \cdots p_{m-1}^{a_{m-1}}.
$$
Se existe exponente $a_j = 0$, o $c$ não codifica nenhuma seqüência.
Caso contrário, todos os exponentes são positivos, e o $c$ codifica
a seqüência
$$
\tup{a_0-1, a_1-1, \dotsc, a_m-1} \in S.
$$

\endproblem
%%}}}

%%{{{ prob: canonical_representation_of_rats 
\problem Representação canónica de racionais.
\label{canonical_representation_of_rats}%
Generalize a representação canónica de inteiros para racionais.

\hint
Qual foi tua resposta no~\ref{canonical_representation_with_int_exponents}?

\endproblem
%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

Veja o~\cite[\S\S1.6--1.8]{babybm}.

\cite{elements},
\cite{disquisitiones}.

\cite{andrewsnumber}.

\cite{nivennumbers},
\cite{hardywright}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Number_theory_congruences 
\chapter Teoria dos números II: congruências.
\label{Number_theory_congruences}%

%%{{{ The idea behind congruence relation 
\section A idéia da relação de congruência.

\blah.
Vamos fixar um inteiro positivo $m\in\nats$.
Graças à divisão de Euclides~(\refn{euclidean_division}),
qualquer inteiro $a\in\ints$ pode ser escrito na forma
$$
a = mk + r,
\qquad
0 \leq r < m,
$$
num jeito único.
\endgraf
Enquanto investigando a (ir)racionalidade dos $\sqrt 2$, $\sqrt 3$, $\sqrt {\vphantom3 m}$,
etc., nós percebemos que foi útil separar os inteiros em classes,
``agrupando'' aqueles que compartilham o mesmo resto quando divididos por $m$.
Trabalhando com essa idéia nós encontramos nosso primeiro contato com
\emph{aritmética modular}.%
\footnote{Mentira.  Não foi o primeiro não: somos todos acostumados com
aritmética modular mesmo sem perceber.  Um desses contatos é por causa de ter
que contar com horas e relógios, cuja aritmética não parece muito com aquela
dos inteiros.  Por exemplo: $21 + 5 = 26$, mas se agora são 21h00, que horas
serão depois de 5 horas?  Nossos relógios não vou mostrar 26h00, mas 02h00.}

\endsection
%%}}}

%%{{{ Two equivalent definitions 
\section Duas definições equivalentes.

\blah.
Precisamos definir formalmente a noção de ``\emph{dois inteiros $a$ e $b$ pertencem na
mesma classe, quando separamos eles em grupos usando o inteiro $m$}''.
A primeira coisa que precisamos perceber é que essa frase é uma afirmação sobre 3 objetos.
Queremos então uma definição e uma notação que captura essa relação \emph{de aridade 3}.

%%{{{ Congruences intuitively 
\note Congruência intuitivamente.
Chamamos dois inteiros \dterm{congruentes} módulo um terceiro inteiro,
sse eles têm o mesmo resto, quando divididos por ele.
%%}}}

%%{{{ Critique 
\note Crítica.
Primeiramente, o texto da definição é bem informal e ambíguo.
Para tirar essas ambigüidades, precisamos introduzir variáveis para
referir sobre os ``mesmos restos'':
%%}}}

%%{{{ df: congruence_intuitive_definition 
\definition Intuitiva.
\label{congruence_intuitive_definition}%
Sejam $a,b,m\in\ints$ com $m>0$, e sejam $q_a$, $r_a$, $q_b$, e $r_b$
os inteiros determinados por as divisões:
$$
\alignat 2
a &= mq_a + r_a     &\qquad& 0 \leq r_a < m\\
b &= mq_b + r_b     &      & 0 \leq r_b < m
\endalignat
$$
Digamos que os $a$ e $b$ são \dterm{congruentes} módulo~$m$,
sse $r_a = r_b$.
%%}}}

%%{{{ remark: from_same_remainders_to_divides_the_diference 
\remark.
\label{from_same_remainders_to_divides_the_diference}%
Olhando para dois números $a$ e $b$, congruêntes módulo~$m$,
o que podemos dizer sobre a diferença deles?
Observe:
$$
\rightbrace{
\aligned
a - b
&= (mq_a + r_a) - (mq_b + r_b)\\
&= mq_a - mq_b + r_a - r_b\\
&= m(q_a - q_b) + (r_a - r_b)\\
&= m(q_a - q_b) + 0\\
&= m(q_a - q_b)
\endaligned
}
\qquad
\aligned
\text{ou seja, $m\divides a - b$.}
\endaligned
$$
Essa observação nos mostra um caminho mais curto e elegante para definir o mesmo
conceito.  É o seguinte:
%%}}}

%%{{{ df: congruence 
\definition Congruência (Gauss).
\label{congruence}%
\tdefined{congruência}%
\tdefined{módulo}%
\sdefined
    {\sholed a \cong {\sholed b} \pmod {\sholed m}}
    {$a$ é congruente com $b$ módulo $m$}%
\Gauss[definição de congruência]%
Sejam $a,b,m\in\ints$ com $m>0$.
Digamos que os $a$ e $b$ são \dterm{congruentes} \dterm{módulo} $m$,
sse $m \divides a - b$.
Em símbolos, escrevemos
$$
a \cong b \pmod m
\defiff m \divides a - b
$$
e lemos: \emph{o $a$ é congruente com $b$ módulo~$m$}.
%%}}}

%%{{{ beware: cong_mod_is_a_ternary_relation 
\beware.
\label{cong_mod_is_a_ternary_relation}%
A notação de congruência as vezes iluda de ser interpretada como se fosse
uma relação entre o lado esquerdo $L$ e o lado direito $R$, assim:
$$
\tunderbrace {a} {L} \cong \tunderbrace {b \pmod m} {R}.
$$
\emph{Não!}
Principalmente, o lado direito, $b \pmod m$, nem é definido, então não tem significado,
e nem faz sentido afirmar algo sobre ele.
Prestando mais atenção, percebemos que o $\hole \cong \hole$ também não foi definido!
O que nos definimos foi o:
$$
\holed u \cong \holed v \pmod {\holed w}
$$
dados $u,v,w\in\ints$ com $w>1$.
%%}}}

%%{{{ Intuition 
\note Intuição.
Se precisamos para algum motivo pessoal---porque sim---separar mentalmente a
notação de congruência em dois lados, o único jeito que faz algum sentido
seria o:
$$
\tunderbrace {\mathstrut a \cong b} {L}
\quad
\tunderbrace {\!\!\pmod m} {R}.
$$
Assim, entendemos que ``algo acontece'' (lado $L$), ``dentro algo'' (lado $R$),
onde ``algo acontece'' seria ``o $a$ \emph{parece} com $b$'',
e ``dentro algo'' seria ``módulo~$m$''.
Mas, claramente tudo isso é apenas uma guia (caso que queremos)
e nada mais que isso.  Para argumentar sobre a relação de congruência,
usamos \emph{apenas sua definição formal!}
%%}}}

\blah.
Para ganhar o direito de usar qualquer uma das duas definições, precisamos
mostrar que são equivalentes:

%%{{{ thm: cong_mod_equivalence_of_definitions 
\theorem Equivalência das duas definições.
\label{cong_mod_equivalence_of_definitions}%
Sejam $a,b,m\in\ints$ com $m>0$, e sejam $q_a, r_a, q_b, r_b\in\ints$
os números determinados por as divisões:
$$
\alignat 2
a &= mq_a + r_a     &\qquad& 0 \leq r_a < m\\
b &= mq_b + r_b     && 0 \leq r_b < m
\endalignat
$$
Temos a equivalência:
$$
a \cong b \pmod m
\iff
r_a = r_b.
$$
\sketch.
Precisamos mostrar as duas direções do \bidir.
A direção \rldir, é practicamente
a~\ref{from_same_remainders_to_divides_the_diference}.
Para a direção \lrdir, vamos mostrar que $r_a - r_b = 0$.
Usamos a hipótese e propriedades de~$\divides$
para mostrar que $m\divides r_a - r_b$,
e depois as duas desigualdades para confirmar que, com suas restricções,
o único inteiro múltiplo de $m$ que as satisfaça, é o $0$.
\qes
\proof.
Precisamos mostrar as duas direções do \bidir:
\endgraf
\lrdir:
Suponha que
$a \cong b \pmod m$, ou seja,
$m\divides a - b$.
Resolvendo as duas equações das divisões por os restos $r_a$ e $r_b$,
temos:
$$
\rightbrace{
\aligned
r_a &= a - mq_a \\
r_b &= b - mq_b 
\endaligned
}
\implies
\aligned
r_a - r_b
&= (a - mq_a) - (b - mq_b)\\
&= (a - b) - (mq_a - mq_b)\\
&= (a - b) - m(q_a - q_b).
\endaligned
$$
Observe que $m\divides a-b$ e $m\divides m(q_a - q_b)$.
Então $m$ tem que dividir a diferença deles também:
$$
m\divides \munderbrace {(a - b) - m(q_a - q_b)} {\dsize r_a - r_b}
$$
Usando as duas desigualdades: $0 \leq \abs{r_a - r_b} < m$.
Como $\abs{r_a-r_b}$ é um múltiplo de $m$, concluimos que necessariamente
$0 = \abs{r_a - r_b}$, ou seja: $r_a = r_b$.
\endgraf
\rldir:
Suponha que $r_a = r_b$.
Temos:
\compute
a - b
&= (mq_a + r_a) - (mq_b + r_b)  \\
&= (mq_a - mq_b) - (r_a - r_b)  \\
&= (mq_a - mq_b) - 0            \by {hipótese}
&= m(q_a - q_b),
\endcompute
e como $q_a - q_b\in\ints$,
concluimos que
$m\divides a - b$, ou seja:
$a \cong b \pmod m$.
\qed
%%}}}

%%{{{ note: binary_mod 
\note A operação binária ``mod''.
\label{binary_mod}%
Em linguagens de programação é comum encontrar o operador \emph{binário}
``mod'', frequentemente denotado com o símbolo ``\thinspace{\tt \%}\thinspace''.
Em matemática, essa função \emph{binária} (aridade 2) é mais
encontrada como $\bmod$ mesmo.
Cuidado não confundir a \emph{função}
$\bmod : \ints\times\nats_{>0} \to \nats$
com a \emph{relação} $a \cong b \pmod m$.
Faz sentido escrever:
$$
69 \bmod 5 = 4.
$$
Isso significa apenas que o resto da divisão de 69 por 5, é 4.
No outro lado, nenhuma das expressões abaixo tem significado!:
$$
69 \pmod 5 = 4
\qquad\qquad
4 = 69 \pmod 5
$$
%%}}}

%%{{{ x: explain_the_type_of_bmod 
\exercise.
\label{explain_the_type_of_bmod}%
Explique o tipo da função $\bmod : \ints\times\nats_{>0} \to \nats$.

\hint
Qual seria o valor de $4 \bmod 0$?

\solution
Por~\ref{euclidean_division},
precisamos $a\in\ints$ e $b\in\nats_{>0}$ para definir a divisão
de $a$ por $b$.

\endexercise
%%}}}

%%{{{ x: mod_vs_mod 
\exercise mod vs mod.
\label{mod_vs_mod}%
Para cada uma das expressões abaixo uma das 3 opções é valida:
(a) ela denota um termo;
(b) ela denota uma afirmação; ou
(c) ela não tem significado.
Para cada expressão, decida qual é a opção certa e:
se for a (a), ache o seu valor (objeto);
se for a (b), ache o seu valor (de verdade).
\beginol
\li $69 \pmod 5 = 4$
\li $12 = 3 \pmod 8 $
\li $12 \cong 20 \pmod 4 $
\li $8 \pmod 3 \cong 12$
\li $108 \cong 208 \pmod {(43 \bmod 30)}$
\li $x \bmod 4 = 2 \implies x \cong 0 \pmod 2$
\li $5^{192 \bmod 3}$
\li $13\pmod 8 \cong 23 \pmod {18}$
\endol

\solution
Vamo lá:
\beginol
\li $69 \pmod 5 = 4$ não significa nada.
\li $12 = 3 \pmod 8$ não significa nada.%
\footnote{Se o $=$ fosse $\cong$, então significaria que $8 \divides 12 - 3 = 9$ (que é falso).}
\li $12 \cong 20 \pmod 4$ significa que $4 \divides 12 - 20 = -8$, que é verdade.
\li $8 \pmod 3 \cong 12$ não significa nada.
\li $108 \cong 208 \pmod {(43 \bmod 30)}$ significa que $43\bmod 30 \divides 108 - 208$, e para achar se é verdade ou não, calculamos $43\bmod 30 = 13$, e $108 - 208 = -100$ e substituimos: $13 \divides -100$, que é falso.
\li $\lforall {x\in\ints} {x \bmod 4 = 2 \limplies x \cong 0 \pmod 2}$ denota a afirmação que para todo $x\in\ints$, se $x \bmod 4 = 2$ então $x \cong 0 \pmod 2$, que é verdade:
seja $x\in\ints$ tal que $x \bmod 4 = 2$.  Logo $x = 4k + 2 = 2(2k + 1)$ para algum $k\in\ints$, ou seja, $2 \divides x = x - 0$.
\li $5^{192 \bmod 3}$ é o número 5 elevado ao resto da divisão de 192 por 3.  Como $3 \divides 192$ (por quê?  1 + 9 + 2 = 12; 1 + 2 = 3; veja o~\ref{divisibility_criterion_3_9}), temos $192 \bmod 3 = 0$, então o valor da expressão é o número $5^0 = 1$.
\li $13\pmod 8 \cong 23 \pmod {18}$ não significa nada.
\endol

\endexercise
%%}}}

%%{{{ notation 
\note Notação.
Talvez ficaria mais intuitivo (e menos confúso), usar uma notação como a
$$
a \congmod m b \defiff m \divides a - b
$$
que aparece mais fiel na sua semántica.
Mas a notação que é usada internacionalmente é aquela que nós definimos
e nós vamos ficar consistentemente fieis nela!
%%}}}

\endsection
%%}}}

%%{{{ The relation congruence modulo $m$ 
\section A relação de congruência módulo~$m$.

%%{{{ Fixing an $m$ 
\note Fixando um $m$.
Se fixar um inteiro $m>0$, então a expressão
$$
\holed a \cong \holed b \pmod m
$$
tem duas variáveis livres: a $a$ e a $b$.
Assim, a ``congruência módulo~$m$'' é uma relação binária,
cujas propriedades investigamos agora.
%%}}}

%%{{{ thm: congruence_mod_m_is_an_eqrel 
\theorem.
\label{congruence_mod_m_is_an_eqrel}%
Fixe um inteiro $m > 0$.
Para todos os $a,b\in\ints$,
temos:
$$
\xxalignat 2
(1)\quad&a \cong a \pmod m                             &&\textrm{(reflexividade)}\\
(2)\quad&a \cong b \pmod m \mland b \cong c \pmod m
\implies
a \cong c \pmod m                                      &&\textrm{(transitividade)}\\
(3)\quad&a \cong b \pmod m \implies b \cong a \pmod  m &&\textrm{(simetria)}.
\endxxalignat
$$
\sketch.
Todas são facilmente provadas aplicando diretamente
a definição de congruência módulo~$m$ (\refn{congruence})
e as propriedades básicas da $\divides$.
\qes
\proof.
(1) Óbvio porque $m\divides a - a = 0$.
(2) Pela hipótese temos $m\divides a-b$ e $m\divides b-c$.
Então pelo~\ref{divides_properties} $m\divides (a-b) + (b-c) = a-c$.
(3) Pela hipótese temos $m\divides a - b$\thinspace; logo (\refn{divides_properties} de novo) $m\divides -(a - b) = b - a$.
\qed
%%}}}

%%{{{ remark: equivalence relation 
\remark.
\ii{relação}[de equivalência]%
Uma relação que satisfaz essas três propriedades é chamada
\dterm{relação de equivalência}~(\refn{Equivalence_relations}).
Estudamos relações no~\ref{Relations}.  Paciência!
%%}}}

\endsection
%%}}}

%%{{{ Modular arithmetic 
\section Aritmética modular.

%%{{{ prop: modular_arithmetic_properties 
\property.
\label{modular_arithmetic_properties}%
Se $a \cong b \pmod m$, então para todo $x\in\ints$ temos:
$$
(1)\quad a + x \cong b + x   \pmod m;
\quad\enspace
(2)\quad ax \cong bx         \pmod m;
\quad\enspace
(3)\quad -a \cong -b         \pmod m.
$$
\sketch.
Todas seguem facilmente pela definição (\refn{congruence}) de congruência módulo~$m$.
\qes
%%}}}

%%{{{ beware: wrong_cancellation_law_modulo_m 
\beware.
\label{wrong_cancellation_law_modulo_m}%
O lei de cancelamento, mesmo valido nas igualdades,
não é valido nas congruências em geral.
Por exemplo,
$3\ntimes 2 \cong 3\ntimes 8 \pmod {18}$,
mas não podemos cancelar os $3$ nos dois lados:
$2 \ncong 8 \pmod {18}$.
%%}}}

\blah.
Felizmente, o teorema seguinte mostra quando realmente podemos cancelar:

%%{{{ thm: cancellation_law_modulo_m 
\theorem Lei de cancelamento módulo $m$.
\label{cancellation_law_modulo_m}%
Seja $c\in\ints$ tal que $\gcd c m = 1$.
$$
ca\cong cb\pmod m
\implies
a \cong b \pmod m.
$$
\sketch.
Multiplicamos tudo por $c^{-1}$, cuja existência (módulo~$m$) é garantida
pela hipótese (aplicando o~\ref{find_inverse_modulo_m}).
\qes
\proof.
Como $\gcd c m = 1$, existe $c^{-1}$ (módulo~$m$) então:
$$
\align
ca\cong cb\pmod m
&\implies          c^{-1}c a\cong          c^{-1}c b\pmod m\\
&\implies \phantom{c^{-1}c}a\cong \phantom{c^{-1}c}b\pmod m.
\endalign
$$
\moveqedup
\qed
%%}}}

%%{{{ x 
\exercise.
Aplicando as definições e propriedades de congruência e da relação $\divides$,
ache uma outra prova do~\refn{cancellation_law_modulo_m}.

\solution
Pela hipótese $m\divides ca - cb = c(a - b)$.
Mas $\gcd m c = 1$, então
(pelo~\ref{coprime_with_a_part_of_a_product_must_divide_the_other_part_to_divide_the_product})
$m\divides a - b$, ou seja, $a \cong b \pmod m$.

\endexercise
%%}}}

%%{{{ x: from_mod_m_to_mod_am 
\exercise.
\label{from_mod_m_to_mod_am}%
Suponha que $x \cong t \pmod m$, e seja $a$ um inteiro positivo.
O que podemos concluir sobre o $x$ módulo~$ma$?

\hint
Use as definições de congruência (\refn{congruence}) e de $\divides$ (\refn{divides})
para escrever o $x$ na forma $x = mk + t$ para algum $k\in\ints$.

\hint
Agora divida o $k$ por $a$.

\solution
Pela definição de congruência (\refn{congruence}) e de $\divides$ (\refn{divides}) temos que:
$$
\align
x &= mk + t, \quad\text{para algum $k\in\ints$}.
\intertext{Dividindo o $k$ por $a$,
temos $k = aq + i$, onde $q,i\in\ints$ e $0\leq i < a$.  Substituindo:}
x &= m(aq + i) + t\\
  &= maq + (mi + t).
\intertext{Logo, chegamos nas $a$ congruências}
x &\cong mi + t \pmod{ma}, \quad\text{para $i=0,\dotsc,a-1$},
\endalign
$$
e $x$ tem que satisfazer (exatamente) uma delas.

\endexercise
%%}}}

%%{{{ x: from_equality_to_congruence 
\exercise De igualdades para congruências.
\label{from_equality_to_congruence}%
Seja $a,b\in\ints$.
Se $a = b$, então $a\cong b\pmod m$ para qualquer inteiro $m\in\nats$.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Divisibility criteria 
\section Critéria de divisibilidade.
\label{Divisibility_criteria}%
\ii{divisibilidade}[critéria]%

%%{{{ criterion: divisibility_criterion_powers_of_10 
\criterion Divisibilidade por potências de 10.
\label{divisibility_criterion_powers_of_10}%
Um inteiro $c\neq 0$ é divisível por $10^k$
sse
o $c$ escrito em base decimal termina com $k$ dígitos 0.
%%}}}

%%{{{ criterion: divisibility_criterion_2_5 
\criterion Divisibilidade por $2$ ou $5$.
\label{divisibility_criterion_2_5}%
Seja $m\in\set{2, 5}$.
Um inteiro $c$ é divisível por $m$
sse
o valor do último dígitos do $c$ (em base decimal) é $m$.
%%}}}

%%{{{ criterion: divisibility_criterion_3_9 
\criterion Divisibilidade por 3 ou 9.
\label{divisibility_criterion_3_9}%
Seja $m\in\set{3, 9}$.
Um inteiro $c$ é divisível por $m$
sse
o somatório dos valores dos dígitos do $c$ (em base decimal) é
divisível por $m$.
%%}}}

%%{{{ criterion: divisibility_criterion_4_20_25_50
\criterion Divisibilidade por 4, 20, 25, 50.
\label{divisibility_criterion_4_20_25_50}%
Seja $m\in\set{4, 20, 25, 50}$.
Um inteiro $c$ é divisível por $m$
sse
o número formado por os \oldstyle{2} últimos dígitos do $c$ (em base decimal)
é divisível por $m$.
%%}}}

%%{{{ criterion: divisibility_criterion_11 
\criterion Divisibilidade por 11.
\label{divisibility_criterion_11}%
Um inteiro $c$ é divisível por $11$
sse
o somatório dos valores dos dígitos do $c$ (em base decimal) em posição par
menos o somatório dos valores dos seus dígitos em posição ímpar
é divisível por $11$.
%%}}}

%%{{{ x: divisibility_criterion_6 
\exercise Divisibilidade por 6.
\label{divisibility_criterion_6}%
Ache um critério (para o sistema decimal) para divisibilidade por 6.

\hint
$6 = 2\ntimes 3$

\solution
Observe que por causa do~\ref{product_of_coprimes_divides_common_multiple}, temos:
$$
6\divides c
\iff
2 \divides c
\mland
3 \divides c.
$$
Logo, aplicamos os critéria de divisibilidade por $2$ e por $3$.

\endexercise
%%}}}

%%{{{ prop: divisibility_criterion_8_wrong 
\proposition Divisibilidade por 8.
\label{divisibility_criterion_8_wrong}%
Um número $c$ é divisível por 8 sse ele satisfaz
os critéria de divisibilidade por $2$ e $4$.
\wrongproof.
Observe que por causa do~\ref{product_of_coprimes_divides_common_multiple}, temos:
$$
8 \divides c
\iff
2 \divides c
\mland
4 \divides c.
$$
Logo, aplicamos os critéria de divisibilidade por $2$ e por $4$.
\mistaqed
%%}}}

%%{{{ x: divisibility_criterion_8_wrong_why 
\exercise.
\label{divisibility_criterion_8_wrong_why}%
Ache o erro no~\ref{divisibility_criterion_8_wrong},
e compare com a solução do~\ref{divisibility_criterion_6}.

\hint
Veja o~\ref{product_of_coprimes_divides_common_multiple}.

\solution
Como $\gcd 4 2 = 4 \neq 1$, não podemos aplicar
o~\ref{product_of_coprimes_divides_common_multiple}.
Um contraexemplo:
$2 \divides 12$ e $4 \divides 12$, mas $2\ntimes 4 = 8 \ndivides 12$.

\endexercise
%%}}}

%%{{{ x: divisibility_criterion_8_powers_of_2 
\exercise.
\label{divisibility_criterion_8_powers_of_2}%
Ache um critério (no sistema decimal) para divisibilidade por 8,
e generalize para divisibilidade por $2^k$

\hint
$8 = 2^3$, e $2 \divides 10$.

\hint
$2 \divides 10 \implies 2^3 \divides 10^3$.

\endexercise
%%}}}

%%{{{ x: divisibility_criterion_2_exp_x_times_5_exp_y 
\exercise.
\label{divisibility_criterion_2_exp_x_times_5_exp_y}%
Ache um critério (no sistema decimal) para divisibilidade por $2^x5^y$, onde $x,y\in\nats$.

\hint
Os $2$ e $5$ são divisores de $10$.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Inverses modulo $m$ 
\section Inversos módulo~$m$.

%%{{{ df: inverse_modulo_m 
\definition Inverso módulo $m$.
\label{inverse_modulo_m}%
\tdefined{inverso}[multiplicativo módulo~$m$]%
\sdefined {{\sholed a}^{-1}} {o inverso (multiplicativo) do $a$ (módulo~$m$)}%
Seja $a,a',m\in\ints$.
Chamamos $a'$ \dterm{um inverso (multiplicativo) de $a$ módulo~$m$},
sse
$$
aa' \cong 1 \pmod m.
$$
Se existe inverso do $a$, o denotamos com $a^{-1}$ (dado um módulo~$m$).\mistake
%%}}}

%%{{{ x: what is wrong? 
\exercise.
Qual o problema com a definição do $a^{-1}$?

\solution
Para o símbolo $a^{-1}$ ser bem-definido, precisamos mostrar que, caso que
existe um inverso, ele é único, que nos realmente mostramos
no~\ref{inverse_modulo_m_uniqueness}.

\endexercise
%%}}}

\blah.
Podemos falar sobre \emph{o} inverso (ao invés de \emph{um} inverso) graças ao teorema seguinte:

%%{{{ thm: inverse_modulo_m_uniqueness 
\theorem Unicidade do inverso.
\label{inverse_modulo_m_uniqueness}%
Sejam $a,m\in\ints$.
Se $b,b'\in\ints$ satisfazem a $ax \cong 1 \pmod m$, então $b \cong b' \pmod m$.
\proof.
Como
$$
ab  \cong 1 \pmod m \qquad\mland\qquad ab' \cong 1 \pmod m,
$$
pela transitividade e reflexividade da congruência módulo~$m$, temos:
$$
ab \cong ab' \pmod m.
$$
Pela~\ref{modular_arithmetic_properties}, podemos multiplicar os dois lados por $b$:%
\footnote{Nada especial sobre $b$ contra o $b'$.  Poderiamos multiplicar por qualquer inverso do $a$ aqui.}
$$
bab \cong bab' \pmod m.
$$
Daí,
$(ba)b \cong (ba)b' \pmod m$,
ou seja $b \cong b' \pmod m$.
\qed
%%}}}

%%{{{ eg 
\example.
O inverso de $2$ módulo~$9$ é o $5$, porque $2\ntimes 5 = 10 \cong 1 \pmod 9$.
\endexample
%%}}}

\blah.
Como o exemplo seguinte mostra, os inversos não existem sempre:

%%{{{ eg 
\example.
O $4$ não tem inverso módulo~$6$.

\solution
Podemos verificar com força bruta:
$$
\align
4 \ntimes 1 = \phantom04    &\cong 4 \pmod 6\\
4 \ntimes 2 = \phantom08    &\cong 2 \pmod 6\\
4 \ntimes 3 = 12            &\cong 0 \pmod 6\\
4 \ntimes 4 = 16            &\cong 4 \pmod 6\\
4 \ntimes 5 = 20            &\cong 2 \pmod 6
\endalign
$$
\moveqedup
\endexample
%%}}}

\blah.
O teorema seguinte esclariza a situação:

%%{{{ thm: find_inverse_modulo_m 
\theorem Inverso módulo $m$.
\label{find_inverse_modulo_m}%
Sejam $a,m\in\ints$.
$$
\text{$a$ tem inverso módulo~$m$}
\iff
\gcd a m = 1.
$$
\proof.
Precisamos mostrar as duas direções do \bidir.
\endgraf
\lrdir:
Escrevemos o $\gcd a m = 1$ como combinação\ii{combinação linear} linear dos $a$ e $m$
(sabemos que é possivel por \ref{gcd_as_linear_combination}, e, até melhor construtível
graças ao algoritmo estendido de Euclides,~\ref{extended_euclidean_algorithm}):
$$
\alignat 2
1 &= sa + tm, &&\qquad\text{para alguns $s,t\in\ints$.}
\intertext{Então temos:}
1 &\cong sa + tm    &&\pmod m\\
  &\cong sa + 0     &&\pmod m\\
  &\cong sa         &&\pmod m.
\endalignat
$$
Acabamos de achar um inverso de $a$ módulo~$m$: o $s$.
\endgraf
\rldir:
Seja $b$ um inverso de $a$ módulo~$m$; em outras palavras:
$$
ab \cong 1 \pmod m,
$$
ou seja, $m \divides ab - 1$, e $mu = ab - 1$ para algum $u\in\ints$.
Conseguimos escrever
$$
1 = um - ba,
$$
a combinação linear dos $a$ e $m$.
Pelo~\ref{gcd_divides_any_linear_combination}, $\gcd a m \divides 1$,
logo $\gcd a m = 1$.
\qed
%%}}}

\endsection
%%}}}

%%{{{ The Chinese remainder theorem 
\section O teorema chinês do resto.

%%{{{ thm: chinese_remainder_theorem 
\theorem Teorema chinês do resto.
\label{chinese_remainder_theorem}%
\ii{teorema}[chinês do resto]%
\iisee{chinês}[teorema do resto]{teorema chinês}%
\ii{sistema}[de congruências]%
\ii{congruência}[sistema]%
Sejam $a_1,\dotsc,a_k,m_1,\dotsc,m_k\in\ints$,
com os $m_i$'s coprimos dois-a-dois:
$$
\lforall {i,j\in\set{1,\dotsc,k}} {i\neq j \limplies \gcd {m_i} {m_j} = 1}.
$$
Então existe $x\in\ints$ que satisfaz o sistema de congruências
$$
\align
x &\cong    a_1    \pmod {m_1}\\
x &\cong    a_2    \pmod {m_2}\\
  &\eqvdots                   \\
x &\cong    a_k    \pmod {m_k}.
\endalign
$$
Alem disso, a solução do sistema é única módulo~$m_1\dotsb m_k$.
\sketch.
\proofstyle{Existência:}
Seja
$$
\align
M   &\asseq \Prod_{i=1}^k m_i = m_1m_2\dotsb m_k
\intertext{e, para todo $i\in\set{1,\dotsc,k}$, defina o}
M_i &\asseq \Prod_{\Sb j=1\\j\neq i\endSb}^k m_j
     = m_1\dotsb m_{i-1}m_{i+1}\dotsb m_k
     = \frac M {m_i}.
\endalign
$$
Observe que $M_i$ é invertível módulo~$m_i$,
então seja $B_i$ o seu inverso.
Verificamos que o inteiro
$$
x =
\Sum_{i=1}^k
a_i M_i B_i
$$
satisfaz todas as $k$ congruências,
e é então uma solução do sistema.
\endgraf
\proofstyle{Unicidade:}
Suponha que $x'\in\ints$ é uma solução do sistema.
Usando a definição de congruência e propriedades
de $\divides$, mostramos que $x' \cong x \pmod M$.
\qes
%%}}}

%%{{{ eg 
\example.
Ache todos os inteiros $x\in\ints$ que satisfazem o sistema de congruências:
$$
\align
x &\cong 2 \pmod 9\\
x &\cong 1 \pmod 5\\
x &\cong 2 \pmod 4.
\endalign
$$

\solution
Observamos primeiramente que os módulos $9$, $5$, e $4$ realmente são coprimos
dois-a-dois.  Então, pelo teorema chinês do resto,
o sistema realmente tem solução.
Seguindo sua método---e usando os mesmos nomes para as variáveis como
no~\ref{chinese_remainder_theorem} mesmo---calculamos os:
$$
\xalignat2
M_{\phantom0}   &= 9\ntimes5\ntimes4 = 180  &      &               \\
M_1 &= \phantom{9\ntimes{}}5\ntimes4 = 20   &  B_1 &\cong 5 \pmod 9\\
M_2 &= 9\phantom{{}\ntimes5}\ntimes4 = 36   &  B_2 &\cong 1 \pmod 5\\
M_3 &= 9\ntimes5\phantom{{}\ntimes4} = 45   &  B_3 &\cong 1 \pmod 4, 
\endxalignat
$$
onde os invérsos $B_i$'s podemos calcular usando o algoritmo estendido de
Euclides~(\refn{extended_euclidean_algorithm}) como na prova
do~\ref{find_inverse_modulo_m}), mas nesse caso, sendo os módulos tão pequenos
fez mas sentido os achar testando, com ``força bruta''.
Então, graças ao teorema chinês, as soluções são exatamente os inteiros $x$ que satisfazem
$$
\alignat2
x &\cong a_1M_1B_1 + a_2M_2B_2 + a_3M_3B_3                                      &&\pmod M\\
  &\cong 2 \ntimes 20\ntimes 5 + 1 \ntimes 36\ntimes 1 + 2 \ntimes 45\ntimes 1  &&\pmod {180}\\
  &\cong 200 + 36 + 90                                                          &&\pmod {180}\\
  &\cong 146                                                                    &&\pmod {180}.
\endalignat
$$
Para resumir, as soluções do sistema são todos os elementos do
$\set{ 180k + 146 \st k\in\ints }$.
\endexample
%%}}}

%%{{{ eg 
\example.
Ache todos os inteiros $x\in\ints$ com $\abs x < 64$ que satisfazem o sistema de congruências:
$$
\align
x  &\cong 1 \pmod 3\\
3x &\cong 1 \pmod 4\\
4x &\cong 2 \pmod 5.
\endalign
$$

\solution
Para aplicar o teorema chinês do resto precisamos os $3$, $4$, e $5$ coprimos dois-a-dois,
que realmente são.
Mas observe que o sistema não está na forma do teorema;
aí, não podemos aplicá-lo diretamente.
Nosso primeiro alvo então seria transformar a segunda e a terceira congruência para
equivalentes, na forma necessária para aplicar o teorema.
Na segunda vamos nos livrar do fator $3$, e na terceira do fator $4$.
Como $\gcd 3 4 = 1$,%
\footnote{Qual ``4'' foi esse?}
o $3$ é invertível módulo~$4$.
Como o $3\cong -1 \pmod 4$, temos diretamente que $3^{-1} \cong -1 \pmod 4$.
Similarmente achamos o inverso $4^{-1} \cong -1 \pmod 4$.
Então temos:
$$
\rightbrace{
\aligned
x  &\cong 1 \pmod 3\\
3x &\cong 1 \pmod 4\\
4x &\cong 2 \pmod 5
\endaligned
}
\iff
\brace{
\aligned
x  &\cong \phantom{1^{-1}}1 \pmod 3\\
3^{-1}3x &\cong 3^{-1}1 \pmod 4\\
4^{-1}x &\cong 4^{-1}2 \pmod 5
\endaligned
}
\iff
\leftbrace{
\aligned
x &\cong \phantom{-}1 \pmod 3\\
x &\cong -1 \pmod 4\\
x &\cong -2 \pmod 5.
\endaligned
}
$$
Agora sim, podemos aplicar o teorema chinês.
Usando os mesmos nomes para as variáveis
como no~\ref{chinese_remainder_theorem}, calculamos:
$$
\xalignat2
M_{\phantom0}   &= 3\ntimes4\ntimes5              = 60 &     &               \\
M_1             &= \phantom{3\ntimes{}}4\ntimes5  = 20 & B_1 &\cong 2 \pmod 3\\
M_2             &= 3\phantom{{}\ntimes4}\ntimes5  = 15 & B_2 &\cong 3 \pmod 4\\
M_3             &= 3\ntimes4\phantom{{}\ntimes5}  = 12 & B_3 &\cong 3 \pmod 5, 
\endxalignat
$$
onde os invérsos $B_1$ e $B_2$ calculamos percebendo que
$20\cong-1 \pmod 3$ e $15\cong-1 \pmod 4$, e o $B_3$ com força bruta mesmo.
Pronto: as soluções do sistema são exatamente os inteiros $x$ que satisfazem:
$$
\alignat 3
x &\cong a_1M_1B_1 + a_2M_2B_2 + a_3M_3B_3                            &&\pmod M\\
  &\cong 2\ntimes20\ntimes1 + 3\ntimes15\ntimes3 + 3\ntimes12\ntimes3 &&\pmod {60}\\
  &\cong 40 + 135 + 108                                               &&\pmod {60}\\
  &\cong 40 + 15 + 108                                                &&\pmod {60}\by {$135\cong15\pmod{60}$}
  &\cong 55 + 48                                                      &&\pmod {60}\by {$108\cong48\pmod{60}$}
  &\cong -5 + 48                                                      &&\pmod {60}\by {$\phantom055\cong-5\pmod{60}$}
  &\cong 43                                                           &&\pmod {60}.
\endalignat
$$
Logo, o conjunto de todas as soluções do sistema é o $\set{ 60k + 43 \st k\in\ints }$.
Facilmente verificamos que os únicos dos seus elementos que satisfazem nossa
restricção $\abs x < 64$ são os inteiros obtenidos pelos valores de $k = 0$ e $-1$:
$x_1 = 43$, $x_2 = -17$.
\endexample
%%}}}

%%{{{ x: coprime_vs_pairwise_coprime 
\exercise ``entre si'' vs ``dois-a-dois''.
\label{coprime_vs_pairwise_coprime}%
Considere as frases:
\beginol
\li Os inteiros $a_1, a_2, \dotsc, a_n$ são coprimos entre si.
\li Os inteiros $a_1, a_2, \dotsc, a_n$ são coprimos dois-a-dois.
\endol
São equivalentes?
Se sim, prove as duas direções da equivalência; se não, ache um contraexemplo.

\hint
Não são equivalentes.

\hint
Procure um contraexemplo com três inteiros.

\solution
Os $2$, $4$, $5$ são coprimos entre si (têm m.d.c.~1) mas mesmo assim não são coprimos dois-a-dois:
$\gcd 2 4 = 2$.

\endexercise
%%}}}

%%{{{ x 
\exercise.
Acha as soluções dos seguinte sistemas de congruências:
$$
\xalignat2
\text{(1)}\quad&
\leftbrace{
\aligned
x  &\cong 3\phantom0 \pmod 4\\
5x &\cong 1\phantom0 \pmod 7\\
x  &\cong 2\phantom0 \pmod 9
\endaligned
}
&
\text{(2)}\quad&
\leftbrace{
\aligned
x  &\cong 3\phantom0 \pmod 3\\
3x &\cong 3\phantom0 \pmod 4\\
4x &\cong 2\phantom0 \pmod 5\\
5x &\cong 1\phantom0 \pmod 7.
\endaligned
}
\endxalignat
$$

\endexercise
%%}}}

\blah.
O exercício seguinte te convida descobrir que o teorema chinês pode ser aplicado
em casos mais gerais do que aparece inicialmente!

%%{{{ x 
\exercise.
Resolva os sistemas de congruências:
$$
\xalignat2
\text{(1)}\quad&
\leftbrace{
\aligned
5x &\cong 2\phantom0  \pmod 6\\
x  &\cong 13 \pmod {15}\\
x  &\cong 2\phantom0  \pmod 7
\endaligned
}
&
\text{(2)}\quad&
\leftbrace{
\aligned
x  &\cong 2\phantom0  \pmod 6\\
x  &\cong 13 \pmod {15}\\
x  &\cong 2\phantom0  \pmod 7.
\endaligned
}
\endxalignat
$$

\hint
Observe que não podes aplicar o teorema chinês diretamente: $\gcd 6 {15} > 1$.

\hint
Tente substituir a congruência $5x \cong 2  \pmod 6$ com um sistema equivalente, de \emph{duas} congruências.

\hint
Mostre que para qualquer $a\in\ints$,
$$
\rightbrace{
a \cong 2 \pmod 6
}
\iff
\leftbrace{
\aligned
a &\cong 0 \pmod 2\\
a &\cong 2 \pmod 3.
\endaligned
}
$$

\hint
Não todos os sistemas de congruências tem soluções.
(Acontéce quando temos restricções contraditórias.)
Nesse exercício um dos dois sistemas não tem solução.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Euler's totient function 
\section A função totiente de Euler.

%%{{{ df: euler_phi_function 
\definition Função totiente de Euler.
\label{euler_phi_function}%
\iisee{totiente}{função totiente}%
\iisee{Euler}[função]{função totiente}%
\Euler[função totiente]%
\tdefined{função}[totiente de Euler]%
\sdefined {\totsym} {a função totiente de Euler}%
Seja inteiro $n>0$.
Definimos
$$
\tot n \defeq \sizeof {\set { i \in \set{1,\dotsc,n} \st \gcd i n = 1 } }.
$$
Em palavras, $\tot n$ é o número dos inteiros entre $1$ e $n$ que são coprimos com $n$.
%%}}}

%%{{{ x 
\exercise.
Calcule os valores da $\tot n$ para $n=1,2,3,4,8,11,12,16.$

\endexercise

\property.
\label{tot_of_prime}%
$\text{$p$ primo} \implies \tot p = p-1.$
\proof.
Como $p$ é primo, ele é coprimo com todos os $1,\dotsc,p-1$.
E como $\gcd p p = p \neq 1$, pela definição da $\totsym$ temos
$\tot p = p-1$.
\qed
%%}}}

%%{{{ x: number_of_multiples_of_a_until_ai 
\exercise.
\label{number_of_multiples_of_a_until_ai}%
Quantos multiplos de $a$ existem no $\set{1,2,\dotsc,a^i}$?

\endexercise
%%}}}

%%{{{ x: tot_of_power_of_prime 
\exercise.
\label{tot_of_power_of_prime}%
$
\text{$p$ primo} \implies
\tot {p^a} = p^a - p^{a-1} = p^{a-1} (p-1)
$.

\hint
Use a definição de $\totsym$ e o~\ref{number_of_multiples_of_a_until_ai}.

\solution
Seguindo a definição de $\totsym$, vamos contar todos os números
no $\set{1,2,\dotsc,p^i}$ que são coprimos com $p^i$.
Quantos não são?
Observe que como $p$ é primo,
os únicos que não são coprimos com ele,
são os múltiplos de $p$.
Pelo~\ref{number_of_multiples_of_a_until_ai} temos a resposta.

\endexercise
%%}}}

%%{{{ x: sum_of_tots_of_powers_of_prime 
\exercise.
\label{sum_of_tots_of_powers_of_prime}%
Sejam $p$ primo e $k\in\ints$.  Calcule o valor do somatório
$\Sum_{i=0}^k \tot {p^i}$.

\hint
Calcule o valor de cada termo aplicando o~\ref{tot_of_power_of_prime}.

\endexercise
%%}}}

%%{{{ x: tot_of_product_of_primes 
\exercise.
\label{tot_of_product_of_primes}%
$\text{$p,q$ primos, $p\neq q$} \implies \tot {pq} = (p-1)(q-1)$.

\endexercise
%%}}}

%%{{{ thm: tot_is_multiplicative 
\theorem.
\label{tot_is_multiplicative}%
\iisee{multiplicativa}{função multiplicativa}%
\tdefined{função}[multiplicativa]%
A função $\totsym$ é \dterm{multiplicativa}:
$$
\gcd m n = 1 \implies \tot {mn} = \tot m \tot n.
$$
%%}}}

%%{{{ cor 
\corollary.
Se $n\geq 2$, então
$$
\tot n
= n \!\!\Prod_{\Sb\text{$p$ primo}\\p \divides n\endSb}\!\!\left(1-\frac 1 p\right)
= n
\left(1-\frac 1 {p_1}\right)
\left(1-\frac 1 {p_2}\right)
\dotsb
\left(1-\frac 1 {p_k}\right),
$$
onde os $p_i$'s são todos os primos divisores de $n$.
\sketch.
Escrevemos o $n$ na sua representação canónica pelo teorema fundamental da
aritmética~(\refn{fundamental_theorem_of_arithmetic}),
e aplicamos repetetivamente o~\ref{tot_is_multiplicative}.
\qes
\proof.
Pelo teorema fundamental da aritmética~(\refn{fundamental_theorem_of_arithmetic}),
seja $n \eqass p_0^{a_0} p_1^{a_1} \dotsb p_k^{a_k}$ a representação canónica
\ii{representação canónica} do $n$.
Calculamos:
\compute
\tot n
&= \tot {p_0^{a_0} p_1^{a_1} \dotsb p_k^{a_k}}              \\
&= \tot {p_0^{a_0}} \tot{p_1^{a_1}} \dotsb \tot{p_k^{a_k}}  \by {\ref{tot_is_multiplicative}}
&=
p_0^{a_0}\paren{1 - \frac 1 {p_0}}
p_1^{a_1}\paren{1 - \frac 1 {p_1}}
\dotsb
p_k^{a_k}\paren{1 - \frac 1 {p_k}}                          \by {\ref{tot_of_power_of_prime}}
&=
p_0^{a_0}p_1^{a_1}\dotsb p_k^{a_k}
\paren{1 - \frac 1 {p_0}}\paren{1 - \frac 1 {p_1}}\dotsb\paren{1 - \frac 1 {p_k}}\\
&=
n
\paren{1 - \frac 1 {p_0}}\paren{1 - \frac 1 {p_1}}\dotsb\paren{1 - \frac 1 {p_k}}.
\endcompute
\moveqedup
\qed
%%}}}

%%{{{ x 
\exercise.
$a\divides b \implies \tot a \divides \tot b$.

\endexercise
%%}}}

%%{{{ x 
\exercise.
$
\tot {2n} =
\knuthcases{
2\tot n,& $n$ é par \cr
\tot n, & $n$ é ímpar.
}
$

\endexercise
%%}}}

%%{{{ x: tot_is_par_for_n_greater_than_2 
\exercise.
\label{tot_is_par_for_n_greater_than_2}%
$\tot n$ é par para todo $n\geq 3$.

\hint
Os inverso aparecem ``em pares''.
Mas uns são emparelhados com eles mesmo, sendo seus próprios inversos
(por exemplo, o inverso de 1, é o 1, módulo qualquer $m$).

\hint
Escreva o $n$ na sua representação canónica pelo teorema fundamental
da aritmética~(\refn{fundamental_theorem_of_arithmetic}).

\hint
Aplica o~\ref{tot_is_multiplicative} e o~\ref{tot_of_power_of_prime}.

\hint
Ou o $2$ aparece nos fatores primos do $n$, ou não.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Theorems of Euler and Fermat 
\section Teoremas de Euler e de Fermat.

%%{{{ thm: euler_congruence_theorem 
\theorem Euler.
\label{euler_congruence_theorem}%
\Euler[teorema]%
Sejam $a,m\in\ints$ com $\gcd a m = 1$.
Então
$$
a^{\tot m} \cong 1 \pmod m.
$$
\sketch.
Considere o conjunto
$$
\align
 R &=\set{r_1, r_2, \dotsc, r_{\tot m}}
\intertext{de todos os inteiros $r$ com $1 \leq r \leq m$, e $\gcd r m = 1$, e o conjunto}
aR &= \set{ar \st r \in R}\\
   &= \set{ar_1, ar_2, \dotsc, ar_{\tot m}}.
\endalign
$$
Observamos agora que (módulo~$m$) os $ar_1,ar_2,\dotsc,ar_{\tot m}$
são apenas uma permutação dos $r_1,r_2,\dotsc,r_{\tot m}$.
Logo os seus produtórios são congruentes:
$$
(ar_1)(ar_2)\dotsb (ar_{\tot m})
\cong
r_1r_2\dotsb r_{\tot m}
\pmod m.
$$
Trabalhando na última congruência chegamos na congruência desejada.
\qes
%%}}}

%%{{{ cor: fermat_little_theorem_1 
\corollary Fermat.
\label{fermat_little_theorem_1}%
\Fermat[teorema]%
\ii{teorema}[pequeno Fermat]%
Sejam $p$ primo e $a\in\ints$ com $\gcd a p = 1$.
Então
$$
a^{p-1} \cong 1 \pmod p.
$$
\sketch.
O resultado é imediato usando o teorema de Euler
(\refn{euler_congruence_theorem}) e a~\ref{tot_of_prime}.
\qes
\proof.
Como $p$ é primo, sabemos que $\tot p = p-1$, então temos:
\compute
a^{p-1}
&= a^{\tot m}       \by {\ref{tot_of_prime}}
&\cong 1 \pmod m.   \by {\ref{euler_congruence_theorem}}
\endcompute
\qed
%%}}}

%%{{{ cor: fermat_little_theorem_2 
\corollary Fermat.
\label{fermat_little_theorem_2}%
\Fermat[teorema]%
\ii{teorema}[pequeno Fermat]%
Sejam $p$ primo e $a\in\ints$.
Então
$$
a^p \cong a \pmod p.
$$
\sketch.
Considere dois casos: $\gcd a p = 1$ ou $\gcd a p > 1$.
No primeiro usamos o~\ref{fermat_little_theorem_1}.
No segundo, necessariamente temos $0\cong a^p\cong a \pmod p$.
\qes
\proof.
Temos dois casos:
\endgraf
\case{Caso $\gcd a p$ = 1}:
Pelo~\ref{fermat_little_theorem_1} temos:
$$
\align
a^{p-1} &\cong 1 \pmod p
\intertext{e multiplicando por $a$,}
a^p     &\cong a \pmod p.
\endalign
$$
\case{Caso $\gcd a p$ > 1}:
Nesse caso, como $p$ é primo, necessariamente $p\divides a$,
ou seja, $a \cong 0 \pmod p$,
logo $a^p \cong 0 \pmod p$.
Agora pela transitividade e
simetria da $congruência$ módulo~$m$, finalmente temos:
$a^p \cong a \pmod p$
\qed
%%}}}

%%{{{ Summarizing the three theorems 
\note Resumindo os três teoremas.
Esquematicamente:
$$
\alignat 4
\text{$\gcd a m = 1$}
&\implies{}
&a^{\tot m} &&{}\cong 1 & \pmod m
&\qqqquad&\text{Euler, (\refn{euler_congruence_theorem})}
\\
\rightbrace{
\aligned
\text{$p$ primo}\\
\gcd a p = 1
\endaligned
}
&\implies{}
&a^{p-1} &&{}\cong 1& \pmod p
&\qqqquad&\text{Fermat, (\refn{fermat_little_theorem_1})}
\\
\text{$p$ primo}
&\implies{}
&a^p &&{}\cong a &\pmod p
&\qqqquad&\text{Fermat, (\refn{fermat_little_theorem_2})}.
\endalignat
$$
%%}}}

%%{{{ eg: last_digit_of_big_number_example 
\example.
\label{last_digit_of_big_number_example}%
Ache o último dígito do $2^{800}$.

\solution
Procuramos um $y$ tal que $2^{800}\cong y \pmod {10}$
(por quê?).
Usando o teorema de Fermat~(\ref{fermat_little_theorem_1}) temos:
$$
\align
2^4 &\cong 1 \pmod 5,
\intertext{logo}
2^{800} = (2^4)^{200} &\cong 1 \pmod 5.
\endalign
$$
Então módulo~$10$ temos duas possibilidades (por quê?):
$$
2^{800} \cong
\knuthcases{
1 \pmod {10}\cr
6 \pmod {10}.\cr
}
$$
Podemos já eliminar a primeira porque $2^{800}$ é par.
Finalmente, o último dígito de $2^{800}$ é o $\digit6$.
\endexample
%%}}}

%%{{{ x 
\exercise.
Responda no primeiro ``por quê?'' do~\ref{last_digit_of_big_number_example}.

\hint
Escreva o inteiro como somatório baseado na sua forma decimal.

\hint
Divide ele por 10.

\solution
Para o número $n$ escrito em base decimal como
$\delta_k\delta_{k-1}\dotsb \delta_1\delta_0$,
temos:
$$
\align
n
&= d_0 + 10d_1 + 100d_2 + \dotsb 10^{k-1}d_{k-1} + 10^kd_k\\
&= \tunderbrace {d_0} {resto} + 10\tunderbrace {(d_1 + 10d_2 + \dotsb 10^{k-2}d_{k-1} + 10^{k-1}d_k)} {quociente},
\endalign
$$
onde $d_i$ é o correspondente valor do dígito $\delta_i$.
(Evitamos aqui confundir o ``dígito'' com seu valor usando notação diferente
para cada um, para enfatizar a diferença entre os dois conceitos.)

\endexercise
%%}}}

%%{{{ x 
\exercise.
Responda no segundo também, e ache um outro caminho para chegar no resultando, usando
o teorema chinês do resto (\ref{chinese_remainder_theorem}).

\hint
Qual a solução do sistema
$$
\align
x &\cong 1 \pmod 5\\
x &\cong 0 \pmod 2?
\endalign
$$

\solution
Podemos ou aplicar o teorema chinês (\ref{chinese_remainder_theorem}) no sistema de congruências
$$
\align
x &\cong 1 \pmod 5\\
x &\cong 0 \pmod 2,
\endalign
$$
ou, como $5\divides 10$, usar diretamente o~\ref{from_mod_m_to_mod_am},
para concluir que $x = 10k + 5i + 1$, onde $i=0,1$.

\endexercise
%%}}}

%%{{{ x 
\exercise.
Ache o resto da divisão de $41^{75}$ por $3$.

\hint
Procure $y$ tal que $41^{75} \cong y \pmod 3$.

\hint
$\gcd {41} 3 = 1$.

\hint
$41^{75} = 41^{74}\ntimes 41$.

\hint
Fermat.

\solution
Como $\gcd {41} 3 = 1$, pelo teorema de Fermat (\ref{fermat_little_theorem_1})
temos
$$
41^{\tot 3} = 41^2 \cong 1 \pmod 3,
$$
e agora dividindo o $75$ por $2$, temos $75 = 2\ntimes 37 + 1$, então:
$$
\alignat 3
41^2 \cong 1 \pmod 3 &\implies (41^2)^{37}  &&\cong \phantom01  &&\pmod 3    \\
                     &\implies 41^{74}      &&\cong \phantom01  &&\pmod 3    \\
                     &\implies 41^{74}41    &&\cong 41 &&\pmod 3    \\
                     &\implies 41^{75}      &&\cong 41 &&\pmod 3    \\
                     &\implies 41^{75}      &&\cong \phantom02  &&\pmod 3.
\endalignat
$$
Outro jeito para escrever exatamente a mesma idéia,
mas trabalhando ``de fora pra dentro'', seria o seguinte:
$$
\alignat 2
41^{75} &= 41^{2\ntimes 37 + 1}\\
        &= 41^{2 \ntimes 37} 41\\
        &= (41^2)^{37} 41\\
        &\cong  1^{37} 41       &&\pmod 3\\
        &\cong  41              &&\pmod 3\\
        &\cong  2               &&\pmod 3.
\endalignat
$$
Então $41^{75} \bmod 3 = 2$.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Exponentiation 
\section Exponenciação.

\endsection
%%}}}

%%{{{ Cryptography 
\section Criptografía.

%%{{{ The idea of cryptography 
\TODO A idéia da criptografia.
%%}}}

%%{{{ Public-key cryptography 
\TODO Criptografia ``public-key''.
%%}}}

%%{{{ Criptografia RSA 
\TODO RSA criptografia e descriptografia.
%%}}}

%%{{{ thm 
\theorem.
Sejam $e, M\in\ints$ com $\gcd e {\tot M} = 1$,
e seja $d$ um inverso de $e$ módulo~$\tot M$: $ed \cong 1 \pmod {\tot M}$.
Para cada $m$ com $\gcd m M = 1$,
$$
\paren{m^e}^d \cong m \pmod M.
$$
\proof.
Observe primeiramente que:
\compute
ed \cong 1 \pmod {\tot M}
&\iff \tot M \divides ed - 1                    \by {\ref{congruence}}
&\iff \lexists {k\in\ints} {k\tot M = ed - 1}.  \by {\ref{divides}}
\endcompute
Seja $k\in\ints$ então um tal $k$, e agora resolvendo por $ed$:
$$
ed = k\tot M + 1.
\eqdef{rsa_ed_equality}
$$
Calculamos:
\compute
\paren{m^e}^d
&= m^{ed}                   \\
&= m^{k\tot M + 1}          \by {por~\eqref{rsa_ed_equality}}
&= m^{k\tot M} m            \by {def.~de exponenciação}
&= \paren{m^k}^{\tot M} m   \\
&\cong m  \pmod M,          \by {por teorema de Euler~\refn{euler_congruence_theorem}}
\endcompute
onde no último pásso precisamos a hipótese que $m$ e $\tot M$ são coprimos
e logo, $m^k$ e $\tot M$ também são: $\gcd m {\tot M} = \gcd {m^k} {\tot M} = 1$.
\qed
%%}}}

%%{{{ x 
\exercise.
O que acontece se $m$ e $\tot M$ não são coprimos?

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Digital signatures 
\section Assinaturas digitais.

\endsection
%%}}}

%%{{{ Problems 
\problems.

%%{{{ prob 
\problem.
Prove numa linha o~\ref{odd_to_any_power_is_odd}:
{\proclaimstyle
para todo $n\in\nats$ e todo ímpar $k\in\ints$, $k^n$ é ímpar.}

\endproblem
%%}}}

%%{{{ prob 
\problem.
(Generalização do~\ref{odd_to_any_power_is_odd}.)
Sejam $a\in\ints$ e $m\in\nats$.
Prove numa linha que para todo $n\in\nats$, existe $b\in\ints$ tal que $(am + 1)^n = bm + 1$.

\endproblem
%%}}}

%%{{{ prob 
\problem.
Prove que para todo $m\in\nats$, o produto de $m$ consecutivos inteiros é divisível por $m!$.

\endproblem
%%}}}

%%{{{ prob: freshmans_dream 
\problem O sonho do calouro.
\label{freshmans_dream}%
\ii{sonho do calouro}%
Seja $p$ primo, $x,y\in\ints$.
$$
(x + y)^p \cong x^p + y^p \pmod p.
$$

\hint
Use o teorema binomial~\refn{binomial_theorem}.

\hint
Use o \ref{p_divides_comb_p_r}.

\solution
Temos
\compute
(x + y)^p
&= \Sum_{i=0}^p \binom p i x^{p-i}y^i             \by {por~\ref{binomial_theorem}}
&= \binom p 0 x^p + \Sum_{i=1}^{p-1} \binom p i x^{p-i}y^i + \binom p p y^p             \by {$p\geq2$}
&= x^p + \Sum_{i=1}^{p-1} \binom p i x^{p-i}y^i + y^p     \\
&= x^p + \Sum_{i=1}^{p-1} p c_i x^{p-i}y^i + y^p, \quad\text{para algum $c_i\in\ints$}  \by {por~\ref{p_divides_comb_p_r}}
&= x^p + p \Sum_{i=1}^{p-1} c_i x^{p-i}y^i + y^p          \\
&\cong x^p + y^p \pmod p.
\endcompute

\endproblem
%%}}}

%%{{{ prob: little_fermat_new_proof 
\problem.
\label{little_fermat_new_proof}%
Ache uma nova prova, \emph{por indução}, do teorema de Fermat~\refn{fermat_little_theorem_2}:
\endgraf\noindent
{\sl Para todo primo $p$ e todo $a\in\ints$},
$$
a^p \cong a \pmod p.
$$
(Note que $a\in\ints$ e não $a\in\nats$.)

\hint
Use o sonho de calouro (\ref{freshmans_dream}).

\endproblem
%%}}}

%%{{{ prob 
\problem.
Prove que
$$
\tot {mn}
=
{\tot m \tot n}
\frac
d
{\tot d}
,\qquad\text{onde $d={\gcd m n}$}.
$$
Note quantas e quais das propriedades que já provamos são casos especiais dessa!

\endproblem
%%}}}

%%{{{ prob 
\problem.
Sejam $p,q$ primos com $p\neq q$.  Prove que
$$
p^{q-1} + q^{p-1} \cong 1 \pmod {pq}.
$$

\hint
O que seria o $p^{q-1} + q^{p-1}$ módulo~$p$?
E módulo~$q$?

\hint
China.

\endproblem
%%}}}

%%{{{ prob 
\problem.
Ache uma generalização do problema anterior,
aplicável para inteiros $a,b$ com $\gcd a b = 1$:

\hint
Nesse caso \emph{não} temos
$$
a^{b-1} + b^{a-1} \cong 1 \pmod {ab}.
$$

\hint
$p-1 = \tot p$ para qualquer primo $p$.

\hint
Prove que:
$$
a^{\tot b} + b^{\tot a} \cong 1 \pmod {ab}.
$$

\endproblem
%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

Veja o~\cite[\S1.9]{babybm}.

\cite{disquisitiones}.

\cite{nivennumbers},
\cite{hardywright}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: The natural numbers: recursion; induction 
\chapter Os números naturais: recursão; indução.
\label{Natrecind}%

%%{{{ chapintro: we define Nats, not the natural numbers 
\chapintro
Vou começar definindo formalmente os naturais.
Na verdade, não vou definir os próprios números naturais.
Não: os \emph{números} estão lá nas núvens do nosso coração.
Não vamos nos preocupar com a questão <<o que \emph{é} o número cinco?>>.
Vamos começar definindo uns \emph{numeráis}, que vou chamá-los de Nats,
e a gente vai estudá-los e ver o que podemos definir, calcular, e demonstrar
sobre eles.
%%}}}

%%{{{ The natural numbers formally 
\section Os números naturais formalmente.
\label{Nats_formally}%

%%{{{ df: Nat 
\definition Nat.
\label{Nat}%
\tdefined{Nat}%
Definimos os \dterm{numerais $\Nat$} para representar os números naturais
com uma definição inductiva:
\beginul
\li $0$ é um $\Nat$;
\li Se $n$ é um $\Nat$, então $Sn$ é um $\Nat$;
\endul
Nada mais é um $\Nat$.
%%}}}

%%{{{ With BNF 
\note Com gramática BNF.
Já fizemos isso na~\ref{Nat_grammar}:
$$
\bnf{Nat} \bnfeq 0 \bnfor S \bnf{Nat}
$$
%%}}}

%%{{{ With rules of inference 
\note Com regras de inferência.
Uma maneira diferente de descrever a mesma idéia é com \dterm{regras de inferência}.
Essa abordagem combina bem com as árvores sintácticas:
escrevemos
$$
\Proofm {
\I0-------------- {}
    {0 \is \Nat}
}
$$
e entendemos isso como
$$
\text{<<(do nada) posso concluir que $0$ é um $\Nat$>>}.
$$
Esse ``do nada'' aqui quis dizer ``sem nenhuma premissa''.
Vamos dar o nome \rule{Zero}\ para essa \emph{regra de inferência},
pois vamos precisar referir a ela depois.
Escrevemos seu nome no lado direito da linha de inferência.
Fica assim:
$$
\Proofm {
\I0-------------- {Zero}
    {0 \is \Nat}
}
$$
Olhando pra isso entendemos o seguinte:
a regra \rule{Zero}\ nos permite inferir que $0$ é um $\Nat$.
%%}}}

\question.
Como tu representaria a segunda regra da~\ref{Nat} como uma regra
de inferência?
\spoiler.

%%{{{ with inference rules 
\note Com regras de inferência.
$$
\xalignat2
&
\Proofm {
\I0----------- {Zero}
{0 \is \Nat}
}
&&
\Proofm {
\A  {n \is \Nat}
\I1-------------- {Succ}
   {Sn \is \Nat}
}
\endxalignat
$$
%%}}}

%%{{{ x: spot meta vs object on the definitions above 
\exercise.
Identifique variáveis \vs metavariáveis e símbolos da
linguagem-objeto \vs da metalinguagem nas definições acima.

\endexercise
%%}}}

%%{{{ eg: SSSS0 is a nat (inference tree) 
\example (usando árvores).
Vamos inferir que $SSSS0$ é um $\Nat$ mesmo.

\solution
Vamos construir sua árvore ``bottom-up''.
O desafio é inferir que
$$
SSSS0 \is \Nat
$$
e usando a regra \rule{Succ}\ podemos \emph{reduzir} esse problema para
$$
\Proofm {
\A  {SSS0 \is \Nat}
\I1------------------ {Succ}
    {SSSS0 \is \Nat}
}
$$
Essa árvore tem afirmações ``abertas'' então não terminamos ainda.
Usando a mesma regra reduzimos o $SSS0 \is \Nat$ para:
$$
\Proofm {
\A {SS0 \is \Nat}
\I1---------------- {Succ}
   {SSS0 \is \Nat}
\I1----------------- {Succ}
   {SSSS0 \is \Nat}
}
$$
e continuando nessa maneira, chegamos finalmente no
$0 \is \Nat$ que inferimos com a regra \rule{Zero},
fechando assim a única coisa que tava aberta:
$$
\Proofm {
\I0------------ {Zero}
   {0 \is \Nat}
\I1------------- {Succ}
   {S0 \is \Nat}
\I1-------------- {Succ}
   {SS0 \is \Nat}
\I1--------------- {Succ}
   {SSS0 \is \Nat}
\I1---------------- {Succ}
   {SSSS0 \is \Nat}
}
$$
\endexample
%%}}}

%%{{{ x: read the tree bottom-up and top-down 
\exercise.
Leia essa árvore tanto de baixo pra cima, quanto de cima pra baixo!

\endexercise
%%}}}

%%{{{ eg: SSSS0 is a nat (grammar) 
\example (usando a gramática).
Vamos inferir que $SSSS0 \is \Nat$ de novo, essa vez usando
a definição com a gramática.

\solution
Temos:
$$
\align
\bnf{Nat}
&\leadsto S\bnf{Nat} \\
&\leadsto SS\bnf{Nat} \\
&\leadsto SSS\bnf{Nat} \\
&\leadsto SSSS\bnf{Nat} \\
&\leadsto SSSS0.
\endalign
$$
\endexample
%%}}}

%%{{{ Using words 
\note Usando palavras.
Podemos inferir que $SSSS0 \is \Nat$ usando palavras tambem, ficando assim
mais perto da~\ref{Nat}, mas para esse tipo de derivação fica bizarro:
\quote
<<Como $0$ é um Nat (pela primeira cláusula),
logo $S0$ é um Nat (pela segunda com $n\asseq 0$).
Logo $SS0$ é um Nat, de novo pela segunda cláusula, essa vez com $n\asseq S0$\dots>>
\endquote
E já cansei de escrever então vou parar aqui.
Espero que apreciamos a laconicidade e clareza das árvores
para esse tipo de inferência.
%%}}}

%%{{{ eg: 0,1,2,3 ; primes 
\example.
Aqui os numerais de $\Nat$ que correspondem nos primeiros
quatro números naturais:
$$
0,\quad
S0,\quad
SS0,\quad
SSS0.
$$
Escrevemos a seqüência de primos então assim:
$$
SS0,\quad
SSS0,\quad
SSSSS0,\quad
SSSSSSS0,\quad
SSSSSSSSSSS0,\quad\dots
$$
Ou seja, cada número natural $n$ corresponde numa seqüência
de $n$ cópias de $S$, seguidas por um $0$.
\endexample
%%}}}

%%{{{ remark: unary numeral system 
\remark.
Esse sistema de numerais é praticamente um sistema unário.
A grande \emph{desvantagem} dele é que o tamanho dos numeráis cresce
analogamente com o tamanho de números.
Comparando com os sistemas mais comuns com bases $b > 1$ como o binário
ou o decimal, já parece deficiente nesse sentido.
Mas uma \emph{vantagem} para a gente nesse caso é sua simplicidade
na sua definição recursiva:
\emph{cada $\Nat$ ou é o zero, ou o sucessor de um $\Nat$}.
Todo esse capítulo é desenvolvido usando apenas essa definição.
%%}}}

%%{{{ canonic_nats 
\definition Os Nats canônicos.
\label{canonic_nats}%
\tdefined{canônico}%
Chamamos os termos da linguagem $\bnf{Nat}$ os Nats \dterm{canônicos:}
$$
0, S0, SS0, SSS0, SSSS0, \dotsc
$$
%%}}}

%%{{{ operator_vs_constructor 
\note Operador \vs construtor.
\tdefined{construtor}%
Logo vamos definir operações nos Nats ($+$, $\ntimes$, etc.)
e vamos ter, por exemplo, que
$$
S(SS0 + (SSS0 \ntimes SS0)) \is \Nat
$$
também, mas obviamente faz sentido perguntar
\quote
<<Quanto é $S(SS0 + (SSS0 \ntimes SS0))$?>>
\endquote
e a resposta deve ser $SSSSSSSSS0$.
Mas não faz sentido perguntar
\quote
<<Quanto é $SS0$?>>
\endquote
Ou seja: esse $S$ (quem vem da palavra ``sucessor'') não representa
um operador que deve ser aplicado num argumento e que vai retornar um
resultado com valor.  Não!  Esse $S$ é o que chamamos de \dterm{construtor}
de valores, ou seja, o $SS0$ já é um valor próprio, um valor final,
um valor canônico: sem nada mais para ser calculado.
Por o mesmo motivo não faz sentido perguntar
\quote
<<Quanto é $2$?>>
\endquote
$2$ é $2$ ué.
%%}}}

%%{{{ property: Equality 
\property Igualdade.
Naturalmente consideramos todos os valores canônicos como distintos,
ou seja, para todos os $x,y\is\Nat$ temos:
$$
\align
& 0 \neq Sx \\
x \neq y &\implies Sx \neq Sy
\intertext{freqüentemente usada na forma da sua contrapositiva:}
Sx = Sy &\implies x = y.
\endalign
$$
que nos permite ``cortar os $S$'s'' numa igualdade entre sucessores.
%%}}}

%%{{{ Syntactic sugar 
\note Açúcar sintáctico.
Eu vou usar os
$$
0, 1, 2, 3, \dotsc
$$
como outros nomes dos Nats
$$
0, S0, SS0, SSS0, \dotsc
$$
ou seja, como açúcar sintáctico.
Mas é importante entender que são apenas isso, um nóme alternativo
para os termos ``verdadeiros''; então quando eu peço para calcular,
por exemplo, o $3\ntimes 2$, tu precisas calcular mesmo o
$$
SSS0 \ntimes SS0.
$$
E espero que tu chegarás no resultado que eu chamaria de $6$,
ou seja, no $SSSSSS0$.
%%}}}

\endsection
%%}}}

%%{{{ Defining functions recursively 
\section Definindo funções recursivamente.

%%{{{ df: nats_plus_recursive_def 
\definition Adição.
Definimos a operação $+$ no $\Nat$ pelas:
$$
\align
n + 0   &= n      \tag{a1}\\
n + S m &= S(n+m) \tag{a2}
\endalign
$$
%%}}}

%%{{{ eg: three_plus_two_formally 
\example.
\label{three_plus_two_formally}%
Calcule a soma $SSS0 + SS0$.

\solution
Temos a expressão
$$
SSS0 + SS0.
$$
Qual equação aplica?
Com certeza não podemos aplicar a primeira (na direção ``$\Rightarrow$''),
pois nossa expressão não tem a forma $n + 0$.
Por que não?  O primeiro termo na nossa expressão, o $SSS0$, não é um problema
pois ele pode ``casar'' com o $n$ do lado esquerdo da (a1).
Mas nosso segundo termo, o $SS0$,
não pode casar com o $0$, então a (a1) não é aplicável.
A segunda equação é sim, pois nossos termos podem casar assim
com as variáveis da (a2):
$$
\alignat2
{\munderbrace{SSS0}n} + {S\munderbrace{S0}m}\\
\intertext{Tomando $n\asseq SSS0$ e $m\asseq S0$ substituimos nossa expressão por seu
igual seguindo a (a2):}
{\munderbrace{SSS0}n} + {S\munderbrace{S0}m}
&= S\bigparen{ {\munderbrace{SSS0}n} + {\munderbrace{S0}m} }  \by {por (a2)}
\intertext{Depois um passo de cálculo então chegamos na expressão
$S(SSS0 + S0)$.
Como nenhuma equação tem a forma $S(\text{\thole}) = \text{\lthole}$,
olhamos ``dentro'' da nossa expressão para achar nas suas subexpressões
possíveis ``casamentos'' com nossas equações.
Focamos então na subexpressão sublinhada
$S(\underline{SSS0 + S0})$:
vamos tentar substituí-la por algo igual.
Novamente a primeira equação não é aplicavel
por causa do novo segundo termo ($S0$), mas a (a2) é:}
S\bigparen{{\munderbrace{SSS0}n} + {S\munderbrace{0}m}}\\
\intertext{Tomando agora $n\asseq SSS0$ e $m\asseq 0$ substituimos de novo
seguindo a (a2):}
S\toverbrace{\bigparen{{\munderbrace{SSS0}n} + {S\munderbrace{0}m}}}{isso}
&= S\toverbrace{S\bigparen{ {\munderbrace{SSS0}n} + {\munderbrace{0}m} }}{por isso}  \by {por (a2)}
\intertext{Agora focamos na subexpressão $SS(\underline{SSS0 + 0})$ e podemos finalmente
aplicar a primeira equação:}
SS\bigparen{{\munderbrace{SSS0}n} + 0}\\
\intertext{então tomando $n\asseq SSS0$ substituimos}
SS\toverbrace{\bigparen{{\munderbrace{SSS0}n} + 0}}{isso}
&= SS\toverbrace{ {\munderbrace{SSS0}n} }{por isso}  \by {por (a1)}
\endalignat
$$
Finalmente chegamos no resultado: no termo $SSSSS0$.
Nunca mais vamos escrever tudo isso com tanto detalhe!
Esse cálculo que acabamos de fazer, escrevemos curtamente nessa forma:
\compute
SSS0 + SS0
&= S(SSS0 + S0) \by {por (a2)}
&= SS(SSS0 + 0) \by {por (a2)}
&= SSSSS0       \by {por (a1)}
\endcompute
escrevendo apenas em cada linha o que foi usado.

\endexample
%%}}}

%%{{{ When do I stop? 
\note Quando termino?.
Termino quando chegar num \emph{valor canônico}.
Quando eu peço calcular quanto é $SSS0 + SS0$ por exemplo,
a idéia é achar seu valor canônico, exatamente como acontece
quando pedimos para uma pessoa achar
\quote
<<Quanto é $2+3$?>>
\endquote
Uma resposta
\quote
<<$2+3=2+3$>>
\endquote
não seria aceitável---mesmo assim, é correta, não é?---pois
a pessoa que perguntamos não achou o valor canόnico (nesse caso $5$).
%%}}}

%%{{{ Is it always possible to terminate? 
\note Dá pra terminar sempre?.
Sempre tem como chegar num valor canônico?
Por enquanto não sabemos!
Realmente a $+$ na maneira que foi definida é uma operação
\dterm{total}, ou seja, sempre termina num valor canônico,
mas não é algo que deve se preocupar neste momento.
Estudamos muito esse assunto no~\ref{Theory_of_recursive_functions}.
%%}}}

%%{{{ x: zero_plus_four_formally 
\exercise.
\label{zero_plus_four_formally}%
Calcule a soma dos $0 + SSSS0$.

\endexercise
%%}}}

%%{{{ Evaluation strategy 
\note Estratégias de evaluação.
\tdefined{estratégia}[de evaluação]%
Vamos dizer que queremos calcular começando com uma expressão mais complexa,
como por exemplo a
$$
0 + \bigparen{0 + S\bigparen{(SS0 + 0) + 0}}.
$$
Como procedimos?
A expressão inteira não pode ser substituida pois nenhuma das (a1)--(a2) tem
essa forma, mas aparecem várias subexpressões em quais podemos \emph{focar}
para nosso próximo passo de cálculo:
$$
\align
0 + \underline{\bigparen{0 + S\bigparen{(SS0 + 0) + 0}}},&\quad\text{casando com (a2)}\\
0 + \bigparen{0 + S\underline{\bigparen{(SS0 + 0) + 0}}},&\quad\text{casando com (a1)}\\
0 + \bigparen{0 + S\bigparen{\underline{(SS0 + 0)} + 0}},&\quad\text{casando com (a1)}.
\endalign
$$
Podemos seguir uma \dterm{estratégia de evaluação} específica, por exemplo,
focando sempre na expressão que aparece primeira à esquerda; ou podemos
escolher cada vez onde focar aleatoriamente; etc.
No~\ref{three_plus_two_plus_one} tu vai ter que escolher onde focar
várias vezes.
%%}}}

%%{{{ x: three_plus_two_plus_one 
\exercise.
\label{three_plus_two_plus_one}%
Calcule os valor das expressões $SSS0 + (SS0 + S0)$ e $(SSS0 + SS0) + S0$.

\solution
Um caminho para calcular a primeira é o seguinte:
\compute
SSS0 + \underline{(SS0 + S0)}
&= SSS0 + S\underline{(SS0 + 0)} \by {por (a2)}
&= \underline{SSS0 + SSS0}       \by {por (a1)}
&= S\underline{(SSS0 + SS0)}     \by {por (a2)}
&= SS\underline{(SSS0 + S0)}     \by {por (a2)}
&= SSS\underline{(SSS0 + 0)}     \by {por (a2)}
&= SSSSSS0                       \by {por (a1)}
\intertext{e um caminho para calcular a segunda é o:}
\underline{(SSS0 + SS0) + S0}
&= S(\underline{(SSS0 + SS0)} + 0)  \by {por (a2)}
&= S(S\underline{(SSS0 + S0)} + 0)  \by {por (a2)}
&= S\underline{(SS(SSS0 + 0) + 0)}  \by {por (a2)}
&= SSS\underline{(SSS0 + 0)}        \by {por (a1)}
&= SSSSSS0                          \by {por (a1)}
\endcompute

\endexercise
%%}}}

%%{{{ Where is the recursion and what don't we have a tijolo problem? 
\note Cadê a recursão e por quê não temos problema tipo tijolo?.
Estamos definindo a própria operação $+$, e na segunda linha
da sua definição aparece o $+$ tanto no lado esquerdo, quanto no lado direito.
Por isso chamamos a definição recursiva.
Se definimos $+$ em termos dele mesmo, por que não temos o problema
tipo \emph{tijolo} que discutimos no \ref{what_is_tijolo}?
(Chegou a hora que tinha prometido no~\refn{recursive_definitions_teaser}.)
Olhando com mais atenção, percebemos que não definimos o que significa
\emph{somar} em termos do que significa \emph{somar} mesmo;
mas definimos sim o que significa \emph{somar os números $n$ e $Sm$}
em termos do que significa \emph{somar os números $n$ e $m$}.
No lado direito, uma coisa nos argumentos da nossa operação está
diminuindo (os $S$'s do segundo argumento) assim evitando o loop
infinito, chegando finalmente na primeira equação \emph{depois duma
quantidade finita} de perguntas <<e o que é\dots?>>.
%%}}}

%%{{{ x: nats_double_def 
\exercise.
\label{nats_double_def}%
Defina (recursivamente) a função $d : \Nat \to \Nat$ que dobra sua entrada.
Verifique que o dobro de três ($SSS0$) é seis ($SSSSSS0$).

\hint
Pensando fora do $\Nat$:
como podemos calcular o valor de $2(n+1)$, se sabemos como dobrar
qualquer número menor de $n+1$?

\hint
$2(n+1) = 2n + 2$.

\solution
Definimos:
$$
\align
d( 0 )  &= 0        \tag{D1}\\
d( Sn ) &= SSd(n).  \tag{D2}
\endalign
$$
Calculamos:
\compute
d( SSS0 )
&= SSd(SS0)    \by {por (D2)}
&= SSSSd(S0)   \by {por (D2)}
&= SSSSSSd(0)  \by {por (D2)}
&= SSSSSS0.    \by {por (D1)}
\endcompute

\endexercise
%%}}}

%%{{{ A worse programmer 
\note Um programador pior.
Alguém definiu a adição usando essas quatro equações:
$$
\align
0  + 0  &= 0  \\
Sn + 0  &= Sn \\
0  + Sm &= Sm \\
Sn + Sm &= S(Sn + m)
\endalign
$$
Ou seja, para cada argumento da operação, ele tratou os dois
casos principais separadamente, resultando assim em quatro
equações.
Mas, olhando nas primeiras duas, dá pra ver que ambás são
casos especiais da nossa primeira equação.
No final das contas, nas duas o que acontece é que o primeiro
argumento acaba sendo o resultado da soma, e é exatamente isso
que nossa primeira equação disse.
Nossa definição é bem melhor então, mais elegante e econômica.
%%}}}

%%{{{ x: nats_ntimes_recursive_def 
\exercise.
\label{nats_ntimes_recursive_def}%
Defina a multiplicação no $\nats$.

\hint
Precisa de novo duas equações:
$$
\align
n \ntimes 0  &= \text{\lthole}\\
n \ntimes Sm &= \text{\lthole}
\endalign
$$

\hint
A primeira equação é fácil completar:
$$
\align
n \ntimes 0   &= 0
\intertext{talvez ajuda pensar numa outra equação mais simples:}
n \ntimes S0  &= \text{\lthole}
\endalign
$$
Depois?

\hint
Tu tens acesso na operação \sq{$+$} pois já definimos!

\hint
Provavelmente até agora tens:
$$
\align
n \ntimes 0    &= 0 \\
n \ntimes S0   &= n \\
n \ntimes SS0  &= n + n \\
n \ntimes SSS0 &= (n + n) + n \\
               &\eqvdots
\intertext{Observe que o ``valor'' (lado direito) de cada nova linha é o valor
da linha anterior ``$+n$''.  Mas temos um nome para o lado direito da linha
anterior: \emph{seu lado esquerdo!}
Isso deve ser suficiente para achar como escrever a segunda linha da definição:}
n \ntimes 0  &= \text{\lthole}\\
n \ntimes Sm &= \text{\lthole}
\endalign
$$

\hint
Na segunda equação, no seu lado direito, tu tens acesso no valor
$n \ntimes m$, pois é ``mais simples'' do que o $n \ntimes Sm$.
Isso é o poder da recursão: podes considerar o problema que tu
tá tentando resolver (definir a multplicação), como resolvido
para as ``entradas mais simples''.

\solution
$$
\align
n \ntimes 0  &= 0                 \tag{m1}\\
n \ntimes Sm &= (n\ntimes m) + n  \tag{m2}
\endalign
$$

\endexercise
%%}}}

%%{{{ x: two_times_zero_plus_one 
\exercise.
\label{two_times_zero_plus_one}%
Calcule o $2(0+1)$.

\endexercise
%%}}}

%%{{{ x: two_times_three_and_three_times_two 
\exercise.
\label{two_times_zero_plus_one}%
Calcule os $2 \ntimes 3$ e $3 \ntimes 2$.

\endexercise
%%}}}

%%{{{ x: nats_exp_recursive_def 
\exercise.
\label{nats_exp_recursive_def}%
Defina a exponenciação no $\nats$.

\endexercise
%%}}}

%%{{{ x: two_times_zero_plus_one 
\exercise.
\label{two_times_zero_plus_one}%
Calcule o $2^3$.

\endexercise
%%}}}

%%{{{ x: fibonacci_nats 
\exercise.
\label{fibonacci_nats}%
Defina usando equações recursivas a \dterm{seqüência Fibonacci},
como uma função de $\Nat$ para $\Nat$.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Proving properties of natural numbers without induction 
\section Provando propriedades de naturais sem indução.
\label{Proving_properties_of_nats_by_induction}%

%%{{{ convention about quantifiers 
\note Convenção.
Nessa secção todos os quantificadores que aparecem ``nus'' em fórmulas
\emph{quantificam sobre os naturais}.  Por exemplo
$$
\forall x
\forall y
\exists z
\forall w
P(x,y,z,w)
$$
significa
$$
\pforall {x \in \nats}
\pforall {y \in \nats}
\pexists {z \in \nats}
\lforall {w \in \nats}
{P(x,y,z,w)}.
$$
%%}}}

\blah.
Vamos primeiramente \emph{definir} recursivamente as tres operações de adição,
multiplicação, e exponenciação:

%%{{{ df: natops_rec_defs 
\definition.
\label{natops_rec_defs}%
Definimos as operações de adição, multiplicação, e exponenciação
recursivamente assim:
$$
\xxalignat3
&
\alignedat2
\text{(a1)}&\quad&  n + 0  &= n     \\
\text{(a2)}&&       n + Sm &= S(n+m)
\endalignedat
&&
\alignedat2
\text{(m1)}&\quad&  n \ntimes 0  &= 0   \\
\text{(m2)}&&       n \ntimes Sm &= (n \ntimes m) + n
\endalignedat
&&
\alignedat2
\text{(e1)}&\quad&  n \expop 0  &= S0   \\
\text{(e2)}&&       n \expop Sm &= (n \expop m) \ntimes n.
\endalignedat
\endxxalignat
$$
Observe que cada uma dessas equações tem um implícito
$\forall n$ ou $\forall n\forall m$ na frente dela.
%%}}}

%%{{{ conventions about precedence and associativity 
\note Convenções.
Seguindo a convenção comum, escrevemos o $x\expop y$ como $x^y$,
mas mesmo assim consideramos isso como um açúcar sintáctico para
a expressão $x \expop y$.  Entendemos então que no $x^y$ temos
uma aplicação duma operação binária (aplicada nos argumentos $x$ e $y$).
Vamos seguir também a convenção que a exponenciação
``pega mais forte'' que as outras duas operações,
e que multiplicação pega mais forte que a adição:
$a \ntimes b^c$ escrito sem parênteses quis dizer
$a \ntimes (b \expop c)$ e não $(a \ntimes b) \expop c$;
e $a + b\ntimes c$ quis dizer $a + (b\ntimes c)$.
Graças às associatividades das $+$ e $\ntimes$
(\ref{natadd_is_associative} e~\ref{natmult_is_associative})
podemos escrever $a + b + c$ e $a \ntimes b \ntimes c$,
mas para a exponenciação que não é associativa escolhemos
a associatividade-direita: $a^{b^c}$ é $a \expop (b \expop c)$
e não $(a \expop b) \expop c$.
%%}}}

%%{{{ + is associative 
\proposition.
A $+$ é associativa.
%%}}}

%%{{{ natadd_is_associative_failed_proof_attempt 
\note Tentativa de demonstração.
\label{natadd_is_associative_failed_proof_attempt}%
Vamos tentar provar essa proposição.
Primeiramente, o que a afirmação significa?
A adição é essa operação $+$ que definimos na~\ref{natops_rec_defs}.
Vamos tentar escrever essa afirmação numa maneira mais formal
para expor sua estrutura lógica:
$$
\forall n \forall m \forall k
\bigparen{ (n+m) + k = n + (m+k) }.
$$
Nosso alvo tem a forma
$$
\lforall {x\in\nats} {\phi(x)}
$$
olhando como
$$
\forall n
\munderbrace {
\alertb{\forall m \forall k \bigparen{ (n+m) + k = n + (m+k) }}
} {\alertb{\phi_1(n)}}
$$
podemos atacá-la tomando um arbitrario membro de $\Nat$ e mostrando
que ele goza a propriedade $\phi$.
\endgraf
Seja $a \in \Nat$ então.
Agora precisamos mostrar que $\phi(a)$, ou seja nosso alvo é
$$
\forall m \forall k
\bigparen{ (n+m) + k = n + (m+k) }.
$$
Observe que nosso álvo é apenas uma afirmação sobre o natural $k$.
Beleza.
Mas nosso alvo tem a mesma forma,
$$
\munderbrace{
\forall m
\munderbrace{
\alertb{
\forall k
\bigparen{ (a+m) + k = a + (m+k) }
}} {\alertb{\phi_2(m)}}
} {\phi_1(a)}
$$
então podemos atacar novamente
coma mesma idéia, ``sejando'' mais um natural.
\endgraf
Seja $m\in\Nat$.
Preciso provar que
$$
\munderbrace{
\forall k
\munderbrace{
\alertb{
(a+m) + k = a + (m+k)
}} {\alertb{\phi_3(k)}}
} {\phi_2(m)}.
$$
Atacamos uma última vez com a mesma estratégia:
\endgraf
Seja $y\in\Nat$.
Agora precisamos provar
$$
\munderbrace{
(a+m) + y = a + (m+y)
} {\phi_3(y)}.
$$
E agora?
Como chegamos numa igualdade, precisamos verificar que seus dois lados
realmente denotam o mesmo valor.
Vamos calcular então.
Tomando o lado esquerdo, $(a+m)+y$, tantamos casá-lo com as equações
(a1)--(a2), mas ele não casa com nenhuma delas, então não tem como
simplificá-lo.%
\footnote{Isso não é exatamente verdade, pois o lado direito
da (a1), sendo apenas uma variável, casa com qualquer coisa.
Mas escolhendo qualquer (sub)expressão da $(a+m)+y$, para casar
com $n$, não vamos ter progresso nenhum, pois vamos acabar
adicionando apenas uns ``$+0$'' até cansar, sem nenhuma
mudança na posição das parenteses que nos importam aqui.}
%%}}}

%%{{{ Q: Seems like a dead end---or is it? 
\question.
\label{not_a_dead_end_without_induction}%
Parece que chegamos num ``dead end''.
Tem como continuar?
%%}}}
\spoiler.

%%{{{ A: case split 
\blah Resposta.
Tem!
O problema foi que não sabemos nem sobre o $m$ nem sobre o $y$
se são da forma $0$ ou da forma $S\bnf{Nat}$ e por isso não conseguimos
aplicar nenhuma das (a1)--(a2).
Mas podemos \emph{separar em casos}.
Vamos escolher um desses Nats então, o $y$, e considerar:
\beginul
\li \case{Caso} $y$ é o $0$: \dots
\li \case{Caso} $y$ é o successor de algum Nat: \dots
\endul
Lembre-se que cada vez que separamos em casos, nosso alvo
tá sendo \emph{copiado e colado} para cada um deles.
%%}}}

%%{{{ x: solve_the_zero_case_of_case_split_of_natadd_is_associative 
\exercise O primeiro caso.
\label{solve_the_zero_case_of_case_split_of_natadd_is_associative}%
Prove que
$$
(a+m) + y = a + (m+y)
$$
no primeiro caso.

\hint
Pega um lado e calcule até chegar no outro;
ou se não conseguir chegar no outro lado,
trabalhe no outro lado separadamente até
chegar no mesmo.

\hint
Calculamos:
\compute
(a + m) + y
&= (a + m) + 0 \by {hipótese do caso}
&= \dots?
\endcompute

\hint
\compute
(a + m) + y
&= (a + m) + 0 \by {hipótese do caso}
&= a + m       \by {pela~(a1)}
\intertext{Se travou aqui, sem problema:
trabalhe no outro lado até chegar em $a + m$:}
a + (m + y) &= \dots? \\
&\eqvdots\\
&= a + m
\endcompute

\solution
Calculamos:
\compute
(a + m) + y
&= (a + m) + 0 \by {hipótese do caso}
&= a + m       \by {pela~(a1)}
a + (m + y)
&= a + (m + 0) \by {hipótese do caso}
&= a + m       \by {pela~(a1)}
\endcompute

\endexercise
%%}}}

%%{{{ The second case 
\note O segundo caso.
Sabemos que $y$ é o sucessor de algum natural,
então vamos escolher um nome pra denotá-lo:
\emph{seja $y'$ natural tal que $y = Sy'$}\fact1.
Calculamos:
\compute
(a + m) + y
&= (a + m) + Sy'       \by {hipótese~\byfact1}
&= S\paren{(a+m) + y'} \by {(a2), com $n\asseq (a+m)$, $m\asseq y'$}
\intertext{e o outro lado}
a + (m + y)
&= a + (m + Sy')   \by {hipótese~\byfact1}
&= a + S(m + y')   \by {(a2) com $n\asseq m$, $m\asseq y'$}
&= S(a + (m + y')) \by {(a2) com $n\asseq a$, $m\asseq m+y'$}
\endcompute
E agora peguntamos
$$
S\paren{(a+m) + y'}
\askeq
S(a + (m + y'))
$$
e para resolver isso basta ``cortar os $S$'s'' e provar que
$$
(a+m) + y' = a + (m + y').
$$
\emph{E estamos onde estavamos!}
Só com $a,m,y'$ em vez de $a,m,y$.  E daí?
Podemos separar esse caso em dois subcasos:
\beginul
\li \case{Caso $y'$} é o $0$: \dots
\li \case{Caso $y'=Sy''$} para algum $y''\in\Nat$: \dots
\endul
O primeiro subcaso vamos conseguir matar, pois é igual ao
primeiro caso.  Mas a melhor coisa que conseguimos no segundo
caso seria chegar ate o alvo
$$
(a + m) + y'' \askeq a + (m+y'').
$$
E depois?  Considerar dois casos novamente?
Não importa quantas vezes repetir essa idéia, a gente
sempre cai conseguir matar apenas um dos sub-(sub-sub-\dots)-casos,
e chegar num
$$
(a + m) + y^{\prime\prime\cdots\prime}
\askeq
a + (m + y^{\prime\prime\cdots\prime}).
$$
Obviamente precisamos uma outra técnica para provar esse teorema.
%%}}}

\endsection
%%}}}

%%{{{ Induction 
\section Indução.
\label{Induction}%

%%{{{ Induction scheme 
\note Schema da indução.
Suponha que $\phi(x)$ é uma afirmação que depende num $x\in\nats$.
Em forma de regra de inferência, o princípio da indução é o seguinte:
$$
\Proofm {
\A {\phi(0)}
\A                    {\lforall k {\phi(k)\implies \phi(Sk)}}
\I2------------------------------------------------------------ {Ind$_\phi$}
            {\lforall n {\phi(n)}}
}
$$
%%}}}

%%{{{ induction_as_a_new_attack 
\note Novo ataque.
\label{induction_as_a_new_attack}%
Para usar então a indução, precisamos ter algo dessa forma:
\def\SIZEFIX{\hphantom{\coloredcancel{red}{\lforall {k \in \nats} {\phi(k) \implies \phi(Sk)}}}}%
\proofrepl
\givens
\goals
\gim {\lforall {n \in \ints} {\phi(n)}}
\gim {\SIZEFIX}
\endproofrepl
\proofrepl
\alert{Indução no $n$.}\cr
\givens
\goals
\gim {\coloredcancel{red}{\lforall {n \in \nats} {\phi(n)}}}
\gim {\alert{\phi(0)}}
\gim {\alert{\lforall {k \in \nats} {\phi(k) \implies \phi(Sk)}}}
\gim {\SIZEFIX}
\endproofrepl
\proofrepl
Indução no $n$.\cr
\alert{\proofpart{Base.}}\cr
\qquad \alert{$\vdots$}\cr
\qquad \alert{(prova de $\phi(0)$)}\cr
\givens
\gim {\alert{\phi(0)}}
\goals
\gim {\faded{\lforall {n \in \nats} {\phi(n)}}}
\gim {\coloredcancel{red}{\phi(0)}}
\gim {\lforall {k \in \nats} {\phi(k) \implies \phi(Sk)}}
\gim {\SIZEFIX}
\endproofrepl
\proofrepl
Indução no $n$.\cr
\proofpart{Base.}\cr
\qquad $\vdots$\cr
\qquad (prova de $\phi(0)$)\cr
\alert{\proofpart{Passo indutivo.}}\cr
\qquad \alert{Seja $k\in\nats$}\cr
\givens
\gim {\phi(0)}
\gim {\alert{k\in\nats}}
\goals
\gim {\faded{\lforall {n \in \nats} {\phi(n)}}}
\gim {\coloredcancel{black}{\phi(0)}}
\gim {\coloredcancel{red}{\lforall {k \in \nats} {\phi(k) \implies \phi(Sk)}}}
\gim {\alert{\phi(k) \implies \phi(Sk)}}
\gim {\SIZEFIX}
\endproofrepl
\proofrepl
Indução no $n$.\cr
\proofpart{Base.}\cr
\qquad $\vdots$\cr
\qquad (prova de $\phi(0)$)\cr
\proofpart{Passo indutivo.}\cr
\qquad Seja $k\in\nats$ \alert{tal que $\phi(k)$ (H.I.).}\cr
\givens
\gim {\phi(0)}
\gim {k\in\nats}
\gim {\alert{\phi(k)}}
\goals
\gim {\faded{\lforall {n \in \nats} {\phi(n)}}}
\gim {\coloredcancel{black}{\phi(0)}}
\gim {\faded{\lforall {k \in \nats} {\phi(k) \implies \phi(Sk)}}}
\gim {\coloredcancel{red}{\phi(k) \implies \phi(Sk)}}
\gim {\alert{\phi(Sk)}}
\gim {\SIZEFIX}
\endproofrepl
\proofrepl
Indução no $n$.\cr
\proofpart{Base.}\cr
\qquad $\vdots$\cr
\qquad (prova de $\phi(0)$).\cr
\proofpart{Passo indutivo.}\cr
\qquad Seja $k\in\nats$ tal que $\phi(k)$ (H.I.).\cr
\qquad \alert{$\vdots$}\cr
\qquad \alert{(prova de $\phi(Sk)$)\quad$\qedsymbol$}\cr
\givens
\gim {\phi(0)}
\gim {k\in\nats}
\gim {\phi(k)}
\goals
\gim {\faded{\lforall {n \in \nats} {\phi(n)}}}
\gim {\coloredcancel{black}{\phi(0)}}
\gim {\faded{\lforall {k \in \nats} {\phi(k) \implies \phi(Sk)}}}
\gim {\faded{\phi(k) \implies \phi(Sk)}}
\gim {\coloredcancel{red}{\phi(Sk)}}
\gim {\SIZEFIX}
\endproofrepl
%%}}}

%%{{{ remark: nothing special about induction once performed 
\remark.
Observe que no momento que escrevemos
\quote
<<Seja $k \in \nats$ tal que $\phi(k)$ (H.I.).>>
\endquote
no~\refn{induction_as_a_new_attack}
não fizemos nada especial relacionado a indução!
Isso é o ``ataque padrão'' duma fórmula da forma
$$
\lforall {x \in A} {\phi(x) \implies \psi(x)}
$$
onde juntamos os passos de atacar o \sq{$\forall$} e o \sq{$\impliessymbol$}
numa frase só.
Em geral, podes considerar a indução como um ``feitíço'' que
quando usado transforma um alvo da forma
$$
\lforall {x \in \nats} {\phi(x)}
$$
para \emph{dois} novos alvos (com nomes chique):
$$
\align
\text{\proofpart{Base}:}\quad           & \phi(0) \\
\text{\proofpart{Passo indutivo}:}\quad & \lforall {k\in\nats} {\phi(k) \implies \phi(Sk)}
\endalign
$$
Fora disso, \emph{não tem nada mais mágico} que acontece:
o feitiço já foi feito e seu efeito já aconteceu.
E depois?
Depois \emph{continuamos normalmente para matar esses dois alvos}.
%%}}}

%%{{{ remark: induction_on_a_variable? 
\remark Indução numa variável?.
No~\ref{induction_as_a_new_attack} escrevemos <<Indução no $n$>>.
Como assim ``no $n$''?  Quem é esse $n$?
Não tem $n$ no nosso escopo!
Sim, realmente não faz sentido no pé da letra essa frase,
mas ajudamos nosso leitor entender qual quantificador estamos atacando
do nosso alvo, caso que aparecem mais que um.
Talvez ficaria (pouco) mais correto escrever
<<Indução no $\forall n$.>>
(No final das contas, é o quantificador que estamos atacando.)
De qualquer forma, isso é apenas um ``modo de falar'', e presuponha
que nosso leitor tem acesso no nome da variável ligada que escolhemos
quando escrevemos nosso alvo.  (Muitas vezes isso faz parte do enunciado.)
%%}}}

\endsection
%%}}}

%%{{{ Proving properties with induction 
\section Provando propriedades de naturais com indução.

%%{{{ thm: natadd_is_associative 
\theorem Associatividade da adição.
\label{natadd_is_associative}%
A operação $+$ da~\ref{natops_rec_defs} é associativa:
$$
\forall n
\forall m
\forall k
\bigparen{ n + (m + k) = (n + m) + k }.
$$
%%{{{ preproof 
\preproof.
Vamos demonstrar esse teorema duas vezes.
É importantíssimo entender a diferença e seguir todos os detalhes.
Antes de começar, lembre nossa tentativa~\refn{natadd_is_associative_failed_proof_attempt} e como e onde exatamente a gente travou:
\proofrepl
Seja $n$ natural.\cr
Seja $m$ natural.\cr
Seja $k$ natural.\cr
Separamos em casos:\cr
\proofpart{Caso $k=0$:}\cr
\quad(resolvido no~\ref{solve_the_zero_case_of_case_split_of_natadd_is_associative})\cr
\proofpart{Caso $k=Sk'$ para algum $k' \is \Nat$:}\cr
\quad(caimos num caminho infinito aqui)\cr
\givens
\gim {n \is \Nat}
\gim {m \is \Nat}
\gim {k \is \Nat}
\goals
\gim {n + (m + k) = (n + m) + k}
\endproofrepl
E como caimos num caminho de sempre separar em dois novos casos sem fim, percebemos que algo deu errado; queremos tentar nossa nova técnica, indução.
Neste momento na nossa prova, podemos atacar nosso alvo por indução?
Não!
Para atacar um alvo por indução ele precisa ter a forma
$$
\lforall {x \is \Nat} {\phi(x)}
$$
e nosso alvo não é um \sq{$\forall$} mas uma igualdade!
Vamos fazer uns ``undo'' então na nossa prova e voltar nesse momento:
\proofrepl
Seja $n$ natural.\cr
Seja $m$ natural.\cr
\strikeout{Seja $k$ natural.}\cr
\strikeout{Separamos em casos:}\cr
\givens
\gim {n \is \Nat}
\gim {m \is \Nat}
\goals
\gim {\sforall k \munderbrace {n + (m + k) = (n + m) + k} {\phi(k)}}
\endproofrepl
Agora sim!  Nosso alvo tem uma forma que casa com o padrão que precisamos para aplicar indução.
Bora ver essa demonstração primeiro então.
\endpreproof
%%}}}
%%{{{ First proof 
\proof Primeira demonstração.
Sejam $n, m$ naturais.
Vamos provar por indução no $k$ que
$$
\forall k
\munderbrace {n + (m + k) = (n + m) + k} {\phi(k)}.
$$
\proofpart {Base.}
Precisamos mostrar que
$$
n + (m + 0) = (n + m) + 0.
$$
Calculamos:
\compute
n + (m + 0)
&= n + m    \by {pela (a1) com $n \asseq m$}
(n + m) + 0
&= n + m    \by {pela (a1) com $n \asseq n + m$}
\endcompute
\proofpart {Passo indutivo.}
Precisamos mostrar que
$$
\forall t
\bigparen {
\munderbrace {n + (m + t) = (n + m) + t} {\phi(t)}
\implies
\munderbrace {n + (m + St) = (n + m) + St} {\phi(St)}
}
$$
Seja $w$ natural tal que
$$
n + (m + w) = (n + m) + w.  \tag{H.I.}
$$
Precisamos mostrar que
$$
n + (m + Sw) = (n + m) + Sw.  \tag{H.I.}
$$
Calculamos:
\compute
n + (m + Sw)
&= n + S(m + w)     \by {(a2): $n \asseq m$; $m \asseq w$}
&= S(n + (m + w))   \by {(a2): $n \asseq n$; $m \asseq m + w$}
(n + m) + Sw
&= S((n + m) + w)   \by {(a2): $n \asseq n + m$; $m \asseq w$}
\endcompute
Basta então mostrar que
$$
S(n + (m + w)) = S((n + m) + w)
$$
que realmente temos pela (H.I.).
\qed
%%}}}
%%{{{ preproof 
\preproof.
Precisamos discutir o que aconteceu.
Agora bora ver uma demonstração que também usa indução, mas numa maneira bem diferente:
Queremos provar a afirmação
$$
\forall n
\forall m
\sforall k
\psi(n,m,k)
$$
onde
$$
\psi(x,y,z) \abbrdefiff x + (y + z) = (x + y) + z.
$$
Talvez parece que ela não está no formato $\sforall n \phi(n)$
e que não podemos atacá-la diretamente com indução.
Mas, na verdade, reescrevendo como
$$
\forall n
\munderbrace {\forall m \sforall k \psi(n,m,k)} {\phi_1(n)}
$$
já percebemos que tem a forma certa.
Pela lógica podemos trocar a órdem de quantificadores consecutivos
\emph{do mesmo tipo}, então o que queremos provar é equivalente aos
$$
\xalignat3
\forall n & \munderbrace {\forall m \sforall k \psi(n,m,k)} {\phi_1(n)}; &
\forall m & \munderbrace {\forall n \sforall k \psi(n,m,k)} {\phi_2(m)}; &
\forall k & \munderbrace {\forall n \sforall m \psi(n,m,k)} {\phi_3(k)};
\endxalignat
$$
etc.~(tem ainda mais três opções que não escrevi),
onde em cada caso o $\phi_i$ tem uma definição diferente,
mas o $\psi$ tem sempre a mesma.
Escolhemos provar a
$$
\forall k \munderbrace {\forall n \sforall m \psi(n,m,k)} {\phi(k)}.
$$
por indução.
Vamos ver o que vai acontecer.
\endpreproof
%%}}}
%%{{{ Second proof 
\proof Segunda demonstração.
Por indução no $k$.
\crproofpart{Base.}
Precisamos provar que
$$
\munderbrace {\forall n \sforall m {n + (m + 0) = (n + m) + 0}} {\phi(0)}.
$$
Sejam $n,m$ naturais.
Calculamos os dois lados:
\compute
\underline{\paren{n+m} + 0} &= n + m \by {a1)}
n + \paren{\underline{m+0}} &= n + m \by {a1)}
\endcompute
Ou seja, a $\phi(0)$ realmente é verdade.
\crproofpart{Passo indutivo.}
Precisamos provar a afirmação:
$$
\forall t \bracket{\phi(t) \implies \phi(St)},
$$
ou seja,
$$
\forall t
\bigbracket{
\paren{\forall n\forall m \bracket{ (n + m) + t  = n + (m + t) }}
\implies
\paren{\forall u\forall v \bracket{ (u + v) + St = u + (v + St)}}
}
$$
onde escolhi nomes diferentes nas variáveis quantificadas apenas para
enfatizar que são realmente diferentes!
Bora provar isso então.
Seja $w$ natural tal que
$$
\forall n\forall m \bracket{ (n + m) + w = n + (m + w) }. \tag{H.I.}
$$
Preciso mostrar que:
$$
\forall u\forall v \bracket{ (u + v) + Sw = u + (v + Sw)}
$$
Sejam $u,v\in\nats$.
Calculamos:
\compute
\underline{(u + v) + Sw}
&= S(\underline{(u + v) + w})  \by {a2}
&= \underline{S(u + (v + w))}  \by {H.I., com $n := u$, $m := v$}
&= u + \underline{S(v + w)}    \by {(a2)$^{\leftarrow}$}
&= u + (v + Sw).               \by {(a2)$^{\leftarrow}$}
\endcompute
Isso termina nossa prova.
\qed
%%}}}
%%}}}

%%{{{ Q: How do we choose which forall to attack by induction? 
\question.
Acabamos de escolher para provar por indução no $k$.
Por que $k$?
Faz diferença ou não?
Como escolherias qual dos $\forall$ seria o melhor para atacar por indução?
%%}}}
\spoiler.

%%{{{ A: How to choose on which variable to induct 
\note Como escolher a variável da indução.
Como a definição da adição foi recursiva no segundo argumento
da função, vai nos ajudar se a indução é feita numa variável
que aparece mais como segundo argumento da adição do que como primeiro.
Aqui por exemplo, a $k$ aparece duas vezes como argumento da $+$,
e as duas vezes ela é o segundo argumento da $+$.  Perfeito.
O $n$ no outro lado aparece duas vezes como primeiro argumento,
e o $m$ uma como primeiro e uma como segundo.
%%}}}

%%{{{ thm: natadd_is_commutative 
\theorem Comutatividade da adição.
\label{natadd_is_commutative}%
A operação $+$ da~\ref{natops_rec_defs} é comutativa:
$$
\forall n
\forall m
\bigparen{n + m = m + n}.
$$
\wrongproof.
Provamos a
$$
\forall n
\munderbrace {\forall m \bigparen{n + m = m + n}} {\phi(n)}.
$$
\proofpart{Base.}
Queremos provar o $\phi(0)$, ou seja, o seguinte:
$$
\forall m \munderbrace {\bigparen{0 + m = m + 0}} {\psi(m)}.
$$
Vamos provar por indução!
\leftindent
\proofpart{Sub-base.}
Trivial, pois o que queremos provar é $0 + 0 = 0 + 0$ e os dois lados
são a mesma expressão.
\crproofpart{Sub-passo indutivo.}
Precisamos provar que:
$$
\forall k \Bigbracket{\munderbrace {0 + k = k + 0} {\psi(k)}
          \implies \munderbrace {0 + Sk = Sk + 0} {\psi(Sk)}}.
$$
Seja $k\in\nats$ tal que
$$
0 + k = k + 0.   \tag{S.H.I.}
$$
Queremos mostrar que
$$
0 + Sk = Sk + 0.
$$
Calculamos:
\compute
0 + Sk
&= S(0 + k)  \by {(a2)}
&= S(k + 0)  \by {(S.H.I.)}
&= Sk        \by {(a1)}
&= Sk + 0.   \by {(a1)}
\endcompute
Isso termina nossa base.
\endleftindent
\proofpart{Passo indutivo.}
Queremos provar:
$$
\forall k
\Bigbracket{
\munderbrace {\forall m \paren{k + m = m + k}}
{\phi(k)}
\implies
\munderbrace {\forall m \paren{Sk + m = m + Sk}}
{\phi(Sk)}
}.
$$
Seja $k\in\nats$ tal que
$$
\munderbrace {\forall m \paren{k + m = m + k}} {\phi(k)} \tag{H.I.}
$$
então.
Basta provar que
$$
\munderbrace {\forall m \paren{Sk + m = m + Sk}} {\phi(Sk)}.
$$
Seja $m\in\nats$.
Calculamos:
\compute
Sk + m
&= S(k+m)   \by {(a2)}
&= S(m+k)   \by {(H.I.)}
&= m + Sk.  \by {(a2)}
\endcompute
Isso termina nossa prova.
\mistaqed
%%}}}

%%{{{ x: natadd_is_commutative_find_the_error 
\exercise.
\label{natadd_is_commutative_find_the_error}%
A prova do~\ref{natadd_is_commutative} tem um erro!
Ache o erro.

\hint
Está no passo indutivo.

\hint
Está no último cálculo.

\solution
O erro está na primeira equação do último cálculo:
\compute
Sk + m
&= S(k+m). \by {a2}
\endcompute
A \byfact{a2} não nos permite concluir isso; só o seguinte:
$$
k + Sm = S(k+m).
$$
Se soubessimos que $Sk + m = k + Sm$ seria fácil
terminar essa prova corretamente.
Essa propriedade parece razoável para afirmar:
$$
\forall x \forall y \bracket{ Sx + y = x + Sy }
$$
Bora provar então!

\endexercise
%%}}}

%%{{{ lemma: succx_plus_y_eq_x_plus_succy
\lemma.
\label{succx_plus_y_eq_x_plus_succy}%
A operação $+$ satisfaz:
$$
\forall a
\forall b
\bigparen{ Sa + b = a + Sb }.
$$
\proof.
Provamos por indução que
$$
\forall b
\munderbrace {\forall a \bigparen{ Sa + b = a + Sb }} {\phi(b)}.
$$
\proofpart{Base.}
Precisamos provar que
$$
\munderbrace {\forall a \bigparen{ Sa + 0 = a + S0 }} {\phi(0)}.
$$
Calculamos:
\compute
Sa + 0
&= Sa        \by {a1}
a + S0
&= S(a + 0)  \by {a2}
&= Sa.       \by {a1}
\endcompute
\proofpart{Passo indutivo.}
Queremos provar:
$$
\forall k
\Bigbracket{
\munderbrace
    {\forall a \bigparen{ Sa + k = a + Sk }}
    {\phi(k)}
\implies
\munderbrace
    {\forall a \bigparen{ Sa + Sk = a + SSk }}
    {\phi(Sk)}
}.
$$
Seja $k\in\nats$ tal que
$$
\munderbrace
    {\forall a \bigparen{ Sa + k = a + Sk }}
    {\phi(k)}.
\tag{H.I.}
$$
Basta mostrar que
$$
\munderbrace
    {\forall a \bigparen{ Sa + Sk = a + SSk }}
    {\phi(Sk)}.
$$
Seja $a\in\nats$.
Calculamos
\compute
Sa + Sk
&= S(Sa + k)    \by {a2}
&= S(a + Sk)    \by {H.I.~com $a := a$}
&= a + SSk.     \by {a2}
\endcompute
Isso termina nossa prova, e logo substituindo a
justificação~``(a2)'' na prova do~\ref{natadd_is_commutative} por
``pelo~\ref{succx_plus_y_eq_x_plus_succy}'' ganhamos também o direito de
substituir seu~``\thinspace\mistakesymbol\thinspace'' por um
legítimo~``\thinspace\qedsymbol\thinspace''.
\qed
%%}}}

%%{{{ x: natmult_is_associative 
\exercise Associatividade da multiplicação.
\label{natmult_is_associative}%
$
\forall n
\forall m
\forall k
\bigparen{(n \ntimes m) \ntimes k = n \ntimes (m \ntimes k)}.
$

\hint
Por indução no $k$.

\hint
Não seria bom ter uma distributividade?

\solution
Por indução no $k$.
\crproofpart{Base: $\forall n \forall m \bigparen{(n \ntimes m) \ntimes 0 = n \ntimes (m \ntimes 0)}$.}
Sejam $n,m$ naturais.
Calculamos:
\compute
(n \ntimes m) \ntimes 0
&= 0            \by {(m1)}
n \ntimes (m \ntimes 0)
&= n \ntimes 0  \by {(m1)}
&= 0.           \by {(m1)}
\endcompute
\proofpart{Passo indutivo.}
Seja $w$ natural tal que
$$
\forall n \forall m \bigparen{(n \ntimes m) \ntimes w = n \ntimes (m \ntimes w)}. \tag{H.I.}
$$
Ou seja: ``$w$ na direita associa com todos''.
Queremos demonstrar que seu sucessor $Sw$ faz a mesma coisa:
$$
\forall n \forall m \bigparen{(n \ntimes m) \ntimes Sw = n \ntimes (m \ntimes Sw)}.
$$
Sejam $n,m$ naturais.
Calculamos:
\compute
(n \ntimes m) \ntimes Sw
&= ((n \ntimes m) \ntimes w) + (n \ntimes m)    \by {(m2)}
n \ntimes (m \ntimes Sw)
&= n \ntimes ((m \ntimes w) + m)                \by {(m2)}
&= (n \ntimes (m \ntimes w)) + (n \ntimes m)    \by {(*)}
&= ((n \ntimes m) \ntimes w) + (n \ntimes m).   \by {(H.I.)}
\endcompute
Onde devemos para o (*) demonstrar como lemma a distributividade (esquerda) da $\ntimes$ sobre a $+$ (feito no~\ref{natmult_distributes_over_natadd}).

\endexercise
%%}}}

%%{{{ x: natmult_is_commutative 
\exercise Comutatividade da multiplicação.
\label{natmult_is_commutative}%
$
\forall n
\forall m
\bigparen{n \ntimes m = m \ntimes n}.
$

\hint
Por indução em qualquer uma das $m,n$.

\hint
Prove a base da tua indução com uma sub-indução!

\hint
Teu passo indutivo vai precisar duma sub-indução também!
Alternativamente, tu podes demonstrar outras propriedades
que ajudaria ter (por exemplo distributividade) e usá-las
como lemmas nas tua prova.

\solution
Por indução no $m$.
\crproofpart{Base: $\forall n \paren{n \ntimes 0 = 0 \ntimes n}$.}
Vamos provar por indução!
\leftindent
\proofpart{Sub-base: $0 \ntimes 0 = 0 \ntimes 0$.}
Trivial!
\crproofpart{Sub-passo indutivo.}
Seja $k\in\nats$ tal que
$$
k \ntimes 0 = 0 \ntimes k.  \tag{S.H.I.1}
$$
Ou seja, \emph{$k$ é um número que comuta com o $0$}.
Vamos provar que $Sk \ntimes 0 = 0 \ntimes Sk$.
Calculamos:
\compute
Sk \ntimes 0  &= 0  \by {(m1)}
0 \ntimes Sk
&= 0 \ntimes k + 0  \by {(m2)}
&= 0 \ntimes k      \by {(a1)}
&= k \ntimes 0      \by {(S.H.I.1)}
&= 0.               \by {(m1)}
\endcompute
Isso prova nossa base.
\endleftindent
\proofpart{Passo indutivo.}
Seja $w\in\nats$ tal que
$$
\forall n \paren{n \ntimes w = w \ntimes n}. \tag{H.I.}
$$
Ou seja, \emph{$w$ é um número que comuta com todos}.
Queremos provar que seu sucessor $Sw$ faz a mesma coisa:
$$
\forall n \paren{n \ntimes Sw = Sw \ntimes n}.
$$
Vamos provar por mais uma indução!
\leftindent
\proofpart{Sub-base: $0 \ntimes Sw = Sw \ntimes 0$.}
Calculamos:
\compute
0 \ntimes Sw
&= 0 \ntimes w + 0 \by {(m2)}
&= 0 \ntimes w     \by {(a1)}
&= w \ntimes 0     \by {Base ($0$ comuta com todos) ou (H.I.) ($w$ comuta com todos)}
&= 0               \by {(m1)}
&= Sw \ntimes 0.   \by {(m1)}
\endcompute
\crproofpart{Sub-passo indutivo.}
Seja $p\in\nats$ tal que ele comuta com o $Sw$:
$$
p \ntimes Sw = Sw \ntimes p.    \tag{S.H.I.2}
$$
Vamos provar que $Sp$ também comuta com o $Sw$:
$$
Sp \ntimes Sw = Sw \ntimes Sp.
$$
Calculamos:
\compute
Sp \ntimes Sw
&= Sp \ntimes w + Sp        \by {(m2)}
&= w \ntimes Sp + Sp        \by {(H.I.): $w$ comuta com todos}
&= (w \ntimes p + w) + Sp   \by {(m2)}
&= w \ntimes p + (w + Sp)   \by {associatividade da $+$}
&= w \ntimes p + S(w + p)   \by {(a2)}
&= w \ntimes p + S(p + w)   \by {comutatividade da $+$}
&= w \ntimes p + (p + Sw)   \by {(a2)}
Sw \ntimes Sp
&= Sw \ntimes p + Sw        \by {(m2)}
&= p \ntimes Sw + Sw        \by {(S.H.I.2): $p$ comuta com o $Sw$}
&= (p \ntimes w + p) + Sw   \by {(m2)}
&= p \ntimes w + (p + Sw)   \by {associatividade da $+$}
&= w \ntimes p + (p + Sw).  \by {(H.I.): $w$ comuta com todos}
\endcompute
\endleftindent

\endexercise
%%}}}

%%{{{ x: natmult_distributes_over_natadd 
\exercise Distributividade.
\label{natmult_distributes_over_natadd}%
$
\forall x
\forall y
\forall z
\bigbracket{x \ntimes (y + z) = (x \ntimes y) + (x \ntimes z)}.
$

\hint
Indução no $z$.

\solution
Provamos a afirmação por indução no $z$.
\crproofpart{Base: $\forall x \forall y \bracket{x \ntimes (y + 0) = (x \ntimes y) + (x \ntimes 0)}$}.
Sejam $x,y \in \nats$.
Queremos provar que
$$
x \ntimes (y + 0) = (x \ntimes y) + (x \ntimes 0).
$$
Calculamos:
\compute
x \ntimes (y + 0)
&= x \ntimes y                 \by {(a1)}
&= x \ntimes y + 0             \by {(a1)}
&= x \ntimes y + x \ntimes 0.  \by {(m1)}
\endcompute
\proofpart{Passo indutivo.}
Seja $k\in \nats$ tal que
$$
\forall x
\forall y
\bracket{x \ntimes (y + k) = (x \ntimes y) + (x \ntimes k)}. \tag{H.I.}
$$
Vamos provar que
$$
\forall x
\forall y
\bracket{x \ntimes (y + Sk) = (x \ntimes y) + (x \ntimes Sk)}.
$$
Sejam $x,y\in\nats$.
Calculamos
\compute
x \ntimes (y + Sk)
&= x \ntimes S(y + k)                \by {(a1)}
&= \bigparen{x \ntimes (y + k)} + x  \by {(m2)}
&= (x \ntimes y + x \ntimes k) + x   \by {(H.I.) com $x\asseq x$, $y\asseq y$}
&= x \ntimes y + (x \ntimes k + x)   \by {associatividade de $+$}
&= x \ntimes y + x \ntimes Sk.       \by {(m2)}
\endcompute

\endexercise
%%}}}

%%{{{ thm: natmult_identity 
\theorem Identidade da multiplicação.
\label{natmult_identity}%
$
\forall x
\bigparen{ x \ntimes S0 = x = S0 \ntimes x}.
$
\proof.
Seja $x\in \nats$.
Calculamos:
\compute
x \ntimes S0
&= (x \ntimes 0) + x    \by {(m2), $n\asseq x$, $m\asseq 0$}
&= 0 + x                \by {(m1)}
&= x + 0                \by {$+$ comut.~(\refn{natadd_is_commutative})}
&= x.                   \by {(a1)}
\endcompute
Como já provamos a comutatividade da $\ntimes$, isso termina nossa prova.
\qed
%%}}}

%%{{{ x: law_of_natexp_1 
\exercise Lei de exponenciação 1.
\label{law_of_natexp_1}%
$
\forall x
\forall a
\forall b
\bigparen{x^{a + b} = (x^a) \ntimes (x^b)}.
$

\hint
Indução no $b$.

\hint
\proofpart{Base: $\forall x \forall a \bigbracket{x^{a+0} = x^a \ntimes x^0}$}.

\hint
\proofpart{Passo indutivo.}
Seja $k\in\nats$ tal que
$$
\forall x \forall a \bigbracket{x^{a+k} = x^a \ntimes x^k}. \tag{H.I.}
$$
Agora precisas provar que
$$
\forall x \forall a \bigbracket{x^{a+Sk} = x^a \ntimes x^Sk}.
$$

\solution
Por indução no $b$.
\crproofpart{Base: $\forall x \forall a \bigbracket{x^{a+0} = x^a \ntimes x^0}$}.
Sejam $x,a\in\nats$.
Calculamos:
\compute
x^{a+0}
&= x^a              \by {(a1)}
&= x^a \ntimes S0   \by {$S0$ identidade (\refn{natmult_identity})}
&= x^a \ntimes x^0. \by {(e1)}
\endcompute
\crproofpart{Passo indutivo.}
Seja $k\in\nats$ tal que
$$
\forall x \forall a \bigbracket{x^{a+k} = x^a \ntimes x^k}. \tag{H.I.}
$$
Basta provar que
$$
\forall x \forall a \bigbracket{x^{a+Sk} = x^a \ntimes x^Sk}.
$$
Sejam $x,a\in\nats$.
Queremos provar $x^{a+Sk} = x^a \ntimes x^Sk$.
Calculamos:
\compute
x^{a + Sk}
&= x^{S(a + k)}                 \by {(a2)}
&= x^{a+k} \ntimes x            \by {(e2)}
&= (x^a\ntimes x^k) \ntimes x   \by {(H.I.)}
&= x^a\ntimes (x^k \ntimes x)   \by {assoc.~de~$\ntimes$~(\refn{natmult_is_associative})}
&= x^a\ntimes x^Sk.             \by {(e2)}
\endcompute

\endexercise
%%}}}

%%{{{ x: law_of_natexp_2 
\exercise Lei de exponenciação 2.
\label{law_of_natexp_2}%
$
\forall a
\forall b
\forall c
\bigparen{a^{b \ntimes c} = (a^b)^c}.
$

\hint
Indução no $c$.

\hint
\proofpart{Base: $\forall a \forall b \bigparen{ a^{b \ntimes 0} = (a^b)^0 }$.}

\hint
\proofpart{Passo indutivo.}
Seja $k\in\nats$ tal que
$$
\forall a \forall b \bigbracket{ a^{b \ntimes k} = (a^b)^k }.\tag{H.I.}
$$
Agora precisas provar que
$$
\forall a \forall b \bigbracket{ a^{b \ntimes Sk} = (a^b)^{Sk} }.
$$

\solution
Por indução no $c$.
\crproofpart{Base: $\forall a \forall b \bigbracket{ a^{b \ntimes 0} = (a^b)^0 }$.}
Sejam $a,b\in\nats$.
Calculamos:
\compute
a^{b \ntimes 0}
&= a^0    \by {(m1)}
&= S0     \by {(e1)}
(a^b)^0
&= S0.    \by {(e1)}
\endcompute
\crproofpart{Passo indutivo.}
Seja $k\in\nats$ tal que
$$
\forall a \forall b \bigbracket{ a^{b \ntimes k} = (a^b)^k }.\tag{H.I.}
$$
Queremos provar que
$$
\forall a \forall b \bigbracket{ a^{b \ntimes Sk} = (a^b)^{Sk} }.
$$
Sejam $a,b\in\nats$.
Basta mostrar que $a^{b \ntimes Sk} = (a^b)^{Sk}$.
Calculamos:
\compute
(a^b)^{Sk}
&= (a^b)^k \ntimes (a^b)        \by {(e2), $n\asseq a^b$, $m\asseq k$}
&= a^{b \ntimes k} \ntimes a^b  \by {(H.I.), $a\asseq a$, $b\asseq b$}
&= a^{(b \ntimes k) + b}        \by {\refn{law_of_natexp_1}, $x\asseq a$, $a\asseq b \ntimes k$, $b\asseq b$}
&= a^{b \ntimes Sk}.            \by {(m2), $n\asseq b$, $m\asseq k$}
\endcompute

\endexercise
%%}}}

%%{{{ x: law_of_natexp_3 
\exercise Lei de exponenciação 3.
\label{law_of_natexp_3}%
$
\forall n
\bigparen{S0^n = S0}
$

\hint
Indução no $n$.

\hint
\proofpart{Base: $S0^0 \askeq S0$}.

\hint
\proofpart{Passo indutivo.}
Seja $k\in\nats$ tal que
$$
S0^k = S0.\tag{H.I.}
$$
Agora precisas provar que
$$
S0^{Sk} = S0.
$$

\solution
Por indução no $n$.
\crproofpart{Base: $S0^0 \askeq S0$.}
Imediato pela definição de $S0^0$.
\crproofpart{Passo indutivo.}
Seja $k\in\nats$ tal que
$$
S0^k = S0.\tag{H.I.}
$$
Basta demonstrar que
$$
S0^{Sk} = S0.
$$
Calculamos:
\compute
(S0)^{Sk}
&= S0 \ntimes S0^k              \by {(e2),   $n\asseq S0$, $m\asseq k$}
&= S0^k                         \by {$S0$ é identidade da $\ntimes$ (\ref{natmult_identity})}
&= S0.                          \by {(H.I.)}
\endcompute

\endexercise
%%}}}

%%{{{ df: natops_leq_def 
\definition.
\label{natops_leq_def}%
Definimos a relação $\leq$ assim:
$$
n \leq m \defiff \lexists {k\in\nats} {n + k = m}.
$$
%%}}}

%%{{{ x: natleq_lemma 
\exercise.
\label{natleq_lemma}%
Prove que
$$
\forall n \forall m \bigparen{ n \leq S m  \iff  n \leq m  \mlor  n = S m}
$$

\hint
Tente sem indução.

\solution
Sejam $n,m$ naturais.
\endgraf
\lrdir:
Suponha $n \leq S m$.
Logo seja $u$ tal que $n + u = Sm$.
Separamos em casos.
\case{Caso $u=0$.}
Logo $Sm = n+u = n+0 = n$ e temos o que queremos demonstrar.
\case{Caso $u=Su'$ para algum $u'$.}
Logo $Sm = n + Su' = S(n + u')$.
Agora, como $Sm = S(n + u')$, logo $m = n + u'$.
Ou seja, $n \leq m$.
\endgraf
\rldir:
Suponha $n \leq m$ ou $n = Sm$.
Vamos demonstrar que $n \leq Sm$.
Separamos em casos.
\case{Caso $n \leq m$}.
Logo seja $u$ tal que $n + u = m$.
Logo $S(n + u) = Sm$.
E pela (a1) temos $n + Su = Sm$, e logo $n \leq Sm$.
\case{Caso $n = Sm$}.
Nesse caso imediatamente $n + 0 = Sm$ (pois $n + 0 = n$ pela (a2))
e logo $n \leq Sm$.

\endexercise
%%}}}

\blah.
Nos exercícios seguintes vamos provar que $\leq$ é uma \dterm{ordem linear}.

%%{{{ x: natleq_refl 
\exercise Reflexiva.
\label{natleq_refl}%
A $\leq$ é \dterm{reflexiva}, i.e.,
$$
\forall x \bigparen{ x \leq x }.
$$

\endexercise
%%}}}

%%{{{ x: natleq_antisym 
\exercise Antissimétrica.
\label{natleq_antisym}%
A $\leq$ é \dterm{antissimétrica}, i.e.,
$$
\forall x \forall y \bigparen{x \leq y  \mland  y \leq x  \implies  x = y}.
$$

\endexercise
%%}}}

%%{{{ x: natleq_trans 
\exercise Transitiva.
\label{natleq_trans}%
A $\leq$ é \dterm{transitiva}, i.e.,
$$
\forall x \forall y \forall z \bigparen{x \leq y  \mland  y \leq z  \implies  x \leq z}.
$$

\endexercise
%%}}}

%%{{{ x: natleq_total 
\exercise Total.
\label{natleq_total}%
A $\leq$ é \dterm{total}, i.e.,
$$
\forall x \forall y \bigparen{x \leq y  \mlor  y \leq x}.
$$

\endexercise
%%}}}

\blah.
Na verdade, $\leq$ é ainda mais legal: olha no~\ref{natleq_woset}.

\endsection
%%}}}

%%{{{ Why accept the induction principle? 
\section Por que aceitar o princípio da indução?.

%%{{{ Intuition 
\note Intuição.
Por que provando $\phi(0)$ e $\lforall {k\in\nats} {\phi(k) \implies \phi(Sk}$
é suficiente para demonstrar o $\lforall {n\in\nats} {\phi(n)}$?
Estabelecendo esses dois álvos significa que ganhamos como regras de inferência
as seguintes:
$$
\xalignat2
&
\Proofm {
\I0------------ {IndZero$_\phi$}
    {\phi(0)}
}
&&
\Proofm {
\A  {\phi(n)}
\I1------------ {IndSucc$_\phi$}
    {\phi(Sn)}
}
\endxalignat
$$
onde $n$ é uma metavariável pegando valores em todos os naturais,
e onde eu escolhi esses rótulos talvez estranhos para nomear essas regras.
Vamos ver o que podemos demonstar graças essas duas regras agora:
com certeza temos o próprio $\phi(0)$ pela primeira que não tem
nenhuma premissa.
Mas, agora, usando a segunda com $n\asseq 0$ temos uma demonstração
do $\phi(S0)$:
$$
\Proof {
\I0----------- {IndZero$_\phi$}
   {$\phi(0)$}
\I1------------ {IndStep$_\phi$}
   {$\phi(S0)$}
}
$$
Ou seja, ganhamos o $\phi(S0)$.
Então podemos usar a regra \rule{IndZero$_\phi$} agora com $n\asseq S0$
para ganhar o $\phi(SS0)$:
$$
\Proof {
\I0----------- {IndZero$_\phi$}
   {$\phi(0)$}
\I1------------ {IndStep$_\phi$}
   {$\phi(S0)$}
\I1------------- {IndStep$_\phi$}
   {$\phi(SS0)$}
}
$$
E por aí vai!
Olhando para as duas regras 
$$
\xalignat2
&
\Proof {
\I0------------ {IndZero$_\phi$}
   {$\phi(0)$}
}
&&
\Proof {
\A {$\phi(n)$}
\I1------------ {IndSucc$_\phi$}
   {$\phi(Sn)$}
}
\intertext{observamos que são bem parecidas com as}
&
\Proof {
\I0----------- {Zero}
{$0 \is \Nat$}
}
&&
\Proof {
\A {$n \is \Nat$}
\I1-------------- {Succ}
  {$Sn \is \Nat$}
}
\endxalignat
$$
e logo dado qualquer natural $n$, o desafio de estabelecer que $n$ tem
a propriedade $\phi$, acaba sendo o mesmo com o ``desafio'' de estabelecer
que $n$ é um natural mesmo!
Em outras palavras, assim que demonstrar os dois alvos da indução para
matar o $\lforall {n\in\nats} {\phi(n)}$, temos:
$$
n \is \Nat \implies \phi(n).
$$
Ou seja: \emph{todos os naturais têm a propriedade $\phi$ mesmo}.
%%}}}

%%{{{ Does this blah-blah mean anything? 
\note Esse bla-bla presta mesmo?.
O leitor alerto justamente ficaria com dúvidas sobre o texto acima.
Realmente faz sentido essa descrição e essa intuição, mas todo esse
``bla-bla'' serve como uma prova mesmo do princípio da indução?
Serve não.  E por isso que o chamamos de \dterm{princípio}, ou seja
axioma!  Mas calma:
dependendo na fundação de matemática que trabalhamos,
o princípio pode virar teorema mesmo!  No~\ref{Axiomatic_set_theory}
por exemplo, vamos \emph{demonstrar mesmo} o princípio da indução
para os naturais.  Mas por enquanto não temos as ferramentas
nem a maduridade que precisamos para entender essas idéias;
então paciência.
O que podes mesmo fazer desde já é demonstrar a equivalência
desse princípio com um outro, que também é facilmente aceitável:
o princípio da boa ordem (\ref{WOP_iff_PFI}).
%%}}}

\endsection
%%}}}

%%{{{ Defining relations recursively 
\section Definindo relações recursivamente.

%%{{{ nats_leq_rec_def 
\definition Ordem.
\label{nats_leq_rec_def}%
Com que temos já definido podemos definir recursivamente
uma \emph{relação} no $\nats$.  A relação de ordem $\preceq$:
$$
\align
0  \preceq m  &\iff \True      \tag{LE1}\\
Sn \preceq 0  &\iff \False     \tag{LE2}\\
Sn \preceq Sm &\iff n \preceq m   \tag{LE3}
\endalign
$$
%%}}}

%%{{{ eg: two_leq_four_but_four_notleq_two 
\example.
\label{two_leq_four_but_four_notleq_two}%
Ache se $SS0 \preceq SSSS0$ e se $SSSS0 \preceq SS0$.

\solution
Calculamos:
\compute
SS0 \preceq SSSS0
&\iff S0 \preceq SSS0  \by {por (LE3)}
&\iff 0  \preceq SS0   \by {por (LE3)}
&\iff \True         \by {por (LE1)}
\endcompute
ou seja, realmente $SS0 \preceq SSSS0$.
No outro lado, calculamos
\compute
SSSS0 \preceq SS0
&\iff SSS0 \preceq S0  \by {por (LE3)}
&\iff SS0  \preceq 0   \by {por (LE3)}
&\iff \False        \by {por (LE2)}
\endcompute
ou seja, $SSSS0 \not\preceq SS0$.

\endexample
%%}}}

\blah.
Podemos demonstrar que $\preceq$ é uma ordem linear,
provando cada uma das propriedades como fizemos sobre a
$\leq$ nos exercícios
(\refn{natleq_refl},
\refn{natleq_antisym},
\refn{natleq_trans},
\refn{natleq_total})
mas uma maneira melhor que vai nos permitir ganhar
muitos mais resultados de graça é provar que $\leq$
e $\preceq$ são na verdade a mesma relação.
Ou seja, as definições~\refn{natops_leq_def}
e~\refn{nats_leq_rec_def} são equivalentes.
Tu demonstrarás isso no~\ref{rec_and_nonrec_def_of_order_agree}.

\endsection
%%}}}

%%{{{ Two sides of the same coin 
\section Dois lados da mesma moeda.

%%{{{ Inductive definition 
\note Definição inductiva.
\label{inductive_definitions}%
Definimos o tipo Nat assim:
$$
\bnf{Nat} \bnfeq 0 \bnfor S \bnf{Nat}
$$
Note que o Nat aparece no lado direito também;
e nesse sentido podemos dizer que essa foi uma definição recursiva.
Esse tipo de definição chamamos de \dterm{definição inductiva}.
Ele libera duas ferramentas poderosas:
definir operações e relações por recursão;
e provar propriedades por indução.
%%}}}

%%{{{ inductive_vs_recursive_definitions 
\beware.
\label{inductive_vs_recursive_definitions}%
Muitas vezes ``definição inductiva'' acaba sendo chamada ``definição recursiva''.
Vários autores, dependendo da área que estão trabalhando adoptam um uso ou
o outro, ou ambos, ou até diferenciando o que cada um significa.
Tradicionalmente o slogan seria:
\standout
<<define por recursão; demonstre por indução>>.
\endstandout
%%}}}

%%{{{ the_power_of_recursion 
\note O poder da recursão.
\label{the_power_of_recursion}%
Estamos tentando \emph{definir algo por recursão},
por exemplo a operação de multiplicação
(\ref{nats_ntimes_recursive_def}).
Escrevemos já
$$
\align
n \ntimes 0  &= 0 \\
n \ntimes Sm &= \text{\lthole}
\endalign
$$
e estamos pensando em como completar nossa definição.
E a Recursão chega e nos oferece um presente:
\quote
<<Para definir o $n \ntimes Sm$, considere o valor do $n \ntimes m$ como dado,
de graça por mim; e veja se tu consegues definir o valor de $n \ntimes Sm$ com isso.>>
\endquote
E é exatamente o que fizemos.
É isto o \dterm{poder da recursão}.
%%}}}

%%{{{ the_power_of_induction 
\note O poder da indução.
\label{the_power_of_induction}%
Estamos tentando \emph{demonstrar algo por indução}
por exemplo a associatividade da adição.
Já provamos a base (o $\phi(0)$), e queremos
demonstrar o $\phi(Sn)$.
E a Indução chega e nos oferece um presente:
\quote
<<Para provar o $\phi(Sn)$, considere o $\phi(n)$ como dado, de graça por mim;
e veja se tu consegues provar o $\phi(Sn)$ com isso agora.>>
\endquote
E é exatamente o que fizemos.
É isto o \dterm{poder da indução}.
Compare com nossa primeira tentativa de demonstrar a associatividade da adição
(sem indução) onde nossa única maneira de andar era separar em casos,
mas cada vez que conseguimos matar o ``caso 0'' o ``caso sucessor'' tava
sempre gerando mais dois casos: um novo ``caso 0'' e um novo ``caso sucessor''.
E nossos dados não eram suficientes para matar o ``caso sucessor''.
%%}}}

%%{{{ Where is recursion's principle? 
\note E a recursão?  Não tem princípio não?.
Se recursão é indução são dois lados da mesma moeda mesmo,
e já encontramos e enunciamos o princípio da indução;
a gente não deveria ter analogamente um princípio da recursão
também?
Temos sim, e vamos voltar a estudá-lo e demonstrá-lo depois,
pois precisamos mais ferramentas e maduridade (capítulos
\ref{Theory_of_recursive_functions} e~\ref{Axiomatic_set_theory}).
%%}}}

%%{{{ how_about_non_nats 
\note E os não-naturais?.
\label{how_about_non_nats}%
Como falei no~\ref{inductive_definitions} o que nos permite
usar recursão e indução nos naturais é sua definição inductiva.
Ou seja, podemos usar essas ferramentas em qualquer tipo que
foi definido assim.  Nos problemas peço a você formalizar
o princípio da indução como um pequeno ``teaser'' da teoria
que voltaremos estudar mais no~\ref{Structural_recursion_and_induction}.
%%}}}

\endsection
%%}}}

%%{{{ Problems 
\problems.

%%{{{ prob: tetration 
\problem.
\label{tetration}%
\tdefined{tetração}%
Definimos as operações binárias de adição, multiplicação, e exponenciação no $\Nat$.
Descubra um ``padrão'' nas definições dessas operações, e defina a próxima operação, \dterm{tetração}, nessa seqüência de operações.

\endproblem
%%}}}

%%{{{ prob: natleq_woset 
\problem.
\label{natleq_woset}%
Prove que $\leq$ é uma bem-ordem, i.e.,
$$
\text{para todo $A \subset \nats$,\quad
se $A \neq \emptyset$ então $A$ tem elemento mínimo}.
$$

\endproblem
%%}}}

%%{{{ prob: rec_and_nonrec_def_of_order_agree 
\problem.
\label{rec_and_nonrec_def_of_order_agree}%
Na~\ref{natops_leq_def} definimos a ordem $\leq$ nos naturais.
Na~\ref{nats_leq_rec_def} definimos a relação $\preceq$ nos naturais.
Obviamente não podemos dar duas definições diferentes para a mesma coisa.
Prove que as duas definições sempre concordam:
$$
\text{para todo $n,m\in\nats$, \quad $n \leq m \iff n \preceq m$.}
$$

\endproblem
%%}}}

%%{{{ prob: structural_induction_teaser_prob 
\problem.
\label{structural_induction_teaser_prob}%
Em qual outros (não-Nat) tipos de coisas tu pode enunciar um princípio
de indução?  Como definarias algo por recursão?
Tente provar alguma propriedade simples sobre tua escolha.

\hint
Tente as fórmulas de lógica proposicional e de predicados (FOL) também.
Podes definir uma função que conta quantos $\lor$ aparecem na sua entrada?
Podes demonstrar que em cada fórmula bem formada a quantidade de \sq{$($}
e a quantidade de \sq{$)$} são iguais?

\endproblem
%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

Recursão e indução vamos ficar usando o tempo todo.
Especialmente nos capítulos~\refn{Structural_recursion_and_induction},
\refn{Theory_of_recursive_functions}, e~\refn{Axiomatic_set_theory},
vamos mergulhar na teoria desses assuntos; mas sugiro paciência
por enquanto, e \emph{ganhar experiência trabalhando} com recursão
e indução.

Nesse capítulo tivemos nosso primeiro contato com \emph{programação funcional},
um assunto que vamos estudar no~\ref{Functional_programming}.
Para o ansioso e animado-para-programar leitor recomendo brincar com uma
linguagem puramente funcional:
\tool{Haskell} (\cite{lyah}, \cite{birdfphaskell}, \cite{birdthinking},
\cite{huttonhaskell}) ou \tool{PureScript} (\cite{purescriptbook}).

Vale muito a pena investir em trabalhar com uma implementação
como o \tool{Coq} ou a \tool{Agda}.  Ambos podem ser vistos tanto como uma
linguagem de programação funcional, quanto como um \emph{proof assistant}.
Dois textos excelentes para inciantes que meu leitor é muito recomendado
começar desde já estudar são os \cite{piercesf1} (que usa Coq)
e o \cite{wadlerplfa} (que usa Agda).

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Sets 
\chapter Conjuntos.
\label{Sets}%

%%{{{ chapintro: sets like assembly 
\chapintro
Nesse capítulo estudamos um tipo de objeto matemático: o \emph{conjunto}.
Alem dele, encontramos seus tipos-amigos: \emph{tuplas}, \emph{seqüências},
e \emph{famílias indexadas}.
Como nos vamos apreciar no~\ref{Axiomatic_set_theory},
os conjuntos e sua linguagem têm um papel importante para a
\emph{fundação de matemática}.
Mas por enquanto nos importa apenas nos acostumar com esses tipos,
seus objetos, suas operações e relações; aprender usá-los e nada mais!
%%}}}

%%{{{ Concept, notation, equality 
\section Conceito, notação, igualdade.
\tdefined{conjunto}%

%%{{{ Q: What does it mean to be a set? 
\question.
O que significa ser conjunto?
%%}}}

\blah.
\Cantor{}Cantor deu a seguinte resposta:

%%{{{ pseudodf: set 
\pseudodefinition.
\label{set_pseudodefinition}%
\tdefined{conjunto}[definição intuitiva]%
Um \dterm{conjunto} $A$ é a colecção numa totalidade
de certos objetos (definidos e separados) da nossa intuição ou mente, que chamamos de \dterm{elementos} de $A$.
%%}}}

%%{{{ x: set_pseudodefined 
\exercise.
Qual é o problema principal com a definição acima?

\solution
O que é uma ``colecção (numa totalidade)''?
Cuidado: para responder nessa pergunta
tu não podes usar a palavra ``conjunto'', pois assim teria uma
definição circular.
Em outras palavras, definimos a palavra ``conjunto'' em termos da palavra
``colecção'', que no final das contas, é algo sinónimo.

\endexercise
%%}}}

%%{{{ Primitive notions 
\note Noções primitivas.
\ii{noção primitiva}%
Aceitamos apenas duas \emph{noções primitivas}\/:
$$
\gathered
\text{ser conjunto}\\
\Set(\dhole)
\endgathered
\qqqquad
\gathered
\text{pertencer}\\
\dhole\in\dhole
\endgathered
$$
%%}}}

%%{{{ Convention: family, colection, agglomerate, and fonts 
\note Convenção.
\tdefined{família}%
\tdefined{colecção}%
\tdefined{aglomerado}%
Usamos os termos \dterm{família}, \dterm{colecção}, \dterm{aglomerado}, etc.\ como
sinónimos da palavra ``conjunto''.
Mesmo assim, seguindo uma práctica comum, quando temos conjuntos de conjuntos
dizemos ``família de conjuntos'', e depois ``colecção de famílias'', etc.
Com o mesmo motivo (de facilitar nossos olhos ou ouvidos humanos), as vezes
mudamos (elevamos) a font que usamos para denotar esses conjuntos,
de $A,B,C,\dots$ para $\scr A, \scr B, \scr C, \dots$ por exemplo.
Para ilustrar, imagine que já temos definido uns conjuntos $A_1, A_2, A_3, B, C$
e agora queremos falar sobre os conjuntos $\set{A_1, A_2, A_3}$ e $\set{B,C}$
e dar nomes para eles.  Uma escolha razoável seria botar
$$
\xalignat2
\scr A &\defeq \set{A_1, A_2, A_3} &
\scr B &\defeq \set{B,C}
\endxalignat
$$
mas isso é apenas questão de costume.  Nada profundo aqui.
%%}}}

%%{{{ df: set_notation 
\definition Notação de conjuntos.
\label{set_notation}%
\tdefined{conjunto}[notação]%
\tdefined{conjunto}[homogêneo]%
\tdefined{conjunto}[heterogêneo]%
\tdefined{homogeneidade}%
\tdefined{heterogeneidade}%
A notação mais simples para denotar um conjunto é usar
``chaves'' (os símbolos~\sq{$\{$}~e~\sq{$\}$}) e listar todos os seus elementos dentro.
Por exemplo:
$$
\xalignat2
A &=\set {0,1}                          &E &=\set {2,3,\set{5,7}, \set{\set{2}}}\\
B &=\set {\nats, \ints, \rats, \reals}  &F &=\set {\mathrm{Thanos}}\\
C &=\set {2}                            &G &=\set {1,2,4,8,16,31,A,B,\nats}\\
D &=\set {2,3,5,7}                      &H &=\set {\mathrm{Thanos}, \mathrm{Natal}, \set{E,\set{F,G}}}
\endxalignat
$$
Chamamos os conjuntos cujos elementos são ``do mesmo tipo'' \dterm{homogêneos},
e os outros \dterm{heterogêneos}.
Deixamos ambíguo o que significa ``do mesmo tipo'', mas, naturalmente, consideramos
os $A, B, C, D, F$ homogêneos e os $E, G, H$ heterogêneos.
%%}}}

%%{{{ Dealing with more complicated sets 
\blah.
Todos os conjuntos que acabamos de escrever aqui são \emph{finitos},
seus elementos são conhecidos, e ainda mais são poucos e conseguimos os listar todos.
Nenhuma dessas três propriedades é garantida!
Se não temos a última fica impráctico listar todos elementos,
e quando não temos uma das duas primeiras, é plenamente impossível.
Considere por exemplo os conjuntos seguintes:
$$
\align
X &= \text{o conjunto de todos os números reais entre 0 e 1}\\
Y &= \text{o conjunto dos assassinos do Richard \Montague{}Montague}\\
Z &= \text{o conjunto de todos os números naturais menores que $2^{256!}$}.
\endalign
$$
%%}}}

%%{{{ df: set_builder 
\definition Set builder.
\label{set_builder}%
\label{definite_condition}%
\tdefined{set builder}%
\tdefined{set comprehension}%
\tdefined{condição definitiva}%
\sdefined {\setst {\sholed x} {\sholed {\thole}}} {o conjunto de todos os $x$ tais que \thole}%
\iiseealso{set!comprehension}{set builder}%
Uma notação diferente e bem útil é chamada
notação \dterm{set-builder} (ou \dterm{set comprehension}),
onde escrevemos
$$
\setstt x {\thole$x$\thole}
$$
para denotar <<o conjunto de todos os objetos $x$ tais que \thole$x$\thole>>.%
\footnote{Na literatura aparecem também os símbolos~\sq{$:$}~e~\sq{$;$}~em
vez do~\sq{$\st$}~que usamos aqui.}
Entendemos que no lado direito escrevemos o \dterm{filtro},
uma \emph{condição definitiva},
e não algo ambíguo ou algo subjectivo.  Por exemplo, não podemos escrever 
algo do tipo
$$
\setst p { \text{$p$ é uma pessoa linda} }.
$$
Mas como podemos formalizar o que é uma \dterm{condição definitiva}?
Bem, concordamos escrever apenas algo que podemos (se precisarmos e se quisermos)
descrever usando uma fórmula de FOL $\phi(x)$ onde possivelmente aparece
a variável $x$ livre e todos os símbolos da FOL tem interpretações bem-definidas.%
\footnote{Pouco mais sobre isso no~\ref{fol_filter_by_fraenkel_and_skolem}.}
Chegamos então na forma
$$
\setst x {\phi(x)}.
$$
A notação set-builder é bem mais poderosa do que acabamos de mostrar,
pois nos permite utilisar \emph{termos} mais complexos na sua parte esquerda,
e não apenas uma variável.
Vamos investigar isso e mais variações logo na~\ref{full_setbuilder}.
%%}}}

%%{{{ remark: variable_binder_in_set_builder 
\remark.
\label{variable_binder_in_set_builder}%
\tdefined{variável}[ligada]%
\tdefined{variável}[livre]%
Na notação
$$
\setstt {\alert{x}} {\thole$x$\thole}
$$
temos um \emph{ligador de variável}, pois o $\alert{x}$ no lado esquerdo
liga todos os $x$'s que aparecem no lado direito livres (e assim viram ligados).
Por exemplo, o conjunto
$$
\setst x {x^2 < xy}
$$
depende no $y$ (mas não no $x$).
%%}}}

%%{{{ beware: variable_capturing_in_set_builder 
\beware Capturação de variável.
\label{variable_capturing_in_set_builder}%
\tdefined{variável}[capturada]%
\ii{variável}[dummy]%
\ii{variável}[capturada]%
Podemos trocar o ``dummy'' $x$ por qualquer variável
\emph{que não aparece livre na parte direita},
tomando cuidado para renomiar as ligadas também.
Por exemplo
$$
\setst {\alert{x}} {\alert{x}^2 < \alert{x}y} \inteq
\setst {\alert{z}} {\alert{z}^2 < \alert{z}y}
$$
Mas
$$
\setst {\alert{x}} {\alert{x}^2 < \alert{x}y} \intneq
\setst {\alert{y}} {\alert{y}^2 < \alert{y}\alert{y}}
$$
pois o $y$ que tava livre no ``filtro'' acabou sendo
\emph{capturado} pelo ligador no set builder:
dentro dos $\set{\dots}$ perdemos o
acesso no objeto denotado por $y$ fora.
O $\setst y {y^2 < yy}$ não depende mais do $y$.
%%}}}

%%{{{ What we need to specify for each new type 
\note Tipos.
Cada vez que introduzimos um novo tipo de objetos,
devemos especificar:
\beginol
\li Quando dois objetos desse tipo são \emph{iguais}?
\li Qual é o ``interface'' desses objetos?
\endol
%%}}}

%%{{{ Black boxes 
\note Black boxes.
\label{blackbox_set}%
\tdefined{black box}%
\tdefined{white box}%
\iiseealso{white box}{black box}%
\iiseealso{black box}{white box}%
\tdefined{black box}[de conjunto]%
\iisee{conjunto!como black box}{black box}%
O conceito de \dterm{black box} (ou \dterm{caixa preta}) é uma ferramenta muito
útil para descrever tipos.
A idéia é que queremos descrever o que realmente determina um objeto desse tipo,
e \emph{esconder} os detalhes ``de implementação'', apresentado apenas seu
``interface''.
Podemos então pensar que um conjunto $A$ é um black box que tem apenas uma
entrada onde podemos botar qualquer objeto $x$ desejamos, e tem como única
``saída'' uma luz que pode piscar ``sim'' ou ``não'' (correspondendo nos casos
$x\in A$ e $x\notin A$ respectivamente).
$$
\tikzpicture
\tikzi blackboxset;
\endtikzpicture
$$
Usamos o termo \emph{black} box para enfatizar que não temos como ``olhar dentro''
desse aparelho, dessa caixa, e ver o que acontece assim que botar uma entrada;
nossa única informação será a luz da caixa que vai piscar ``sim'', ou ``não''.
Quando temos acesso nos ``internals'' da caixa a gente chama de \dterm{white box}
ou \dterm{transparent box}; mas não vamos precisar o uso desse conceito nesse texto.
\endgraf
A única \emph{estrutura interna} de um conjunto é a capabilidade de
\emph{decidir se dois elementos $x,y$ do conjunto são iguais ou não}.
%%}}}

%%{{{ Q: When are two sets equal? 
\question.
Quando dois conjuntos são iguais?
%%}}}
\spoiler.

%%{{{ pseudodf: set_eq_pseudodefinition 
\pseudodefinition.
\label{set_eq_pseudodefinition}%
Consideramos dois conjuntos $A,B$ \dterm{iguais} sse não tem como diferenciar
eles como black boxes.  Em outras palavras, para cada objeto $x$
que vamos dar como entrada para cada um deles, eles vão concordar:
ou os dois vão piscar ``sim'', ou os dois vão piscar ``não''.
O ``slogan'' aqui é:
$$
\text{\emph{um conjunto é determinado por seus membros}}.
$$
%%}}}

%%{{{ df: set_eq 
\definition Igualdade de conjuntos.
\label{set_eq}%
Dois conjuntos são iguais sse têm exatamente os mesmos membros.
Em símbolos,
$$
A = B \defiff \lforall x {x\in A \iff x\in B}.
$$
%%}}}

%%{{{ defining_sets 
\note Definindo conjuntos.
Para determinar então um conjunto $A$, precisamos dizer exatamente
quando um objeto arbitrário $x$ pertence nele.
As notações que viermos até agora realmente deixam isso claro;
mas um outro jeito muito útil para \emph{definir} um certo conjunto $A$,
seria apenas preencher o
$$
x \in A  \defiff  \text{\xlthole}
$$
com alguma \ii{condição definitiva}condição definitiva
(veja~\ref{definite_condition}).
\endgraf
Concluimos que as duas formas seguintes de definir um conjunto $A$,
são completamente equivalentes:
$$
\xalignat2
x &\in A \defiff \text{\lthole}
&
A &\defeq \setst x {\text{\lthole}}.
\endxalignat
$$
As duas afirmações tem exatamente o mesmo efeito:
definir o mesmo conjunto $A$.
Qual das duas usamos, será mais questão de gosto ou de contexto.
%%}}}

%%{{{ remark: what_is_being_defined_really_sets 
\remark O que tá sendo definido mesmo?.
\label{what_is_being_defined_really_sets}%
Definindo um conjunto $A$ pela
$$
x \in A \defiff \xlthole
$$
o que estamos definindo diretamente não é o \sq{$A$} mas o \sq{$x \in A$}.
Mas o $A$ sendo conjunto, ele é \emph{determinado por seus membros}
(lembra a~\ref{set_eq_pseudodefinition}) ou seja, sabendo
o que $x \in A$ significa para todo $x$, sabemos quem é o $A$.
%%}}}

%%{{{ note: order_and_multiplicity 
\note Ordem e multiplicidade.
\label{order_and_multiplicity}%
\ii{conjunto}[ordem de membros]%
\ii{conjunto}[multiplicidade]%
Considere os conjuntos seguintes:
$$
\xalignat3
A&=\set{2,3},&
B&=\set{3,2},&
C&=\set{3,2,2,2,3}
\endxalignat
$$
Observe que $A = B = C$.
Ou seja, esses não são três conjuntos, mas apenas \emph{um} conjunto
denotado em três jeitos diferentes.
O ``dispositivo'' conjunto não sabe nem de \dterm{ordem}
nem de \dterm{multiplicidade} dos seus membros.
Não podemos perguntar a um conjunto
<<qual é teu \emph{primeiro} elemento?>>, nem 
<<quantas vezes o tal elemento pertence a ti?>>.
Lembre o conjunto como black box!
Sua única interface aceita qualquer objeto,
e responda apenas com um pleno ``sim'' ou ``não''.
Logo encontramos outros tipos de ``recipientes'',
onde as informações de ordem e de multiplicidade são preservadas:
multisets~(\refn{Multisets}), tuplas~(\refn{Tuples}), e seqüências~(\refn{Sequences}).
Bem depois vamos estudar \emph{conjuntos ordenados} (\ref{Posets}).
%%}}}

\blah.
Logo vamos definir mais relações entre conjuntos;
mas antes disso, bora discutir sobre dois conceitos de igualdade diferentes.

\endsection
%%}}}

%%{{{ Intension vs. Extension 
\section Intensão vs{.}~extensão.
\label{Intension_vs_extension_in_sets}%

%%{{{ Consider four extensionally equal sets 
\note.
Condidere os conjuntos
$$
\align
P &= \setst d {\text{$d$ é um divisor primo de $2^{256!}$}}\\
Q &= \setst p {\text{$p$ é primo e par}}\\
R &= \setst x {\text{$x$ é raiz real do polinómio $x^3 - 8$}}\\
S &= \set {2}.
\endalign
$$
%%}}}

%%{{{ Q: what_are_the_extensions_of_these_four_sets} 
\question.
Quais são os membros de cada um dos conjuntos acima?
\label{what_are_the_extensions_of_these_four_sets}%
%%}}}

%%{{{ A: thinking a bit, they're all the same set 
\blah Resposta.
\emph{Pensando um pouco} percebemos que esses quatro conjuntos
consistem em exatamente os mesmos membros, viz.~o número $2$ e nada mais.
Lembrando na idéia de black box, realmente não temos como diferenciar
entre esses black boxes.
Começando com o $S$, é direto que ele responda ``sim'' apenas no número $2$
e ``não'' em todos os outros objetos.
Continuando com o $P$, realmente temos que o único objeto que satisfaz
seu filtro é o número $2$.  Mesma coisa sobre os $Q$ e $R$.
%%}}}

%%{{{ Intension description 
\note.
\label{intension_description}%
\tdefined{extensão}%
\tdefined{intensão}%
\tdefined{igualdade}[extensional]%
\tdefined{igualdade}[intensional]%
Como comporta o $S$?
Recebendo sua entrada $a$, ele a compara com o $2$ para ver se $a=2$ ou não,
e responde ``sim'' ou ``não'' (respectivamente) imediatamente.
E o $R$?
Recebendo sua entrada $a$, ele verifica se $a$ é uma raiz do $x^3 - 8$.
Substituindo então o $x$ por $a$, elevando o $a$ ao $3$ e subtraindo $8$,
se o resultado for $0$ responda ``sim''; caso contrário, ``não''.
E o $Q$?
Recebendo sua entrada $a$, ele verifica se $a$ é primo, e se $a$ e par.
Se as duas coisa acontecem, ele responda ``sim''; caso contrário, ``não''.
E o $P$?
Recebendo sua entrada $a$, ele verifica se $a\divides 2^{256!}$ e se $a$ é
um número primo.
Se as duas coisa acontecem, ele responda ``sim''; caso contrário, ``não''.
\endgraf
Acabamos de descrever a \dterm{intensão} de cada conjunto.
Mas, sendo black boxes, dados esses conjuntos $P,Q,R,S$,
não conseguimos diferenciá-los, pois a única interação que sua interface
permite é botar objetos $a$ como entradas, e ver se pertencem ou não.
Falamos então que \dterm{extensionalmente} os quatro conjuntos
são iguais, mas \dterm{intensionalmente}, não.
Usamos os termos \dterm{igualdade extensional} e \dterm{igualdade intensional}.
E para abusar a idéia de black box:
provavelmente o black box $Q$ demora mais para responder, ou fica mais quente,
ou faz mais barulho, etc., do que o $S$.
\endgraf
Quando definimos um conjunto simplesmente listando todos os seus membros,
estamos escrevendo sua \dterm{extensão}.  E nesse caso, a intensão é a mesma.
Quando usamos a notação builder com um filtro, estamos mostrando a \dterm{intensão}
do conjunto.  Nesse caso as duas noções podem ser tão diferentes, que nem
sabemos como achar sua extensão!
%%}}}

%%{{{ eg: number_theory_conjectures_set_intension 
\example.
\label{number_theory_conjectures_set_intension}%
Revise a~\ref{Open_problems_in_number_theory} e considere os conjuntos
$$
\align
T &\defeq
\setstt p {$p$ e $p+2$ são prímos}\\
L &\defeq
\setstt n {$n \in \nats_{>0}$ e não existe primo entre $n^2$ e $(n+1)^2$}\\
G &\defeq
\setstt n {$n \in \nats_{>1}$ e $2n=p+q$ para alguns primos $p,q$}\\
C &\defeq
\setstt n {$n \in \nats_{>0}$ e a seqüência Collatz começando com $n$ nunca pega o valor $1$}.
\endalign
$$
Sobre o $T$ não sabemos se é finito ou não!
Sobre o $G$, não sabemos se $G = \nats_{>1}$ ou não!
E, sobre os $L$ e $C$ nem sabemos se eles têm elementos ou não,
ou seja, não sabemos nem se $L=\emptyset$ nem se $C=\emptyset$!
\endexample
%%}}}

\blah.
Fechando essa secção lembramos que em conjuntos (e em matemática em geral)
usamos igualdade \sq{$=$} como igualdade extensional.

\endsection
%%}}}

%%{{{ Relations between sets and how to define them 
\section Relações entre conjuntos e como defini-las.

%%{{{ df: subconjunto 
\definition.
\label{subconjunto}%
\tdefined{subconjunto}%
\tdefined{subconjunto}[próprio]%
\sdefined {\sholed A \subset \sholed B} {$A$ é um subconjunto de $B$}%
O conjunto $A$ é um \dterm{subconjunto} de $B$ sse todos os membros de
$A$ pertencem ao $B$.
Em símbolos:
$$
\align
A \subset B
&\defiff
\lforall {x\in A} {x\in B}\\
&\intiff
\forall x \paren{ x \in A \limplies x \in B }
\endalign
$$
Se $B$ tem elementos que não pertencem ao $A$, chamamos o $A$
um \dterm{subconjunto próprio} de $B$, e escrevemos $A \psubset B$.
%%}}}

%%{{{ warning: psubset_vs_nsubset_notation 
\warning.
\label{psubset_vs_nsubset_notation}%
Naturalmente escrevemos $A \nsubset B$ para a negação da $A \subset B$,
que é diferente da afirmação $A \psubset B$:
$$
\align
A \nsubset B &\intiff \text{$A$ não é um subconjunto de $B$}; \\
A \psubset B &\intiff \text{$A$ é um subconjunto próprio de $B$}.
\endalign
$$
E se quiser dizer que $A$ não é um subconjunto próprio de $B$?
Escreva isso mesmo, ou traduza para seu equivalente
(``$A \nsubset B$ ou $A = B$'')
pois ninguém merece ler algo do tipo ``$A \smartnot\psubset B$''.
%%}}}

%%{{{ x: eq_implies_subset 
\exercise.
\label{eq_implies_subset}%
$A = B \implies A \subset B$.

\solution
Suponha $A = B$.
Vamos mostrar que $A \subset B$.
Seja $x \in A$.
Mas como $A = B$, logo $x \in B$ também; que foi o que queremos provar.

\endexercise
%%}}}

%%{{{ x: eq_using_subsets 
\exercise.
\label{eq_using_subsets}%
$A = B \iff A \subset B \mland B \subset A$

\solution
\proofpart{\lrdir}.
Imediata pelo~\ref{eq_implies_subset} (pois a igualdade é simétrica).
\crtabproofpart{\rldir}.
Suponha $A \subset B$ e $B \subset A$.
Vamos mostrar que $A = B$.
Seja $x$ um objeto arbitrário.
Calculamos:
\compute
x \in A &\implies x \in B \by {def.~$A \subset B$} \\
x \in B &\implies x \in A \by {def.~$B \subset A$}
\endcompute
Ou seja,
$$
x \in A \iff x \in B
$$
que foi o que queremos demonstrar.

\endexercise
%%}}}

%%{{{ x: define_subsetneq 
\exercise.
\label{define_subsetneq}%
Defina com uma fórmula o $A\subsetneq B$.

\hint
Já definimos o $\subset$, então podemos usá-lo!

\solution
$
A \subsetneq B
\defiff
A \subset B \land A \neq B.
$
\quad
(Lembre-se que $A \neq B \abbreq \lnot(A = B)$.)

\endexercise
%%}}}

%%{{{ notation of subsets 
\beware.
O uso dos símbolos $\knuthsubseteq$, $\knuthsubset$, e $\knuthsubsetneq$ não é muito
padronizado: encontramos textos onde usam $\knuthsubseteq$ e $\knuthsubset$ para
``subconjunto'' e ``subconjunto próprio'' respectivamente;
outros usam $\knuthsubset$ e $\knuthsubsetneq$.
Assim o símbolo $\knuthsubset$ é usado com dois significados diferentes.
Por isso usamos $\subset$ e $\proper$ aqui, evitando completamente
o uso do ambíguo $\knuthsubset$.
%%}}}

%%{{{ notation: supset_sugar 
\note Notação.
\label{supset_sugar}%
Seguindo uma práctica comum que envolve símbolos ``direcionais'' de relações
binárias como os $\rightarrow$, $\leq$, $\subset$, etc., introduzimos os:
$$
\xalignat2
A \supset    B & \defiff B \subset A &
A \supsetneq B & \defiff B \subsetneq A
\endxalignat
$$
%%}}}

\endsection
%%}}}

%%{{{ Empty, universal, singletons 
\section Vazio, universal, singletons.

%%{{{ df: empty 
\definition Vazio.
\label{empty}%
\tdefined{vazio}%
Um conjunto é \dterm{vazio} sse ele não contem nenhum elemento.
Formalmente, definimos o predicado unário
$$
\Empty(A) \defiff \forall x (x \notin A).
$$
%%}}}

%%{{{ df: singleton 
\definition Singleton.
\label{singleton}%
Um conjunto é \dterm{singleton} (ou \dterm{unitário}) sse ele contem
exatamente um elemento.
Formulamente,
$$
\Singleton(A)
\defiff
\exists x
\paren{x \in A}
\mland
\lforall {u,v \in A} { u = v }.
$$
%%}}}

%%{{{ x: compare_altdef_of_singleton 
\exercise.
\label{compare_altdef_of_singleton}%
Decida se a afirmação seguinte pode servir como definição de singleton:
$$
\Singleton(A)
\askiff
\exists a
\paren{ a \in A \land \forall x \paren{ x \in A \limplies x = a } }.
$$

\hint
Substitua a fórmula longa com uma equivalente aproveitando
uns açúcares sintácticos dos quantificadores $\forall, \exists$.

\hint
Escrevemos a fórmula
$$
\exists a
\paren{ a \in A \land \forall x \paren{ x \in A \limplies x = a } }
$$
como
$$
\pexists {a \in A}
\lforall {x \in A} { x = a }.
$$

\endexercise
%%}}}

%%{{{ df: emptyset 
\definition.
\sdefined {\emptyset} {o conjunto vazio}%
\label{emptyset_symbol}%
Denotamos o conjunto vazio por $\emptyset$.
\mistake
%%}}}

%%{{{ x: what_is_wrong_with_the_emptyset_definition 
\exercise.
\label{what_is_wrong_with_the_emptyset_definition}%
Na~\ref{emptyset_symbol} roubamos!
Resolva o crime.

\hint
``o''

\solution
Como não provamos a unicidade do vazio não podemos usar o artigo
definido ``o'', e conseqüentemente, não podemos usar um símbolo
para \emph{o} denotar.  Seria mal-definido.

\endexercise
%%}}}

%%{{{ Parallelism with Singleton(-) to emphasize error 
\note.
Para apreciar ainda mais a gravidade do erro acima:
se apenas a definição de $\Empty(\dhole)$ fosse suficiente
para introduzir a notação $\emptyset$ para denotar ``o conjunto vazio'',
poderiamos também escolher um símbolo para denotar ``o conjunto unitário'':
$$
\align
\text{$\Empty(\dhole)$ definido}
&\quad\leadsto\quad \text{<<Denotamos o conjunto vazio por $\emptyset$.>>}\\
\text{$\Singleton(\dhole)$ definido}
&\quad\leadsto\quad \text{<<Denotamos o conjunto unitário por $\cancel{1}$.>>}
\endalign
$$
Qual de todos---quantos são?---os conjuntos unitários seria o $\cancel{1}$?
Essa ambigüidade não é permitida em matemática.%
\footnote{Se ainda não tá convencido, bota o artigo definido ``o'' na frase
similar <<seja $x$ (um) inteiro>>.
O que significaria se fosse <<seja $x$ \emph{o} inteiro>>?!}
%%}}}

%%{{{ x: how_many_singletons 
\exercise.
\label{how_many_singletons}%
Quantos são mesmo?

\solution
Infinitos!  Pois, para cada objeto $x$ já temos um singleton $\set{x}$.
E agora o singleton dele $\set{\set{x}}$, e dele, e dele, \dots

\endexercise
%%}}}

\blah.
Então precisamos provar existência e unicidade.
Faça isso agora nos exercícios seguintes.

%%{{{ x: naive_existence_of_emptyset 
\exercise Existência do vazio.
\label{naive_existence_of_emptyset}%
Usando as ferramentas que temos desenvolvido, construe um conjunto vazio.

\hint
Use o set-builder.

\hint
Basta achar um filtro que garante que nenhum objeto ``passa'':
$$
\setst x {\asklhole}
$$

\solution
O conjunto $\setst x {x \neq x}$ é um conjunto vazio.

\endexercise
%%}}}

%%{{{ x: naive_uniqueness_of_emptyset 
\exercise unicidade do vazio.
\label{naive_uniqueness_of_emptyset}%
\ii{unicidade!do $\emptyset$}%
Supondo que existe pelo menos um conjunto vazio, mostre sua unicidade.
Não use reductio ad absurdum.

\hint
Em outras palavras, prove que:
$$
\text{se $A,B$ são vazios, então $A = B$.}
$$

\hint
Suponha que $A,B$ são vazios.
Qual é teu alvo agora, e o que ele significa mesmo?

\hint
Teu alvo é mostrar que $A = B$.
Para fazer isso é necessário lembrar a definição de $=$ nos conjuntos (\refn{set_eq}).

\solution
Suponha que $A,B$ são vazios.
Preciso mostrar $A=B$, ou seja, que $\forall x( x\in A \liff x \in B )$.
Seja $x$ um objeto arbitrário.
Pela definição de vazio, as duas afirmações $x \in A$ e $x \in B$ são
falsas, e logo a equivalência $(x\in A \liff x\in B)$ verdadeira,
que foi o que queremos provar.

\endexercise
%%}}}

%%{{{ x: naive_uniqueness_of_emptyset_absurdum 
\exercise.
\label{naive_uniqueness_of_emptyset_absurdum}%
\ii{unicidade!do $\emptyset$}%
Ache uma prova diferente, essa vez usando reductio ad absurdum.

\hint
Suponha que $A,B$ são vazios.
Queremos mostrar que $A = B$.
Então suponha o contrário ($A \neq B$) pera chegar num absurdo.

\hint
Qual é teu alvo agora?
Achar um absurdo qualquer!
Como podemos usar o fato de $A \neq B$?
Lembre-se que $A \neq B$ é apenas uma abreviação para $\lnot(A = B)$.

\solution
Suponha que $A,B$ são vazios.
Queremos provar que $A = B$.
Para chegar num absurdo, suponha que $A \neq B$.
Logo, pela definição de igualdade, temos
que existe $x$ tal que:
$x \in A$ mas $x \notin B$; ou $x \in B$ mas $x \notin A$.
As duas alternativas chegam num absurdo:
a primeira pois $A$ é vazio e logo $x \notin A$, e similarmente
a segunda pois $B$ é vazio e logo $x \notin B$.

\endexercise
%%}}}

%%{{{ df: universal 
\definition Universal.
\tdefined{universal}[conjunto]%
\iiseealso{universo}{universal}%
\label{universal}%
Um conjunto é \dterm{universal} sse todos os objetos pertencem nele.
Formalmente,
$$
\Universal(A) \defiff \forall x(x \in A).
$$
%%}}}

%%{{{ x: naive_uniqueness_of_universet 
\exercise Existência e unicidade do universal.
\label{naive_uniqueness_of_universet}%
\ii{unicidade!do universal}%
Demonstre a existência e unicidade do conjunto universal.

\hint
Já demonstrou a existência (\ref{naive_existence_of_emptyset}) e a unicidade
(\ref{naive_uniqueness_of_emptyset} ou
\refn{naive_uniqueness_of_emptyset_absurdum})
do vazio?

\endexercise
%%}}}

%%{{{ df: universet 
\definition.
\label{universet_symbol}%
\sdefined {\universet} {o conjunto universal}%
Denotamos o conjunto universal por $\universet$.
%%}}}

%%{{{ Q: How do we use a fact that a set is nonempty? 
\question.
\label{how_do_we_use_nonempty}%
Como podemos usar um fato do tipo $D\neq \emptyset$ em nossas provas?
O que ganhamos realmente?
%%}}}
\spoiler.

%%{{{ A: We can pick an element from it! 
\blah Resposta.
Ganhamos o direito de escrever ``Seja $d\in D$.''
Em outras palavras: de tomar um elemento arbitrário de $D$;
de declarar uma variável (não usada) para denotar um membro de $D$.
%%}}}

%%{{{ warning: letting_in_empty_like_division_by_0 
\warning.
\label{letting_in_empty_like_division_by_0}%
Quando temos um conjunto $A$, escrever ``seja $x \in A$''
seria errado se não sabemos que $A \neq \emptyset$.
É um erro parecido quando dividimos uma expressão de aritmética
por $x$, ou apenas escrever uma expressão como a $a/x$,
sem saber que $x\neq 0$.
Como em aritmética precisamos separar em casos
(caso $x = 0$ e caso $x\neq 0$) e os tratar em formas diferentes,
precisamos fazer a mesma coisa trabalhando com conjuntos:
caso $A \neq \emptyset$, achamos uma prova onde podemos
realmente declarar uma variável não-usada para declarar
um elemento de $A$;
caso $A = \emptyset$, achamos uma prova
diferente---e na maioria das vezes esse caso vai ser trivial
para provar.
%%}}}

\endsection
%%}}}

%%{{{ Eight simple propositions 
\section Oito proposições simples.

%%{{{ x: yes_no_depends_emptyset_arbitraryset 
\exercise.
\label{yes_no_depends_emptyset_arbitraryset}%
Seja $A$ um conjunto.
Responda para cada uma das afirmações abaixo com
{``sim''},
{``não''}, ou
{``depende''}:
$$
\xalignat4
\emptyset &\subset \emptyset;& \emptyset &\in \emptyset; \\
\emptyset &\subset A        ;& \emptyset &\in A        ; \\
A         &\subset \emptyset;& A         &\in \emptyset; \\
A         &\subset A        ;& A         &\in A        .
\endxalignat
$$

\solution
Temos:
$$
\xalignat5
\emptyset &\subset \emptyset& &\text{(sim)}    &\qqqquad&&\emptyset &\in \emptyset&&\text{(não)} \\
\emptyset &\subset A        & &\text{(sim)}    &        &&\emptyset &\in A        &&\text{(depende)} \\
A         &\subset \emptyset& &\text{(depende)}&        &&A         &\in \emptyset&&\text{(não)} \\
A         &\subset A        & &\text{(sim)}    &        &&A         &\in A        &&\text{(depende)}.
\endxalignat
$$

\endexercise
%%}}}

%%{{{ beware: claiming yes/no/depends without proof isn't much 
\beware.
Nossa intuição muitas vezes nos engana, e por isso apenas responder no jeito
que o~\ref{yes_no_depends_emptyset_arbitraryset} pediu não vale muita coisa.
Precisamos provar todas essas respostas.  Para cada uma das oito afirmações
então, precisamos dizer:
\beginul
\li {``sim''} e \emph{provar} a afirmação;
\li {``não''} e \emph{refutar} a afirmação;
\li {``depende''} e \emph{mostrar} pelo menos dois casos:
um onde a afirmação é verdadeira, e outro onde ela é falsa.
Idealmente nesse último caso queremos determinar quando a afirmação é verdadeira,
achando condições \emph{suficientes} e/ou \emph{necessárias}.
\endul
Vamos fazer tudo isso agora.
%%}}}

%%{{{ x: attack_order 
\exercise.
\label{attack_order}%
Em qual ordem tu escolharia ``atacar'' essas afirmações?

\endexercise
%%}}}

%%{{{ property: A_notin_emptyset 
\property.
\label{A_notin_emptyset}%
Para todo conjunto $A$, $A \notin \emptyset$.
\proof.
Seja $A$ conjunto.  Agora diretamente pala definição de vazio
tomando $x\asseq A$, temos $A \notin \emptyset$.
\qed
%%}}}

%%{{{ cor: emptyset_notin_emptyset 
\corollary.
\label{emptyset_notin_emptyset}%
$\emptyset \notin \emptyset$.
\proof.
Essa afirmação é apenas um \emph{caso especial} de~\ref{A_notin_emptyset}:
tome $A \asseq \emptyset$.
\qed
%%}}}

%%{{{ x: emptyset_notin_emptyset_direct_proof 
\exercise.
\label{emptyset_notin_emptyset_direct_proof}%
Prove o~\ref{emptyset_notin_emptyset} diretamente, sem usar a~\ref{A_notin_emptyset}.

\hint
Quais noções são envolvidas nessa afirmação?
Quais são as definições delas?

\endexercise
%%}}}

%%{{{ property: A_subset_A 
\property.
\label{A_subset_A}%
Para todo conjunto $A$, temos $A \subset A$.
\proof.
Seja $A$ conjunto.  Suponha que $a \in A$.
Agora precisamos mostrar $a\in A$, algo que já temos.
\qed
%%}}}

%%{{{ x: A_subset_A_quickest_proof 
\exercise.
Pode achar uma prova com menos passos?

\solution
A fórmula que queremos provar é uma tautologia lógica!

\endexercise
%%}}}

%%{{{ cor: emptyset_subset_emptyset 
\corollary.
\label{emptyset_subset_emptyset}%
$\emptyset\subset\emptyset$.
\proof.
Caso especial da~\ref{A_subset_A} tomando $A\asseq \emptyset$,
pois $\emptyset$ é um conjunto.
\qed
%%}}}

%%{{{ property: emptyset_subset_A 
\property.
\label{emptyset_subset_A}%
Para todo conjunto $A$, temos $\emptyset \subset A$.
\sketch.
Para chegar num absurdo suponha que tem um contraexemplo:
um conjunto $A$ tal que $\emptyset\nsubset A$.
Daí achamos rapidamente o absurdo desejado lembrando a definição de $\nsubset$.
Sem usar reductio ad absurdum, vamos acabar querendo provar que uma implicação é verdadeira.
Mas cuja premissa é falsa, algo que garanta a veracidade da implicação!
\qes
%%}}}

%%{{{ x: emptyset_subset_A_does_not_imply_A_subset_A_and_vv 
\exercise.
\label{emptyset_subset_A_does_not_imply_A_subset_A_and_vv}%
Podemos ganhar a~\ref{A_subset_A} como corolário da~\refn{emptyset_subset_A}
ou vice-versa?  Explique.

\solution
Não; nenhuma das duas proposições implica a outra.
Da $A\subset A$ não podemos substituir o $A$ com nenhum conjunto para chegar na $\emptyset\subset A$.
Nem como o $\emptyset$, pois ele teria sido substituito selectivamente em apenas na sua primeira instância, algo que obviamente não podemos fazer.
(Similarmente $x = x$ para todos os números $x$ mas não podemos concluir disso que $0 = x$ para todos os $x$.)
Da $\emptyset\subset A$ não podemos chegar na $A \subset A$, pois precisamos substituir a constante $\emptyset$ por a variável $A$.
(Similarmente $0 + x = x$ para todos os números $x$, mas não podemos concluir que $x + x = x$.)

\endexercise
%%}}}

%%{{{ prop: emptyset_in_A_sometimes 
\proposition.
\label{emptyset_in_A_sometimes}%
Existe uma infinidade de conjuntos $A$ que satisfazem a $\emptyset \in A$
e uma infinidade de conjuntos $A$ que não a satisfazem.
%%}}}

%%{{{ property: A_subset_emptyset_iff_A_eq_emptyset 
\property.
\label{A_subset_emptyset_iff_A_eq_emptyset}%
O único subconjunto do $\emptyset$ é ele mesmo.
Em outras palavras:
$$
A \subset \emptyset
\iff
A = \emptyset.
$$
%%}}}

\blah.
Agora falta apenas uma afirmação para examinar: $A \in A$?

%%{{{ x: can_you_find_an_irregular_set 
\exercise.
\label{can_you_find_an_irregular_set}%
Consegues mostrar algum conjunto com a propriedade que ele pertence nele mesmo?
Ou seja, podes achar um conjunto $A$ tal que $A\in A$?

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ More set-builder 
\section Mais set-builder.
\label{full_setbuilder}%

%%{{{ blah section intro 
\blah.
Já encontramos a versão mais simples de set comprehension
(ou notação set-builder) que nos permite escrever
$$
\setstt { x } {\thole$x$\thole}
$$
onde $x$ é uma variável, e $\text{\thole$x$\thole}$
uma afirmação onde pode aparecer essa variável $x$.
Essa notação é bem mais flexível que isso.
Por exemplo
$$
\setst {p^n + x} {\text{$p$ é primo, $n$ é ímpar, e $x\in[0,1)$}}
$$
seria o conjunto de todos os números reais que podem ser escritos na forma
$p^n + x$ para algum primo $p$, algum ímpar $n$, e algum real $x$ com $0 \leq x < 1$.
\endgraf
Finalmente, mais uma extensão dessa notação é que usamos
$$
\setstt {x \in A} {\thole$x$\thole}
\defeq
\setst {x} {x \in A \mland \text{\thole$x$\thole}}.
$$
%%}}}

%%{{{ x: why_treat_x_in_A_sugar_separately 
\exercise.
\label{why_treat_x_in_A_sugar_separately}%
Por que a notação
$$
\setst {x \in A} {\text{\thole$x$\thole}}
$$
não é apenas um caso especial da notação que nos permite escrever
termos na parte esquerda de set-builder?

\hint
O ``$x \in A$'' é um termo?

\solution
Pois o ``$x \in A$'' não é um termo, mas uma proposição (afirmação).

\endexercise
%%}}}

%%{{{ x: div_mul_pow_of_12_and_m_setbuilder_practice 
\exercise.
\label{div_mul_pow_of_12_and_m_setbuilder_practice}%
Usando a notação set-builder defina os conjuntos
$D_{12}$, $M_{12}$, e $P_{12}$
de todos os divisores, todos os múltiplos, e todas as potências de $12$.
Generalize para um inteiro $m$.
Identifique quais variáveis que aparecem na tua resposta são livres e quais são ligadas.

\solution
$$
\xalignat2
D_{12} &\defeq \setst {n \in \ints} {n \divides 12}  &
D_m    &\defeq \setst {n \in \ints} {n \divides m}   \\
M_{12} &\defeq \setst {12n}  {n \in \ints}           &
M_m    &\defeq \setst {mn}   {n \in \ints}           \\
P_{12} &\defeq \setst {12^n} {n \in \nats}           &
P_m    &\defeq \setst {m^n}  {n \in \nats}
\endxalignat
$$
Onde aparece a variável \sq{$m$}, ela está livre, e
onde aparece a variável \sq{$n$}, ela está ligada.

\endexercise
%%}}}

%%{{{ x: set_builder_map_size_limit 
\exercise.
\label{set_builder_map_size_limit}%
Seja $T = \set{u,v}$ um conjunto com dois elementos $u,v$.
Definimos um conjunto $A$ pela
$$
A \defeq \setst {f(n,m)} {n,m \in T}
$$
Quantos elementos tem o $A$?

\hint
Primeiramente calcule a extensão do $A$:
$$
A = \set{ \dots?\dots }.
$$

\solution
Calculando a extensão de $A$ achamos:
$$
A = \set{ f(u,u), f(u,v), f(v,u), f(v,v) }.
$$
Então o $A$ tem \emph{no máximo} $4$ elementos---mas pode acontecer que tem menos (veja~\ref{set_builder_map_exercise}).

\endexercise
%%}}}

%%{{{ x: set_builder_map_exercise 
\exercise.
\label{set_builder_map_exercise}%
Escreva a extensão do conjunto
$$
B \defeq \setst {n^2 + m^2} {n,m \in \set{1,3}}.
$$

\solution
Calculamos:
$$
\align
B
&= \setst {n^2 + m^2} {n,m \in \set{1,3}}\\
&= \set{ 1^2 + 1^2, 1^2 + 3^2, 3^2 + 1^2, 3^2 + 3^2 }\\
&= \set{ 2, 10, 10, 18 }\\
&= \set{ 2, 10, 18 }.
\endalign
$$

\endexercise
%%}}}

%%{{{ x: rich_set_builder_sugar 
\exercise.
\label{rich_set_builder_sugar}%
Mostre como a notação ``mais rica'' de
$$
\setst {t(x_1, \dotsc, x_n)} {\phi(x_1,\dotsc,x_n)}
$$
pode ser definida como açúcar sintáctico se temos já a notação de
comprehensão que permite apénas uma variável no lado esquerdo.
Aqui considere que o $t(x_1,\dotsc, x_n)$ é um termo que pode ser
bem complexo, formado por outros termos complexos, etc., e onde
possivelmente aparecem as variáveis $x_1,\dotsc,x_n$.

\hint
Precisa descrever (definir) o conjunto
$$
\align
\setst {t(x_1, \dotsc, x_n)} {\phi(x_1,\dotsc,x_n)} &\\
\intertext{com uma notação que já temos:}
\setst {t(x_1, \dotsc, x_n)} {\phi(x_1,\dotsc,x_n)}
&\defeq
\dots?
\endalign
$$

\hint
$$
\setst {t(x_1, \dotsc, x_n)} {\phi(x_1,\dotsc,x_n)}
\defeq
\setst x {\text{\thole?\thole}}
$$

\solution
$
\setst {t(x_1, \dotsc, x_n)} {\phi(x_1,\dotsc,x_n)}
\defeq
\setst x { \exists x_1\dotsb\exists x_n \paren{ x = t(x_1,\dotsc,x_n) \land \phi(x_1,\dotsc,x_n)}}.
$

\endexercise
%%}}}

%%{{{ beware: variable-binding in set-builder 
\beware.
As variáveis que aparecem na parte esquerda de set-builder,
são \emph{ligadores}\ii{ligador}~que ligam com as correspondentes variáveis livres
que aparecem na afirmação na parte direita (filtro).
Então cuidado com o uso dessas variáveis pois é fácil escrever
algo que mesmo que realmente determina um conjunto,
não é o conjunto desejado!
%%}}}

%%{{{ x: variable_binding_in_setbuilder_exercise 
\exercise.
\label{variable_binding_in_setbuilder_exercise}%
Para cada um dos conjuntos abaixo,
decida se sua definição realmente é correta.
Caso que sim, determina a extensão do conjunto definido.
Caso que não, explique qual é o problema com a definição.
Em todas elas, considere que nosso universo é o $\reals$.
$$
\align
A &= \setstt x {$\sqrt{x^2 + 2} \mland x \in \reals$}\\
B &= \setstt x {$\sqrt{x^2 + 2}$ para algum $x\in \reals$}\\
C &= \setstt t {$\sqrt{x^2 + 2} = t$ para algum $x\in \reals$}\\
D &= \setstt x {$\sqrt{x^2 + 2} = x$ para algum $x\in \reals$}\\
E &= \setstt x {$\sqrt{x^2 + 2} = x$ para todo $x\in \reals$}\\
F &= \setstt x {$\sqrt{t^2 + 2} = x$ para todo $t\in \reals$}\\
G &= \setstt x {$\sqrt{t^2 + 2} = x$ para algum $t\in \reals$}.
\endalign
$$

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Operations on sets and how to define them 
\section Operações entre conjuntos e como defini-las.

%%{{{ Operações 
\note Operações.
Lembramos que uma operação num tipo de objetos
mapeia certos objetos desse tipo (suas entradas)
para \emph{exatamente um} objeto desse tipo (sua saída).
%%}}}

%%{{{ Definindo operações 
\note Definindo operações.
Então como podemos \emph{definir uma operação} nos conjuntos?
O que precisamos deixar claro?
\standout
\emph{Um operador é determinado por seu comportamento.}
\endstandout
Então se a ``saída'' (ou o ``resultado'') duma operação
é um conjunto, basta determinar esse conjunto para quaisquer entradas
aceitáveis pela operação.
E como determinamos um conjunto?
Para começar, podemos usar um dos jeitos que já encontramos para definir um conjunto $A$:
$$
\xalignat2
A       &\defeq \setst x {\text{\thole$x$\thole}} &
x \in A &\defiff \text{\thole$x$\thole}.
\endxalignat
$$
Bora definir umas operações conhecidas para aquecer.
%%}}}

%%{{{ df: union_def 
\definition.
\label{union_def}%
\tdefined{união}%
\sdefined {\sholed A \union \sholed B} {a união dos $A$ e $B$}%
Sejam $A,B$ conjuntos.  Definimos
$$
A \union B \defeq \setst x {\text{$x \in A$ ou $x\in B$}}
$$
Alternativamente, podemos definir a mesma operação na seguinte forma equivalente:
$$
x \in A \union B \defiff \text{$x \in A$ ou $x\in B $}.
$$
Chamamos o $A \union B$ a \dterm{união} dos $A$ e $B$.
%%}}}

%%{{{ remark: from_x_in_A_union_B_to_A_union_B_to_union 
\remark.
\label{from_x_in_A_union_B_to_A_union_B_to_union}%
Primeiramente esquematicamente:
$$
\align
\alert{x \in A \union B}           &\alertdefiff \text{$x \in A$ ou $x \in B$} \\
x \in \alert{A \union B}           &\alertdefiff \text{$x \in A$ ou $x \in B$} \\
x \in A \mathbin{\alert{\union}} B &\alertdefiff \text{$x \in A$ ou $x \in B$}.
\endalign
$$
onde colorifiquei três maneiras de entender o que é que tá sendo definido mesmo.
\endgraf
E agora com palavras:
se eu determinar o que significa que um $x$ arbitrário pertence ao
$A \union B$, então eu determinei o $A \union B$, pois ele é um conjunto e
\emph{um conjunto é determinado por seus membros;}
e como eu fiz isso para quaisquer conjuntos $A,B$ (arbitrários),
então eu determinei o $\union$, pois ele é um operador e
\emph{um operador é determinado por seu comportamento}.
Vamos voltar nesse assunto nos capítulos~\refn{Functions}
e~\refn{Axiomatic_set_theory} onde estudamos funções e teoria dos
conjuntos respectivamente.
%%}}}

%%{{{ df: inter_def 
\definition.
\label{inter_def}%
\tdefined{intersecção}%
\sdefined {\sholed A \inter \sholed B} {a intersecção dos $A$ e $B$}%
Sejam $A,B$ conjuntos.  Definimos
$$
x \in A \inter B \defiff x \in A \mland x\in B.
$$
Chamamos o $A\inter B$ a \dterm{intersecção} dos $A$ e $B$.
%%}}}

%%{{{ x: inter_altdef
\exercise.
\label{inter_altdef}%
Defina a operação $\inter$ usando a notação set-builder.

\solution
Sejam $A,B$ conjuntos.
Qualquer uma das definições seguintes serve:
$$
\align
A \inter B &\defeq \setst {x} {x \in A \mland x\in B}\\
A \inter B &\defeq \setst {x\in A} {x\in B}\\
A \inter B &\defeq \setst {x\in B} {x\in A}
\endalign
$$

\endexercise
%%}}}

%%{{{ df: disjoint_sets 
\definition.
\label{disjoint_sets}%
\tdefined{disjuntos}%
Chamamos dois conjuntos \dterm{disjuntos}
sse não têm nenhum elemento em comum.
Em símbolos,
$$
\text{$A,B$ disjuntos} \defiff A \inter B = \emptyset.
$$
%%}}}

%%{{{ beware: type_errors 
\beware Type errors.
\label{type_errors}%
Não confunda o uso dos \sq{$\defeq$} e \sq{$\defiffsymbol$} (nem dos \sq{$=$} e~\sq{$\iffsymbol$}).
Usamos o \sq{$=$} para denotar \emph{igualdade} entre dois \emph{objetos},
e usamos o \sq{$\iffsymbol$} para denotar que as \emph{afirmações} que
aparecem nos dois lados são \emph{equivalentes}.
No mesmo jeito que não podemos escrever
$$
\xalignat3
2 + 3 &\iff 5 &&\text{nem} & (x \leq y) &\;=\; (x + 1 \leq y + 1)\\
\intertext{não podemos escrer também}
A \setminus B &\iff A \inter \compl B &&\text{nem} & (A \subsetneq B) &\;=\; (A \subset B \mland A \neq B).\\
\intertext{O que queriamos escrever nesses casos seria:}
2 + 3 &= 5                           &&& x \leq y &\iff x+1 \leq y + 1\\
A \setminus B &= A \inter \compl B &&& A \subsetneq B &\iff A \subset B \mland A \neq B.
\endxalignat
$$
Caso que tudo isso não foi óbvio, sugiro revisitar o~\ref{Introduction}:
\ref{Propositions_vs_objects}, \ref{Errors}, \ref{Notation_of_fmcbook}).
%%}}}

%%{{{ remark: The rich language of sets 
\remark A linguagem rica dos conjuntos.
Observe que conseguimos traduzir a frase
``os $A,B$ não têm nenhum elemento em comum''
como uma igualdade entre dois conjuntos, o $A\inter B$
e o $\emptyset$:
$$
\text{``os $A,B$ não têm nenhum elemento em comum''}
\quad\leadsto\quad
A\inter B = \emptyset.
$$
A linguagem de conjuntos é realmente muito expressiva,
algo que vamos começar a apreciar ainda mais, na
\ref{Translating_from_and_to_the_language_of_sets}.
%%}}}

\blah.
Continuamos com mais operações, incluindo nossa primeira operação unária.

%%{{{ df: complement_def 
\definition.
\label{complement_def}%
\tdefined{complemento}%
\sdefined {\compl{\sholed A}} {o complemento de $A$}%
Seja $A$ conjunto.  Definimos
$$
\compl A \defeq \setst x {x\notin A}
$$
Chamamos o $\compl A$ o \dterm{complemento} de $A$.
%%}}}

%%{{{ df: setminus_def 
\definition.
\label{setminus_def}%
\tdefined{complemento}[relativo]%
\sdefined {\sholed A \setminus \sholed B} {o complemento relativo de $B$ no $A$}%
Sejam $A,B$ conjuntos.
$$
A \setminus B
\defeq
\setst { x\in A } {x \notin B}
$$
Chamamos o conjunto $A\setminus B$ o \dterm{complemento relativo} de $B$ no $A$,
e pronunciamos o $A\setminus B$ como <<$A$ \emph{menos} $B$>> ou <<$A$ \emph{fora} $B$>>.
%%}}}

%%{{{ x: setminus_practice 
\exercise.
\label{setminus_practice}%
Calcule (a extensão d)os conjuntos:
\beginol
\li $\set{0,1,2,3,4} \setminus \set{4,1}$
\li $\set{0,1,2,3,4} \setminus \set{7,6,5,4,3}$
\li $\set{0,1,2} \setminus \nats$
\li $\nats \setminus \set{0,1,2}$
\li $\nats \setminus \ints$
\li $\set{\set{0,1}, \set{1,2}, \set{0,2}} \setminus \set{0,1}$
\li $\set{\set{0,1}, \set{1,2}, \set{0,2}} \setminus \set{0,1,2}$
\li $\set{\set{0,1}, \set{1,2}, \set{0,2}} \setminus \set{\set{0,1,2}}$
\li $\set{\set{0,1}, \set{1,2}, \set{0,2}} \setminus \set{\set{1,2}}$
\li $\set{\set{0,1}, \set{1,2}} \setminus \set{\set{1}}$
\li $\set{7,\emptyset} \setminus \emptyset$
\li $\set{7,\emptyset} \setminus \set{\emptyset}$
\li $\reals \setminus 0$
\li $\reals \setminus \set{0}$
\li $\set{1,\set{1}, \set{\set{1}}, \set{\set{\set{1}}}} \setminus 1$
\li $\set{1,\set{1}, \set{\set{1}}, \set{\set{\set{1}}}} \setminus \set{\set{1}}$
\endol

\hint
Não siga tua intuição; siga fielmente a definição!

\solution
\beginol
\li $\set{0,1,2,3,4} \setminus \set{4,1} = \set{0,2,3}$
\li $\set{0,1,2,3,4} \setminus \set{7,6,5,4,3} = \set{0,1,2}$
\li $\set{0,1,2} \setminus \nats = \emptyset$
\li $\nats \setminus \set{0,1,2} = \set{3,4,5,6,\dotsc} = \setst {n \in \nats} {n \geq 3}$
\li $\nats \setminus \ints = \emptyset$
\li $\set{\set{0,1}, \set{1,2}, \set{0,2}} \setminus \set{0,1} = \set{\set{0,1}, \set{1,2}, \set{0,2}}$
\li $\set{\set{0,1}, \set{1,2}, \set{0,2}} \setminus \set{0,1,2} = \set{\set{0,1}, \set{1,2}, \set{0,2}}$
\li $\set{\set{0,1}, \set{1,2}, \set{0,2}} \setminus \set{\set{0,1,2}} = \set{\set{0,1}, \set{1,2}, \set{0,2}}$
\li $\set{\set{0,1}, \set{1,2}, \set{0,2}} \setminus \set{\set{1,2}} = \set{\set{0,1}, \set{0,2}}$
\li $\set{\set{0,1}, \set{1,2}} \setminus \set{\set{1}} = \set{\set{0,1}, \set{1,2}}$
\li $\set{7,\emptyset} \setminus \emptyset = \set{7,\emptyset}$
\li $\set{7,\emptyset} \setminus \set{\emptyset} = \set{7}$
\li $\reals \setminus 0 = \reals$
\li $\reals \setminus \set{0} = (-\infty,0)\union(0,+\infty)$
\li $\set{1,\set{1}, \set{\set{1}}, \set{\set{\set{1}}}} \setminus 1 = \set{1,\set{1}, \set{\set{1}}, \set{\set{\set{1}}}}$
\li $\set{1,\set{1}, \set{\set{1}}, \set{\set{\set{1}}}} \setminus \set{\set{\set{1}}} = \set{1,\set{1}, \set{\set{\set{1}}}}$
\endol

\endexercise
%%}}}

%%{{{ x: setminus_equalities_practice 
\exercise.
\label{setminus_equalities_practice}%
Sejam $A,B$ conjuntos.
Para cada uma das afirmações abaixo: prove se é verdadeira;
refuta se é falsa; mostre um exemplo e um contraexemplo
se depende nos $A,B$ (e tente determinar exatamente quando é verdadeira).
$$
\xalignat3
(1)  \quad& \emptyset \setminus \emptyset = \emptyset       &
(5)  \quad& A \setminus A = A                               &
(9)  \quad& A \setminus B = B                               \\
(2)  \quad& A \setminus \emptyset         = A               &
(6)  \quad& A \setminus A = \emptyset                       &
(10) \quad& A \setminus B                   = B \setminus A \\
(3)  \quad& \emptyset \setminus A         = \emptyset       &
(7)  \quad& A \setminus B = \emptyset                       &
(11) \quad& A \setminus \set{B}             = A             \\
(4)  \quad& \set{\emptyset} \setminus A   = \emptyset       &
(8)  \quad& A \setminus B = A                               &
(12) \quad& \set{A,B} \setminus (A\union B) = \emptyset     
\endxalignat
$$

\endexercise
%%}}}

%%{{{ df: symdiff_def 
\definition.
\label{symdiff_def}%
\tdefined{diferença simétrica}%
\sdefined {\sholed A \symdiff \sholed B} {a diferença simétrica dos $A$ e $B$}%
Sejam $A,B$ conjunto.  Definimos
$$
x \in A \symdiff B \defiff \text{$x$ pertence a exatamente um dos $A,B$}.
$$
Chamamos o $A \symdiff B$ a \dterm{diferença simétrica} dos $A$ e $B$.
%%}}}

%%{{{ eg: symdiff_example 
\example.
\label{symdiff_example}%
Calculamos os conjuntos:
\beginul
\li $\set{0,1,2,3} \symdiff \set{1,2,4,8} = \set{0,3,4,8}$
\li $\set{\set{0,1}, \set{1,2}} \symdiff \set{0,1,2} = \set{ \set{0,1}, \set{1,2}, 0, 1, 2 }$
\li $\set{\set{0,1}, \set{1,2}} \symdiff \set{\set{0,1},\set{0,2}} = \set{ \set{0,2}, \set{1,2} }$
\li $(-2,1) \symdiff (-1,2) = (-2,-1] \union [1,2)$
\endul
\endexample
%%}}}

%%{{{ x: what_is_A_symdiff_A_and_A_symdiff_emptyset 
\exercise.
\label{what_is_A_symdiff_A_and_A_symdiff_emptyset}%
Dado $A$ conjunto, calcule os conjuntos $A\symdiff A$ e $A \symdiff \emptyset$.

\endexercise
%%}}}

%%{{{ An intuition about symmetric difference 
\note Uma intuição sobre a diferença simétrica.
Pensando pouco nas definições de
$$
A \symdiff B
\qqqqtext{e}
A = B
$$
concluimos que a diferença simétrica de dois conjuntos tem exatamente
todas as \dterm{testemunhas}\ii{testemunha}\ que mostram que
os conjuntos são diferentes.
O que podes concluir então assim que souberes que $A \symdiff B = \emptyset$?
(Veja o~\ref{when_A_symdiff_B_is_empty}.)
%%}}}

%%{{{ Venn_diagrams 
\note Diagramas de Venn.
\label{Venn_diagrams}%
\tdefined{diagrama de Venn}%
O leitor provavelmente já encontrou os \dterm{diagramas de Venn}\Venn{} na sua vida,
uma ferramenta muito útil para descrever operações e ajudar em raciocinar sobre
relações de conjuntos.
Por exemplo, podemos visualizar as quatro operações binárias que definimos até agora
assim:
$$
\xalignat4
A\union B:
&\quad
\gathered
\tikzpicture
\tikzi venn2union;
\endtikzpicture
\endgathered
&
A\inter B:
&\quad
\gathered
\tikzpicture
\tikzi venn2inter;
\endtikzpicture
\endgathered
\\
A \setminus B:
&\quad
\gathered
\tikzpicture
\tikzi venn2setminus;
\endtikzpicture
\endgathered
&
A \symdiff B:
&\quad
\gathered
\tikzpicture
\tikzi venn2symdiff;
\endtikzpicture
\endgathered
\endxalignat
$$
E a única operação unária, o complemento, assim:
$$
\align
\compl A:
&\quad
\gathered
\tikzpicture
\tikzi venn1compl;
\endtikzpicture
\endgathered
\endalign
$$
%%}}}

%%{{{ Venn_diagrams_limitations 
\beware Limitações de Venn.
Assim que tiver mais que três conjuntos os diagramas de
Venn perdem sua clareza e logo sua utilidade.
%%}}}

%%{{{ x: Venn_4_what_is_wrong 
\exercise.
\label{Venn_4_what_is_wrong}%
Um aluno desenhou o seguinte diagrama Venn para representar todas as
possíveis maneiras que $4$ conjuntos $A,B,C,D$ podem intersectar entre si:
$$
\tikzpicture
\tikzi venn4wrong;
\endtikzpicture
$$
Qual o problema com esse diagrama?

\hint
$$
\tikzpicture
\tikzi venn4wrongmarked;
\endtikzpicture
$$
Contamos $14$ regiões.
Qual o problema?

\solution
Temos $4$ conjuntos; e como cada objeto pode ou pertencer ou não pertencer
a cada um deles, temos no total $2^4=16$ distintas configurações.
Mas no diagrama do aluno aparecem apenas $14$:
$$
\tikzpicture
\tikzi venn4wrongmarked;
\endtikzpicture
$$
Logo tem duas configurações então que não são representadas por nenhuma parte do diagrama.
São essas:
$$
\gather
x \in A \mland x \notin B \mland x \in C \mland x \notin D \\
x \notin A \mland x \in B \mland x \notin C \mland x \in D.
\endgather
$$

\endexercise
%%}}}

%%{{{ x: Venn_4_correct 
\exercise.
\label{Venn_4_correct}%
Tem como desenhar um correto?

\hint
Esqueça a idéia de usar $4$ cíclos.

\hint
Começa assim:
$$
\tikzpicture
\tikzi venn4correcthint;
\endtikzpicture
$$

\solution
Uma maneira de dezenhá-lo seria assim:
$$
\tikzpicture
\tikzi venn4correct;
\endtikzpicture
$$
Se tu achou outra e realmente tem todas as $16$ configurações possíveis,
tá tranqüilo!

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Proving equalities and inclusions 
\section Provando igualdades e inclusões.

%%{{{ x: simple_inclusion_practice_proof 
\exercise.
Prove ou refute a afirmação:
$$
\text{para todos os conjuntos $A,B,C$,
se $A \subset B \mland A \subset C$ então $A \subset B \inter C$}.
$$

\solution
Vou provar a afirmação.
\endgraf
Suponha que $A \subset B$ e $A \subset C$.
Tome um $a \in A$.  Precisamos mostrar que $a \in B \inter C$.
Como $a \in A$ e $A \subset B$, temos $a \in B$;
e como $a \in A$ e $A \subset C$, temos $a \in C$.
Logo $a \in B\inter C$, pela definição de $B\inter C$.

\endexercise
%%}}}

%%{{{ x: simple_inclusion_practice_refutation 
\exercise.
Prove ou refute a afirmação:
$$
\text{para todos os conjuntos $A,B,C$,
se $A \subsetneq B \mland A \subsetneq C$, então $A \subsetneq B \inter C$.}
$$

\solution
Vou refutar a afirmação com um contraexemplo.
Tome
$$
\align
A &\asseq \set { 2 }\\
B &\asseq \set { 1,2 }\\
C &\asseq \set { 2,3 }.
\endalign
$$
Realmente $A \subsetneq B$ e $A \subsetneq C$, mas mesmo assim $A = B\inter C$.

\endexercise
%%}}}

%%{{{ prop: set_de_morgan 
\proposition.
\label{set_de_morgan}%
\ii{dualidade}%
Para todos os conjuntos $A,B,C$,
$$
\align
C \setminus (A \union B) &= (C \setminus A) \inter (C \setminus B)\\
C \setminus (A \inter B) &= (C \setminus A) \union (C \setminus B).
\endalign
$$
\proof \proofname~(usando fórmulas).
Sejam $A,B,C$ conjuntos.  Temos:
\compute
x \in C \setminus (A \union B)
&\iff x \in C \land \lnot (x \in A \union B)                       \by {def.~$\setminus$}
&\iff x \in C \land \lnot (x \in A \lor x \in B)                   \by {def.~$\union$}
&\iff x \in C \land (x \notin A \land x \notin B)                  \by {De Morgan}
&\iff (x \in C \land x \notin A) \land (x \in C \land x \notin B)  \by {lógica}
&\iff (x \in C \setminus A) \land (x \in C \setminus B)            \by {def.~$\setminus$}
&\iff x \in (C \setminus A) \inter (C \setminus B)                 \by {def.~$\inter$}
\endcompute
Logo
$
C \setminus (A \union B)
=
(C \setminus A) \inter (C \setminus B)
$
pela definição de igualdade de conjuntos.
A prova da outra igualdade é similar:
trocamos apenas os $\union$ com os $\inter$, e os $\lor$ com os $\land$!
\qed
%%}}}

%%{{{ x: set_de_morgan_nat_lang 
\exercise.
Escreva uma prova em linguagem natural da~\ref{set_de_morgan}.

\solution
Mostramos as duas inclusões separadamente:
\endgraf
\lrdirset:
Tome $x \in C \setminus (A \union B)$.
Daí $x \in C$ e $x \notin (A \union B)$, ou seja $x\notin A$ e $x \notin B$.
Como $x \in C$ e $x\notin A$, temos $x\in C\setminus A$, e,
similarmente $x\in C\setminus B$.
Logo chegamos no desejado $x\in (C\setminus A) \inter (C\setminus B)$.
\endgraf
A inclusão inversa \rldirset\ é similar.

\endexercise
%%}}}

%%{{{ prop: symdiff_altdef1 
\proposition.
Sejam $A,B$ conjuntos.  Logo,
$$
A \symdiff B
=
(A \setminus B) \union (B \setminus A).
$$
\sketch.
Antes de começar, traduzimos os dois lados:
<<em exatamente um dos dois>> na esquerda,
<<no primeiro mas não no segundo ou no segundo mas não no primeiro>> na direita.
Faz sentido que os dois conjuntos são iguais, pois as duas frases são equivalentes!
Mas para provar formalmente a afirmação, mostramos as duas direções
$$
\xalignat3
A \symdiff B &\subset (A \setminus B) \union (B \setminus A) && \mland &
A \symdiff B &\supset (A \setminus B) \union (B \setminus A)
\endxalignat
$$
separadamente, usando as definições de $\subset$ e $\supset$.
\qes
%%}}}

%%{{{ prop: symdiff_altdef2 
\proposition.
Sejam $A,B$ conjuntos.  Logo,
$$
A \symdiff B
=
(A \union B) \setminus (A \inter B).
$$
\sketch.
Novamente, começamos pensando nos dois lados e suas intensões:
<<em exatamente um dos dois>> na esquerda;
<<em pelo menos um dos dois, mas não nos dois>> na direita.
As duas frases são equivalentes, mas vamos mostrar formalmente
a igualdade desses conjuntos, mostrando novamente as
``$\subset$'' e ``$\supset$'' separadamente.
\qes
%%}}}

%%{{{ remark: we could have defined symdiff elsehow 
\remark.
No~\refn{symdiff_def} eu dei uma definição elementária,
para determinar o conjunto $A\symdiff B$.
De fato, seria até melhor \emph{definir} a operação $\symdiff$ usando uma das
duas expressões que encontramos acima.
%%}}}

%%{{{ x: when_A_symdiff_B_is_empty 
\exercise.
\label{when_A_symdiff_B_is_empty}%
Prove ou refute a afirmação:
$$
\text{para todo conjunto $A,B$,
se $A\symdiff B = \emptyset$,
então $A = B$}.
$$

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Cardinality 
\section Cardinalidade.

%%{{{ df: naive_cardinality 
\definition.
\label{naive_cardinality}%
\tdefined{cardinalidade}[ingenuamente]%
\sdefined {\card {\sholed A}} {a cardinalidade de $A$}%
Seja $A$ um conjunto.
A \dterm{cardinalidade} de $A$ é a quantidade de elementos de $A$.
A denotamos por $\card A$:
$$
\card A \defeq \knuthcases{
    n,      & se $A$ é finito com exatamente $n$ membros distintos\cr
    \infty, & se $A$ é infinito.
}
$$
%%}}}

\blah.
Nos capítulos~\refn{Cantors_paradise} e~\refn{Axiomatic_set_theory}
vamos \emph{refinar} essa notação pois como \Cantor{}Cantor percebeu,
o segundo caso na~\ref{naive_cardinality} é \emph{bem}, \emph{bem}, \emph{bem}
mais rico do que aparece!

%%{{{ property: cardinality_of_union_of_finite_sets 
\property.
\label{cardinality_of_union_of_finite_sets}%
Sejam $A,B$ conjuntos finitos.
Logo
$$
\card{A\union B} \leq \card A + \card B.
$$
\proof.
Pelo princípio da inclusão--exclusão
(\refn{Inclusion_exclusion_principle})
temos
$$
\card{A\union B} = \card A + \card B - \card{A \inter B}
$$
e como uma cardinalidade não pode ser negativa, segue a desigualdade desejada.
\qed
%%}}}

%%{{{ x: cardinality_of_union_of_disjoint_finite_sets 
\exercise.
\label{cardinality_of_union_of_disjoint_finite_sets}%
Determine quando temos \sq{$=$} na desigualdade
da~\ref{cardinality_of_union_of_finite_sets}.

\solution
Exatamente quando $A,B$ são disjuntos.
Em símbolos,
$$
\card{A\union B} = \card A + \card B
\iff
A \inter B = \emptyset.
$$

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Powerset 
\section Powerset.

%%{{{ df: powerset_def 
\definition.
\label{powerset_def}%
\tdefined{powerset}%
\iisee{conjunto}[de partes]{powerset}%
\sdefined {\pset{\sholed A}} {o powerset de $A$ (conjunto de partes)}%
Seja $A$ conjunto.
Chamamos o \dterm{powerset} (ou \dterm{conjunto de partes}, ou
\dterm{conjunto potência}) de $A$,
denotado por $\pset A$, é o conjunto de todos os subconjuntos de $A$.
Formalmente:
$$
X \in \pset A \defiff X \subset A.
$$
%%}}}

%%{{{ x: cardinality_of_poweset_of_finite_set 
\exercise.
\label{cardinality_of_poweset_of_finite_set}%
Seja $A$ conjunto finito.  Qual a cardinalidade do $\pset A$?

\solution
Já resolvemos isso na~\ref{Number_of_subsets}!
Concluimos que:
$$
\card{\pset A} = 2^{\card A}.
$$

\endexercise
%%}}}

%%{{{ df: subset_setbuilder 
\definition Mais set-builder.
\label{subset_setbuilder}%
Dado conjunto $A$, introduzimos a notação
$$
\setst {X \subset A} { \phi(X) }
\defeq
\setst {X \in \pset A} { \phi(X) }.
$$
%%}}}

%%{{{ x: calculating_powersets 
\exercise.
Calcule (ache a extensão d)os conjuntos seguintes:
$$
\pset\set{1, 2}
\qquad \pset\set{a,b,\set{a,b}},
\qquad \pset\set{\emptyset,\set{\emptyset}},
\qquad \pset\set{\nats}.
$$

\endexercise
%%}}}

%%{{{ x: iterate_pset_on_emptyset 
\exercise.
\label{iterate_pset_on_emptyset}%
Calcule os conjuntos seguintes:
$$
\pset\emptyset,
\qquad
\pset\pset\emptyset,
\qquad
\pset\pset\pset\emptyset.
$$

\solution
Calculamos pela definição de $\pset$:
$$
\align
\pset\emptyset &= \set { \emptyset }\\
\pset\pset\emptyset &= \set { \emptyset, \set{\emptyset} }\\
\pset\pset\emptyset &= \set { \emptyset, \set{\emptyset}, \set{\set{\emptyset}}, \set{\emptyset, \set{\emptyset}} }
\endalign
$$

\endexercise
%%}}}

%%{{{ x: powersingletons 
\exercise.
Defina usando duas maneiras diferentes um operador unário $\pset_1$
que forma o conjunto de todos os \emph{singletons} feitos por membros
da sua entrada.

\solution
Qualquer uma das duas definições serve:
$$
\align
\pset_1 A &\defeq \setst {\set{a}} {a \in A} \\
\pset_1 A &\defeq \setst {X \subset A} {\Singleton(X)}.
\endalign
$$

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Big union; big intersections 
\section União grande; intersecção grande.

%%{{{ intro 
\blah.
Generalizamos agora as operações binárias de união e intersecção para suas
versões arbitrárias, as operações unitárias $\Union\dhole$ e $\Inter\dhole$.
Antes de dar uma definição, mostramos uns exemplos.
Esses operadores são mais interessantes e úteis quando são aplicados em
conjunto cujos membros são conjuntos também, pois---coloquiamente
falando---eles correspondem na união e na intersecção dos seus membros.
%%}}}

%%{{{ eg: Union_Inter_example 
\example.
\label{Union_Inter_example}%
Aplicamos as operações $\Union$ e $\Inter$ nos conjuntos seguintes:
$$
\align
\Union \set{ \set{1,2,4,8}, \set{0,2,4,6}, \set{2,10} } &= \set{0,1,2,4,6,8,10}\\
\Inter \set{ \set{1,2,4,8}, \set{0,2,4,6}, \set{2,10} } &= \set{2}\\
\Union \set{ \nats, \ints, \rats, \reals }              &= \reals\\
\Inter \set{ \nats, \ints, \rats, \reals }              &= \nats\\
\Union \set{ 2, 3, \set{4,5}, \set{4,6} }               &= \set{4,5,6}\\
\Inter \set{ 2, 3, \set{4,5}, \set{4,6} }               &= \emptyset
\endalign
$$
\endexample
%%}}}

%%{{{ from_binary_connectives_to_quantifiers 
\note De conectivos binários para quantificadores.
\label{from_binary_connectives_to_quantifiers}%
Considere a afirmação:
$$
\text{<<Alex comeu manga ou Babis comeu manga.>>}
$$
Naturalmente essa proposição corresponde numa disjunção:
$$
\mubraceleg {\text{Alex comeu manga}} {\phi(\mathrm{Alex})}
\mubraceleg {\text{ou}} {\lor}
\mubraceleg {\text{Babis comeu manga}} {\phi(\mathrm{Babis})}.
$$
Dualmente (trocando o ``ou'' por ``e'') chegamos numa conjunção:
$$
\mubraceleg {\text{Alex comeu manga}} {\phi(\mathrm{Alex})}
\mubraceleg {\text{e}} {\land}
\mubraceleg {\text{Babis comeu manga}} {\phi(\mathrm{Babis})}.
$$
E agora a pergunta:
%%}}}

%%{{{ Q: How can you express those with exists and forall? 
\question.
Como podemos descrever cada uma das
$$
\xalignat2
&\paren{\phi(A) \lor  \phi(B)} &
&\paren{\phi(A) \land \phi(B)}
\endxalignat
$$
(que são uma disjunção e uma conjunção) como uma fórmula
que começa com quantificador?
%%}}}
\spoiler.

%%{{{ A: like this 
\note Resposta.
Assim!:
$$
\align
\paren{\phi(A) \lor  \phi(B)} & \iff \lexists {x \in \set{A,B}} {\phi(x)} \\
\paren{\phi(A) \land \phi(B)} & \iff \lforall {x \in \set{A,B}} {\phi(x)}.
\endalign
$$
Com palavras pouco mais humanas:
$$
\gather
\text{<<alguem dos $A,B$ comeu manga>>} \\
\text{<<todos os $A,B$ comeram manga>>}.
\endgather
$$
%%}}}

%%{{{ Q: How would you define Union and Inter? 
\question.
Como tu definarias as $\Union$ e $\Inter$ formalmente então?
Podes adivinhar definições que concordam com todos esses exemplos no
\refn{Union_Inter_example}?
%%}}}
\spoiler.

\blah.
Observe pela definição de $\union$ temos
%%{{{ pre-Union_def
\compute
x \in A \union B
&\iff x \in A \mlor  x \in B \\
&\iff \text{$x$ pertence a algum dos $A, B$} \\
&\iff \lexists {X \in \set{A,B}} {x \in X}
\intertext{e dualmente para a intersecção:}
x \in A \inter B
&\iff x \in A \mland x \in B \\
&\iff \text{$x$ pertence a cada um dos $A, B$} \\
&\iff \lforall {X \in \set{A,B}} {x \in X}.
\endcompute
%%}}}
Chegamos assim na resposta formal:

%%{{{ df: Union_def 
\definition.
\label{Union_def}%
\label{Inter_def}%
\tdefined{união}[grande]%
\tdefined{intersecção}[grande]%
\sdefined {\Union \sholed {\scr A}} {a união de $\scr A$}%
\sdefined {\Inter \sholed {\scr A}} {a intersecção de $\scr A$}%
Seja $\scr A$ um conjunto.
$$
\align
x \in \Union \scr A
&\defiff
\text{$x$ pertence a algum dos membros do $\scr A$}\\
x \in \Inter \scr A
&\defiff
\text{$x$ pertence a todos os membros do $\scr A$}.
\intertext{Equivalentemente com fórmulas,}
x \in \Union \scr A
&\defiff
\lexists {A \in \scr A} {x \in A}\\
x \in \Inter \scr A
&\defiff
\lforall {A \in \scr A} {x \in A}.
\endalign
$$
Chamamos o $\Union\scr A$ a \dterm{união} de $\scr A$, e o $\Inter\scr A$
a \dterm{intersecção} de $\scr A$.
%%}}}

%%{{{ x: union_and_inter_from_Union_and_Inter_sugar 
\exercise.
\label{union_and_inter_from_Union_and_Inter_sugar}%
Defina os operadores binários $\union$ e $\inter$ como açúcar sintáctico
definido pelos operadores unários $\Union$ e $\Inter$ respectivamente.

\solution
Sejam $A,B$ conjuntos.
Botamos
$$
\xalignat2
A \union B &\defeq \Union\set{A,B} &
A \inter B &\defeq \Inter\set{A,B}.
\endxalignat
$$

\endexercise
%%}}}

%%{{{ x: iterate_Union_on_emptyset 
\exercise.
\label{iterate_Union_on_emptyset}%
Calcule os conjuntos:
$\Union \emptyset$;
$\Union\Union \emptyset$.

\endexercise
%%}}}

%%{{{ x: Inter_emptyset 
\exercise.
\label{Inter_emptyset}%
Calcule o $\Inter\emptyset$.

\hint
Siga a definição e nada mais!

\solution
Por enquanto a resposta correta é $\Inter\emptyset = \universet$.
Mas ``stay tuned'' pois isso vai mudar no~\ref{Axiomatic_set_theory}.
Em geral $\universet$ não é o que queremos, então vamo tomar cuidado
para verificar que uma família de conjuntos não é vazia antes de
considerar sua intersecção!

\endexercise
%%}}}

%%{{{ x: Inter_universet 
\exercise.
\label{Inter_universet}%
Calcule o $\Inter\universet$.

\hint
Siga a definição e nada mais!

\hint
$\Inter\universet = \emptyset$.
Por quê?

\endexercise
%%}}}

%%{{{ x: Union_and_Inter_of_singleton 
\exercise.
\label{Union_and_Inter_of_singleton}%
Seja $A$ conjunto.
Calcule os $\Union\set{A}$ e $\Inter\set{A}$.

\endexercise
%%}}}

%%{{{ x: Inter_of_supsets_supset 
\exercise.
\label{Inter_of_supsets_supset}%
Sejam $C$ conjunto e $\scr A$ família de conjuntos tais que todos
contêm o $C$ (ou seja, $C$ é um subconjunto de cada membro da $\scr A$).
Prove que $C \subset \Inter \scr A$.

\solution
Seja $c \in C$.
Para mostrar que $c \in \Inter \scr A$, seja $A \in \scr A$ e agora
basta mostrar que $c \in A$.
Mas pela definição de $\scr A$ sabemos que $A \supset C$.
Logo $c \in A$.

\endexercise
%%}}}

%%{{{ x: Inter_is_contained_in_every_member 
\exercise.
\label{Inter_is_contained_in_every_member}%
Seja $\scr A$ família não vazia de conjuntos.
Prove que $\Inter \scr A$ é contido em todo membro da $\scr A$.

\solution
Seja $A \in \scr A$.
Para provar que $\Inter \scr A \subset A$, tome $x \in \Inter \scr A$.
Basta mostrar que $x \in A$.
Logo $x$ pertence a todos os membros da $\scr A$, e logo $x \in A$ também,
que foi o que precisamos provar.

\endexercise
%%}}}

%%{{{ note: intuition_about_Inter_Union_powerset_and_set_braces 
\note.
\label{intuition_about_Inter_Union_powerset_and_set_braces}%
Bem, bem, bem informalmente podemos dizer que: a operação $\Union$ tire o nível
mais externo de chaves; a $\Inter$ também mas jogando fora bem mais elementos
(aqueles que não pertencem em todos os membros do seu argumento); e o $\pset$
bote todas as chaves em todas as combinações possíveis para ``o nível mais
próximo''.
%%}}}

%%{{{ x: scr_A_might_not_contain_union 
\exercise.
\label{scr_A_might_not_contain_union}%
Sejam $A$ conjunto e $\scr A \subset \pset A$ tal que
$$
\Union \scr A = A.
$$
A afirmação
$$
A \in \scr A
$$
é verdadeira?
Se sim, demonstre; se não, refute;
se os dados não são suficientes para concluir,
mostre um exemplo e um contraexemplo.

\hint
Depende: ache um exemplo e contra exemplo.

\solution
\proofpart{Exemplo.}
Tome
$$
\align
A        &= \set {1, 2} \\
\scr A   &= \set {\set{1}, \set{1, 2} } \subset \pset A.
\endalign
$$
Observe que realmente $\Union \scr A = A$
e que $A \in \scr A$.
\crproofpart{Contraexemplo.}
Tome
$$
\align
A        &= \set {1, 2} \\
\scr A   &= \set {\set{1}, \set{2} } \subset \pset A.
\endalign
$$
Observe que realmente $\Union \scr A = A$
mas mesmo assim $A \notin \scr A$.

\endexercise
%%}}}

%%{{{ x: card_of_set_its_Union_and_its_Inter_comparison 
\exercise.
\label{card_of_set_its_Union_and_its_Inter_comparison}%
Ache conjuntos finitos $A,B$ tais que
$$
\xalignat2
&0 < \card { \Inter A } < \card A < \card { \Union A } &
&0 < \card B < \card { \Inter B } < \card { \Union B }.
\endxalignat
$$

\solution
Tome
$$
\xalignat2
A &\asseq \set{ \set{ 1,2,3 },   \set{ 3,4,5 }   } &&(0 < 1 < 2 < 4)\\
B &\asseq \set{ \set{ 1,2,3,4 }, \set{ 2,3,4,5 } } &&(0 < 2 < 3 < 5).
\endxalignat
$$

\endexercise
%%}}}

%%{{{ x: inter_subset_union_for_nondisjoint_families 
\exercise.
Sejam $\scr A, \scr B$ famílias de conjuntos
com $\scr A \inter \scr B \neq \emptyset$.
Prove ou refute a afirmação:
$$
\Inter\scr A \subset \Union\scr B.
$$

\hint
A afirmação é verdadeira.  Prove!

\hint
O teu alvo é provar que um conjunto está contido em outro.
Como atacamos isso?

\hint
Como usarás a hipótese $\scr A \inter \scr B \neq \emptyset$?

\hint
Use as definições de $\Inter$ e $\Union$.

\solution
Vamos provar a afirmação.
Suponha $x \in \Inter\scr A$\fact1.
Para mostrar que $x \in \Union\scr B$, basta achar um membro da $\scr B$ em que o $x$ pertence.
Seja $W \in \scr A \inter \scr B$ (sabemos que $\scr A \inter \scr B \neq \emptyset$).
Logo $W \in \scr A$\fact2~e $W \in \scr B$ (def.~$\inter$).
Pelas \byfact1,\byfact2 temos $x\in W$,
e como $W \in \scr B$, temos o desejado $x \in \Union\scr B$.
\endgraf
(Obs.: demonstramos assim um $W$ tal que
$\Inter\scr A \subset W \subset \Union\scr B$.)

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Tuples 
\section Tuplas.
\label{Tuples}%

\blah.
Começamos com a idéia de \dterm{par ordenado}, ou seja,
um par de objetos onde um deles é considerado primeiro
e o outro segundo.
Naturalmente, podemos generalizar a idéia de par ordenado,
cujo tamanho é $2$, para um conceito correspondente de tamanho $n$,
onde $n$ é qualquer número natural.  Oi, tuplas!

%%{{{ Notation and terminology 
\note Notação e terminologia.
Denotamos o par ordenado dos objetos $a$ e $b$ pelo $\tupa{a, b}$
ou $\tupp{a, b}$.
Em geral, usamos as notações $\tupa{a_0, a_1, \dotsc, a_{n-1}}$
e~$\tupp{a_0, a_1, \dotsc, a_{n-1}}$ para tuplas de tamanho~$n$.
Às vezes é mais legível usar índices começando com $1$---tanto faz.
Quando queremos enfatizar o tamanho da tupla, falamos de
\dterm{$n$-tupla}.
Assim, um par ordenado é uma $2$-tupla.
\emph{Às vezes} escolhemos como nome duma tupla uma variável
decorada com uma setinha em cima dela, e usando a mesma
letra com índices para seus membros, por exemplo
$\vec x = \tup{x_0,x_1,\dotsc,x_n}$, $\vec w = \tup{w_1,w_2}$, etc.
Outra convençao comum é usar uma fonte em ``negrito'', por exemplo
$\mathbf{a} = \tup{a_1,a_2,a_3}$, $\mathbf{u} = \tup{u_0,u_1}$, etc.
%%}}}

%%{{{ tuples_interface_and_equality 
\note Interface e igualdade.
\label{tuples_interface_and_equality}%
Precisamos: (1) descrever qual é o ``interface primitivo'' desse novo
tipo, em tal forma que deixamos claro o que precisamos definir
para determinar uma tupla; e (2) o que significa $=$ entre tuplas.
Nossa única interface dada uma tupla de tamanho $n$, é que podemos
pedir seu $i$-ésimo elemento, onde $0 \leq i < n$.
Conversamente, para definir uma tupla de tamanho $n$, basta
determinar todos os objetos (distintos ou não) nas suas $n$ posições.
Consideramos que duas tuplas são iguais sse elas
``concordam em cada posição''.
Sem aspas, chegamos nas definições:
%%}}}

%%{{{ df: tuple_projections 
\definition Projecções.
\label{tuple_projections}%
Definimos as operações $\pi_i$ chamadas \dterm{projecções}, tais que
para todos os $x,y$, temos
$$
\xalignat2
\proj 0 \tup{x,y} &= x &
\proj 1 \tup{x,y} &= y
\endxalignat
$$
e similarmente para tuplas de tamanho $n$.
Quando o $n$ não é implícito pelo contexto, decoramos
esses símbolos com essa informação para evitar confusão.
Por exemplo:
$$
\xalignat4
\projfrom 2 1 \tup{x,y}                 &= y ; &
\projfrom 3 1 \tup{x_1,x_2,x_3}         &= x_2 ; &
\projfrom 5 4 \tup{x_2,x_3,y_1,x_8,y_0} &= y_0 ; &
\text{etc.}
\endxalignat
$$
%%}}}

%%{{{ remark: Alternative notations 
\remark Notações alternativas.
Outros nomes para as projecções $\proj 0$ e $\proj 1$ são:
$$
\tproj0,\ \tproj1,\ \dotsc;
\qquad
\pproj0 {\dhole},\ \pproj1 {\dhole},\ \dotsc;
\qquad
\fst,\ \snd;
\qquad
\outl,\ \outr.
$$
Em vez de decorar os símbolos das projecções com índices começando
no $0$, as vezes é mais útil começar no $1$.  Mas não se preocupe
tanto com isso pois pelo contexto vai sempre ser claro qual é a
notação seguida.
%%}}}

%%{{{ df: tuples_equality 
\definition Igualdade.
\label{tuples_equality}%
Definimos
$$
\align
\tup{x,y} = \tup{x',y'}
&\defiff
x = x' \mland y = y'
\intertext{Generalizando,}
\tup{a_1,\dotsc,a_n} = \tup{b_1,\dotsc,b_m}
&\defiff
m = n
\mland
\text{$a_i = b_i$ para todo $i\in\set{0,\dotsc,n}$}
\endalign
$$
%%}}}

%%{{{ Do we need bigger tuples? 
\note Precisamos tuplas maiores?.
Introduzimos então esse novo \emph{tipo primitivo} de $2$-tuplas.
E se precisar uma tripla?  Precisamos escolher se vamos aceitar
mais tipos como primitivos ($3$-tuplas (triplas), $4$-tuplas,
(quadruplas), $5$-tuplas (quintuplas), etc., etc.) ou não.
\endgraf
Caso que sim, vamos precisar uma $n$-upla para cada $n\in\nats$.
E precisamos definir a igualdade para cada um desses tipos,
algo que fazemos facilmente com:
$$
\tup{x_1, \dots, x_n}
=
\tup{x'_1, \dots, x'_n}
\defiff
x_1 = x'_1
\mland \cdots \mland
x_n = x'_n.
$$
Naturalmente dizemos que uma $n$-tupla $t$ é \emph{determinada
por os objetos em cada uma das suas $n$ posições}.
Então para definir uma $n$-tupla basta só definir as
$$
\projfrom n 0 t,
\projfrom n 1 t,
\dotsc,
\projfrom n {n-1} t.
$$
\endgraf
E caso contrário?  Será que podemos utilizar apenas as $2$-tuplas
para conseguir o que nossos amigos que trabalham com $n$-tuplas como
tipos primitivos conseguem?
A resposta é sim.
Vamos investigar.
%%}}}

%%{{{ Q: How would you define $n$-tuples for n > 2, given 2-tuples? 
\question.
Como tu definarias os tipos de $n$-tuplas para $n>2$, dado um tipo
de $2$-tuplas?
%%}}}
\spoiler.

%%{{{ x: tuples_of_size_2_are_good_for_3 
\exercise.
\label{tuples_of_size_3_are_good_for_3}%
Mostre que com a definição de
$$
\tup{x,y,z} \defeq \tup{x,\tup{y,z}}
$$
conseguimos a igualdade \emph{desejada}
$$
\tup{x,y,z} = \tup{x',y',z'}
\iff x = x' \mland y = y' \mland z = z'.
$$
Cuidado: é um \sq{$\iffsymbol$} acima, não um \sq{$\defiffsymbol$}!
Ou seja, definindo as $3$-tuplas nessa maneira, querendo
ou não, a igualdade entre seus objetos já é definida!
Não teriamos o direito de defini-la novamente!

\solution
Calculamos
\compute
\tup{x,y,z} = \tup{x',y',z'}
&\sugariff \tup{x,{y,z}} = \tup{x',\tup{y',z'}} \\
&\iff x = x' \mland \tup{y,z} = \tup{y',z'}     \by {def.~de~$=$~para $2$-tuplas}
&\iff x = x' \mland y = y' \mland z = z'.       \by {def.~de~$=$~para $2$-tuplas}
\endcompute
que é exatamente o que desejamos mostrar!

\endexercise
%%}}}

%%{{{ df: n_tuples_based_on_2_tuples 
\definition.
\label{n_tuples_based_on_2_tuples}%
Seja $n\in\nats$ com $n > 2$.
Dados $n$ objetos $x_1,x_2,\dotsc,x_n$ definimos a $n$-tupla
$$
\tup{x_1, x_2, \dotsc, x_n}
\defeq
\tup{x_1, \tup{x_2, \dotsc, x_n}}.
$$
%%}}}

%%{{{ Tuples of extreme sizes 
\note Tuplas de tamanhos extremos.
O que seria uma $1$-tupla?
E, pior ainda, o que seria uma $0$-tupla?
E uma tupla infinita?
Vamos responder apenas na primeira pergunta agora.
Os outros dois casos vamos discutir logo depois:
sobre a(s?)\ $0$-tupla(s?)\ aqui e na \refn{Cartesian_product}
onde introduzimos o \emph{produto cartesiano};
e sobre tuplas infinitas nas \refn{Sequences} e
\refn{Indexed_families} onde conhecemos \emph{seqüências}
e \emph{famílias indexadas} respectivamente.
%%}}}

%%{{{ df: tuples_of_size_1 
\definition Tuplas de tamanho 1.
\label{tuples_of_size_1}%
Observe que escolhendo definir a $1$-tupla como
$$
\tup{x} \defeq x
$$
atende nossas exigências:
$$
\tup{x} = \tup{y} \iff
x = y
$$
que é exatamente a igualdade desejada.
Ou seja, para nossos objectivos podemos \emph{identificar os objetos}
$\tup{x}$ e $x$.
%%}}}

%%{{{ The empty tuple 
\note A tupla vazia.
Seguindo nossa intuição com as tuplas dos outros tamanhos,
o que seria uma $0$-tupla?
Bem, para determinar um objeto $\vec t$ desse tipo, precisamos
definir suas\dots\ $0$ projecções.
Logo existe uma única $0$-tupla, que denotamos por $\tup{}$ mesmo.
%%}}}

\endsection
%%}}}

%%{{{ Cartesian product 
\section Produto cartesiano.
\label{Cartesian_product}%

%%{{{ df: cartesian_product 
\definition.
\label{cartesian_product}%
\tdefined{produto cartesiano}%
\sdefined {{\sholed A} \times {\sholed B}} {o produto cartesiano dos $A$ e $B$}%
Sejam $A,B$ conjuntos.
$$
A \times B \defeq \setst {\tup{a,b}} {a\in A,\ b\in B}
$$
%%}}}

%%{{{ x: times_distributes_over_union_and_inter 
\exercise.
\label{times_distributes_over_union_and_inter}%
Sejam $A,B,C$ conjuntos.  Prove que:
$$
\align
A \times (B \union C) &= (A \times B) \union (A\times C)\\
A \times (B \inter C) &= (A \times B) \inter (A\times C).
\endalign
$$

\solution
Vamos provar a
$$
A \times (B \union C) = (A \times B) \union (A\times C).
$$
Mostramos as duas inclusões separadamente:
\endgraf
\lrdirset:
Seja $w \in A \times (B\union C)$.
Logo $w = \tup{a,d}$ para algum $a \in A$ e algum $d\in B\union C$ (def.~$\times$).
Logo $d\in B$ ou $d \in C$ (def.~$\union$).
Caso $d \in B$, temos $w = \tup{a,d} \in A \times B$ (def.~$\times$).
Caso $d \in C$, temos $w = \tup{a,d} \in A \times C$ (def.~$\times$).
Nos dois casos concluimos que $w \in (A \times B) \union (A\times C)$ pela definição de $\union$.
\endgraf
\rldirset:
Seja $w \in (A \times B) \union (A\times C)$.
Logo $w\in (A\times B)$ ou $w \in (A\times C)$ (def.~$\union$).
Caso $w \in (A \times B)$, temos $w = \tup{a,b}$ para algum $a\in A$ e algum $b\in B$ (def.$\times$).
Logo $b \in B\union C$ (pois $b\in B$) (def.~$\union$).
Logo pela definição de $\times$ temos o desejado $w = \tup{a,b} \in A \times (B\union C)$.
O caso $w \in (A \times C)$ é similar.
\endgraf
A igualdade
$$
A \times (B \inter C) = (A \times B) \inter (A\times C)
$$
é provada similarmente.

\endexercise
%%}}}

%%{{{ x: commutativity of AxB doesn't imply A=B 
\exercise.
Prove ou refute:
para todos os conjuntos $A,B$,
$$
A\times B = B \times A \implies A=B.
$$

\hint
Se conseguiu refutar, tá errado.
Eu imagino que em algum ponto tu ``sejou'' algum objeto
em algum conjunto que não podia!
Lembra a~\ref{how_do_we_use_nonempty}?

\solution
Como contraexemplo tome $A \asseq \emptyset$ e $B\asseq\nats$
(qualquer $B\neq\emptyset$ serve).
Observe que $A\neq B$, mas mesmo assim
$$
A\times B = B \times A
$$
pois
$$
\emptyset \times \nats = \emptyset = \nats \times \emptyset.
$$

\endexercise
%%}}}

%%{{{ x: when_cartesian_commutes 
\exercise.
\label{when_cartesian_commutes}%
Suponha que $A,B\neq\emptyset$.
Escreva uma prova direta (sem usar reductio ad absurdum) do
$A \times B = B\times A \iff A = B$.

\hint
Uma direção é trivial---por quê?

\hint
Como usamos os fatos $A\neq\emptyset$ e $B\neq\emptyset$?

\endexercise
%%}}}

%%{{{ x: when_cartesian_commutes_absurdum 
\exercise.
Prove usando reductio ad absurdum a direção não-trivial
do~\ref{when_cartesian_commutes}.

\endexercise
%}}}

%%{{{ pseudodf: set_exp 
\pseudodefinition.
Sejam $A$ conjunto e $n\in\nats$ com $n\geq 2$.
$$
A^n \pseudodefeq \setstt {\tup{a_1,\dotsc,a_n}} {$a_i \in A$ para todo $1\leq i\leq n$}.
$$
%%}}}

%%{{{ messy quantifier 
\note.
Na definição acima aparece a frase ``para todo $1\leq i\leq n$''.
Qual é a variável ligada com esse ``para todo''?
Bem, $2$ é um constante, e $n$ já foi declarado, então entendemos que a
frase corresponde na quantificação:
$$
\lforall {i\in\nats} {1\leq i \leq n \implies a_i \in A}.
$$
%%}}}

%%{{{ df: set_exp_first_recursive_definition 
\definition.
\label{set_exp_first_recursive_definition}%
Seja $A$ conjunto.
Para $n\in\nats$ com $n\geq 1$ definimos as \dterm{potências} de $A$ recursivamente pelas:
$$
\align
A^1 &= A\\
A^n &= A^{n-1} \times A \qquad \text{($n \geq 2$)}.
\endalign
$$
%%}}}

%%{{{ Comparison with numbers (I) 
\note Comparação com números (I).
A semelhança entre a definição de potências de conjuntos e de números é gritante.
Vamos investigar.
Na~\ref{set_exp_first_recursive_definition} das duas equações recursivas
$$
\xalignat3
A^n &= A^{n-1} \times A &
A^n &= A \times A^{n-1}.
\intertext{escolhemos a primeira.  Por quê?
Observe que no caso de números, para a equação recursiva, as duas opções óbvias}
a^n &= a^{n-1} \ntimes a &
a^n &= a \ntimes a^{n-1} 
\intertext{servem e são equivalentes.
Uma explicação disso usa apenas o fato que a multiplicação de números é comutativa,
então imediatamente temos $a^{n-1} \ntimes a = a \ntimes a^{n-1}$.
Infelizmente não podemos contar nessa propriedade no caso de conjuntos,
pois já sabemos que a $\times$ não é comutativa~(\ref{when_cartesian_commutes}).
Mas as duas equações correspondem nas expressões}
a^n &= \paren{\paren{\paren{\paren{\dotsb\paren{a\ntimes a}\ntimes a}\ntimes a} \dotsb} \ntimes a} &
a^n &= \paren{a\ntimes \paren{\dotsb\paren{a\ntimes\paren{a\ntimes\paren{a \ntimes a}\dotsb}}}} &
\endxalignat
$$
que são iguais agora por causa da \emph{associatividade} da operação $\ntimes$.
%%}}}

%%{{{ Q: is times associative? 
\question.
O produto cartesiano é associativo?
%%}}}
\spoiler.

%%{{{ A: answer with another question 
\blah Resposta.
Respondemos nessa pergunta com outra:
\emph{as tuplas}
$$
\tup{a_0, \tup{a_1, a_2}}
\qquad
\tup{\tup{a_0, a_1}, a_2}
\qquad
\tup{a_0, a_1, a_2}
$$
\emph{são iguais?}
Depende.
Queremos considerá-las como se fossem iguais, pois
qualquer uma delas serve para satisfazer a especificação de tuplas:
podemos definir as $i$-ésimas projecções para cada uma,
e a igualdade vai acabar sendo satisfeita usando uma delas
sse é satisfeita usando qualquer uma das outras.
Para nos convencer que faz sentido considerar essas tuplas como iguais
pense na idéia sobre a \emph{informação} que uma tupla carrega com ela.
Agora tente ler as três tuplas acima:
$$
\gather
\text{<<Primeiro o objeto $a_0$, e depois temos: primeiro o $a_1$ e depois o $a_2$.>>}\\
\text{<<Primeiro temos: primeiro o objeto $a_0$ e depois o $a_1$; e depois temos o $a_2$.>>}\\
\text{<<Primeiro temos o objeto $a_0$ e depois o $a_1$ e depois o $a_2$.>>}
\endgather
$$
%%}}}

%%{{{ Comparison with numbers (II) 
\note Comparação com números (II).
Uma diferença entre as definições de potências de números e de conjuntos
é que no caso de conjuntos definimos o $A^n$ para todo $n \geq 1$,
mas no caso de números naturáis conseguimos uma definição mais geral,
definindo o $a^n$ para todo $n \geq 0$.
Nossa base da recursão então foi $a^0 = 1$.
Por que $1$?
%%}}}

%%{{{ Unit 
\note Unit.
Se é para generalizar bem a definição de potências de números para o caso de
conjuntos, procuramos nosso $1$, ou seja, uma \dterm{unidade}
(também \dterm{identidade}, ou \dterm{elemento neutro})
da nossa ``multiplicação'', $\times$.
Essa unidade é chamada \dterm{unit}, e muito usada em linguagens de programação.
Vamos usar o $\tup{}$ para denotá-la.
Isso é um abuso notacional, pois $\tup{}$ também denota a tupla vazia,
que é o único membro da unit;
mas o contexto é em geral suficiente para tirar a ambigüidade.
%%}}}

\TODO Explicar o ``seja $(a,b) \in A \cross B$''.
Link com os itens: \ref{only_declare_variables}, \ref{picking_elements_from_indexed_sets}.

\endsection
%%}}}

%%{{{ Sequences 
\section Seqüências.
\label{Sequences}%

%%{{{ df: sequence 
\definition Seqüência.
\label{sequence}%
\tdefined{seqüência}%
\sdefined {\sequence {\sholed {a_n}} n} {a seqüência $a_0,a_1,a_2,\dotsc$}%
A generalização de tuplas para seqüências é bem simples.
Uma $n$-tupla $\tup{a_0,\dotsc,a_{n-1}}$ tem um membro para cada uma das
$n$ posições $i = 0, \dotsc, n-1$, e nada mais.
Uma \dterm{seqüência} tem um membro para cada natural $i \in \nats$.
Usamos a notação $\sequence {a_n} n$ para denotar a seqüência
$$
a_0, a_1, a_2, a_3, \dotsc
$$
Uma \dterm{seqüência finita} é apenas uma $n$-tupla, para algum $n\in\nats$.
%%}}}

%%{{{ remark: variable_binder_in_sequences 
\remark Ligador de variável.
\label{variable_binder_in_sequences}%
Na notação $\sequence {a_n} {\alert{n}}$ o $\alert{n}$
é um \emph{ligador} da variável $n$.
%%}}}

%%{{{ beware: ambiguous notations for sequences 
\beware.
Em certos textos aparece a notação $a_n$ ou $\set{a_n}$ para denotar uma inteira seqüência.
Aqui não vamos usar nenhuma dessas, pois introduzem ambigüidades possivelmente perigosas:
\beginul
\li Se encontrar o termo $a_n$, é a seqüência inteira ou apenas o $n$-ésimo membro dela?
\li Se encontrar o termo $\set{a_n}$, ele denota a seqüência inteira, o
singleton cujo único membro é a seqüência inteira, ou o singleton cujo único
membro é o $n$-ésimo membro da seqüência?
\endul
%%}}}

%%{{{ df: sequences_equality 
\definition Igualdade.
\label{sequences_equality}%
Sejam
$\sequence {a_n} n$,
$\sequence {b_n} n$
seqüências.
Chamamo-nas iguais sse
$$
\lforall {n\in\nats} {a_n = b_n}.
$$
%%}}}

%%{{{ Limits of sequences 
\note.
No coração de calculus é o estudo de seqüências
de números reais.  No~\ref{Real_numbers} definimos a noção de \dterm{limite}
de uma seqüência de reais $\seqn a n$, e no~\ref{Metric_spaces}
estendemos essa idéia num contexto mais geral e abstrato, onde
os membros da seqüência não são necessariamente números reais,
mas membros de um \emph{espaço métrico}.
Nada mais por enquanto---paciência!
%%}}}

%%{{{ Sequences of sets 
\note Seqüências de conjuntos.
Mais interessante para a gente neste momento são \emph{seqüências de conjuntos}.
%%}}}

%%{{{ Q: how_would_you_define_Union_of_sequence 
\question.
\label{how_would_you_define_Union_of_sequence}%
Imagina que temos definido, para cada $n\in\nats$, um conjunto $A_n$.
Como tu definirias os conjuntos
$\Union_{n=0}^{\infty} A_n$
e 
$\Inter_{n=0}^{\infty} A_n$
?
%%}}}
\spoiler.

%%{{{ df: Union_Inter_of_sequence 
\definition.
\label{Union_Inter_of_sequence}%
Seja $\seqn A n$ uma seqüência de conjuntos.
Definimos os operadores unários
$\Union_{n=0}^{\infty}$ e
$\Inter_{n=0}^{\infty}$ pelas:
$$
\align
x \in \Union_{n=0}^{\infty} A_n &\defiff \lexists {n \in \nats} {x \in A_n} \\
x \in \Inter_{n=0}^{\infty} A_n &\defiff \lforall {n \in \nats} {x \in A_n}.
\endalign
$$
Às vezes usamos a notações mais curtas: $\Union_n A_n$ e $\Inter_n A_n$
respectivamente.
%%}}}

%%{{{ x: sequence_of_sets_inclusions_tricky_indices_1 
\exercise.
\label{sequence_of_sets_inclusions_tricky_indices_1}%
Sejam $\seqn A n$ e $\seqn B n$ duas seqüências de conjuntos tais que
$$
\text{para todo $n\in\nats$, $A_n \subset B_{n+1}$.}
$$
Prove que:
$$
\Union_{n=0}^\infty A_n \subset \Union_{n=0}^{\infty} B_n.
$$

\solution
Suponha $x \in \Union_{n=0}^\infty A_n$\fact1.
Preciso mostrar que $x \in \Union_{n=0}^{\infty} B_n$,
ou seja, mostrar que $x$ pertence a pelo menos um dos $B_n$'s.
(Ou seja, procuro um $k\in \nats$ tal que $x \in B_k$.)
Seja $m\in \nats$ tal que $x \in A_m$
(tal $m$ existe pela \byfact1).
Agora pela hipótese (com $n \asseq m$) $A_m \subset B_{m+1}$,
e logo $x \in B_{m+1}$, algo que mostra que
$x \in \Union_{n=0}^{\infty} B_n$, pois $m+1\in\nats$.

\endexercise
%%}}}

%%{{{ Union_Inter_of_sequences_as_sugar 
\exercise.
\label{Union_Inter_of_sequences_as_sugar}%
Na~\ref{Union_Inter_of_sequence} definimos \emph{elementariamente}
as operações $\Union_{n=0}^{\infty}$ e $\Inter_{n=0}^{\infty}$.
Defina-las usando as operações de $\Union$ e $\Inter$.

\solution
Seja $A_n$ uma seqüência de conjuntos.
Defina
$$
\xalignat2
\Union_{n=0}^{\infty} &\defeq \Union\setst {A_n} {n\in\nats} &
\Inter_{n=0}^{\infty} &\defeq \Inter\setst {A_n} {n\in\nats}.
\endxalignat
$$

\endexercise
%%}}}

%%{{{ prop: set_de_morgan_gen 
\proposition.
\label{set_de_morgan_gen}%
\ii{dualidade}%
Para todo conjunto $C$ e cada seqüência de conjuntos
$\set{ A_n }_n$,
$$
\align
C \setminus {\Union_{n=0}^\infty A_n} &= \Inter_{n=0}^{\infty} \paren{C \setminus A_n}\\
C \setminus {\Inter_{n=0}^\infty A_n} &= \Union_{n=0}^{\infty} \paren{C \setminus A_n}.
\endalign
$$
\proof \proofname~(usando fórmulas).
Sejam $C$ conjunto e $\set{ A_n }_n$ seqüência de conjuntos.
Calculamos
\compute
x \in C \setminus \Unionl_{n=0}^{\infty}A_n
&\iff x \in C \land \lnot \biggparen{x \in \Unionl_{n=0}^{\infty}A_n}   \by {def.~$\setminus$}
&\iff x \in C \land \lnot (\exists n\in\nats)[x \in A_n]  \by {def.~$\Unionl_{n=0}^{\infty}$}
&\iff x \in C \land (\forall n\in\nats)[x \notin A_n]     \by {De Morgan}
&\iff (\forall n\in\nats)[x \in C \land x \notin A_n]     \by {lógica}
&\iff (\forall n\in\nats)[x \in C \setminus A_n]          \by {def.~$\setminus$}
&\iff x \in \Interl_{n=0}^{\infty}(C \setminus A_n).      \by {def.~$\Interl_{n=0}^{\infty}$}
\endcompute
A prova da outra igualdade é similar:
é só trocar os $\Union$ com os $\Inter$, e os $\exists$ com os $\forall$!
\qed
%%}}}

\blah.
Observe a semelhança entre essa prova e a prova da~\ref{set_de_morgan}:
até nas justificativas de cada passo!
Realmente, a~\ref{set_de_morgan_gen} é uma generalização
da~\refn{set_de_morgan}, algo que tu provarás no exercício seguinte:

%%{{{ x: set_de_morgan_gen_indeed 
\exercise.
\label{set_de_morgan_gen_indeed}%
O que precisamos fazer para ganhar a~\ref{set_de_morgan} como um corolário
da~\refn{set_de_morgan_gen}?

\hint
Quais são os dados que precisamos ter per aplicar a~\ref{set_de_morgan_gen}?

\solution
Dados conjuntos $A,B,C$, precisamos mostrar que:
$$
C \setminus (A \union B)
=
(C \setminus A) \inter (C \setminus B).
$$
Seja $\set{A_n}_n$ a seqüência $A,B,B,B,\dotsb$, (ou seja, a seqüência definida pelas:
$A_0 = A$; e $A_i = B$ para $i > 0$).
Pela~\ref{set_de_morgan_gen} temos então:
$$
C \setminus \munderbrace{\Union_{n=0}^\infty A_n} {A \union B}
=
\munderbrace{\Inter_{n=0}^{\infty} (C \setminus A_n)} {(C\setminus A) \inter (C\setminus B)}.
$$

\endexercise
%%}}}

%%{{{ x: set_de_morgan_gen_nat_lang 
\exercise.
Escreva uma prova em linguagem natural da~\ref{set_de_morgan_gen}.

\solution
Mostramos as duas inclusões separadamente:
\endgraf
\lrdirset:
Tome $x \in C \setminus \Union_{n=0}^{\infty}A_n$,
ou seja, $x \in A_k$ para algum $k\in \nats$,
e logo $x \notin C \setminus A_k$ e daí
$x \notin \Inter_n \paren{C \setminus A_n}$
(pois não pertence no seu $k$-ésimo conjunto)
\endgraf
A inclusão inversa \rldirset\ é similar.

\endexercise
%%}}}

%%{{{ x: distributivity over a sequence of sets 
\exercise.
Prove ou refute:
para todo conjunto $A$ e toda seqüência de conjuntos $\set{B_n}_n$
$$
A \union \Inter_{n=0}^{\infty} B_n
=
\Inter_{n=0}^\infty \paren{A \union B_n}
$$

\solution
A afirmação é verdadeira.
\endgraf
{\lrdirset}:
Suponha $x \in A \union \Inter_{n=0}^{\infty} B_n$.
Logo $x\in A$ ou $x \in \Inter_{n=0}^{\infty} B_n$.
\case{Caso $x\in A$.}
Temos que para todo $n\in\nats$, $x\in A\union B_n$ (pois $x \in A$), e logo $x \in \Inter_{n=0}^\infty \paren{A \union B_n}$.
\case{Caso $x\in \Inter_{n=0}^{\infty} B_n$.}
Seja $n\in\nats$.  Preciso mostrar que $x \in A \union B_n$,
que é verdade pois $x \in B_n$ pela hipótese do caso.
\endgraf
{\rldirset}:
Suponha $x \in \Inter_{n=0}^\infty \paren{A \union B_n}$.
Logo $x \in A \union B_n$ para todo $n \in \nats$.
\case{Caso $x\in A$,} o resultado é imediato
\case{Caso $x\notin A$.}
Seja $m\in \nats$.
Vou mostrar que $x\in B_m$.
Sabemos pela hipótese que $x \in A \union B_m$, e como $x \notin A$, logo $x\in B_m$.
Como o $m$ foi arbitrário, concluimos que para todo $m\in \nats$, $x \in B_m$, que foi
exatamente o que precisamos provar.

\endexercise
%%}}}

%%{{{ x: running_intervals_on_nats 
\exercise.
\label{running_intervals_on_nats}%
Para $n\in\nats$, defina os conjuntos de naturais
$$
\xalignat2
A_n &= \setst {i\in\nats} {i \leq n} &
B_n &= \nats\setminus A_n.
\endxalignat
$$
Calcule os conjuntos $\Union_n A_n$ e $\Inter_n B_n$.

\hint
Use as definições e/ou a~\ref{set_de_morgan_gen}.

\solution
Temos
$$
\align
a \in \Unionl_n A_n
&\iff \lexists {n\in \nats} {a\in A_n}
\iff a \in \nats \\
b \in \Interl_n B_n
&\iff \lforall {n\in \nats} {b\in B_n}
\iff \False.
\endalign
$$
Ou seja: $\Union_n A_n = \nats$ e $\Inter_n B_n = \emptyset$.
Equivalentemente ganhamos a segunda imediatamente pela primeira
e a~\ref{set_de_morgan_gen}.

\endexercise
%%}}}

%%{{{ warning: big_setops_vs_sum 
\warning.
\label{big_setops_vs_sum}%
Uma diferença importantíssima entre os operadores ${\Sum}$ e ${\Union}$ e seus índices:
um ``somatório infinito'' não é nem associativo nem comutativo!
O seguinte teorema de \Riemann{}Riemann é bastante impressionante!
%%}}}

%%{{{ thm: riemann_rearrangement 
\theorem Riemann's rearrangement.
\label{riemann_rearrangement}%
Se uma série infinita $\Sum a_i$ de reais é \emph{condicionalmente convergente},%
\footnote{Uma série $\Sum a_i$ é \dterm{condicionalmente convergente}
sse ela é convergente, mas a $\Sum |a_i|$ não é.}
então podemos apenas permutando seus termos criar uma nova série infinita que
converga em \emph{qualquer} $x\in[-\infty,\infty]$ que desejamos.
\sketch.
Separe as metas: (i) mostrar como criar uma série que converge num dado número $\ell$;
(ii) mostrar como criar uma série divergente.
\endgraf
Observe que como $\Sum a_i$ é condicionalmente convergente, ela contem uma infinidade
de termos positivos, e uma infinidade de termos negativos.
Para o (i), fixe um $\ell\in\reals$.
Fique tomando termos positivos da série $a_i$ até seu somatório supera o $\ell$.
Agora fique tomando termos negativos da $a_i$ até seu somatório cai embaixo do $\ell$.
Agora fique tomando termos positivos até superar o $\ell$, etc.~etc.
Continuando assim conseguimos construir uma série feita por termos da
$\Sum a_i$ que converge no $\ell$.
Para o (ii), a idéia é similar.
\qes
\proof.
Veja~\cite[\S10.21~\&~Teorema~10.22]{apostol1}.
\qed
%%}}}

%%{{{ Limits of sequences of sets. 
\note Limites de seqüências de conjuntos.
Seja $\sequence {A_n} n$ uma seqüência de conjuntos.
Podemos definir a noção $\lim_n A_n$ de \emph{limite}
dessa seqüência.  Claramente, não todas as seqüências
de conjuntos convergem em algum limite.  Investigamos
isso nos problemas (\ref{set_liminf_limsup_problem}
e~\ref{set_limits}).
%%}}}

\endsection
%%}}}

%%{{{ Intervals on the real line 
\section Intervalos na reta real.

%%{{{ intervals_of_reals 
\definition Intervalos.
\label{intervals_of_reals}%
\tdefined{intervalos}[de números]%
Sejam $\alpha,\beta\in\reals$.
Definimos os \dterm{intervalos} seguintes:
$$
\xalignat2
(\alpha, \beta) &\defeq \setst {x\in\reals} {\alpha < x < \beta} &
(\alpha, \beta] &\defeq \setst {x\in\reals} {\alpha < x \leq \beta} \\
[\alpha, \beta) &\defeq \setst {x\in\reals} {\alpha \leq x < \beta} &
[\alpha, \beta] &\defeq \setst {x\in\reals} {\alpha \leq x \leq \beta}.
\endxalignat
$$
%%}}}

%%{{{ x: running_intervals_on_reals 
\exercise.
\label{running_intervals_on_reals}%
Para $n=1,2,3,\dotsc$ defina os intervalos de reais
$$
\xalignat2
F_n &= \ival[ {-1+\frac1n \,,\; 1-\frac1n} ] &
G_n &= \ival( {-1-\frac1n \,,\; 1+\frac1n} ).
\endxalignat
$$
Calcule os conjuntos $\Union_n F_n$ e $\Inter_n G_n$.

\hint
Use as definições!

\solution
Temos
$$
\align
x \in \Unionl_n F_n
&\iff \lexists {n\in \nats} {x\in F_n}
\iff x \in (-1,1) \\
x \in \Interl_n G_n
&\iff \lforall {n\in \nats} {x\in G_n}
\iff x \in [-1,1].
\endalign
$$
Ou seja: $\Union_n F_n = (-1,1)$ e $\Inter_n G_n = [-1,1]$.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Indexed families 
\section Famílias indexadas.
\label{Indexed_families}%

\blah.
Na \refn{Sequences} vimos como nos livrar da restricção de usar
um conjunto $\set{0,\dotsc,n-1}$ como ``rótulos'' para indexar os
membros duma tupla e, usando o conjunto infinito $\nats$,
chegamos na idéia de \emph{seqüências}.
Agora vamos generalizar os conceitos tanto de tuplas, quanto de
seqüências: oi, famílias indexadas!

%%{{{ Motivation 
\note Motivação.
A idéia que nos motiva é: \emph{por que nos limitar ``acessando''
os membros de uma tupla apenas usando inteiros como índices (rótulos),
enquanto podemos ``liberar'' qualquer objeto para servir como rótulo?}
E é assim que fazemos mesmo.
%%}}}

%%{{{ eg: daughters_of_p 
\example.
\label{daughters_of_p}%
Seja $\cal C$ o conjunto de todos os países do mundo e,
para cada $c \in \cal C$, seja $V_c$ o conjunto de todos os vilarejos do $c$.
Em símbolos,
$$
V_c = \setstt v {$v$ é um vilarejo no país $c$}.
$$
O que acabamos de definir aqui?
Para \emph{cada} país $c\in\cal C$ um novo objeto foi definido:
o conjunto de todos os vilarejos de $c$.
Ou seja, acabamos de definir vários objetos,
\emph{exatamente um para cada membro do $\cal C$}.
Assim que determinar isso, dizemos que temos uma \dterm{família indexada
por $\cal C$}.
\endexample
%%}}}

%%{{{ df: indexed_family 
\definition Notação.
\label{indexed_family}%
\tdefined{família}[indexada]%
\tdefined{tupla}[$\cal I$-tupla]%
\tdefined{conjunto}[de índices]%
\sdefined
    {\family {\sholed {a_i}} {\sholed i\in \sholed {\cal I}}}
    {a família indexada dos $a_i$'s}%
Chegamos assim na idéia de \dterm{família indexada}\ii{família!indexada}~por
algum conjunto $\cal I$, cuja totalidade denotamos por
$\family {a_i} {i\in \cal I}$ ou $\famst {a_i} {i\in \cal I}$,
onde $a_i$ é um determinado objeto para cada $i \in \cal I$.
Chamamos o $\cal I$ o \dterm{conjunto de índices} da família,
e quando ele é implícito pelo contexto denotamos a família apenas
com $\family {a_i} i$.
Alternativamente usamos como sinônimo o termo \dterm{$\cal I$-tupla},
enfatizando assim que o conceito de família indexada é apenas
uma generalização da $n$-tupla.
%%}}}

\blah.
Vamos ver mais uns exemplos de famílias!

%%{{{ eg: anscestors_and_children 
\example.
\label{ancestors_and_children}%
Seja $\cal P$ o conjunto de todas as pessoas do mundo.
Definimos para cada pessoa $p\in \cal P$, os conjuntos $A_p$ e $C_p$ de todos
os ancestrais e todos os filhos de $p$, respectivamente.
Ou seja, acabamos de definir duas \emph{famílias indexadas} de conjuntos:
a $\famil A p {\cal P}$ e a $\famil C p {\cal P}$.
\endexample
%%}}}

%%{{{ eg: airports_direct_flights 
\example.
\label{airports_direct_flights}%
Seja $\cal A$ o conjunto de todos os aeroportos.
Para cada aeroporto $a\in\cal A$, seja
$$
D_a \defeq \setst { b \in \cal A } { \text{existe vôo direto de $a$ para $b$} }.
$$
Acabamos de definir uma família de conjuntos
$\famst {D_a} {a \in \cal A}$.
\endexample
%%}}}

%%{{{ eg: books_and_authors 
\example.
\label{books_and_authors}%
Seja $\cal B$ o conjunto de todos os livros.
Para cada livro $b\in\cal B$, sejam
$$
\align
A_b &\defeq \setstt a {$a$ é um autor do livro $b$}\\
W_b &\defeq \setstt w {$w$ é uma palavra que aparece no texto do livro $b$}.
\endalign
$$
\endexample
%%}}}

\blah.
Sabendo a definição de igualdade entre tuplas, definir
igualdade entre famílias indexadas é fácil.

%%{{{ df: indexed_families_equality 
\definition Igualdade.
\label{indexed_families_equality}%
Sejam
$\family {a_i} {i\in \cal I}$,
$\family {b_i} {i\in \cal I}$
famílias indexadas por um conjunto de índices $\cal I$.
Chamamo-nas iguais sse
$$
\lforall {i\in\cal I} {a_i = b_i}.
$$
%%}}}

%%{{{ Q: How would you define union and intersection of a family?
\question.
Como tu definarias as operações (unárias!) de união e de intersecção
para famílias?
%%}}}
\spoiler.

%%{{{ df: Union_Inter_of_family 
\definition.
\label{Union_Inter_of_family}%
Seja $\famil A i {\cal I}$ é uma família de conjuntos indexada por um
conjunto de índices $\cal I$.
Definimos
$$
\xalignat2
x \in \Union_{i\in\cal I} A_i &\defiff \lexists {i\in \cal I} {x \in A_i}&
x \in \Inter_{i\in\cal I} A_i &\defiff \lforall {i\in \cal I} {x \in A_i}.
\endxalignat
$$
%%}}}

\blah.
Note que em palavras de rua, as definições são igualzíssimas:
um objeto pertence à união da família sse ele pertence a pelo
menos um dos seus membros; e perence à sua intersecção sse ele
pertence a todos os seus membros.

%%{{{ x: intersection_of_indices_of_families_exercise 
\exercise.
\label{intersection_of_indices_of_families_exercise}%
Sejam $I,J$ conjuntos de índices e para cada $k\in I\union J$ seja $A_k$ um conjunto.
A afirmação
$$
\Union_{k\in I\inter J} A_k
=
\Union_{k\in I} A_k \inter
\Union_{k\in J} A_k
$$
é verdadeira?
Responda\dots
(1) ``sim'', e prove;
(2) ``não'', e refute; ou
(3) ``depende'', e demonstre dois exemplos: um onde a afirmação é verdadeira,
e outro onde não é.

\hint
Depende.
Agora ache um exemplo e um contraexemplo.

\solution
Depende!
Primeiramente um exemplo onde a afirmação é válida:
$$
\xalignat2
I = J &= \set{1} &
A_1 &= \set{5}
\intertext{\dots e um onde a afirmação é falsa:}
I &=\set{1} &
A_1 = A_2 &= \set{5} \\
J &=\set{2}
\endxalignat
$$
Realmente, verificamos calculando no primeiro exemplo:
$$
\xalignat2
\Union_{k\in I\inter J} A_k &= A_1 &
\Union_{k\in I} A_k \inter \Union_{k\in J} A_k &= A_1 \inter A_1 = A_1
\intertext{\dots e no segundo:}
\Union_{k\in I\inter J} A_k &= \Union_{k\in\emptyset} A_k = \emptyset &
\Union_{k\in I} A_k \inter \Union_{k\in J} A_k &= A_1 \inter A_2 = \set{5}
\endxalignat
$$

\endexercise
%%}}}

\blah.
Deixando o \ref{intersection_of_indices_of_families_exercise}
nos guiar, chegamos numa investigação interessante:

%%{{{ x: unions_and_intersections_of_indices 
\exercise.
\label{unions_and_intersections_of_indices}%
Sejam $\cal I$, $\cal J$ conjuntos de índices, e suponha que
para cada membro $k \in \cal I \union \cal J$ um conjunto
$A_k$ é determinado.
O que podemos concluir sobre os conjuntos
$$
\xalignat4
\Union_{k\in\cal I\union\cal J} {A_k} &\quad\mathrel{(?)}\quad
\Union_{i\in\cal I} {A_i} \union
\Union_{j\in\cal J} {A_j} &
\Union_{k\in\cal I\inter\cal J} {A_k} &\quad\mathrel{(?)}\quad
\Union_{i\in\cal I} {A_i} \inter
\Union_{j\in\cal J} {A_j} \\
\Inter_{k\in\cal I\union\cal J} {A_k} &\quad\mathrel{(?)}\quad
\Inter_{i\in\cal I} {A_i} \union
\Inter_{j\in\cal J} {A_j} &
\Inter_{k\in\cal I\inter\cal J} {A_k} &\quad\mathrel{(?)}\quad
\Inter_{i\in\cal I} {A_i} \inter
\Inter_{j\in\cal J} {A_j}
\endxalignat
$$
das opções: \sq{$=$}, \sq{$\subset$}, \sq{$\supset$}, etc.
Investigue.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Indexed_sets_vs_indexed_families 
\section Conjuntos indexados \vs famílias indexadas.
\label{Indexed_sets_vs_indexed_families}%

%%{{{ df: indexed_set 
\definition Conjuntos indexados.
\label{indexed_set}%
\tdefined{conjunto}[indexado por conjunto]%
Quando usamos um conjunto $B$ para ``indexar'' um conjunto $A$,
chamamos o $A$ um \dterm{conjunto indexado por $B$}.
Temos então:
$$
A = \setst {\dots b \dots} {b \in B}.
$$
%%}}}

%%{{{ remark: every_set_can_be_indexed 
\remark.
\label{every_set_can_be_indexed}%
Todo conjunto $A$ pode ser indexado por ele mesmo, pois
$$
A = \setst {a} {a \in A}.
$$
Em outras palavras, o ``conjunto indexado'' não é um tipo
diferente do tipo ``conjunto''.  Não faz sentido nos perguntar
se um conjunto $A$ é indexado ou não, pois todos são
(pelo menos por eles mesmo).
%%}}}

%%{{{ remark: picking_elements_from_indexed_sets 
\remark Tomando elementos de conjuntos indexados.
\label{picking_elements_from_indexed_sets}%
{%
\def\bla{\mathrm{bla}}%
Suponha que temos um conjunto $A$ indexado
por um conjunto $B\neq\emptyset$:
$$
A = \setst {\bla(b)} {b\in B}.
$$
Como podemos ``tomar um arbitrario membro de $A$''?
Claramente podemos dizer: ``seja $a \in A$'', algo válido
para qualquer conjunto $A \neq \emptyset$.
Mas nesse caso, ``sejando'' um $b\in B$, determinamos
um membro de $A$: o $\bla(b)$.
Assim, se provarmos algo sobre o $\bla(b)$,
isso é suficiente para concluir que todos os elementos
de $A$ satisfazem esse algo.
Imagine então que queremos provar que
$$
A \subset C.
$$
Podemos seguir o caminho padrão, provando
$$
\lforall {a \in A} {a \in C}
$$
mas, temos mais um caminho para seguir nesse caso:
provar que
$$
\lforall {b \in B} {\bla(b) \in C}.
$$
}
%%}}}

%%{{{ indexed_sets_equality 
\note Igualdade entre conjuntos indexados.
\label{indexed_sets_equality}%
{%
\def\bla{\mathrm{bla}}%
\def\blu{\mathrm{blu}}%
Para mostrar que dois \emph{conjuntos}
indexados pelo mesmo conjunto são iguais, é \emph{suficiente}
mostrar que são iguais como famílias---mas não \emph{necessário}:
veja~\ref{equal_as_fam_not_necessary_for_equal_as_sets}.
\endgraf
Por exemplo, sejam $A,B$ conjuntos indexados pelo mesmo conjunto $C$:
$$
\xalignat2
A &= \setst {\bla(c)} {c \in C} &
B &= \setst {\blu(c)} {c \in C}.
\endxalignat
$$
Suponha que queremos provar $A=B$.
O caminho orthódoxo seria seguir a definição de igualdade de conjuntos
e provar
$$
x\in A \iff x \in B,
\qqqtext{ou seja,}
A \subset B \mland A \supset B.
$$
Mas, vendo eles como \emph{conjuntos indexados por o $C$},
podemos matar o alvo $A=B$ numa maneira alternativa, aplicando
a definição de igualdade de famílias indexadas.
No final das contas, parecem famílias indexadas por o mesmo conjunto
de índices (o $C$).
Então provando a afirmação
$$
\lforall {c \in C} {\bla(c) = \blu(c)}
$$
é \emph{suficiente} para demonstrar que $A=B$.
}
%%}}}

%%{{{ beware: equal_as_fam_not_necessary_for_equal_as_sets 
\beware Suficiente mas não necessário!.
\label{equal_as_fam_not_necessary_for_equal_as_sets}%
Observe que mostramos algo ainda mais forte: não é apenas
que $A=B$ como conjuntos, mas como \emph{famílias} indexadas também,
ou seja, \emph{concordam em todo índice}.
Mas: pode ser que como famílias
não são iguais, mas como conjuntos, são, como o exemplo
seguinte mostra:
%%}}}

%%{{{ eg: equal_as_fam_not_necessary_for_equal_as_sets_example 
\example.
\label{equal_as_fam_not_necessary_for_equal_as_sets_example}%
Considere os
$$
\xalignat2
A &= \setst {x + 1} {x \in \ints} &
B &= \setst {x - 1} {x \in \ints}.
\endxalignat
$$
São dois conjuntos indexados pelo mesmo conjunto $\ints$.
Obviamente $A=B$, mas para nenhum índice $x \in \ints$ temos
$x + 1 = x - 1$.
\endexample
%%}}}

\endsection
%%}}}

%%{{{ Pairwise-disjointness 
\section Disjuntos dois-a-dois.

%%{{{ df: pairwise_disjoint 
\definition.
\label{pairwise_disjoint}%
Seja $\scr A$ uma família de conjuntos.
Chamamos seus membros \dterm{disjuntos dois-a-dois} sse nenhum deles
tem elementos em comum com nenhum outro deles.
Em símbolos:
$$
\text{os conjuntos da $\scr A$ são disjuntos dois-a-dois}
\defiff
\lforall {A,B \in \scr A} {A \neq B \implies A\inter B = \emptyset }.
$$
Similarmente para famílias indexadas:
$$
\align
\text{os conjuntos da $\famil A i {\cal I}$ são disjuntos dois-a-dois}
&\defiff
\lforall {i,j \in \cal I} {i\neq j \implies A_i \inter A_j = \emptyset}.
\intertext{E logo para seqüências também:}
\text{os conjuntos da $\seqn A n$ são disjuntos dois-a-dois}
&\defiff
\lforall {i,j \in \nats} {i\neq j \implies A_i \inter A_j = \emptyset}.
\endalign
$$
%%}}}

%%{{{ x: disjoint_not_pairwise_disjoint 
\exercise.
\label{disjoint_not_pairwise_disjoint}%
Ache uma família de conjuntos $\scr A$ com $\Inter \scr A = \emptyset$
mas cujos membros não são disjuntos dois-a-dois.

\solution
Tome
$$
\scr A \asseq \set{ \set{0,1}, \set{1,2}, \set{7} }.
$$

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Translating_from_and_to_the_language_of_sets 
\section Traduzindo de e para a linguagem de conjuntos.
\label{Translating_from_and_to_the_language_of_sets}%

\blah.
Lembra os exemplos~\refn{ancestors_and_children},~\refn{airports_direct_flights},
e~\refn{books_and_authors}?
Bom.  Vamos practicar nossa fluência em cojuntos usando esses exemplos agora.

%%{{{ x: ancestors_and_children_translations 
\exercise.
\label{ancestors_and_children_translations}%
Para toda pessoa $p\in\cal P$ defina $A_p$ e $C_p$ como
no~\ref{ancestors_and_children}.
Suponha que $p,q,r$ denotam pessoas.
Traduza as afirmações descritas na linguagem de conjuntos para
linguagem natural e vice versa.
\beginol
\li $p$ e $q$ são irmãos;
\li $C_p \neq \emptyset$;
\li $p$ é filho único;
\li $p$ e $q$ são parentes;
\li $p$ e $q$ são primos de primeiro grau;
\li $r$ é filho dos $p$ e $q$;
\li $C_p \inter C_q \neq \emptyset$;
\li $A_p \subset A_q$;
\li $\emptyset \subsetneq C_p \subsetneq C_q$;
\li $\lexists {p\in\cal P} {p \in C_p}$.
\endol

\solution
Traduzimos:
$$
\align
\text{$p$ e $q$ são irmãos}                      &: \text{$p\neq q \mland \exists r \paren{\set{p,q}\subset C_r}$} \\
\text{$C_p \neq \emptyset$}                      &: \text{$p$ tem pelo menos um filho} \\
\text{$p$ é filho único}                         &: \text{$\lexists {r\in A_p} {C_r = \set{p}}$} \\
\text{$p$ e $q$ são parentes}                    &: \text{$A_p \inter A_q \neq \emptyset$} \\
\text{$p$ e $q$ são primos de primeiro grau}     &: \text{$\exists r,r'\paren{p\in C_r \mland q \in C_{r'} \mland \text{$r$ e $r'$ são irmãos}}$} \\
\text{$r$ é filho dos $p$ e $q$}                 &: \text{$r \in C_p \inter C_q$} \\
\text{$C_p \inter C_q \neq \emptyset$}           &: \text{$p$ e $q$ têm pelo menos um filho juntos} \\
\text{$A_p \subset A_q$}                       &: \text{$p$ é um anscestor ou irmão de $q$} \\
\text{$\emptyset \subsetneq C_p \subsetneq C_q$} &: \text{$q$ tem filho(s) com $p$ mas com outra pessoa também} \\
\text{$\lexists {p\in\cal P} {p \in C_p}$}       &: \text{existe pessoa que é seu próprio filho}.
\endalign
$$
(Tuas traduções podem variar, especialmente se tuas definições
dessas palavras são diferentes que aquelas que eu usei aqui.)

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Generalized cartesian product 
\section Produto cartesiano generalizado.

%%{{{ idea 
\note.
Vamos começar com
\emph{dois objetos} $a$ e $b$, nessa ordem,
ou seja com uma tupla $\tup{a,b}$.
Já sabemos como generalizar essa idéia para uma \emph{família indexada}
por um conjunto abstrato de índices $\cal I$, chegando assim
na $\famil a i {\cal I}$.
\endgraf
Agora comece com \emph{dois conjuntos} $A$ e $B$, nessa ordem,
ou seja com uma tupla $\tup{A,B}$.
Podemos formar o \emph{produto cartesiano} dela,
que em vez de escrever $\times\tup{A,B}$ escrevemos com
notação comum e infixa $A\times B$.
$$
\text{produto de $\tup{A,B}$}
= \setst {\tup{a,b}} {a \in A \mland b \in B} 
$$
Com mais detalhes:
o \emph{produto da tupla de conjuntos} $\tup{A,B}$
é \emph{o conjunto de todas as tuplas} $\tup{a,b}$ tais que seu \emph{primeiro}
membro pertence no \emph{primeiro} membro da nossa tupla de conjuntos
$\tup{A,B}$, e seu \emph{segundo} membro pertence no \emph{segundo} membro de
$\tup{A,B}$.
%%}}}

%%{{{ Q: How to generalize from tuples to indexed families? 
\question.
Como generalizar isso de tuplas para famílias indexadas?
Lembre-se que em famílias indexadas não existe mais essa idéia de
\emph{primeiro} e \emph{segundo} membro.
Em vez disso, temos \emph{membro no índice $i$},
um para cada $i\in\cal I$.
%%}}}
\spoiler.

%%{{{ In search for a generalization 
\note Procurando uma generalização.
Antes de responder na pergunta, vamos construir nosso caminho
numa forma mais metódica.
$$
\matrix
\format
\c & \quad\c\quad & \c \\
\tup{A,B} & \leadsto & A\times B \\
\famil A i {\cal I} & \leadsto & ??
\endmatrix
$$
Um passo importante é perceber que nessa situação são envolvidos
dois processos: um de ``formar o produto de coisas'',
e outro de ``generalizar de tuplas para famílias indexadas''.
Então uma imagem melhor seria o diagrama
$$
\cdopt{sep=2cm}
\tup{A,B}   \ar[r, "\text{product}"]\ar[d, "\text{generalize}"'] \| A\times B\ar[d, dashed, "\text{generalize}"]\\
\famil A i {\cal I}   \ar[r, dashed, "\text{product}"]                  \| ??
\endcd
$$
onde idealmente deveria \dterm{comutar}, que informalmente quis dizer que
os dois caminhos que nos levam de $\tup{A,B}$ para o desejado $??$
vão chegar na mesma coisa.
(Teremos muito mais a falar sobre \dterm{diagramas comutativos} nos próximos
capítulos.)
\endgraf
Assim fica mais fácil achar o $??$:
$$
\cdopt{column sep=2cm, row sep=6mm}
\tup{A,B}       \ar[r]\ar[d] \| \setst  {\tup{a,b}}     {a\in A \mland b\in B}\ar[d]\\
\tup{A_0,A_1}   \ar[r]\ar[d] \| \setst  {\tup{a_0,a_1}} {a_0\in A_0 \mland a_1\in A_1}\ar[d]\\
\tup{A_0,A_1}   \ar[r]\ar[d] \| \setstt {\tup{a_0,a_1}} {$a_i\in A_i$ para todo $i\in\set{0,1}$}\ar[d, dashed]\\
\famil A i {\cal I}   \ar[r, dashed]                          \| ??
\endcd
$$
A definição correta agora da idéia que estavamos procurando é óbvia:
$$
\text{o produto da $\famil A i {\cal I}$ é o conjunto
$\setstt {\famil a i {\cal I}} {$a_i \in A_i$ para todo $i\in\cal I$}$}.
$$
Só basta achar uma notação legal para esse conjunto, e essa escolha também é fácil.
%%}}}

%%{{{ df: gartesian porduct of an indexed family of sets 
\definition Produto cartesiano de família.
\label{cartesian_product_generalized}%
\tdefined{produto cartesiano}[generalizado]%
\sdefined
    {\Prod_{\sholed i\in{\sholed {\cal I}}} {\sholed {A_i}}}
    {o produto cartesiano da família indexada de conjuntos $\famil A i {\cal I}$.}%
Seja $\famil A i {\cal I}$ uma família indexada de conjuntos.
Definimos seu \dterm{produto cartesiano}
$$
\Prod_{i\in\cal I} A_i
\defeq
\setstt {\famil a i {\cal I}} {$a_i \in A_i$ para todo $i\in\cal I$}.
$$
%}}}

%%{{{ x: cardinalidade_of_product_of_finite_sets 
\exercise.
\label{cardinalidade_of_product_of_finite_sets}%
Seja $\cal I$ um conjunto finito de índices e para cada
$i \in \cal I$ seja $A_i$ um conjunto finito.
Qual a cardinalidade do $\Prod_i {A_i}$?

\hint
$\card{A\times B} = ?$

\endexercise
%%}}}

%%{{{ choosers_product 
\note Escolhedores.
\label{choosers_product}%
\tdefined{escolhedor}[produto]%
Vou tentar dar um ponto de vista ``no nível coração'' sobre o produto duma família.
Vamos começar com o produto cartesiano ``normal'' (ou seja, aquele que forma $n$-tuplas mesmo).
Como exemplo real, vamos considerar os $3$ conjuntos: $A,B,C$
Nesse caso o que seria o $A \cross B \cross C$?
Agora tome um membro $t$ do $A \cross B \cross C$.
O que ele \emph{é}?
Uma tripla, certo.
Com certeza tem a forma
$$
t = \tup{ a, b, c }
$$
para alguns $a\in A$, $b\in B$, e $c \in C$.
Mas o que ele é no meu coração?
Posso pensar que ele é um \dterm{escolhedor}.
Ele escolha \emph{exatamente um membro de cada um dos conjuntos $A,B,C$}.
Pense que os $A$, $B$, e $C$ por exemplo são conjuntos de
``starter'', ``main course'', e sobremesa respectivamente
$$
\align
A &= \set{ \textrm{salada}, \textrm{sopa}, \textrm{tzatziki} } \\
B &= \set{ \textrm{pizza}, \textrm{carbonara}, \textrm{pastitsio} } \\
C &= \set{ \textrm{tiramisu}, \textrm{yogurte} }
\endalign
$$
E esse é o menu dum restaurante onde para jantar o cliente (escolhedor)
precisa escolher exatamente uma opção de cada.
O produto cartesiano $A \cross B \cross C$ então, que é o
$$
\align
A \cross B \cross C = {}
   &\{ \tup{\textrm{salada},   \textrm{pizza},     \textrm{tiramisu}} \\
   & , \tup{\textrm{salada},   \textrm{pizza},     \textrm{yogurte}} \\
   & , \tup{\textrm{salada},   \textrm{carbonara}, \textrm{tiramisu}} \\
   & \vdots \\
   & , \tup{\textrm{tzatziki}, \textrm{pastitsio}, \textrm{tiramisu}} \\
   & , \tup{\textrm{tzatziki}, \textrm{pastitsio}, \textrm{yogurte}} \}.
\endalign
$$
representa todos os possíveis escolhedores.
A tripla
$$
\tup{\textrm{tzatziki}, \textrm{pastitsio}, \textrm{tiramisu}}
$$
então alem de ser ``apenas uma tripla'', pode ser vista como
o escolhedor que escolheu:
$$
\align
\textrm{tzatziki}  &\in A \\
\textrm{pastitsio} &\in B \\
\textrm{tiramisu}  &\in C.
\endalign
$$
Observe que a $i$-ésima escolha do escolhedor, pertence ao
$i$-ésimo argumento do produto $A\cross B \cross C$,
onde aqui $i \in \set{0,1,2}$.
\endgraf
Na mesma maneira então,
dada família indexada de conjuntos $\famil A i {\cal I}$ cada
membro do seu produto cartesiano
$$
\Prod_{i\in\cal I} A_i
=
\setstt {\famil a i {\cal I}} {$a_i \in A_i$ para todo $i\in\cal I$}
$$
é uma família indexada
$$
\text{$\famil a i {\cal I}$
tal que $a_i \in A_i$ para todo $i\in\cal I$},
$$
ou seja, um escolhedor que escolha um membro de cada um
dos membros da família $\famil A i {\cal I}$:
a $i$-ésima escolha $a_i$ do escolhedor $\famil a i {\cal I}$
pertence ao $i$-ésimo argumento $A_i$ do produto $\Prod_{i\in\cal I} A_i$.
Pense nisso.
%%}}}

\endsection
%%}}}

%%{{{ Multisets 
\section Multisets.
\label{Multisets}%
\ii{multiset}%
\iisee{bag}{multiset}%

\blah.
Coloquiamente falando, um \dterm{multiset}
(também \dterm{bag} ou \dterm{sacola}) $M$ é como um conjunto,
só que ele não pode responder apenas em perguntas do tipo
<<o objeto $x$ pertence ao $M$?>>, mas também em
<<\emph{quantas vézes pertence} o $x$ ao $M$?>>.
Seus membros continuam sem ordem, mas agora tem \dterm{multiplicidade}.
Usamos a notação
$\bag{x_0, x_1, \dots, x_n}$
para denotar multisets, ou até
$\set{x_0, x_1, \dots, x_n}$
sobrecarregando a notação $\set{\dots}$ se é claro pelo contexto
que é um multiset e não um conjunto.

\note Igualdade.
\label{multisets_equality}%
Consideramos os multisets $M$ e $M'$ iguais sse para todo $x$,
$$
\text{$x$ pertence $n$ vezes ao $M$}
\iff
\text{$x$ pertence $n$ vezes ao $M'$}.
$$

\endsection
%%}}}

%%{{{ Problems 
\problems.

%%{{{ calculate_set_extensions 
\problem.
\label{calculate_set_extensions}%
Calcule as extensões dos conjuntos:
$$
\set{\set{\emptyset}}\cross\pset\emptyset;
\qqqquad
\set{\set{\emptyset}}\symdiff\Union\emptyset
$$

\solution
Calculamos:
$$
\align
\set{\set{\emptyset}}\cross \pset\emptyset &
= \set{\set{\emptyset}}\cross\set{\emptyset}
= \set{(\set{\emptyset},\emptyset)} \\
\set{\set{\emptyset}}\symdiff\Union\emptyset &
= \set{\set{\emptyset}}\symdiff\emptyset
= \set{\set{\emptyset}}
\endalign
$$

\endproblem
%%}}}

%%{{{ equal_Union_and_Inter 
\problem.
\label{equal_Union_and_Inter}%
Seja $\scr A$ família de conjuntos tal que
$$
\Union \scr A = \Inter \scr A.
$$
O que podes concluir sobre o $\scr A$?

\solution
Vou demonstrar que $\scr A$ tem exatamente um membro ($\scr A$ é um singleton).
\crtabproofpart{$\scr A$ tem pelo menos um membro.}
Se $\scr A$ fosse vazio não teriamos
$\Union \scr {A} = \Inter \scr {A}$,
pois o primeiro é o vazio e o segundo o universo.
\crtabproofpart{$\scr A$ tem no máximo um membro.}
Sejam $A,B \in \scr A$.
Vou mostrar que $A=B$.
\crproofpart{\lrdirset}:
Para qualquer $x$ temos:
\compute
x \in A
&\implies x \in \Union \scr A   \by {$A \in \scr A$ e def.~$\Union\scr A$}
&\implies x \in \Inter \scr A   \by {$\Union \scr A = \Inter \scr A$}
&\implies x \in B               \by {$B \in \scr A$ e def.~$\Inter\scr A$}
\endcompute
\proofpart{A {\rldirset}} é similar.
\crproofalt{Alternativa usando reductio ad absurdum.}
Para chegar numa contradição suponha que $A \neq B$.
Logo seja $t \in A \symdiff B$, ou seja $t$ pertence a um dos $A,B$ mas não ao outro.
Logo $t \in \Union \scr A$ e $t \notin \Inter \scr A$, absurdo.

\endproblem
%%}}}

%%{{{ dualize_and_prove_Inter_of_containters_contains 
\problem.
\label{dualize_and_prove_Inter_of_containters_contains}%
Dualize e demonstre o resultado do~\ref{Inter_of_supsets_supset}.

\endproblem
%%}}}

%%{{{ sequence_of_sets_inclusions_tricky_indices_2 
\problem.
\label{sequence_of_sets_inclusions_tricky_indices_2}%
Sejam $\seqn A n$ e $\seqn B n$ duas seqüências de conjuntos tais que
$$
\text{para todo número par $m$, $A_m \subset B_{m/2}$.}
$$
Prove que:
$$
\Inter_{n=0}^\infty A_n \subset \Inter_{n=0}^{\infty} B_n.
$$

\solution
Suponha $x \in \Inter_{n=0}^\infty A_n$.
Preciso mostrar que $x \in \Inter_{n=0}^{\infty} B_n$,
ou seja, provar que $x\in B_k$ para todo $k\in\nats$.
Seja $k \in \nats$.
Como $x \in \Inter_{n=0}^{\infty}A_n$, temos $x \in A_{2k}$.
Mas $A_{2k} \subset B_k$, logo $x \in B_k$.

\endproblem
%%}}}

%%{{{ sequence_of_sets_inclusions_counterexample 
\problem.
\label{sequence_of_sets_proper_inclusions_counterexample}%
Sejam $\seqn A n$ e $\seqn B n$ duas seqüências de conjuntos,
tais que para todo $n\in\nats$,
$A_n \subsetneq B_n$.
Podemos concluir alguma das afirmações seguintes?:
$$
\xalignat2
\Union_{n=0}^\infty A_n &\subsetneq \Union_{n=0}^{\infty} B_n &
\Inter_{n=0}^\infty A_n &\subsetneq \Inter_{n=0}^{\infty} B_n
\endxalignat
$$

\hint
Procure contraexemplos:
para cada afirmação,
defina duas seqüências $\seqn A n$ e $\seqn B n$
que satisfazem a condição do problema, e mesmo assim,
não é valida a conclusão proposta.

\solution
Vamos construir um contraexemplo para cada afirmação.
\endgraf
Considere as seqüências de conjuntos seguintes:
para todo $n\in\nats$ define
$$
A_n \eqass (-n,n)
\qqqquad
\aligned
B_0     &\asseq \emptyset\\
B_{n+1} &\asseq [-n,n].
\endaligned
$$
Observe que, realmente, para todo $n\in\nats$ temos $A_n \subsetneq B_{n+1}$:
$$
A_n = (-n,n) \subsetneq [-n,n] = B_{n+1}.
$$
Mesmo assim,
$$
\Union_{n=0}^\infty A_n = \reals = \Union_{n=0}^{\infty} B_n.
$$
\endgraf
Para refutar a segunda afirmação, considere
as seqüências de conjuntos seguintes:
para todo $n\in\nats$ defina
$$
A_n \eqass \setst {k \in \nats}  {k > n}
\qquad\qquad
B_n \eqass \setst {k \in \nats}  {k \geq n}
$$
Observe que, realmente, para todo $n\in\nats$ temos $A_n \subsetneq B_n$.
Mesmo assim,
$$
\Inter_{n=0}^\infty A_n = \emptyset = \Inter_{n=0}^{\infty} B_n.
$$

\endproblem
%%}}}

%%{{{ sequence_of_sets_inclusions_tricky_indices_3 
\problem.
\label{sequence_of_sets_inclusions_tricky_indices_3}%
Sejam $\seqn A n$ e $\seqn B n$ duas seqüências de conjuntos tais que
$$
\text{para todo número primo $p$, $A_p \subset B_{2p}$.}
$$
Prove ou refute:
$$
\Inter_{n=0}^\infty A_n \subset \Union_{n=28}^{\infty} B_n.
$$

\solution
Suponha $x \in \Inter_{n=0}^\infty A_n$.\fact1
Preciso mostrar que $x \in \Union_{n=28}^{\infty} B_n$,
ou seja, achar um inteiro $m\geq 28$ tal que $x\in B_m$.
Pela {\byfact1} temos $x\in A_{17}$; e como $17$ é primo,
$A_{17}\subset B_{34}$ (pela hipótese).
Logo $x \in B_{34}$.
Então realmente $x \in \Union_{n=28}^{\infty} B_n$.

\endproblem
%%}}}

%%{{{ epsilon-dependent and n-dependent intersections 
\problem.
Para todo real $\epsilon>0$ e todo $n\in\nats$,
sejam os intervalos de reais
$$
\align
I_\epsilon &= [0,1 + \epsilon)\\
U_n &= [n,+\infty).
\endalign
$$
Calcule os conjuntos:
(i) $\Inter \set {I_\epsilon \st \epsilon>0}$;
(ii) $\Inter_{n=2}^{\infty} U_n$.

\solution
(i) $[0,1]$;
(ii) $\emptyset$.

\endproblem
%%}}}

%%{{{ bounded_Union_and_Iter_def_and_prop 
\problem.
\label{bounded_Union_and_Iter_def_and_prop}%
Seja $\set{A_n}_n$ seqüência (infinita) de conjuntos.
Defina recursivamente uma seqüência de conjuntos $\set{D_n}_n$
tal que (informalmente):
$$
\text{$D_k = A_0 \union A_1 \union \dotsb \union A_{k-1}$ para todo $k\in\nats$}.
$$
Em outras palavras,
precisas definir formalmente a operação $\Union_{i=0}^{k-1} \dhole$
para qualquer $k\in\nats$.
Demonstre que para todo $n\in\nats$,
$$
\munderbrace {\Union_{i=0}^{n-1} A_n} {D_n} \subset \Union_{m=0}^{\infty} A_m.
$$
O que muda se trocar de uniões para intersecções?

\solution
\proofpart{Definição da $D_n$} por recursão:
$$
\align
D_0     &= \emptyset \\
D_{n+1} &= D_n \union A_n.
\endalign
$$
\proofpart{Demonstração da afirmação} por indução no $n$.
\crtabproofpart{Base:} $D_0 \subset \Union_{m=0}^{\infty} A_m$.
Imediato pois $D_0 = \emptyset$.
\crtabproofpart{Passo indutivo.}
Seja $w \in \nats$ tal que
$$
D_w \subset \Union_{m=0}^{\infty} A_m.    \tag{H.I.}
$$
Preciso provar que
$$
D_{w+1} \subset \Union_{m=0}^{\infty} A_m.
$$
Seja $d \in D_{w+1}$.
Basta mostrar que
$$
d \in \Union_{m=0}^{\infty} A_m,
$$
ou seja, que $d$ pertence a algum dos $A_m$'s.
Pela definição de $D_{w+1} = D_w \union A_w$, temos
que
$d \in D_w$
ou
$d \in A_w$.
Separo em casos:
\crcase{Caso $d \in D_w$.}
Imediatamente pela (H.I.)
$$
d \in D_w \subset \Union_{m=0}^{\infty} A_m.
$$
\case{Caso $d \in A_w$.}
Imediato.
\crproofpart{O que muda trocando de uniões para intersecções:}
(1) a intersecção vazia tem de ser o $\universet$ em vez do $\emptyset$,
pois $\universet$ é a identidade da $\inter$ binária;
(2) o $\subset$ da afirmação tem de mudar pra $\supset$;
(3) a base da indução também é imediata pois $\universet$
é superconjunto de qualquer conjunto;
(4) o passo indutivo muda numa maneira mais interessante:
nosso alvo é mostrar que um arbitrario membro $a$ que pertence
a intersecção infinita dos $A_i$'s pertence ao $D_{w+1}$ tambem,
dado que qualquer membro dela pertence ao $D_w$;
e temos então ambas as coisas que precisamos
(o $a \in D_w$ pela (H.I.) e o $a \in A_w$
pois $a$ pertence a todos os $A_i$'s).

\endproblem
%%}}}

%%{{{ df: chain_in_sets 
\definition.
\label{chain_in_sets}%
Seja $\scr A$ uma família de conjuntos.
Chamamos a $\scr A$ de \dterm{$\subset$-chain} sse
$$
\text{para todo $A,B\in \scr A$, temos $A\subset B$ ou $B \subset A$}.
$$
%%}}}

%%{{{ chain_first_encounter 
\problem.
\label{chain_first_encounter}%
Seja $\scr C$ uma $\subset$-chain e seja $T = \Union \scr C$.
A afirmação
$$
\text{$\scr C \union \set{T}$ é uma chain}
$$
é verdadeira?
Se sim, demonstre; se não, refute;
se os dados não são suficientes para concluir, mostre um exemplo e um contraexemplo.

\hint
A airmação é verdadeira.  Demonstre.

\solution
Vou demonstrar que $\scr C \union \set {T}$ é uma chain.
\endgraf
Sejam $A,B \in \scr C \union \set T$.
Preciso mostrar que $A \subset B$ ou $B\subset A$.
Vou separar em casos dependendo de se os $A,B$ pertencem à $\scr C$ ou ao $\set{T}$.
\crcase{Caso ambos pertencem à $\scr C$.}
Como $\scr C$ é chain, temos imediatamente $A\subset B$ ou $B \subset A$.
\crcase{Caso exatamente um pertence à $\scr C$.}
Chame $C$ aquele que pertence à $\scr C$.
O outro pertence ao $\set{T}$ e logo é o próprio $T = \Union \scr C$.
Vou mostrar que $C \subset T$.
Seja $c \in C$.
Preciso mostrar que $c$ pertence em algum dos membros do $\scr C$,
que acontece pois $C \in \scr{C}$.
\crcase{Caso nenhum pertence à $\scr C$.}
Ou seja, ambos pertencem ao $\set{T}$; ou seja $A = B = T$; e logo $A\subset B$
e pronto.

\endproblem
%%}}}

%%{{{ chain_first_encounter_interesting_example 
\problem.
\label{chain_first_encounter_interesting_example}%
Uma chain $\scr C$ que atende as hipotéses do~\ref{chain_first_encounter}
pode ter a propriedade que
$$
\Union\scr C \in \scr C.
$$
Mostre um exemplo duma chain infinita $\scr C$ cujos membros são todos
conjuntos infinitos, e tal que $\Union\scr C \notin \scr C$.
Dá pra garantir (com a mesma $\scr C$) que $\Inter\scr C\notin \scr C$ também?
Demonstre tuas afirmações!

\hint
Procure uma $\scr C \subset \pset \reals$.

\hint
Intervalos não triviais (com pelo menos $2$ membros) de reais
com certeza são infinitos.

\solution
\proofpart{Defino a $\scr C$} pela
$$
\scr C \defeq \setst {(-a,a)} {a \in \reals_{>0}}
$$
onde $(-a,a)$ denota o intervalo aberto de
reais $\setst {x\in\reals} {-a < x < a}$.
Realmente temos
$$
\xalignat2
\Union\scr C &= \reals    \notin \scr C; &
\Inter\scr C &= \emptyset \notin \scr C.
\endxalignat
$$
\proofpart{Demonstração que $\emptyset,\reals\notin\scr C$.}
Seja $C \in \scr C$, e logo seja $a_C \in \reals$ tal que $C = (-a_C,a_C)$.
Como $a_C+1 \notin C$ e $a_C+1 \in \reals$, temos $C \neq \reals$.
Como $0 \in C$, temos $C \neq \emptyset$.
Demonstrei então que o arbitrário membro da $\scr C$ não pode ser
nem o $\emptyset$ nem o $\reals$ e logo nenhum dos dois pertence à $\scr C$.

\endproblem
%%}}}

%%{{{ arbitrary_finite_symdiff 
\problem.
\label{arbitrary_finite_symdiff}%
Sejam $n\in\nats$ com $n\geq 2$ e $n$ conjuntos
$A_1, A_2, \dotsc, A_n$.
Seja
$$
A = A_1 \symdiff A_2 \symdiff \dotsb \symdiff A_n.
$$
Observe que como a operação $\symdiff$ é associativa e comutativa,
o $A$ é bem-definido.
Prove que:
$$
A = \setstt a {$a$ pertence a uma quantidade ímpar de $A_i$'s}.
$$

\hint
Indução.

\solution
Provamos por indução que para todo inteiro $n \geq 2$,
$$
A_1 \symdiff A_2 \symdiff \dotsb \symdiff A_n
= \setstt a {$a$ pertence numa quantidade ímpar de $A_i$'s}.
$$
\proofpart{Base ($n=2$):}
$x \in A_1 \symdiff A_2 \iff \text{$x$ pertence a uma quantidade ímpar dos $A_1,A_2$}$ (óbvio).
\endgraf
\proofpart{Passo indutivo:}
Seja $k\in\nats$ tal que 
$$
A_1 \symdiff A_2 \symdiff \dotsb \symdiff A_k
= \set{ a \st \text{$a$ pertence a uma quantidade ímpar de $A_i$'s}}.\tag{H.I.}
$$
Precisamos mostrar que:
$$
A_1 \symdiff \dotsb \symdiff A_{k+1}
= \set{ a \st \text{$a$ pertence a uma quantidade ímpar dos $A_1,\dotsc,A_{k+1}$'s}}.
$$
\endgraf
(\lrdirset):
Suponha que $x\in A_1 \symdiff A_2 \symdiff \dotsb \symdiff A_{k+1}$,
ou seja, $x \in (A_1 \symdiff A_2 \symdiff \dotsb \symdiff A_k) \symdiff A_{k+1}$.
Pela definição de $\symdiff$, temos dois casos:
\endgraf
\case{Caso 1:}
$x \in A_1 \symdiff A_2 \symdiff \dotsb \symdiff A_k \mland x\notin A_{k+1}$.\CR
Pela H.I., $x$ pertence a uma quantidade ímpar dos $A_1,\dotsc,A_k$,
e não ao $A_{k+1}$, então a uma quantidade ímpar dos $A_1,\dotsc,A_{k+1}$.
\endgraf
\case{Caso 2:}
$x \notin A_1 \symdiff A_2 \symdiff \dotsb \symdiff A_k \mland x\in A_{k+1}$.\CR
Pela H.I., $x$ pertence a uma quantidade par dos $A_1,\dotsc,A_k$ e também ao
$A_{k+1}$, então a uma quantidade ímpar dos $A_1,\dotsc,A_{k+1}$.
\endgraf
\bigskip
\endgraf
(\rldirset):
Suponha que $x$ pertence a uma quantidade ímpar dos $A_1,\dotsc,A_{k+1}$.
Separamos em dois casos:
\endgraf
\case{Caso 1:} $x \in A_{k+1}$.\CR
Logo $x$ pertence a uma quantidade par dos $A_1,\dotsc,A_k$
e logo
$x\notin A_1\symdiff\dotsb\symdiff A_k$ (pela H.I.). 
Ou seja,
$x \in (A_1 \symdiff A_2 \symdiff \dotsb \symdiff A_k) \symdiff A_{k+1}$.
\endgraf
\case{Caso 2:} $x \notin A_{k+1}$.\CR
Nesse caso $x$ pertence a uma quantidade ímpar dos $A_1,\dotsc,A_k$
e pela H.I.~temos que $x\in A_1\symdiff\dotsb\symdiff A_k$.
De novo,
$x \in (A_1 \symdiff A_2 \symdiff \dotsb \symdiff A_k) \symdiff A_{k+1}$.

\endproblem
%%}}}

%%{{{ arbitrary_finite_symdiff_gen 
\problem.
\label{arbitrary_finite_symdiff_gen}%
O que devemos mudar (e como) no~\ref{arbitrary_finite_symdiff} e sua resolução,
se apagar o ``$n \geq 2$''?

\hint
O que significa $A_1\symdiff\dotsb\symdiff A_n$ nesse caso?
Por quê?

\solution
Precisamos verificar que a expressão $A_1\symdiff\dotsb\symdiff A_n$
faz sentido no caso que $n=0$, ou seja, definir razoavelmente a
diferença simétrica de uma seqüência vazia de conjuntos.
Formalmente verificamos que
$\emptyset\symdiff C = C = C\symdiff\emptyset$ para qualquer
conjunto $C$:
$\emptyset$ é o elemento neutro da operação $\symdiff$,
e logo o valor próprio da expressão acima.
\endgraf
Na prova, a base muda para $n=0$, onde devemos apenas provar que nenhum $a$ pertence numa quantidade ímpar dos (zero) $A_i$'s, que é óbvio.

\endproblem
%%}}}

%%{{{ sandwiching_a_set_sequence 
\problem Sanduichando uma seqüência de conjuntos.
\label{sandwiching_a_set_sequence}%
Seja $\seqn A n$ uma seqüência de conjuntos.
Demonstre que para todo $k\in\nats$,
$$
\Inter_{i=k}^{\infty} {A_i}
\subset
A_k
\subset
\Union_{i=k}^{\infty} {A_i}.
$$
Ou seja, temos:
$$
\matrix
\format
\c      & \;\c\; & \r                                                 & \quad\c\quad & \c     & \quad\c\quad & \r                                                 & \;\c\; & \c  \\
C_0     & \asseq & A_0 \inter A_1 \inter A_2 \inter A_3 \inter \dotsb & \subset    & A_0    & \subset    & A_0 \union A_1 \union A_2 \union A_3 \union \dotsb & \eqass & D_0 \\
C_1     & \asseq &            A_1 \inter A_2 \inter A_3 \inter \dotsb & \subset    & A_1    & \subset    &            A_1 \union A_2 \union A_3 \union \dotsb & \eqass & D_1 \\
C_2     & \asseq &                       A_2 \inter A_3 \inter \dotsb & \subset    & A_2    & \subset    &                       A_2 \union A_3 \union \dotsb & \eqass & D_2 \\
        & \vdots &                     \ddots \phantom{\inter \dotsb} & \vdots       & \vdots & \vdots       &                     \ddots \phantom{\union \dotsb} & \eqass & \vdots \\
\endmatrix
$$

\endproblem
%%}}}

%%{{{ set_liminf_limsup_problem 
\problem.
\label{set_liminf_limsup_problem}%
Seja $\seqn A n$ uma seqüência de conjuntos.
Definimos os conjuntos
$$
\xalignat 2
A_* &= \Union_{i=0}^{\infty} \Inter_{j=i}^{\infty} A_j &
A^* &= \Inter_{i=0}^{\infty} \Union_{j=i}^{\infty} A_j.
\endxalignat
$$
É verdade que um desses conjuntos é subconjunto do outro?
São iguais?  São disjuntos?

\hint
Podemos provar que $A_* \subset A^*$.

\hint
Use as definições, passo a passo.

\solution
Vamos provar que $A_* \subset A^*$.
\endgraf
Seja então $x\in A_* = \Union_{i=0}^{\infty} \Inter_{j=i}^{\infty} A_j$.
Logo seja $i_0 \in \nats$ tal que $x \in \Inter_{j=i_0}^{\infty} A_j$.
Sabemos então que
$$
\lforall {j \geq i_0} {x \in A_j}.   \tag{*}
$$
Queremos provar que $x\in A^* = \Inter_{i=0}^{\infty} \Union_{j=i}^{\infty} A_j$.
Seja então $n_0\in\nats$.
Agora basta provar que
$$
x \in \Union_{j=n_0}^{\infty} A_j.
$$
Em outras palavras, procuramos um $k\in\nats$ que satisfaz: $k \geq n_0$ e $x \in A_k$.
Tome $k \asseq \max\set{i_0, n_0}$ e observe que esse $k$ satisfaz ambas as condições.
Pela escolha de $k$ a primeira condição é satisfeita imediatamente.
Sobre a segunda, como $k \geq i_0$, pela (*) temos que $x \in A_k$,
que foi o que queremos provar.

\endproblem
%%}}}

%%{{{ set_liminf_limsup_problem_heart_level 
\problem Nível coração.
\label{set_liminf_limsup_problem_heart_level}%
Entenda no teu coração o que tu provaste no~\ref{set_liminf_limsup_problem}.
Como descreverias os elementos dos $A_*$ e $A^*$?
Explique com ``palavras da rua'' justificando o resultado obtenido.

\hint
Comece rascunhando os dois lados, usando \sq{$\dotsb$}, etc.

\hint
Vamos primeiramente analizar o $A_* = \Union_i \Inter_{j\geq i} A_j$.
É uma união duma seqüência de conjuntos, então faz sentido observar
pelo menos os primeiros membros dessa seqüência.
Quais são?

\hint
Os primeiros membros são:
$$
\Inter_{j\geq 0} A_j, \quad
\Inter_{j\geq 1} A_j, \quad
\Inter_{j\geq 2} A_j, \quad
\dotsc
$$
Faça a mesma coisa sobre o $A^* = \Inter_i \Union_{j\geq i} A_j$.

\hint
Cada um desses membros também é uma intersecção ou união duma seqüência.
Escrava cada uma delas como uma expressão que envolve \sq{$\dotsb$}.

\hint
Temos:
$$
\xalignat2
A_* &= \Union \set{
\aligned
A_0 \inter A_1 \inter A_2 \inter A_3 \inter A_4 \inter {}           & {} \dotsb \\
           A_1 \inter A_2 \inter A_3 \inter A_4 \inter {}           & {} \dotsb \\
                      A_2 \inter A_3 \inter A_4 \inter {}           & {} \dotsb \\
                                     \ddots \phantom{A_4 \inter {}} & \\
\endaligned
}
&
A^* &= \Inter \set{
\aligned
A_0 \union A_1 \union A_2 \union A_3 \union A_4 \union {}           & {} \dotsb \\
           A_1 \union A_2 \union A_3 \union A_4 \union {}           & {} \dotsb \\
                      A_2 \union A_3 \union A_4 \union {}           & {} \dotsb \\
                                     \ddots \phantom{A_4 \union {}} & \\
\endaligned
}
\endxalignat
$$
E agora precisamos \emph{entender} as proposições
$$
\xalignat2
x &\in A_* &
x &\in A^*
\endxalignat
$$
para enxergar se uma implica a outra, etc.

\hint
O que podemos concluir sobre a \emph{quantidade} dos $A_n$'s que
$x$ pertence, sabendo a primeira?  O que sabendo a segunda?

\hint
Em ambos os casos podemos concluir que $x$ pertence a uma quantidade
infinita de $A_i$'s, então isso não é suficiente para nosso objectivo.
A segunda proposição realmente é \emph{equivalente} a essa afirmação,
ou seja:
$$
x \in A^* \iff \text{$x$ pertence a uma quantidade infinita de $A_n$'s}.
$$
Mas a primeira afirma algo \emph{mais forte}, ou seja, realmente
$$
x \in A_* \implies x \in A^*.
$$
Mas para enxergar isso precisamos entender qual é toda a informação
que a proposição \sq{$x \in A^*$} contem:
$$
x \in A_* \iff \askdots
$$

\hint
Se $x \in A_*$, a quantos dos $A_n$'s pode ser
que o $x$ \emph{não} pertence?
E se $x \in A^*$?

\solution
A idéia é entender o que cada uma das proposições
$$
\xalignat2
x &\in A_* &
x &\in A^*
\endxalignat
$$
quis dizer, para enxergar se uma implica a outra, etc.
Como já demonstramos ``mecanicamente'' no~\ref{set_liminf_limsup_problem}
que $A_* \subset A^*$, queremos então chegar na conclusão que
$$
x \in A_* \implies x \in A^*
$$
num caminho diferente: do coração.
\endgraf
Vamos primeiramente analizar o $A_* = \Union_i \Inter_{j\geq i} A_j$.
É uma união duma seqüência de conjuntos, então faz sentido observar
pelo menos os primeiros membros dessa seqüência:
$$
\Inter_{j\geq 0} A_j, \quad
\Inter_{j\geq 1} A_j, \quad
\Inter_{j\geq 2} A_j, \quad
\dotsc
$$
Cada um desses membros também é uma intersecção duma seqüência.
Vamos escrever numa maneira que deixa os primeiros termos vizíveis:
$$
\align
\Inter_{j\geq 0} A_j &= A_0 \inter A_1 \inter A_2 \inter \dotsb \\
\Inter_{j\geq 1} A_j &= A_1 \inter A_2 \inter A_3 \inter \dotsb \\
\Inter_{j\geq 2} A_j &= A_2 \inter A_3 \inter A_4 \inter \dotsb \\
&\eqvdots
\endalign
$$
Trabalhando dualmente no $A^*$, chegamos nas:
$$
\xalignat2
x &\in \Union \set{
\aligned
A_0 \inter A_1 \inter A_2 \inter A_3 \inter A_4 \inter {}           & {} \dotsb \\
           A_1 \inter A_2 \inter A_3 \inter A_4 \inter {}           & {} \dotsb \\
                      A_2 \inter A_3 \inter A_4 \inter {}           & {} \dotsb \\
                                     \ddots \phantom{A_4 \inter {}} & \\
\endaligned
}
&
x &\in \Inter \set{
\aligned
A_0 \union A_1 \union A_2 \union A_3 \union A_4 \union {}           & {} \dotsb \\
           A_1 \union A_2 \union A_3 \union A_4 \union {}           & {} \dotsb \\
                      A_2 \union A_3 \union A_4 \union {}           & {} \dotsb \\
                                     \ddots \phantom{A_4 \union {}} & \\
\endaligned
}
\endxalignat
$$
Sabendo a primeira concluimos que $x$ pertence a \emph{pelo menos uma}
das linhas da esquerda, vamos dizer a $u$-ésima, ou seja
$$
x \in A_u \inter A_{u+1} \inter A_{u+2} \inter \dotsb
$$
Logo sabemos que
$$
\text{$x$ pertence a todos os $A_u, A_{u+1}, A_{u+2}, \dotsc$}.
$$
Em outras palavras:
\emph{a partir dum ponto, $x$ pertence a todos os membros da seqüência original}.
Provamos então que
$$
x \in A_* \implies \text{a partir dum ponto, $x$ pertence a todos os $A_n$'s}.
$$
Vamos demonstrar o converso agora.
Suponha que a partir dum $u\in\nats$, sabemos que $x$ pertence a todos os
$A_u, A_{u+1}, A_{u+2}, \dotsc$, ou seja,
$$
x \in A_u \inter A_{u+1} \inter A_{u+2} \inter \dotsb
$$
ou seja, achamos uma linha onde $x$ pertence e logo $x \in A_*$.
\endgraf
Agora a segunda proposição ($x \in A^*$)
concluimos que $x$ pertence a \emph{todas} as linhas
da direita, ou seja:
$$
\alignat 2
x &\in & A_0 \union A_1 \union A_2 \union A_3 \union A_4 \union {}    & {} \dotsb \\
x &\in &            A_1 \union A_2 \union A_3 \union A_4 \union {}    & {} \dotsb \\
x &\in &                       A_2 \union A_3 \union A_4 \union {}    & {} \dotsb \\
  &\eqvdots
\endalignat
$$
Observe que a $j$-ésima linha afirma que
\emph{mesmo depois de andar $j$ passos na seqüência,
ainda terá $A_n$'s com $x$ neles}.
Sabendo então que cada uma dessas linhas é verdade, podemos concluir
que $x$ pertence a uma infinidade dos $A_n$'s, e vice versa:
$$
x \in A^* \iff \text{$x$ pertence a uma infinidade dos $A_n$'s}.
$$
Vamos demonstrar isso.
\endgraf
\lrdir:
Temos como hipótese todas as
$$
\alignat 2
x &\in & A_0 \union A_1 \union A_2 \union A_3 \union A_4 \union {}    & {} \dotsb \\
x &\in &            A_1 \union A_2 \union A_3 \union A_4 \union {}    & {} \dotsb \\
x &\in &                       A_2 \union A_3 \union A_4 \union {}    & {} \dotsb \\
  &\eqvdots
\endalignat
$$
e queremos mostrar que $x$ pertence a uma infinidade dos $A_n$'s.
Basta mostrar que para qualquer ``desafio'' $v\in\nats$,
$x$ pertence a algum dos $A_v, A_{v+1}, A_{v+2}, \dotsc$.
Seja $v\in\nats$ então.
Olha na $v$-ésima linha e é exatamente o que queremos.
\endgraf
\rldir:
Agora sabendo que $x$ pertence a uma quantidade infinita de $A_n$'s precisamos
mostrar que
$$
\text{para todo $v\in\nats$},
\quad
x \in A_v \union A_{v+1} \union A_{v+2} \union \dotsb
$$
Seja $v\in\nats$ então.
Para chegar num absurdo, suponha que
$$
x \notin A_v \union A_{v+1} \union A_{v+2} \union \dotsb
$$
ou seja, $x$ não pertence a nenhum dos $A_v, A_{v+1}, A_{v+2}, \dotsc$.
Mas isso quis dizer que $x$ pertence no máximo em $v$ dos $A_n$'s,
contradizendo nossa hipótese que $x$ pertence numa infinidade deles.
\endgraf
Concluimos então que
$$
x \in A^* \iff \text{$x$ pertence a uma infinidade dos $A_n$'s}.
$$
Como comparam essas afirmações?
\beginul
\li $x\in A_*$: a partir dum ponto, $x$ pertence a todos os $A_n$'s;
\li $x\in A^*$: $x$ pertence a uma infinidade dos $A_n$'s.
\endul
Deve ser óbvio que
$$
x \in A_* \implies x \in A^*.
$$
E como já entendemos o que cada proposição quis dizer mesmo, podemos
demonstrar que o converso não é sempre válido (.
\endgraf
Para um contraexemplo onde
$$
x \in A_* \smartnot{\impliedby} x \in A^*
$$
considere a seqüência
$$
\align
A_0 &= \set {0} \\
A_1 &= \set {0,1} \\
A_2 &= \set {0} \\
A_3 &= \set {0,1} \\
A_4 &= \set {0} \\
A_5 &= \set {0,1} \\
    &\eqvdots
\endalign
$$
Observe que os $0,1$ são aqueles que pertencem a uma infinidade dos $A_n$'s.
Mas apenas o $0$ pertence a todos os $A_n$'s a partir dum certo ponto.

\endproblem
%%}}}

%%{{{ set_liminf_limsup_problem_not_converse 
\problem.
\label{set_liminf_limsup_problem_not_converse}%
Demonstre que o converso não é sempre válido:
construe seqüência de conjuntos $\seqn A n$ tal que
$$
A_* \subsetneq A^*.
$$
Podes construir uma tal que ambos os $A_*, A^*$ são infinitos,
e onde cada um dos $A_n$'s é um subconjunto finito de $\nats$?

\solution
Sem a restricção uma tal seqüência seria a
$$
\emptyset,  \quad
\set{1},    \quad
\emptyset,  \quad
\set{1},    \quad
\emptyset,  \quad
\set{1},    \quad
\dotsc
$$
Assim temos $A_* = \emptyset$ e $A^* = \set{1}$.
\endgraf
Para satisfazer a restricção, considere a seqüência:
$$
A_n =
\knuthcases{
\setstt {k \leq n} {$k$ é primo}, & se $n$ par; \cr
\setstt {k \leq n} {$k$ é ímpar}, & caso contrário.
}
$$
Seus primeiros termos:
$$
\xalignat 2
A_0 &= \emptyset            & A_1 &= \set{1} \\
A_2 &= \set{2}              & A_3 &= \set{1,3} \\
A_4 &= \set{2,3}            & A_5 &= \set{1,3,5} \\
A_6 &= \set{2,3,5}          & A_7 &= \set{1,3,5,7} \\
A_8 &= \set{2,3,5,7}        & A_9 &= \set{1,3,5,7,9} \\
    &\eqvdots               &     &\eqvdots
\endxalignat
$$
Nesse caso,
$$
\alignat2
A_* &= \set{3, 5, 7, 11, 13, 17, \dotsc}      &&= \setstt {n\in\nats} {$n$ é um primo ímpar} \\
A^* &= \set{1, 2, 3, 5, 7, 9, 11, 13, \dotsc} &&= \setstt {n\in\nats} {$n=2$ ou $n$ ímpar}.
\endalignat
$$

\endproblem
%%}}}

\blah.
Os $A_*$ e $A^*$ do \ref{set_liminf_limsup_problem} merecem seus próprios nomes!

%%{{{ df: set_limits 
\definition.
\label{set_limits}%
\tdefined{limite}[de seqüência de conjuntos]%
\tdefined{limite}[de seqüência de conjuntos]%
\sdefined {\liminf_{\sholed n} {\sholed {A_n}}} {o limite inferior da seqüência de conjuntos $\seqn A n$}%
\sdefined {\limsup_{\sholed n} {\sholed {A_n}}} {o limite superior da seqüência de conjuntos $\seqn A n$}%
\sdefined {\lim_{\sholed n} {\sholed {A_n}}} {o limite da seqüência $\seqn A n$}%
Seja $\seqn A n$ uma seqüência de conjuntos.
Definimos seu \dterm{limite inferior} e seu \dterm{limite superior} pelas:
$$
\xalignat2
\liminf_n A_n &\defeq \Union_{i=0}^{\infty} \Inter_{j=i}^{\infty} A_j &
\limsup_n A_n &\defeq \Inter_{i=0}^{\infty} \Union_{j=i}^{\infty} A_j.
\endxalignat
$$
Note que pelo~\ref{set_liminf_limsup_problem} sabemos se um é subconjunto
de outro ou não.  Mas pode ser que os dois conjuntos são iguais.
Digamos que a seqüência de conjuntos $\seqn A n$ \dterm{converge} sse
$$
\liminf_n A_n = \limsup_n A_n.
$$
Nesse caso, chamamos esse conjunto de \dterm{limite} da $\seqn A n$
e usamos a notação $\lim_n A_n$ para denotá-lo.
%%}}}

%%{{{ df: increasing_decreasing_sequence 
\definition.
\label{increasing_decreasing_sequence}%
Seja $\seqn A n$ uma seqüência de conjuntos.
Dizemos que $\seqn A n$ é uma \dterm{seqüência crescente} sse
$A_i \subset A_{i+1}$ para todo $i\in \nats$.
Similarmente, $\seqn A n$ é uma \dterm{seqüência decrescente} sse
$A_i \supset A_{i+1}$ para todo $i\in \nats$.
Rascunhamente:
$$
\align
\text{$\seqn A n$ crescente}
&\defiff A_0 \subset A_1 \subset A_2 \subset \cdots \\
\text{$\seqn A n$ decrescente}
&\defiff A_0 \supset A_1 \supset A_2 \supset \cdots
\endalign
$$
Uma seqüência é \dterm{monótona} (ou \dterm{monotônica}) sse
ela é crescente ou decrescente.
%%}}}

%%{{{ prob: monotone_sequences_have_limits 
\problem.
\label{monotone_sequences_have_limits}%
Seja $\seqn A n$ uma seqüência monótona.
Demonstre que $\seqn A n$ tem limite.
Qual é?

\endproblem
%%}}}

%%{{{ prob: sandwich_breads_are_monotone_and_optimal 
\problem Os pães do sanduiche são monótonos e ótimos.
\label{sandwich_breads_are_monotone_and_optimal}%
No~\ref{sandwiching_a_set_sequence} definimos duas seqüências
``sanduichando'' a $\seqn A n$: uma crescente (a $\seqn C n$)
e uma decrescente (a $\seqn D n$).
Pelo~\ref{monotone_sequences_have_limits} então ambas
têm limites, e realmente temos
$$
\limit_n C_n = \liminf_n A_n \subset \limsup_n A_n = \limit_n D_n.
$$
Ainda mais é verdade:
de todas as seqüências crescentes, $\seqn C n$ é a maior tal que
$C_n\subset A_n$ para todo $n\in\nats$; e similarmente
de todas as decrescentes, $\seqn D n$ é a menor tal que
$A_n\subset D_n$ para todo $n\in\nats$.
Formalize o que significam as palavras ``maior'' e ``menor''
na afirmação acima, e demonstre sua veracidade.

\endproblem
%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

Podes achar boas explicações, dicas, muitos exemplos resovidos,
e exercícios e problemas para resolver no \cite[\S1.3~\&~\S2.4]{velleman}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Functions 
\chapter Funções.
\label{Functions}%

%%{{{ intro 
\chapintro
Nesse capítulo estudamos mais um \emph{tipo} importantíssimo e fundamental em
matemática: a \emph{função}.
Nosso objectivo aqui é familiarizar-nos com funções,
entender como podemos defini-las, usá-las, combiná-las para criar novas,
operar nelas, etc.
\endgraf
Vamos brincar com a poderosa \emph{notação lambda do $\lambda$-calculus}
(\refn{A_touch_of_lambda}), e com funções de \emph{ordem superior}
(\refn{Higher_order_functions})
e apreciar que graças a \emph{currificação}~(\refn{Currying}) nem
precisamos funções de aridades maiores que $1$.
Aqui aprendemos também o que são mesmo os
\emph{diagramas comutativos}~(\refn{Commutative_diagrams}),
ferramentas que vamos usar constantemente a partir de agora!
Estudamos também o que realmente significa definir funções
\emph{recursivamente}~(\refn{Recursive_definitions_as_systems}),
algo que temos feito ``sem pensar'', baseados na nossa intuição e no
nosso insticto muitas vezes até agora.
Finalmente~(\refn{Categories_a_first_taste})
teremos nosso primeiro contato com \emph{categorias}, que oferecem uma abordagem
e linguagem unificativa para diversos cantos de matemática (e mais).
(O~\ref{Category_theory} e dedicádo na teoria das categorias.)
\endgraf
Bem depois, no~\ref{Axiomatic_set_theory}, vamos nos preocupar com
a questão de \emph{como implementar} esse tipo (o tipo de funções),
\emph{como fundamentar} esse conceito---mas esqueça isso por enquanto.
Primeiramente precisamos entender bem o que é uma função e como se comporta.
E muitas ferramentas relevantes.
Bora!
%%}}}

%%{{{ Concept, notation, equality 
\section Conceito, notação, igualdade.
\label{Function_contept}%

%%{{{ unlabeled black box for function 
\note Black boxes.
\tdefined{black box}[de função]%
\iisee{função!como black box}{black box}%
Começamos imaginando funções como black boxes;
parecidos mas diferentes daqueles que usamos para conjuntos
(\refn{blackbox_set}), pois essas caixas têm uma entrada mas
também uma saída própria:
$$
\tikzpicture
\tikzi blackboxfun;
\endtikzpicture
$$
%%}}}

%%{{{ prim: function_primitive 
\primitive função.
\label{function_primitive}%
\iisee{domínio}{função, domínio}%
\iisee{codomínio}{função, codomínio}%
\tdefined{função}[definição intuitiva]%
\tdefined{função}[domínio]%
\tdefined{função}[codomínio]%
\tdefined{função}[valor]%
Sejam $A,B$ conjuntos.
Chamamos $f$ uma \dterm{função de $A$ para $B$}, sse
para todo $x \in A$, o símbolo $f(x)$ é definido e $f(x)\in B$.
O $f(x)$ é o \dterm{valor} da $f$ no $x$.
O \dterm{domínio} da $f$ é o conjunto $A$,
e seu \dterm{codomínio} é o conjunto $B$.
Consideramos então que a função $f$ associa \emph{para todo} elemento $a \in A$,
\emph{exatamente um} elemento $f(a) \in B$.
%%}}}

%%{{{ df: function_notation 
\definition.
\label{function_notation}%
\sdefined {\sholed f : \sholed A \to \sholed B} {$f$ é uma função de $A$ para $B$}%
\sdefined {\sholed A \toby {\sholed f} \sholed B} {$f$ é uma função de $A$ para $B$}%
\sdefined {\dom {\sholed f}} {o domínio da função $f$}%
\sdefined {\cod {\sholed f}} {o codomínio da função $f$}%
\tdefined{ponto}[de conjunto]%
Escrevemos
$$
f : A \to B
\qqqqtext{e sinonimamente}
A \toby f B
$$
para dizer que \emph{$f$ é uma função de $A$ para $B$},
e escrevemos
$$
x \mapstoby f y
$$
para dizer que \emph{$f$ mapeia o $x$ para o $y$}.
Definimos também as operações $\dom$ e $\cod$
que retornam o domínio e o codomínio do seu argumento.
Resumindo:
$$
f : A \to B
\quad\defiff\quad
\text{$f$ é uma função}
\;\mland\;
\dom f = A
\;\mland\;
\cod f = B.
$$
Às vezes o tipo da função aparece olhando para a direção oposta:
$f : B \from A$ em vez de $f : A \to B$.
Escrevemos também $f\app x$ em vez de $f(x)$,
e em certos casos (mais raros) até $x\app f$ ou $x^f$.
Podemos referir aos membros do domínio e do codomínio duma
função como \dterm{pontos} desses conjuntos.
%%}}}

%%{{{ f : A -> B  and  A --f--> B  notations 
\note.
Escrevemos ``sejam $f,g : A \to B$'' e entendemos como:
``sejam funções $f$ e $g$ de $A$ para $B$'', e (abusando) se não temos já
declarados os conjuntos $A,B$, a mesma frase entendemos com um implícito
``sejam conjuntos $A,B$ e funções \dots''.
Do mesmo jeito, a frase
$$
\text{<<{Sejam $A \toby f B \toby g C$.}>>}
$$
pode ser equivalente à frase
$$
\text{<<{Sejam conjuntos $A,B,C$, e funções $f:A\to B$ e $g:B\to C$.}>>}
$$
Espero que dá para apreciar a laconicidade dessa notação.
%%}}}

%%{{{ function vs. application of function 
\note Função vs.~aplicação de função.
Em matemática muitas vezes falamos frases como as seguintes:
$$
\gather
\text{<<a função $\sin(x)$ é periódica>>}, \\
\text{<<a função $f(t)$ é monótona>>}, \\
\endgather
$$
etc.  Literalmente estamos falando algo errado!
As funções, nesse exemplo, são as $\sin$ e $f$, não as $\sin(x)$ e $f(t)$.
Denotamos com $\sin(x)$ o \emph{valor} da função $\sin$ no ponto $x$,
e com $f(t)$ o \emph{valor} da função $f$ no ponto $t$.
Claramente, esse ``erro'' é algo que não vai confundir nenhum matemático,
e com a mínima maturidade matemática não vamos encontrar problema nenhum
trabalhando assim.
Entendemos então que é apenas um ``modo de falar'' usado em certos casos.
Mas aqui nosso objectivo é estudar e \emph{fundamentar} bem a idéia e a ``alma''
dos vários tipos matemáticos, e não podemos nos permitir nenhum abuso desse tipo!
Essa distinção vai ficar ainda mais crucial, com a notação de $\lambda$-calculus
e com as funções de órdem superior.
%%}}}

%%{{{ The type of a function 
\note O tipo duma função.
Seja $f : A \to B$.
Chamamos o ``$A \to B$'' o tipo da $f$, e pronunciamos como
<<função de $A$ para $B$>>.
%%}}}

%%{{{ x: what_is_the_type_of_foo_for_C_programmers 
\exercise.
\label{what_is_the_type_of_foo_for_C_programmers}%
Aqui um programa escrito em C:
\iipl C
\iipl C++
\iipl Java
\sourcecode typefoo.c;
Qual é o tipo desse $\code{x}$ no corpo da $\code{foo}$?
Qual o tipo da $\code{foo}$?
Cuidado: programadores de C (e C++, Java, etc.) tendem errar nessa última questão!

\hint
O tipo de $\code{foo}$ não é $\code{int}$.
Se fosse $\code{int}$ mesmo, o $\code{foo}$ seria um $\code{int}$.

\solution
O tipo de $\code{x}$ é $\code{int}$.
O tipo de $\code{foo}$ é: ``função de $\code{int}$ para $\code{int}$''.
Programadores de $C$ muitas vezes erram nessa terminologia, dizendo que o tipo de $\code{foo}$ é $\code{int}$.
Se fosse $\code{int}$ mesmo, o $\code{foo}$ seria um $\code{int}$.
O que eles querem dizer é que o \emph{return type} de $\code{foo}$ é $\code{int}$, e isso tá certo.
Mas a pergunta foi identificar o \emph{tipo} de $\code{foo}$.

\endexercise
%%}}}

%%{{{ df: function_space 
\definition.
\label{function_space}%
\tdefined{função}[espaço de]%
\sdefined {(\sholed A \to \sholed B)} {o conjunto das funções de $A$ para $B$}%
Sejam $A,B$ conjuntos.
O \dterm{espaço de funções} de $A$ para $B$ é o conjunto de todas as funções de
$A$ para $B$.  Denotamos-lo por $(A \to B)$ ou por $B^A$:
$$
(A \to B) \defeq B^A \defeq \setst f {f: A \to B}.
$$
%%}}}

%%{{{ Conditions: functionhood_conditions 
\note Condições.
\label{functionhood_conditions}%
\tdefined{função}[totalidade]%
\tdefined{função}[determinabilidade]%
{\iisee{univocidade}{determinabilidade}}%
Na~\ref{function_primitive} aparece a frase
``o símbolo $f(x)$ é definido''.
Com isso entendemos que não existe ambigüidade, ou seja, para uma entrada $x$,
a $f$ não pode ter mais que uma saída.
E graças a outra frase, ``para todo $x\in A$'', sabemos que tem
\emph{exatamente uma} saída.  Esta saída é o que denotamos por $f(x)$.
\endgraf
Resumindo: para todo $x\in\dom f$,
\beginil
\item{(1)} existe pelo menos um $y\in\cod f$ tal que $x \mapstoby f y$ (\dterm{totalidade});
\item{(2)} existe no máximo  um $y\in\cod f$ tal que $x \mapstoby f y$ (\dterm{determinabilidade}).
\endil
Quando o (1) acontece dizemos que \emph{a $f$ é definida em todo o seu domínio}.
Usamos o termo \dterm{univocidade} como sinônimo de ``determinabilidade''.
%%}}}

%%{{{ Arity and tuples 
\note Aridade e tuplas.
\ii{aridade}%
No jeito que ``definimos'' o que é uma função, ela só pode depender
em apenas um objeto, apenas uma entrada.
Isso parece bastante limitante, pois estamos já acostumados
com funções com aridades diferentes.%
\footnote{Lembra-se que \dterm{aridade} é a quantidade de
argumentos-entradas.}
Caso que uma função precisa mais que um argumento como entrada,
usamos a notação $f(x_1, \dotsc, x_n)$.
Identificamos isso com uma função que recebe ``apenas um'' objeto
como entrada: a $n$-tupla $\tup{x_1,\dotsc,x_n}$.
Então identificamos as notações
$$
\gather
f(x_1,\dotsc,x_n) = f( \tup{x_1,\dotsc,x_n} ) = f \tup{x_1,\dotsc,x_n}\\
f(x)              = f( \tup{x} )              = f \tup{x} = f \app x\\
f()               = f( \tup{}  )              = f \tup{}
\endgather
$$
onde na última linha as vezes identificamos com o próprio $f$ também
quando não existe possibilidade de confusão (mas vamos evitar isso aqui).
\endgraf
Similarmente, se queremos ``retornar'' mais que um objeto,
podemos ``empacotar'' todos eles numa tupla, e retornar apenas essa tupla,
satisfazendo assim a demanda de unicidade de função---cuidado pois isso
tem que ser refletido no codomínio da função!
%%}}}

%%{{{ Synonyms 
\note Sinônimos.
\tdefined{função!sinônimos}%
\iisee{mapeamento}{função}%
\iisee{mapa}{função}%
\iisee{map}{função}%
\iiseealso{operação}{função}%
\iiseealso{operador}{função}%
\iiseealso{procedimento}{função}%
Lembra que usamos várias palavras como sinônimos de ``conjunto''?
(Quais?)
Pois é, para funções a situação é parecida.
\emph{Dependendo do contexto e da ênfase},
as palavras seguintes podem ser usadas como
sinônimos de ``função'':
mapeamento,
mapa,
map,
operação,
operador,
etc.
%%}}}

%%{{{ Intension vs. extension 
\note Intensão vs{.}~extensão.
\label{intension_vs_extension_in_functions}%
Como nos conjuntos (\ref{Intension_vs_extension_in_sets}),
temos novamente a idéia de \dterm{intensão} e \dterm{extensão} de uma função.
Pensando uma função como uma caixa que dentro dela tem um \emph{programa},
a extensão dela não seria o que ela faz mesmo internalmente (isso seria sua
\emph{intensão}), mas o que ela \emph{consegue}.
Imaginando duas ``caixas pretas'' $f$ e $g$ onde podemos apenas observar
seus comportamentos usando as suas interfaces e nada mais, faz sentido
considerar iguais aquelas que não conseguimos demonstrar nenhum comportamento diferente.
Ou seja: qualquer entrada \emph{aceitável} para uma, deve ser \emph{aceitável}
para a outra também (pois, se não, isso já seria uma diferença observável);
e ainda mais, para a mesma entrada, as funções tem que atribuir o mesmo
valor---novamente: se não isso já seria um comportamento diferente e
observável.
%%}}}

%%{{{ Programs vs. functions 
\note Programas vs.~funções.
\label{programs_vs_functions}%
\iipl Python
Considere as duas funções $\code{f}$ e $\code{g}$ implementadas
no programa seguinte em Python:
\sourcecode intext.py;
Suponha que queremos considerar ambas definidas nos inteiros.
A \emph{extensão} da $\code{f}$ é a mesma com a extensão da $\code{g}$.
Ou seja, como funções, temos $f = g$.
Suas \emph{intensões} são diferentes.
A primeira função, dado um número grande vai fazer bem mais operações até
finalmente retornar um valor.
Tente calcular as duas no interpretador de Python e também perceberás uma diferença
no tempo que cada uma precisa: compare os
$\code{f(1000000000)}$ e $\code{g(1000000000)}$.
Os \emph{programas} então são diferentes (pois num programa é a intensão que importa)
mas as funções são iguais.
Note que quando observamos caixas pretas, não podemos nem medir o tempo que
cada uma precisa para responder com seu valor, nem podemos tocar elas para ver
qual ficou mais quente, nem escutar para possíveis barulhos, etc.
Podemos apenas dar uma entrada e observar a saída e nada mais!
%%}}}

%%{{{ What about the codomain? (I) 
\note E o codomínio? (I).
\label{what_about_the_codomain_1}%
Em matemática clássica, e especialmente em teoria de
conjuntos~(\ref{Axiomatic_set_theory}) e análise,
em geral não consideramos que o codomínio duma função ``faz parte dela''.
Ou seja, a mesma função $\sin$, por exemplo, pode ser considerada como
$$
\xalignat3
\sin_1 &: \reals\to\reals     &
\sin_2 &: \reals\to[-1,1]     &
\sin_3 &: \reals\to(-\infty,2).
\endxalignat
$$
Para esse matemático então, \emph{o codomínio não é algo observável:}
como tu vai diferenciar entre as $\sin_1, \sin_2, \sin_3$ acima,
se tua única interface é dando objetos para elas, e observando seus valores (saídas)?
Pois é, não tem como.
No outro lado, se alterar os domínios isso já é uma diferença demonstrável
(observável) com essa mesma única interface.
%%}}}

%%{{{ x: how? 
\exercise.
Como?

\hint
O que significa que os domínios de duas funções são diferentes?

\solution
Se $f : A \to B$ e $g : C \to D$ são funções com $A\neq C$,
pela definição de igualdade de conjuntos, existe $x \in A\symdiff C$.
Para esse $x$, as funções vão comportar diferentemente.
Se $x \in A$ (e logo $x\notin C$), a $f$ vai aceitar o $x$
e vamos observar sua saída $f(x)$, mas a $g$ não vai aceitar
o $x$, e assim não vamos ver nenhuma saída;
Similarmente, se $x \in C$ (e logo $x\notin A$).

\endexercise
%%}}}

%%{{{ Recoverable or not? 
\note Recuperável ou não?.
\label{recoverable_or_not}%
Com esse ponto de vista, o domínio é um conjunto \emph{recuperável}
pela própria função $f$, pois podemos definir:
$$
\dom f
\defeq
\setstt x {$f(x)$ é definido}.
$$
Mas o codomínio não!
%%}}}

%%{{{ x: cod_wrongdef 
\exercise.
\label{cod_wrongdef}%
Qual o problema com essa suposta definição de codomínio de uma função $f$?:
$$
\cod f
\defeq
\setstt y {$f(x) = y$ para algum $x \in dom f$}.
$$

\hint
Aplique a $\cod$ nos $\sin_1,\sin_2,\sin_3$ do \ref{what_about_the_codomain_1}.

\solution
Aplicando essa definição de $\cod$ nas $\sin_1,\sin_2,\sin_3$ do \ref{what_about_the_codomain_1},
temos que
$$
\cod (\sin_1)
= \cod (\sin_2)
= \cod (\sin_3)
$$
mesmo que claramente não foi essa a nossa intenção.

\endexercise
%%}}}

\blah.
O conjunto definido no~\ref{cod_wrongdef} realmente é interessante
e importante, só que ele não é (necessariamente) o codomínio da
função, mas o que chamamos de range:

%%{{{ df: range 
\definition.
\tdefined{função}[range]%
\iiseealso{função!range}{image}%
\sdefined {\range {\sholed f}} {o range da função $f$}%
\sdefined {\ima {\sholed f}} {a imagem da função $f$}%
Seja $f : A \to B$ função.
Seu \dterm{range} é conjunto
$$
\range f
\defeq
\setstt y {$f(x) = y$ para algum $x \in A$}.
$$
Observe que $\range f \subset B$.
Usamos também a notação $\ima f$, o chamando de \dterm{imagem} da $f$.
%%}}}

%%{{{ x: what about these types for sin? 
\exercise.
Podemos considerar a função $\sin$ como uma função com os tipos seguintes?:
$$
\xalignat4
\sin_4 &: \rats \to \reals &
\sin_5 &: \reals\setminus\rats \to \reals\setminus\rats &
\sin_6 &: \rats \to \rats  &
\sin_7 &: \set{\pi} \to \set{0}
\endxalignat
$$

\solution
É fácil responder sobre as $\sin_4$ e $\sin_7$, pois realmente são
apenas restricções da função $\sin : \reals\to\reals$
(veja~\ref{fresto}).
Mas a situação com as $\sin_5$ e $\sin_6$ é bem mais complicada
que isso!
Sobre a $\sin_5$, supondo que sabemos que $\pi \notin \rats$,
concluimos que o seu tipo está errado,
pois $\sin(\pi) = 0 \notin \reals\setminus\rats$.
Note que para responder nisso precisamos saber a irracionalidade
de $\pi$, algo que não é trivial!
Mesmo sabendo disso, não é fácil responder sobre a $\sin_6$.
Seu tipo é realmente errado, pois
$$
\text{para todo $x \in \rats_{\neq0}$,  $\sin(x) \notin \rats$}
$$
mas a prova desse resultado é fora do escopo desse texto.
(Veja~\cite[Cor.~2.7]{nivenirrational} para mais detalhes.)
Ou seja, podemos considerar a $\sin$ com tipo
$$
\sin_8 : \rats_{\neq0} \to \reals\setminus\rats.
$$

\endexercise
%%}}}

%%{{{ remark: codomain is any superset of range 
\remark.
Seguindo o ponto de vista do~\refn{what_about_the_codomain_1},
tendo uma função $f : A \to B$,
podemos considerar ela como uma função com codomínio qualquer superconjunto de
$B$, sem mudar nada observável.
Em símbolos:
$$
f : A \to B  \mland  \range f \subset B'  \implies  f : A \to B'.
$$
Esse ponto de vista, identifica funções com gráficos iguais,
mas nem definimos ainda o que é um gráfico de função.
É o seguinte.
%%}}}

%%{{{ df: function_graph 
\definition.
\label{function_graph}%
\tdefined{função!gráfico}%
\sdefined {\graph{\sholed f}} {o gráfico da função $f$}%
Dado função $f : X\to Y$, o \dterm{gráfico da $f$}, é o conjunto
$$
\graph f \defeq \setst {\tup{x,f(x)}} {x \in X}.
$$
Observe que $\graph f \subset X\times Y$.
%%}}}

%%{{{ What about the codomain? (II) 
\note E o codomínio? (II).
\label{what_about_the_codomain_2}%
Em outras partes de matemática, especialmente em teoria das
categorias~(\ref{Category_theory}),
teoria dos tipos~(\ref{Type_theory}),
e álgebra,
consideramos que o codomínio duma função faz parte dela sim!
Pensando em funções como black boxes então, com essa visão,
temos que imaginar que as caixas pretas tem dois rótulos
impressos: um na sua entrada com o domínio escrito nele,
e um na sua saída com o codomínio.
Assim, a diferença do codomínio vira uma coisa imediatamente
observável: é só olhar no rótulo da saída!
%%}}}

%%{{{ labeled black box for function 
\note Funções como black boxes com rótulos.
Com a idéia (II) de função visualizamos uma função
$f : A \to B$ assim:
$$
\tikzpicture
\tikzi blackboxfuncat;
\endtikzpicture
$$
%%}}}

%%{{{ Equality in functions 
\note Igualdade de funções.
Dependendo qual ponto de vista de função seguimos,
a definição de igualdade para o tipo de função vai ser diferente!
Mostramos primeiramente as definições corretas para
o ponto de vista~(I) e o ponto de vista~(II)
(explicados nos~\refn{what_about_the_codomain_1}
e~\refn{what_about_the_codomain_2}).
Depois, escrevendo num jeito diferente, chegamos numa definição que
vamos realmente usar e que é aplicável independente do ponto de vista.
Nesse texto vamos sempre deixar claro para cada função encontrada qual
conjunto consideramos como seu domínio e qual como seu codomínio.%
\footnote{Exceto numas partes onde esclarecemos qual a noção de
função que utilizamos.}
Assim, a escolha de ponto de vista de função não vai nos afetar.
%%}}}

%%{{{ df: f_eq_g_setist 
\definition Igualdade (I): ``Conjuntista''.
\label{f_eq_g_setist}%
Sejam $f,g$ funções.
Digamos que $f=g$ sse \emph{quaisquer duas} das afirmações seguintes são válidas:
\beginol
\li $\dom f = \dom g$;
\li para todo $x \in \dom f$, $f(x) = g(x)$;
\li para todo $x \in \dom g$, $f(x) = g(x)$.
\endol
Equivalentemente,
$$
f = g \defiff \graph f = \graph g.
$$
%%}}}

%%{{{ df: f_eq_g_catist 
\definition Igualdade (II): ``Categorista''.
\label{f_eq_g_catist}%
Sejam $f,g$ funções.
Digamos que $f=g$ sse 
\beginol
\li $\dom f = \dom g$;
\li $\cod f = \cod g$;
\li para todo $x \in \dom f$, $f(x) = g(x)$.
\endol
%%}}}

%%{{{ Two religions 
\note Duas religiões.
\label{two_religions}%
Podemos pensar então que tem duas religiões, que vamos chamar
aqui de Conjuntista e de Categorista.  Cada um tem sua idéia
do que se trata uma função.
Note que cada um vai ler as notações $f : A \to B$ e $A \toby f B$
numa maneira diferente:
$$
\align
\text {Conjuntista:}\  &
\text{<<$f$ é uma função com domínio $A$, e $\range(f) \subset B$>>}\\
\text {Categorista:}\  &
\text{<<$f$ é uma função com domínio $A$, e codomínio $B$>>}.
\endalign
$$
Vamos escrever agora uma definição de igualdade flexível
para satisfazer os dois:
%%}}}

%%{{{ df: f_eq_g 
\definition igualdade (agnóstica).
\label{f_eq_g}%
Sejam $f,g : A\to B$ funções.
Definimos
$$
f=g
\defiff
\text{para todo $x \in A$, $f(x) = g(x)$.}
$$
%%}}}

%%{{{ f_eq_g is indeed flexible 
\remark.
Assuma a fé do Conjuntista e leia a~\ref{f_eq_g}:
ela é equivalente à~\refn{f_eq_g_setist}.
Agora assuma a fé do Categorista e leia a~\refn{f_eq_g}
novamente: ela é equivalente à~\refn{f_eq_g_catist}.
%%}}}

%%{{{ df: endomapping 
\definition.
\label{endomapping}%
\tdefined{endomapa}%
Uma função $f$ é um \dterm{endomapa} no $A$ sse $\dom f = \cod f = A$.
%%}}}

%%{{{ eg: succ and its black box 
\example.
A função $\succ : \nats\to\nats$
que retorna para cada natural $n$ seu sucessor $n+1$.
Dando por exemplo $2$ como entrada nela, observamos o valor
$\succ (2) = 3$:
$$
\tikzpicture
\tikzi blackboxfunsucc;
\endtikzpicture
$$
O $\succ$ é um exemplo de endomapa.
\endexample
%%}}}

%%{{{ remark: Some notions don't make sense for the Setist 
\remark.
Observe que a noção de ``ser endomapa'' não faz sentido
para quem escolher definir \emph{função} pela~\ref{f_eq_g_setist}
(ou seja, para o ``Conjuntista'')
pois ele nem sabe dizer qual é o codomínio duma função.
Logo vamos encontrar mais noções que também não fazem
sentido pra ele---fique alerto!
%%}}}

\endsection
%%}}}

%%{{{ Internal and external diagrams 
\section Diagramas internos e externos.
\label{Internal_and_external_diagrams}%

%%{{{ Internal diagrams 
\note Diagramas internos.
\tdefined{diagrama}[interno]%
Em certos casos podemos representar toda a informação numa função
usando \dterm{diagramas internos}, ou seja, diagramas que mostram
o interno do domínio e codomínio duma função, e como ela comporta
nele.
%%}}}

%%{{{ eg: internal_diagram_example 
\example.
\label{internal_diagram_example}%
Aqui um diagrama interno de duas funções $A \toby f B \toby g C$:
$$
\tikzpicture
\tikzi internaldiagram;
\endtikzpicture
$$
Aqui o conjunto $A$ tem 2 membros---não importa quais são, ou seja,
os nomes deles---o $B$ tem 3, e o $C$ tem 2 também.
\endexample
%%}}}

%%{{{ Names of elements 
\note Nomes de elementos.
É muito comum desenhar esse tipo de diagramas para construir exemplos e
contraexemplos que envolvem funções, e quando os \emph{quais são}
os membros não é importante desenhamos apenas um $\bullet$ para
representar os membros, com o entendimento que pontos distintos
representam membros distintos.
Note que \emph{se} quisermos definir formalmente um exemplo baseado num
desenho, nossa tarefa é trivial: é só escolher nomes para os $\bullet$
e pronto.
Por exemplo, dando esses nómes nos pontos
do~\ref{internal_diagram_example} chegamos no seguinte:
$$
\tikzpicture
\tikzi internaldiagramnames;
\endtikzpicture
$$
E agora para definir isso formalmente na escrita podemos apenas dizer:
Sejam os conjuntos
$$
A = \set{\mathrm a, \mathrm b} \qqqquad
B = \set{\mathrm c, \mathrm d, \mathrm e} \qqqquad
C = \set{\mathrm u, \mathrm v}
$$
e as funções $f : A\to B$ e $g : B\to C$ definidas pelas:
$$
\aligned
f(\mathrm a) &= \mathrm e\\
f(\mathrm b) &= \mathrm d
\endaligned
\qqqquad
\aligned
g(\mathrm c) &= \mathrm u\\
g(\mathrm d) &= \mathrm v\\
g(\mathrm e) &= \mathrm v.
\endaligned
$$
Observe que os $\mathrm a, \mathrm b, \mathrm c$, etc.~\emph{não são variáveis},
mas as próprias letras \sq{a}, \sq{b}, \sq{c}, etc.
Naturalmente escolhemos nomes bem conhecidos, como números, letras, etc.
%%}}}

%%{{{ remark: to what do those barred arrows correspond? 
\remark.
Então em que corresponde cada uma das setinhas barradas do diagrama interno?
Numa das \emph{equações} que definam a correspondente função,
ou seja, num par da forma $\tup{x, f(x)}$.
%%}}}

%%{{{ External diagrams 
\note Diagramas externos.
\tdefined{diagrama}[externo]%
Muitas vezes queremos olhar para a ``big picture'' e os detalhes
``internos'' da configuração não nos importam.
Pelo contrário, nos atrapalham: \emph{perdemos a floresta pelas árvores}.
Nesse caso usamos \dterm{diagramas externos}.
%%}}}

%%{{{ eg: external_of_previous_example 
\example.
\label{external_of_previous_example}%
O diagrama externo da configuração do~\ref{internal_diagram_example}
é o seguinte:
$$
A \longtoby f B \longtoby g C.
$$
\endexample
%%}}}

%%{{{ Diagrams of endomaps 
\note Diagramas de endomapas.
No caso especial que temos um endomapa $f:A\to A$,
podemos desenhar seu diagrama interno
sem usar duas cópias de $A$, mas apenas mostrando os mapeamentos assim
como o exemplo seguinte sugere.
%%}}}

%%{{{ eg: internal_diagram_of_endomap 
\example.
Considere o diagrama interno:
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi internaldiagramendo1;
\endtikzpicture
$$
Esse é o diagrama interno da função $f : A \to A$ definida pelas
$$
\xalignat8
f(1) &= 2; &
f(2) &= 1; &
f(3) &= 1; &
f(4) &= 4; &
f(5) &= 5; &
f(6) &= 8; &
f(7) &= 5; &
f(8) &= 5;
\endxalignat
$$
onde $A = \set {1,2,3,4,5,6,7,8}$.
\endexample
%%}}}

\endsection
%%}}}

%%{{{ How to define and how not to define functions 
\section Como definir e como não definir funções.

%%{{{ Q: what must we do to correctly define a function f : A -> B ? 
\question.
O que precisamos fazer para definir corretamente uma função?
%%}}}

%%{{{ A: We must make clear what its values are for all of its domain. 
\note Resposta.
Precisamos deixar claro qual é o seu domínio e o seu valor
para cada ponto no seu domínio (totalidade e determinabilidade).
Se consideramos que o codomínio da função faz parte dela também
(veja conversa na~\refn{Function_contept}), precisamos deixar
claro seu codomínio também---aqui sempre faremos isso.
%%}}}

%%{{{ Definition by expression 
\note Definição por expressão.
Uma das maneiras mais comuns para definir funções, é escrever algo do tipo:
\emph{Seja $f:A\to B$ a função definida pela \thole}
%%}}}

%%{{{ remark: what we define is f(x) not f 
\remark.
Literalmente, o que estamos definindo assim é o ``$f(x)$'' para todo $x \in A$,
e não o próprio $f$.  Mas, a $f$ sendo função, realmente é determinada para
seu comportamento (seus valores) das todas as entradas possíveis do seu domínio,
então isso realmente defina a própria função $f$---graças a definição de igualdade
de funções.  (Veja também a~\ref{from_x_in_A_union_B_to_A_union_B_to_union}.)
%%}}}

%%{{{ eg: a polynomial function on reals 
\example.
Seja $f : \reals \to \reals$ definida pela
$$
f(x) = x^2 + 2x + 1, \qquad \text{para todo $x\in \reals$}.
$$
Em geral, cada polinómio de $n$ variáveis,
pode ser visto como uma função de aridade $n$.
\endexample
%%}}}

%%{{{ not_well_defined_function_danger_argument_name_dependence
\beware depender de nomes de argumentos.
\label{not_well_defined_function_danger_argument_name_dependence}%
Quando definimos uma função vale a pena pensar como programador
que está tentando programar essa função, ou até assumir o papel
da própria função que vai receber seus argumentos e vai precisar
decidir qual seria o seu valor.
Imagine alguém programando uma função $\code{foo}$
de $\code{int}$ para $\code{int}$ numa linguagem de programação.
O programador e sua função não têm como saber o \emph{nome}
que o chamador da função vai usar quando chamando-la.
Em algum ponto ela pode ser chamada pelo $\code{foo(42)}$
passando assim diretamente o \emph{literal} $\code{42}$,
ou, depois de umas atribuições como $\code{int a = 42; int num = 42;}$,
chamá-la $\code{foo(a)}$ ou $\code{foo(num)}$.
Não tem como programar a função depender nesses nomes.
Por exemplo:
<<se for chamada com nome que começa com vogal, retorna o inteiro 0;
caso contrário, retorna o inteiro 1>>;
ou
<<retorna o tamanho do nome do teu argumento>>
(querendo retornar $\code{1}$ caso que for chamada pelo $\code{foo(a)}$,
e $\code{3}$ caso que for chamada pelo $\code{foo(num)}$).
%%}}}

%%{{{ noneg: not_well_defined_function_choice_dependence_noneg 
\nonexample.
\label{not_well_defined_function_choice_dependence_noneg}%
Seja $f : \ints \to \ints$ definida pela
$$
f(x+y) = y.
$$
\endnonexample
%%}}}

%%{{{ not_well_defined_function_danger_choice_dependence 
\beware depender de escolhas.
\label{not_well_defined_function_danger_choice_dependence}%
Por que o~\ref{not_well_defined_function_choice_dependence_noneg}
é um nãœxemplo mesmo?
Imagine que definimos uma
``função'' $f$ pela
$$
f(x+y) = y.
$$
O que seria o $f(2+3)$?  $3$?  Por que não $0$?
No final das contas,
$$
2 + 3 = 5 + 0 = 4 + 1 = 12 + (-5) = \dots
$$
e $f$ não tem como saber o jeito que tu imaginou ``quebrar''
sua entrada em dois somantes!
A $f$ está olhando ao seu argumento (aqui o $5$) e está tentando
decidir qual seria o seu valor nesse ponto!  E não tem como saber
pois, consultando a sua ``definição'' o resultado vai depender
da escolha desses $x$ e $y$.
%%}}}

%%{{{ Definitive description 
\note Descrição definitiva.
\tdefined{descrição definitiva}%
Podemos definir uma função $f : A \to B$ dando uma \dterm{descrição definitiva}
do seu valor num ponto $x$ do seu domínio:
$$
f(x) = \text{aquele $b \in B$ que {\xlthole}}.
$$
Cuidado pois nesse caso precisamos verificar que realmente para cada $x\in A$,
existe exatamente um $b\in B$ que satisfaz a afirmação no {\xlthole}.%
%%}}}

%%{{{ Definitive descriptor 
\remark Descritor definitivo.
\tdefined{descritor definitivo}%
\sdefined {\descrsym} {descritor definitivo}%
Existe uma notação especial para a frase <<aquele $b$ que {\xlthole}>>:
o \dterm{descritor definitivo} $\descrsym$:
$$
\text{<<aquele $b$ que {\xlthole}>>} \quad\leadsto\quad \descr b {{\xlthole}}.
$$
Essa notação parece bastante com a $\lambda$-notação que encontramos logo
na~\ref{A_touch_of_lambda}, mas é diferente pois na {\thole} aqui precisamos
algo que denota uma afirmação; na notação lambda algo que denota um objeto.
Aqui não vamos usar o descritor definitivo~$\descrsym$,
mas a $\lambda$-notação é importantíssima e ficaremos a usando o tempo todo.
Paciência até~\refn{A_touch_of_lambda} então.
%%}}}

%%{{{ eg: mother_and_son_function_and_wannabe 
\example.
\label{mother_and_son_function_and_wannabe}%
Seja $\cal P$ o conjunto de todas as pessoas.
\emph{Queremos} definir as funções $m,s : \cal P \to \cal P$ pelas equações
$$
\align
m(p) &= \text{a mãe de $p$}\\
s(p) &= \text{o filho de $p$}
\endalign
$$
(onde ``mãe'' significa ``mãe biológica'').
Mas\dots
\endexample
%%}}}

%%{{{ x: mother_and_son_function_and_wannabe 
\exercise.
Ache o problema no~\ref{mother_and_son_function_and_wannabe} acima.

\hint
Lembe-se as condições no~\refn{functionhood_conditions}.

\endexercise
%%}}}

%%{{{ definition by cases (branching) 
\note Definição por casos (branching).
Às vezes os valores $f(x)$ duma função $f$ não seguem o mesmo ``padrão'',
a mesma ``regra'' para todos os $x\in\dom f$.
%%}}}

%%{{{ eg: branching_example_1 
\example.
\label{branching_example_1}%
Seja $f : \reals \to \reals$ definida pela
$$
f(x)
=
\knuthcases{
x^2,     & se $x\in\rats$;\cr
0,       & se $x = \sqrt p$ para algum primo $p$;\cr
2x + 1,  & caso contrário.
}
$$
\endexample
%%}}}

%%{{{ beware: function_definition_by_cases_mistakes 
\beware.
\label{function_definition_by_cases_mistakes}%
Cada vez que definimos uma função por casos, precisamos verificar que:
\beginol
\li contamos para todos os casos possíveis da entrada;
\li não existe sobreposição inconsistente em nossos casos.
\endol
Seguem uns exemplos que demonstram esses erros.
%%}}}

%%{{{ eg 
\example.
Definimos a função $f : \nats \to \nats$, pela
$$
f(n) = \knuthcases{
0, & se $n$ pode ser escrito como $3k$ para algum $k\in\nats$;\cr
k, & se $n$ pode ser escrito como $3k+1$ para algum $k\in\nats$.\cr
}
$$
Aqui o problema é que $f$ não foi definida para todo o seu domínio, pois
existem números (por exemplo o $2$) que não satisfazem nenhum dos casos da
definição da $f$.
\endexample
%%}}}

%%{{{ remark: use of otherwise 
\remark.
Para ter certeza que tomamos cuidado de todos os casos possíveis,
podemos descrever o último caso com um ``otherwise''
(ou ``caso contrário'').
Observe que as funções $f_1, f_2 : \nats \to \nats$ definidas pelas
$$
\align
f_1(n) &= \knuthcases{
0, & se $n$ pode ser escrito como $3k$ para algum $k\in\nats$;\cr
n, & se $n$ pode ser escrito como $3k+1$ para algum $k\in\nats$;\cr
2, & otherwise.\cr
}\\
f_2(n) &= \knuthcases{
0, & se $n$ pode ser escrito como $3k$ para algum $k\in\nats$;\cr
n, & otherwise.\cr
}\\
\endalign
$$
são realmente duas funções bem-definidas e diferentes.
%%}}}

%%{{{ x: prove that they are different 
\exercise.
Prove que são diferentes!

\solution
Temos
$$
f_1(5) = 2 \neq 5 = f_2(5),
$$
logo $f_1 \neq f_2$.

\endexercise
%%}}}

%%{{{ eg: overlapping_inconsistent_cases 
\example.
\label{overlapping_inconsistent_cases}%
Definimos a função $g : \nats \to \nats$, pela
$$
g(n) = \knuthcases{
0,  & se $n$ é primo;\cr
1,  & se $n$ é par;\cr
12, & caso contrário.
}
$$
Aqui o problema é que não determinamos um único valor para cada membro do domínio da $g$.
Por exemplo o $2$, satisfaz os dois primeiros casos da definição acima.
Então $g(2) = 0$, pois $2$ é primo, e também $g(2) = 1$, pois $2$ é par!
Por isso essa $g$ é mal-definida, e não uma função.
\endexample
%%}}}

%%{{{ x: is g a well-defined function? 
\exercise.
A $h : \nats \to \nats$, definida pela
$$
h(n) = \knuthcases{
n+2, & se $n$ é primo;\cr
n^2, & se $n$ é par;\cr
12,  & caso contrário.
}
$$
é uma função bem-definida?

\hint
Qual é a sobreposição dos casos que aparecem na definição da $h$ e quais os
valores da $h$ seguindo cada um deles?

\solution
A $h$ realmente é bem-definida, mas isso não é imediatamente óbvio,
pois os dois primeiros casos na sua definição não são distintos,
e os valores que cada um escolhe para a $h$ são aparentemente diferentes.
Para provar que a $h$ é uma função bem-definida 
precisamos ver quais são os membros do seu codomínio que satisfazem
mais que um caso (aqui os dois primeiros casos, pois o terceiro é o ``caso contrário'')
e verificar que o valor da $h$ para esses membros são os mesmos, independente
do caso escolhido.
O único número natural que é primo e par e o $2$.
Seguindo o primeiro caso temos
$$
h(2) = 2 + 2 = 4,
$$
e seguindo o segundo caso temos
$$
h(2) = 2^2 = 4.
$$
Logo, a $h$ realmente é uma função bem-definida.

\endexercise
%%}}}

%%{{{ remark: compatible cases (cases agree) 
\remark.
Quando dois casos diferentes duma definição de função atribuem os mesmos
valores para as mesmas entradas da sua sobreposição comum, dizemos que
são \emph{compatíveis}, ou que \emph{concordam}.
%%}}}

%%{{{ Else-if 
\note Else-if.  Programadores são bastante acostumados com o uso de
``else-if'', e isso é algo que podemos usar definindo funções por casos.
Alterando a definição da função do~\ref{overlapping_inconsistent_cases}
podemos realmente (bem) definir uma função $g : \nats \to \nats$ pela
$$
g(n) = \knuthcases{
0,  & se $n$ é primo;\cr
1,  & senão; se $n$ é par;\cr
12, & caso contrário.
}
$$
Assim, cada caso é necessariamente separado de todos os casos anteriores.
Em programação o múltiplo uso de ``else-if'', é chamado uma
\dterm{if-else-if ladder}.
%%}}}

%%{{{ defining_function_by_formula 
\note Por fórmula.
\label{defining_function_by_formula}%
Outro jeito para definir uma função $f : A \to B$, é
determinar completamente quando é que $f(x) = v$,
para todo $x\in A$ e $v \in B$:
$$
f(x) = v \defiff \tunderbrace {\phi(x,v)} {function-like}.
$$
Onde a fórmula (ou a afirmação) $\phi(x,v)$ deve ser \dterm{function-like}
no $A$, ou seja, $\phi$ é tal que para todo $x\in A$, exatamente um $v \in B$
satisfaz a $\phi(x,v)$.
\footnote{Pode olhar também na definição formal disso,~\refn{functionlike}.}
%%}}}

%%{{{ x: welldefined_functionlike 
\exercise.
\label{welldefined_functionlike}%
As ``funções'' abaixo são bem-definidas?
$$
\xalignat2
f &: \reals_{\geq0} \to \reals &
f(x) = y &\defiff y^2 = x \\
g &: \nats \to \nats &
g(x) = y &\defiff y^2 = x \\
h &: \reals \to \reals &
h(x) = y &\defiff \text{$y$ é o maior inteiro que satisfaz $y \leq x$} \\
u &: \ints^2 \to \ints &
u(x,y) = z &\defiff \text{$z$ é primo} \mland z\divides x+y; \\
v &: \ints^2 \to \ints &
v(x,y) = z &\defiff \text{$z$ é o menor primo tal que $z\divides x+y$}.
\endxalignat
$$
Justifique tuas refutações.

\solution
A $f$ não é bem-definida: perdemos a unicidade; pois, por exemplo, como $1^2 = 1 = (-1)^2$, o $f(1)$ fica sem valor unicamente determinado.
\endgraf
A $g$ não é bem-definida: perdemos a totalidade; pois para o $2\in\nats$
por exemplo, não existe nenhum $y\in\nats$ com $y^2 = 2$.
\endgraf
A $h$ realmente é bem-definida, conhecida como ``floor''.
\endgraf
A $u$ não é bem-definida: perdemos a unicidade; por exemplo o
$u(1,5)$ fica sem valor determinado, pois $2$ é primo e $2 \divides 6$ mas $3$ também é primo e $3\divides 6$.
\endgraf
A $v$ também não é bem-definida: perdemos a totalidade; por exemplo o
$v(0,1)$ fica sem valor nenhum, pois nenhum primo divide o $0+1=1$.

\endexercise
%%}}}

%%{{{ defining_function_by_graph 
\note Por gráfico.
\label{defining_function_by_graph}%
Podemos definir uma função $f : A \to B$ se definir qual é o seu
gráfico $\graph f$.  Observe que do gráfico já podemos recuperar
o domínio mas o codomínio não (veja~\refn{recoverable_or_not}).
Então basta so deixar isso claro e pronto.
Claro que precisamos tomar cuidado: o gráfico tem que satisfazer
as condições de ser função: totalidade e
determinabilidade~(\ref{functionhood_conditions}).
Olhando apenas para o gráfico, só a determinabilidade pode ser
quebrada.  Mas se o domínio foi especificado separadamente,
precisamos verificar a totalidade também.
(Aqui vamos sempre deixar claro o domínio e o codomínio.)
Seguem uns exemplos.
%%}}}

%%{{{ eg: defining_function_by_graph_eg 
\example.
\label{defining_function_by_graph_eg}%
Sejam $A = \set{0,1,2,3}$ e $f : A \to \nats$ a função com gráfico
$$
\graph f = \set{ \tup{0,0}, \tup{1,1}, \tup{2,4}, \tup{3,2} }.
$$
Temos, por exemplo, $f(0) = 0$ e $f(2) = 4$.
\endexample
%%}}}

%%{{{ x: which_of_the_graphs_define_functions 
\exercise.
Quais dos gráficos abaixo definam funções com codomínio o $\nats$?
Quais os seus domínios recuperados por seus gráficos?
$$
\align
\graph f &= \set{ \tup{0,1}, \tup{2,4}, \tup{3,8}, \tup{1,2} } \\
\graph g &= \set{ \tup{0,12^{12}} } \\
\graph h &= \set{ \tup{0,1}, \tup{1,1}, \tup{0,1}, \tup{8,1}, \tup{3,2} } \\
\graph k &= \set{ \tup{\nats,0}, \tup{\ints,0}, \tup{\rats,0}, \tup{\reals,1} } \\
\graph r &= \emptyset \\
\graph s &= \set{ \tup{0,0}, \tup{1,1}, \tup{2,2^3}, \tup{3,3^{-1}} } \\
\graph t &= \set{ \tup{3,0}, \tup{2,0}, \tup{2,1}, \tup{2,7} } \\
\graph w &= \set{ \tup{0,0}, \tup{\tup{1,2},2}, \tup{\tup{12,12},2}, \tup{\tup{0,1,0,0},1} }
\endalign
$$

\solution
Temos:
$$
\xalignat2
f &: \set{ 0,1,2,3 } \to \nats &
r &: \emptyset \to \nats \\
g &: \set{ 0 } \to \nats &
s &: \text{não é (codomínio errado)} \\
h &: \set{ 0,1,3,8 } \to \nats &
t &: \text{não é (quebrou determinabilidade)} \\
k &: \set{ \nats,\ints,\rats,\reals } \to \nats &
w &: \set{ 0, \tup{1,2}, \tup{12,12}, \tup{0,1,0,0} } \to \nats
\endxalignat
$$

\endexercise
%%}}}

\blah.
Ainda não encontramos a notação mais interessante para definir funções.
Vamos estudá-la logo; ela merece uma secção própria (\ref{A_touch_of_lambda}).
Antes disso, vamos ver mais uma maneira de definir funções: com buracos!

\endsection
%%}}}

%%{{{ Empty (co)domains 
\section (Co)domínios vazios.

%%{{{ x: f_from_A_to_emptyset 
\exercise.
\label{f_from_A_to_emptyset}%
Seja $f : A \to \emptyset$.
O que podemos concluir sobre o $A$?
Quantas funções têm esse tipo?

\hint
O que significa ser função?

\solution
$A=\emptyset$, pois, caso contrário, pegando um $a\in A$,
chegamos na contradição $f(a) \in \emptyset$.
Quantas funções $f$ têm esse tipo?
Vamos resolver isso logo: veja~\ref{emptyfun} e~\ref{uniqueness_of_emptyfun}.

\endexercise
%%}}}

%%{{{ x: f_from_emptyset_to_A 
\exercise.
\label{f_from_emptyset_to_A}%
Seja $f : \emptyset \to A$.
O que podemos concluir sobre o $A$?
Quantas funções têm esse tipo?

\endexercise
%%}}}

%%{{{ df: emptyfun 
\definition Função vazia.
\label{emptyfun}%
\tdefined{função}[vazia]%
\iisee{vazia!função}{função, vazia}%
Uma função $f$ com $\dom f = \emptyset$ é chamada \dterm{função vazia}.
%%}}}

%%{{{ x: uniqueness_of_emptyfun 
\exercise.
\label{uniqueness_of_emptyfun}%
<<Uma>> ou <<a>>?

\solution
\proofpart{Para o conjuntista:} <<a>> mesmo!
Pois, tome $f,g$ funções vazias.
Logo $f : \emptyset \to A$ e $g : \emptyset \to B$
para alguns conjuntos $A,B$.
Vacuamente temos que para todo $x\in \emptyset$, $f(x) = g(x)$.
\crproofpart{Para o categorista:} para cada conjunto $A$,
temos exatamente uma função vazia com codomínio $A$.

\endexercise
%%}}}

\endsection

%%}}}

%%{{{ Holed expressions 
\section Expressões com buracos.

%%{{{ What is a holed expression? 
\note O que é uma expressão com buraco?.
\tdefined{buraco}%
Podemos criar uma função através duma expressão,
escolhendo um dos objetos que aparecem nela e o substituindo por um \dterm{buraco}.
Criamos assim \emph{aquela função} que recebendo um argumento,
retorna a expressão criada botando sua entrada no buraco da expressão.
Usamos $\bhole$, $\dhole$, e $\_$, para denotar esses buracos.
%%}}}

%%{{{ eg: holed_expression 
\example.
\label{holed_expression}%
Considere a expressão
$$
\align
\cos(1 + 5\cbrt2)^{2a} + \sin(5)&.
\intertext{Qual o tipo dela?
Ela denota um número real, ou seja,}
\cos(1 + 5\cbrt2)^{2a} + \sin(5) &: \reals.
\intertext{Escolhemos um objeto nela e botamos um buraco no seu lugar:}
\cos(\bhole + 5\cbrt2)^{2a} + \sin(5)&.
\intertext{Assim criamos uma função.
Qual o tipo dela?
Para decidir o domínio dela, olhamos para o tipo do objeto
substituido por esse buraco.  Nesse caso, consideramos $1 : \reals$, então
temos}
\cos(\bhole + 5\cbrt2)^{2a} + \sin(5) &: \reals \to \reals
\intertext{
Uma outra opção seria escolher o $2$ no $5\cbrt2$, ou até o próprio $5\cbrt2$,
criando assim a função}
\cos(1 + \bhole)^{2a} + \sin(5) &: \reals \to \reals
\endalign
$$
do mesmo tipo.
\endexample
%%}}}

%%{{{ more than one hole 
\blah.
Podemos botar mais que um buraco na mesma expressão,
assim criando funções de aridades maiores.
Seguimos a convenção que os seus argumentos são botados
nos buracos que aparecem na ordem de esquerda para direita,
e de cima pra baixo.
%%}}}

%%{{{ eg: holed_expression_many 
\example.
\label{holed_expression_many}%
Considere de novo a expressão
$$
\align
\cos(1 + 5\cbrt2)^{2a} + \sin(5) &: \reals,
\intertext{mas agora bote os buracos}
\cos(\bhole + 5\cbrt2)^{2\bhole} + \sin(\bhole)&.
\intertext{Qual o tipo dessa função?
Cada um dos buracos está esperando receber um real,
ou seja:}
\cos(\bhole + 5\cbrt2)^{2\bhole} + \sin(\bhole)&:\reals^3\to\reals
\intertext{Uma outra opção seria criar a função}
\cos(1 + \bhole\cbrt\bhole)^{\bhole a} + \sin(\bhole) &: \reals^4 \to \reals,
\endalign
$$
etc.
\endexample
%%}}}

%%{{{ x: calculate_holes 
\exercise.
Calcule:
\beginol
\li $(2 + \bhole)(40)$;
\li $(\bhole + 2\bhole)(2,4)$;
\li $(\dhole \ntimes 2^{\dhole})(3,0)$;
\li $(\set{1,2,3} \union \dhole)(\set{2,8})$.
\endol

\solution
Calculamos:
$$
\align
(2 + \bhole)(40) &= 2 + 40 = 42 \\
(\bhole + 2\bhole)(2,4) &= 2 + 2^4 = 18 \\
(\dhole \ntimes 2^{\dhole})(3,0) &= 3 \ntimes 2^0 = 3 \\
(\set{1,2,3} \union \dhole)(\set{2,8}) &= \set{1,2,3} \union \set{2,8} = \set{1,2,3,8}
\endalign
$$

\endexercise
%%}}}

%%{{{ remark: fractions and the symbol of division 
\remark.
Da expressão
$$
\frac 1 2 : \rats
$$
podemos criar as funções
$$
\xalignat3
\frac {\bhole} 2 & : \ints \to \rats &
\frac 1 {\bhole} & : \ints_{\neq0} \to \rats &
\frac {\bhole} {\bhole} & : \ints\times\ints_{\neq0} \to \rats
\endxalignat
$$
Agora o símbolo $\div$ da operação binária de divisão que aparece nos calculadores
talvez faz mas sentido, né?
%%}}}

%%{{{ Limitations 
\note Limitações.
Para um uso simples e rápido as expressões com buracos oferecem uma
ferramenta muito útil.  Mas, temos umas limitações importantes:
\beginol
\li Não podemos ``ligar'' dois ou mais buracos para representar
a idéia que o mesmo argumento vai ser copiado em todos eles.
\li Não podemos escolher a órdem que os argumentos da função
criada vão preencher os buracos.
\endol
Finalmente vamos estudar a notação lambda e com ela vamos
superar essas limitações facilmente!
%%}}}

\endsection
%%}}}

%%{{{ A touch of lambda 
\section Um toque de lambda.
\label{A_touch_of_lambda}%

%%{{{ Useless namings 
\note Nomeamentos inúteis.
\label{useless_namings}%
Imagine que precisamos identificar uma certa função dum conjunto
$A$ prum conjunto $B$, e depois de muitos cálculos e usando várias
outras funções e objetos dados pelo nosso problema,
concluimos com a frase:
\emph{<<\dots a função desejada é aquela função que recebendo
como entrada um número $x$, ela retorna o $2x+5$.>>}.
Vamos isolar esta subfrase:
$$
\text{aquela função que recebendo como entrada um $x$, retorna o \thole$x$\thole}.
$$
O que ela denota?
Claramente uma função.
Mas qual é o \emph{nome} dessa função?
Pois é, ela não tem.
É uma função \emph{anônima}.
Isso talvez parece estranho, mas acontece o tempo todo com outros tipos
de objetos matemáticos, por exemplo com números.
Suponha que temos um triângulo com base $b$ e altura $h$.
Falamos
$$
\text{<<a área do triângulo é $bh/2$>>}
$$
sem nenhuma obrigação de nomear essa área com um nome para usá-la;
e ninguém reclama.
Se tivessimos essa obrigação deveriamos falar:
$$
\text{<<\dots seja $a = bh/2$.  A área do triângulo é $a$.>>}
$$
Claramente isso é inútil.
Introduzimos um novo nome apenas para usá-lo logo após e nunca mais.
Em nossa última frase ``a área do triângulo é $a$'', a informação
nem é mais visível.  O leitor vai ter que lembrar qual foi a definição desse $a$,
ou ir procurar achá-la.
Obviamente a abordagem anterior é melhor.
Com ela podemos enunciar nossa proposição numa maneira melhor:
$$
\text{<<a área dum triângulo com base $b$ e altura $h$ é $bh/2$>>}
$$
em vez de falar algo do tipo
$$
\text{<<a área dum triângulo com base $b$ e altura $h$ é $a$, onde $a = bh/2$>>.}
$$
\endgraf
Para usar um exemplo de ``nomeamento inútil'' em programação,
considere as funções seguintes em Python,
cada uma programada por um programador diferente:
\iipl Python
\sourcecode uselessnaming.py;
Como funções são iguais, mas o programador que programou $\code{g}$,
fez algo estranho.
Decidiu nomear a expressão $\code{2 * x + 1}$ com o nome $\code{r}$,
e a única coisa que ele fez com esse $\code{r}$, foi returnar seu
valor.  Pra quê isso, programador?
%%}}}

%%{{{ From words to lambda 
\note De palavras para lambda.
Voltamos na frase
$$
\text{``aquela função que recebendo como entrada um $x$,
retorna o \thole$x$\thole''}
$$
onde ``\thole$x$\thole'' é uma expressão que determina um único objeto e que,
possivelmente depende (refere) no $x$, como aconteceu por exemplo com o $2x+5$ acima.
Se essa frase realmente determina uma função, então podemos também
definir uma função \dterm{epônima}\ii{epônima}~(``com nome'') quando desejamos,
escrevendo:
$$
\gather
\text{Seja $f : A \to B$ tal que}\\
\text{$f \defeq \text{aquela função que recebendo\dots}$}.
\endgather
$$
Mas escrever todo isso toda vez que queremos ``construir'' uma função anônima
é muito chato.  Bem vindo $\lambda$ (lambda) da notação de
$\lambda$-calculus~(\ref{Lambda_calculus})!
Escrevemos apenas
$$
\lam x {2x+5}
$$
para a frase:
$$
\mobraceleg {\text{aquela função que recebendo como entrada um}} {\lambda}~~x~~\mobraceleg {\text{retorna o}} {.}~~2x+5.
$$
%%}}}

%%{{{ df: lambda_abstraction 
\definition lambda abstracção.
\label{lambda_abstraction}%
\tdefined{$\lambda$-abstracção}%
\tdefined{$\lambda$-abstracção}[corpo]%
\sdefined {\lam {\sholed x} {\sholed {\thole}}} {$\lambda$-abstracção}%
A expressão
$$
\lam x {\text{\thole$x$\thole}}
$$
é chamada \dterm{$\lambda$-abstracção} e \emph{denota uma função}:
$$
\text{``aquela função que recebendo como entrada um $x$,
retorna o \thole$x$\thole''}
$$
Supomos aqui que o domínio e codomínio são claros pelo contexto.
Chamamos a parte ``\thole$x$\thole'' o \dterm{corpo} da abstracção.
%%}}}

%%{{{ df: barred arrow 
\definition.
\label{mapsto}%
\tdefined{setinha barrada}%
\sdefined {(\sholed x \mapsto \sholed \thole)} {função anônima}%
Uma notação diferente usada em matemática para criar funções anônimas
utiliza a \dterm{setinha barrada} \sq{$\mapsto$}:
$$
\text{escrevemos}\qquad
(x \mapsto \thole)
\qqtext{como sinônimo de}
\lam x {\thole}.
$$
%%}}}

%%{{{ remark: we won't use mapsto, we'll use lambdas instead 
\remark.
Não vamos usar muito a notação $(x \mapsto \thole)$.
Pois a notação $\lam x {\thole}$ serve bem melhor para a maioria dos nossos usos.
%%}}}

%%{{{ remark: variable_binder_in_lambda & alpha_equiv_first_contact 
\remark.
\label{variable_binder_in_lambda}%
\label{alpha_equiv_first_contact}%
O $\lambda$ é um \emph{ligador de variável}.
Todos os $x$ que aparecem livres no {\thole$x$\thole}
viram ligados com o $\alert{x}$ do $\lambda \alert{x}$.
Naturalmente consideramos funções que são diferentes apenas nos
nomes das variáveis ligadas como iguais.
Por exemplo:
$$
\lam x x = \lam y y.
$$
Compare com programação onde uma troca \emph{com cuidado} de variáveis
resulta em programas e procedimentos equivalêntes.
Precisamos tomar os mesmos cuidados aqui, e deixamos os
detalhes formais para o~\ref{Lambda_calculus}.
%%}}}

%%{{{ remark: comparison with set builder 
\remark Comparação com set builder.
Num certo sentido o papel de $\lam x {\thole}$ é parecido com o papel
do $\setst x {\thole}$.  O set builder construe conjuntos (anônimos),
e o $\lambda$ parece então um ``function builder'' que construe funções
(anônimas).
%%}}}

%%{{{ Is it functions that we are really constructing? 
\warning Construimos funções mesmo?.
É ``forte demais'' afirmar que a expressão $\lam x {x^2}$ determina
uma função.  Qual é o seu domínio?  E o categorista vai perguntar também
sobre seu codomínio.
Sem essa informação faz mais sentido considerar que um termo como o $\lam x {x^2}$
corresponde numa \emph{alma}, ou seja, \emph{um comportamento} que em geral
pode ``animar o corpo'' de várias funções.%
\footnote{Aqui tô usando a palavra ``corpo'' numa maneira mais antropomórfica,
e nesse caso corresponde num \emph{tipo} de função, que tá esperando uma alma
para habitá-lo.
Quando pegamos emprestada a terminologia de programação a mesma palavra
``corpo'' acaba significando algo diferente:
aí, o corpo duma ``função'' seria o código que determina o seu comportamento.}
Se as informações de domínio (e codomínio dependendo da fé) não estão
claras pelo contexto escrevemos o tipo logo após da $\lambda$-expressão
para realmente determinar uma função.
Podemos ``tipar'' o termo $\lam x {x^2}$ então
$$
\xalignat3
\lam x {x^2} & \eqtype \reals\to\reals &
\lam x {x^2} & \eqtype \nats\to\nats &
\lam x {x^2} & \eqtype \set{0}\to\nats
\endxalignat
$$
etc., e agora sim cada uma dessas determina mesmo uma função.
%%}}}

\blah.
Então:
o $\lambda$ nos permite criar funções anônimas numa maneira simples e útil.
E o que podemos fazer com uma expressão dessas?
\emph{Tudo} que podemos fazer com uma função!

%%{{{ eg: applying an anonymous function to an argument 
\example.
Calculamos:
$$
\align
\plam x {2x+5} (4) &= 2\ntimes 4 + 5 = 13 \\
\plam x x (2)      &= 2.
\endalign
$$
Em geral omitimos as parenteses no argumento, escrevendo:
$$
\plam x {2x+5} \lapp 4, \qquad
\plam x x \lapp 2, \qquad
\text{etc.},
$$
algo que acontece com funções epônimas também
(veja~\ref{function_notation}).
\endexample
%%}}}

%%{{{ dot-till-end convention 
\note Convenção.
Para evitar uso excessivo de parenteses, acordamos que o corpo duma
$\lambda$-abstracção estende o maior possível, por exemplo:
$$
\plam x {x + y + z}
\qqtext{significa}
\plam x {\paren{x + y + z}}.
$$
%%}}}

%%{{{ The soul of lambda-computation 
\note A alma da $\lambda$-computação.
Assim que aparecer uma coisa $\heart$ no lado duma
$\lambda$-abstracção $\plam x {\dotswithsome x}$
temos uma expressão \dterm{reductível} (chamada \dterm{redex})
$$
\plam x {\mubrace {\dotswithsome x} {\tau(x)}} \lapp \heart
$$
ou seja, podemos fazer um passo computacional:
\emph{substituir o redex inteiro por uma nova expressão
criada substituindo todas as instâncias livres de $x$ no $\tau(x)$
por $\heart$, chegando assim no $\tau(\heart)$}.
Denotando esse passo com um \sq{$\lamstep$}, temos então
$$
\plam x {\mubrace {\dotswithsome x} {\tau(x)}} \lapp \heart
\lamstep
\mubrace {\dotswithsome \heart} {\tau(\heart)}.
$$
%%}}}

%%{{{ eg: calculate lambda reduction 
\example.
Calcule a expressão:
$$
\plam x {2 + \plam y {x - y} \lapp 8} \lapp 50.
$$
\solution
Procuramos achar \emph{redexes} e achamos dois:
$$
\xalignat2
&\redex {\plam x {2 + \plam y {x - y} \lapp 8} \lapp 50} &
&\plam x {2 + \redex {\plam y {x - y} \lapp 8}} \lapp 50.
\endxalignat
$$
Então temos dois caminhos diferentes para seguir.
Vamos tentar ambos:
$$
\align
\redex {\plam x {2 + \plam y {x - y} \lapp 8} \lapp 50}
&\lstep 2 + \redex {\plam y {50 - y} \lapp 8} \\
&\lstep 2 + \paren{50 - 8} \\
&\isteq 44.
\intertext{%
Escolhendo o outro caminho, talvez chegamos em algum valor
diferente.
Vamos ver:
}
\plam x {2 + \redex {\plam y {x - y} \lapp 8}} \lapp 50
&\lstep \redex {\plam x {2 + \paren{x - 8}} \lapp 50} \\
&\lstep 2 + \paren{50 - 8} \\
&\isteq 44.
\endalign
$$
Interessante.
Chegamos no mesmo valor.
Mas talvez foi coincidência.
\endexample
%%}}}

%%{{{ Church--Rosser: No it wasn't 
\note Church--Rosser: <<Foi não>>.
{\Church[teorema Church--Rosser]}%
{\Rosser[teorema Church--Rosser]}%
Graças ao teorema Church--Rosser que vamos estudar no~\ref{Lambda_calculus}
sabemos que se existem dois caminhos que chegam em dois valores ``finais'',
não podem ser valores diferentes.
Isso não quis dizer que as escolhas não importam,
pois pode ser que um caminho nem termine!
Mas se dois caminhos realmente chegarem em valores finais mesmo,
então chegaram no mesmo valor!%
\footnote{Essa é uma grande hipersimplificação do teorema de Church--Rosser;
para a versão ``raiz'', paciência até o~\ref{Lambda_calculus}.}
%%}}}

%%{{{ x: calculate_lambda_expressions 
\exercise.
\label{calculate_lambda_expressions}%
Calcule os seguintes:
\beginol
\li $\plam x x \la 5$;
\li $\plam y {42} \la 5$;
\li $\plam z x \la 5$;
\li $\plam x {x+1} \la 41$;
\li $\plam x {2 + \plam y {3y} \la 5} \la 3$;
\li $\plam x {2 + \plam y {3y} \lap {x^2} } \la 3$;
\li $\plam x {2 + \plam y {xy} \la 4 } \la 3$;
\li $\lam x {\plam x {x + 1} \la 1 \ntimes \plam y {xy} \la 4}$. % <- cited as "last"
\endol
Em cada passo, sublinhe o redex que tu escolheu para reduzir.
Não se preocupe se uns deles parecem errados ou bizarros,
nem se tu errar calculando uns deles; mas verifique tuas respostas.

\solution
Calculamos:
$$
\align
\redex {\plam x x \la 5}      &\lstep 5 \\
\redex {\plam y {42} \la 5}   &\lstep 42 \\
\redex {\plam z x \la 5}      &\lstep x \\
\redex {\plam x {x+1} \la 41} &\lstep 41 + 1 \\
&\isteq 42 \\
\redex {\plam x {2 + \plam y {3y} \la 5} \la 3}
&\lstep 2 + \redex{\plam y {3y} \la 5} \\
&\lstep 2 + 3\ntimes 5 \\
&\isteq 17 \\
\redex {\plam x {2 + \plam y {3y} (x^2)} \la 3}
&\lstep 2 + \redex {\plam y {3y} \lap {3^2}} \\
&\lstep 2 + 3 \ntimes 3^2 \\
&\isteq 29 \\
\plam x {2 + \redex {\plam y {xy} \la 4}} \la 3
&\lstep \redex {\plam x {2 + x\ntimes 4} \la 3} \\
&\lstep 2 + 3 \ntimes 4 \\
&\isteq 14 \\
\lam x {\plam x {x + 1} \la 1 \ntimes \redex {\plam y {xy} \la 4}}
&\lstep \lam x {\redex {\plam x {x + 1} \la 1} \ntimes x\ntimes 4} \\
&\lstep \lam x {(1 + 1) \ntimes x \ntimes 4)} \\
&\isteq \lam x {8x}.
\endalign
$$
Se o último cálculo parece insatisfatório, é apenas
por causa de um preconceito teu que favorece os objetos
de tipo ``número'' contra os objetos de tipo ``função''.
Mais sobre isso no~\ref{first_class_citizens}.

\endexercise
%%}}}

%%{{{ x: find_expressions_with_given_types_abstract 
\exercise.
\label{find_expressions_with_given_types_abstract}%
Quando puder, escreva $\lambda$-expressões que podem ser
tipadas com os tipos seguintes:
$$
\xalignat2
&\aligned
&: A \to A \\
&: A\cross B \to A \\
&: A\cross B \to B \\
&: A\cross A \to A \\
&: A \to A \cross A \\
&: A \to A \cross B
\endaligned
&
&\aligned
&: A \cross B \to B \cross A \\
&: A \union B \to A \\
&: A \to A \union B \\
&: A \cross B \to A \union B \\
&: A \union B \to A \cross B \\
&: \paren{\pfcross A B \union \pfcross C D} \to \pfcross {(A \union C)} {(B \union D)}.
\endaligned
\endxalignat
$$
Observe que sobre os $A,B$ tu não tens nenhuma informação.
Pode achar mais que uma resolução para algum desses desafios?

\endexercise
%%}}}

%%{{{ x: find_expressions_with_given_types 
\exercise.
\label{find_expressions_with_given_types}%
Escreva $\lambda$-expressões que podem ser tipadas com os tipos seguintes:
$$
\align
&: \nats \to \nats \\
&: \nats^2 \to \nats \\
&: \nats \to \nats^2 \\
&: \pset\nats\setminus\set{\emptyset} \to \nats \\
&: \pset\nats \to \nats \\
&: \psetfin\nats \to \nats.
\endalign
$$
Tente usar o argumento no corpo dos teus $\lambda$-termos se puder.

\endexercise
%%}}}

%%{{{ x: eta_conversion_first_encounter 
\exercise.
\label{eta_conversion_first_encounter}%
Seja $f : A \to B$.
Qual nome tu daria para a função $\lam x {f \app x}$?
Lembre-se que graças as convenções notacionais essa expressão é a mesma com a
$\lamp x {f(x)}$.

\hint
Como a função $\lam x {f \app x}$ comporta?

\solution
$f$.

\endexercise
%%}}}

%%{{{ beta-reduction 
\note $\beta$-reducção.
O nome real desse passo computacional de $\lambda$-cálculo que encontramos
aqui é \dterm{$\beta$-reducção}, e o redex é formalmente chamado um
\dterm{$\beta$-redex}.
Para enfatisar quando for necessário escrevemos \sq{$\betastep$} para denotar
um passo de $\beta$-reducção.
%%}}}

\blah.
Tem mais duas regras de $\lambda$-computação:
$\alpha$-renomeamento e $\eta$-conversão.

%%{{{ alpha-renaming 
\note $\alpha$-renomeamento.
O princípio que nos permite identificar como equivalentes as $\lambda$-expressões
que diferem apenas nas escolhas das suas variáveis ligadas é chamado
\dterm{$\alpha$-renomeamento} ou \dterm{$\alpha$-conversão} ou
\dterm{$\alpha$-equivalência}.
Podemos considerar cada $\lambda$-abstracção um \dterm{$\alpha$-redex};
denotamos por \sq{$\alphastep$} um passo onde aconteceu um $\alpha$-renomeamento.
%%}}}

%%{{{ eg: alpharename_code 
\example em programação.
\label{alpharename_code}%
Considere o código seguinte:
\sourcecode alpharename1.py;
Aqui parece que o $\code{z}$ é uma variável já declarada e definida
no escopo exterior.
Deve ser óbvio que podemos trocar a variável $\code{x}$ por
qualquer variável que não aparece livre no corpo da $\code{f}$.
Escolhendo trocá-la por $\code{y}$, por exemplo, chegamos na função
equivalente:
\sourcecode alpharename2.py;
onde semanticamente nada mudou no nosso programa.
Mas seria errado ter escolhido a $\code{z}$, pois ela capturaria
a antes-livre $\code{z}$ do corpo da $\code{f}$:
\sourcecode alpharename3.py;
Isso não é mais o mesmo programa.
Antes a função $\code{f}$ poderia ser descrita como
\standout
<<a função que retorna o produto da sua entrada com $z$>>;
\endstandout
uma descrição que serve para qualquer um dos dois primeiros programas.
Observe que não usei nem \sq{$x$} nem \sq{$y$} nessa frase,
mas não teria como descrevé-la sem usar a \sq{$z$}.
Já a terceira função seria
\standout
<<a função que retorna o quadrado da sua entrada>>;
\endstandout
algo claramente diferente.
\endexample
%%}}}

%%{{{ eg: alpharename_sets 
\example em conjuntos.
\label{alpharename_sets}%
\ii{variável}[capturada]%
Considere o conjunto seguinte:
$$
\setst x {x < z^2}.
$$
Obviamente podemos trocar o \sq{$x$} por qualquer variável que não aparece
livre no filtro \sq{$x < z^2$}, por exemplo por \sq{$y$}:
$$
\setst x {x < z^2}
\inteq
\setst y {y < z^2};
$$
mas não poderiamos ter escolhido substituir o \sq{$x$} por \sq{$z$},
pois assim aconteceria \emph{captura de variável}
(já discutimos isso no~\ref{variable_capturing_in_set_builder}).
\endexample
%%}}}

%%{{{ eta-conversion 
\note $\eta$-conversão.
Essa é a idéia de \emph{extensionalidade} para o sistema:
se duas expressões comportam na mesma maneira, as consideramos equivalentes.
Qualquer expressão da forma $\lam x {f \app x}$ é um \dterm{$\eta$-redex},
e denotamos por \sq{$\etastep$} o passo onde o substituimos por $f$.
%%}}}

%%{{{ pic: eta-wrapping 
\note $\eta$-wrapping desenhado.
Começa com uma função $g$; agora pega um embrulho preto e embrulhe;
e pronto, tu criou uma ``nova'' função.
Só que não é tão nova né?
Talvez tu vai rotulá-la como $f$ ou talvez vai escolher um rótulo
mais honesto, como $\lam x {g \app x}$.
$$
\xalignat3
&\tikzpicture
\tikzi blackboxfuneta0;
\endtikzpicture
&
&\tikzpicture
\tikzi blackboxfuneta1;
\endtikzpicture
&
&\tikzpicture
\tikzi blackboxfuneta2;
\endtikzpicture
\endxalignat
$$
A $\eta$-conversão nos permite identificar as duas caixas acima.
%%}}}

%%{{{ eg: etawrap_code 
\example em programação.
\label{etawrap_code}%
Considere o código seguinte, que corresponde no desenho acima:
\sourcecode etawrap.py;
Deve ser óbvio que essa $\code{f}$, como função,
comporta na mesma maneira que a $\code{g}$.
\endexample
%%}}}

%%{{{ x: etawrap_sets 
\exercise em conjuntos.
\label{etawrap_sets}%
Qual seria o equivalente de $\eta$-conversão para os conjuntos?

\solution
$A = \setst x {x \in A}$.

\endexercise
%%}}}

%%{{{ eg: alpha beta eta steps 
\example.
Computamos a mesma expressão usando dois caminhos diferentes:
$$
\xalignat2
&\aligned
\redex {\plam x {\plam y {y^2} \lapp x}} \lapp 3
&\estep \redex {\plam y {y^2}} \lapp 3 \\
&\astep \redex {\plam x {x^2} \lapp 3} \\
&\bstep 3^2.
\endaligned
&
&\aligned
\redex {\plam x {\plam y {y^2} \lapp x}} \lapp 3
&\astep \redex {\plam y {\plam y {y^2} \lapp y}} \lapp 3 \\
&\estep \redex {\plam y {y^2} \lapp 3} \\
&\bstep 3^2.
\endaligned
\endxalignat
$$
Observe que provavelmente nenhum humano sano escolheria esse
$\alpha$-renomeamento no segundo caminho, pois a expressão
piorou para nossos olhos humanos; aqui escolhi proceder assim
para enfatizar que não tem nada (literalmente) errado nisso.
\endexample
%%}}}

\endsection
%%}}}

%%{{{ Composition 
\section Composição.

%%{{{ Composition with black boxes 
\note Composição com black boxes.
Suponha que temos uma configuração de conjuntos e funções assim:
$$
A \toby f B \toby g C.
$$
Note então que a saída da $f$ pode ser usada como entrada para
a $g$:
$$
\tikzpicture
\tikzi blackboxfuncomp1;
\endtikzpicture
$$
Podemos criar um novo black box, conectando os ``cabos'' assim:
$$
\tikzpicture
\tikzi blackboxfuncomp2;
\endtikzpicture
$$
Pintamos preta essa construção, botando os rótulos certos
de domínio e codomínio, e pronto:
$$
\tikzpicture
\tikzi blackboxfuncomp3;
\endtikzpicture
$$
Criamos assim a composição $g\of f$ das funções $f$ e $g$.
Formalmente, chegamos na definição seguinte.
%%}}}

%%{{{ df: fcompose 
\definition.
\label{fcompose}%
\tdefined{função}[composição]%
\iisee{composição!de funções}{função, composição}%
Sejam
$A \toby f B \toby g C$.
Definimos a função $g\of f : A\to C$ pela
$$
\paren{g\of f}(x) \defeq g\paren{f(x)}.
$$
Assim temos
$$
\xalignat2
\dom (g\of f) &= \dom f &
\cod (g\of f) &= \cod g.
\endxalignat
$$
Chamamos a $g\of f$ a \dterm{composição} da $g$ \emph{seguindo}
a $f$ (ou ``da $g$ com $f$'', ou até ``$g$ \emph{de} $f$'').
%%}}}

%%{{{ beware: gof_not_fog ; diagrammatic_notation 
\beware.
\label{gof_not_fog}%
\label{diagrammatic_notation}%
\tdefined{composição}[diagramática]%
{\iisee{diagramática}{composição}}%
{\iisee{notação!diagramática}{composição}}%
Escrevemos $g\of f$ e não $f\of g$ para a composição na~\ref{fcompose}!
Então quando temos $A\toby f B\toby g C$, a composição é
$A \toby {g\of f} C$, que parece o oposto da ordem das setinhas.
Definimos a notação alternativa
$$
f \dcom g \defeq g\of f,
$$
chamada \dterm{notação diagramática}
pois concorda com a posição das setinhas do diagrama:
$$
A \toby {f \dcom g} C.
$$
Mas vamos principalmente usar a notação $g\of f$ mesmo.
%%}}}

%%{{{ x: when_is_fog_defined 
\exercise.
\label{when_is_fog_defined}%
Sejam $A \toby f B \toby g C$.
Qual função é a $f \of g$?

\solution
Nem é definida a $f \of g$ no caso geral!
Para ser definida, é necessário e suficiente ter
$A = C$.

\endexercise
%%}}}

%%{{{ defining functions as compositions 
\note Definindo funções como composições.
Como $\of$ é uma operação de funções, ganhamos então mais uma maneira
de definir funções.
Dadas componíveis funções $A \toby f B \toby g C$ podemos
definir uma função $h : A \to C$ apenas escrevendo:
$$
\text{<<Seja $h = g\of f$.>>}
$$
Claramente (e seguindo a discussão no~\refn{useless_namings})
não precisamos dar um nome para essa função.
Podemos apenas falar sobre a $g\of f$, exatamente no mesmo
jeito que falamos do número $2\ntimes 8$ sem precisar
dar um nome pra ele!
%%}}}

%%{{{ why_not_compose_more 
\note Por que não compor mais?.
\label{why_not_compose_more}%
Sejam $f : A \to B$ e $g : B' \to C$, e suponha que $B \subsetneq B'$.
É tentador definir uma função de composição $g\of f : A \to C$ pela
$$
(g\of f)(x) = g\big(f(x)\big) \quad \text{para todo $x\in A$}.
$$
No final das contas, para qualquer $x\in A$ temos $f(x)\in B$
e como $B\subsetneq B'$, também temos $f(x) \in B'$.
Então $g(f(x))$ é definido!
Ou seja, por que não relaxar pouco a restricção que temos na definição
da composição
$$
\text{de}
\quad
\cod f = \dom g
\quad
\text{para}
\quad
\cod f \subset \dom g
\ \ \text{?}
$$
Usando black boxes, temos as funções
$$
\tikzpicture
\tikzi blackboxfuncompsubset0;
\draw[-Latex]  (1.5,0)  -- (0.5,0);
\draw[-Latex]  (-0.5,0) -- (-1.5,0);
\node (x)   at (4.5,0)    {$x$};
\node (fx) at (0,0)       {$f(x)$};
\node (gfx) at (-4.8,0)   {$g(f(x))$};
\endtikzpicture
$$
e queremos ``conectar os cabos'' para criar um novo black box
$$
\tikzpicture
\tikzi blackboxfuncompsubset0;
\draw [rounded corners=0mm]
      (-3,1)--(-3,-1)--(3,-1)--(3,1)--cycle;
\draw[-Latex]  (1.5,0) -- (-1.5,0);
\node (x)    at (4.5,0)     {$x$};
\node (gfx)  at (-4.8,0)    {$g(f(x))$};
\draw [rounded corners=0.25mm, fill=gray!50]
      (-0.3,0.04)--(-0.3,-0.04)--(0.3,-0.04)--(0.3,0.04)--cycle;
\endtikzpicture
$$
pintar ele preto e considerar como a $g\of f$ de $A$ para $C$ mesmo:
$$
\tikzpicture
\tikzi blackboxfuncompthree;
\node (x)   at (4.5,0)    {$x$};
\node (gfx) at (-4.8,0)   {$g(f(x))$};
\node (gof) at (0,0)      {$g\of f$};
\node (A)   at (2.7,0.7)  {$A$};
\node (C)   at (-2.7,0.7) {$C$};
\endtikzpicture
$$
Qual o problema com isso?
<<Nenhum>>, uns matemáticos responderiam, e ficariam usando esse tipo
de composição ``mais geral''.
Mas para a gente aqui, vamos supor que para motivos que não
importam---talvez religiosos, ou um TOC mesmo---\emph{não podemos}
conectar esse cabo no meio quando os conjuntos são diferentes:
\standout
\emph{<<Não comporás funções $f$ e $g$ se $\cod f \neq \dom g$!>>}
\endstandout
Essa suposta restricção, na verdade não nos restringe---pelo contrário:
nos ajuda criar composições ``limpas'' sem gambiarras como essa
``fita durex'' no cabo conectando o $B$ com o $B'$!
Trabalhe agora no exercício seguinte para demonstrar exatamente isso!
%%}}}

%%{{{ x: inclusions_for_compositions 
\exercise.
\label{inclusions_for_compositions}%
Mostre como construir a função criada no~\ref{why_not_compose_more}
como composição de black boxes que contenha as $f$ e $g$ mas
sem nenhuma conexão ``proibida''.

\hint
Tu vai precisar definir uma terceira função $i$, e usar
seu black box na tua construção.

\hint
O que falta é decidir o que botar nos ``?'' abaixo,
e definir formalmente a função que corresponde nesta caixa:
$$
\tikzpicture
\tikzi blackboxfuncompsubset0;
\draw [rounded corners=0mm]
      (-3,1)--(-3,-1)--(3,-1)--(3,1)--cycle;
\draw[-Latex]  (1.5,0)  -- (0.5,0);
\draw[-Latex]  (-0.5,0) -- (-1.5,0);
\node (x)    at (4.5,0)     {$x$};
\node (gfx)  at (-4.8,0)    {$g(f(x))$};
\draw [rounded corners=0mm, fill=gray!10]
      (-0.5,0.5)--(-0.5,-0.5)--(0.5,-0.5)--(0.5,0.5)--cycle;
\node (i)  at (0,0)      {$?$};
\node (iS) at (0.3,0.3)  {$?$};
\node (iT) at (-0.3,0.3) {$?$};
\endtikzpicture
$$

\solution
Definimos a função $i : B \to B'$ pela regra
$$
i(x) = x,   \quad\text{para todo $x\in B$}.
$$
Seu black box então, parece assim:
$$
\tikzpicture
\draw [rounded corners=0mm, fill=gray!10]
      (-0.5,0.5)--(-0.5,-0.5)--(0.5,-0.5)--(0.5,0.5)--cycle;
\node (i)  at (0,0)      {$i$};
\node (iS) at (0.3,0.3)  {$B$};
\node (iT) at (-0.3,0.3) {$B'$};
\draw[-Latex]  (1.5,0)  -- (0.5,0);
\draw[-Latex]  (-0.5,0) -- (-1.5,0);
\endtikzpicture
$$
e é exatamente o ``missing link'' para construir nosso black box:
$$
\tikzpicture
\tikzi blackboxfuncompsubset0;
\draw [rounded corners=0mm]
      (-3,1)--(-3,-1)--(3,-1)--(3,1)--cycle;
\draw[-Latex]  (1.5,0)  -- (0.5,0);
\draw[-Latex]  (-0.5,0) -- (-1.5,0);
\draw [rounded corners=0mm, fill=gray!10]
      (-0.5,0.5)--(-0.5,-0.5)--(0.5,-0.5)--(0.5,0.5)--cycle;
\node (i)  at (0,0)      {$i$};
\node (iS) at (0.3,0.3)  {$B$};
\node (iT) at (-0.3,0.3) {$B'$};
\endtikzpicture
$$
Construimos e usamos então a $g\of i\of f : A \to C$
em vez da ``gambiarrada'' e proibida $g\of f$.
Essa função $i$ é chamada a \dterm{inclusão do $A$ no $B$}
que definimos na~\ref{inclusion_function}.

\endexercise
%%}}}

%%{{{ lazier_clearer_functional_notation 
\note Mais preguiça (clareza) na notação funcional.
\label{lazier_clearer_functional_notation}%
{\ii{juxtaposição}}%
{\ii{notação}[funcional]}%
Como tu já se acostumou---eu espero---as vezes denotamos a aplicação duma
função no seu argumento silenciosamente, ou seja, por \dterm{juxtaposição:}
escrevemos $f x$ em vez do (mais comum em matemática clássica) $f(x)$.
Agora que temos \emph{uma operação padrão} entre funções queremos
pegar emprestada a mesma preguiça e denotar por juxtaposição a
composição também:
$$
\msqq{fg}
\qqtext{quis dizer}
\msqq{f \of g}.
$$
Com essa convenção, o que seria o
\sqq{$f g x$}?
Acontece que ambas as interpretações
$$
\msqq{(f g) x}
\qqtext{ou}
\msqq{f (g x)}
$$
são iguais nesse caso (deu sorte \emph{extensional}\/),
mas \emph{intensionalmente} falando elas correspondem
nas notações tradicionais
$$
\msqq{(f \of g) (x)}
\qqtext{e}
\msqq{f (g(x))}
$$
respectivamente.
E até pior---nossa preguiça não tem fim---entre números também
temos uma operação padrão que denotamos por juxtaposição:
$$
xy
\qqtext{é o produto}
x\ntimes y.
$$
E supondo que $f,g:\reals\to\reals$ e $x,y\in\reals$,
a expressão
$$
\msqq{g f x y}
$$
denota o que?
Sem parenteses, nada, por isso vamos escrever
$$
\msqq{g \fa f \fa (xy)}
\qqtext{ou}
\msqq{(gf)(xy)}
$$
que denotam o
$$
(g \of f)(x\ntimes y)
\qqtext{que é igual ao}
g (f (x\ntimes y))
$$
pela definição da $\of$.
Eu vou ficar misturando a notação mais tradicional e a notação mais
``funcional'' dependendo do contexto e assim vamos se acostumar com ambas.
%%}}}

\blah.
Bora ver uns examplos para resumir:

%%{{{ eg 
\example.
Sejam $f,g,h:\reals\to\reals$ e $x,y,z\in\reals$.
Usando \sq{$\syneq$} para igualdade sintáctica e \sq{$=$} para igualdade
semántica (veja~\ref{arithmetic_expressions_syntax_vs_semantics}) temos:
$$
\align
fx         &\syneq f(x) \\
(fg)x      &\syneq (f\of g)(x) = f(g(x))\\
f(gx)      &\syneq f(g(x)) \\
fgh        &\syneq (f\of g\of h) \\
f(ghx)     &\syneq f ((g\of h)(x)) = f(g(h(x))) \\
(fg)h(xy)  &\syneq ((f\of g) \of h)(x\ntimes y)
                   = (f\of g)(h(x\ntimes y)) = f(g(h(x\ntimes y))).
\endalign
$$
Espero que ficou claro.
\endexample
%%}}}

\endsection
%%}}}

%%{{{ Functions_for_free 
\section Funções de graça.
\label{Functions_for_free}%

\blah.
Investigamos aqui umas primeiras funções garantidas para existir assim
que tivermos alguns outros objetos: um conjunto, uma função, etc.

%%{{{ df: identity_function 
\definition Identidade.
\label{identity_function}%
\tdefined{função}[identidade]%
\sdefined {\idof {\sholed A}} {a identidade do $A$}
\iisee{identidade}{função, identidade}%
Seja $A$ conjunto.
A função $\lam x x : A \to A$ é chamada
\dterm{identidade do $A$}.
Denotamos a identidade do conjunto $A$ por $\idof A : A \to A$ ou $1_A : A \to A$.
%%}}}

%%{{{ df: inclusion_function 
\definition Inclusão.
\label{inclusion_function}%
\tdefined{função}[inclusão]%
\sdefined {\incofin {\sholed A} {\sholed B}} {a inclusão do $A$ no $B$}%
\sdefined {\sholed i : \sholed A \subsetto \sholed B} {$i$ é a inclusão do $A$ no $B$}%
\sdefined {\sholed i : \sholed A \subset \sholed B} {$A \subsetto B$ (notação alternativa)}%
\sdefined {\sholed i : \sholed A \incto \sholed B} {$i$ é a inclusão do $A$ no $B$ (ou uma injecção)}%
Sejam $A,B$ conjuntos com $A\subset B$.
A função $\lam x x : A \to B$ é chamada \dterm{inclusão do $A$ no $B$}.
Usamos o $\inc$ para denotar uma inclusão e escrevemos
$$
\inc : A \incto B
\qqtext{ou}
\inc : A \subsetto B
\qqtext{ou até}
\inc : A \subset B
$$
para enfatizar que é uma inclusão mesmo.
Decoramos a notação escrevendo $\incofin A B$ quando essa informação
não é implícita pelo contexto.
Todos os $i,\imath,\iota$ são símbolos freqüentemente usados para
denotar inclusões.
%%}}}

%%{{{ beware: incto might be some other injection 
\beware.
A notação $A \incto B$ não sempre denota a própria inclusão; pode ser usada
para denotar uma \emph{injecção} (\refn{Jections}) diferente dependendo do
contexto.
%%}}}

%%{{{ remark: inclusion is not id 
\remark.
Note que seguindo o ponto de vista categorial (\refn{f_eq_g_catist}),
se $A \subsetneq B$ então $\incofin A B \neq \idof A$,
mas seguindo o ponto de vista conjuntista (\refn{f_eq_g_setist}),
temos $\incofin A B = \idof A$.
%%}}}

%%{{{ x: composition_of_inclusions 
\exercise.
\label{composition_of_inclusions}%
Verifique que composição de inclusões é inclusão.

\hint
$A \subset B \mland B \subset C \implies A \subset C$.

\endexercise
%%}}}

%%{{{ df: constant_function ; stable_function
\definition Constante; invariável.
\label{constant_function}%
\label{steady_function}%
\tdefined{função}[constante]%
\tdefined{função}[invariável]%
\iisee{função!steady}{função, invariável}%
Dados conjuntos $A,B$, e $b\in B$, definimos a função
$\kondom A b : A \to B$ pela
$$
\kondom A b (x) = b.
$$
A $\kondom A b$ é chamada
\dterm{função constante (do $A$ para $B$) com valor $b$}.
Quando o $A$ é implícito pelo contexto, escrevemos apenas $\kon b$.
Dizemos que uma função $f : A \to B$ é \dterm{constante}
sse ela é constante com valor $b$ para algum $b \in B$:
$$
\align
\text{$f : A \to B$ constante}
&\defiff
\lexists {b \in B} {f = \kon b}.
\intertext{%
Chamamos uma função de \dterm{invariável} (ou \dterm{steady})
sse ela mapeia todos os membros do seu domínio para o mesmo objeto.
Formulamente,
}
\text{$f : A \to B$ invariável}
&\defiff
\lforall {x, y \in A} {f(x) = f(y)}.
\endalign
$$
%%}}}

%%{{{ beware: constant_may_mean_something_different 
\beware O termo ``constante''.
\label{constant_may_mean_something_different}%
Muitos textos usam o termo ``constante'' para descrever o que
chamamos de ``invariável'' (ou ``steady'').
Na maioria dos casos não existe confusão, pois as duas definições
concordam.  Mas precisamos tomar cuidado, como tu vai descobrir
agora fazendo o~\ref{constant_notiff_steady}.
%%}}}

%%{{{ x: constant_notiff_steady 
\exercise.
\label{constant_notiff_steady}%
Às vezes aparece como definição de constante a seguinte:
\emph{<<A função $f : A \to B$ é constante sse mapeia todos
os membros do seu domínio para o mesmo objeto.>>}
Essa definição é equivalente com a~\ref{constant_function}?
Ou seja, com nossa terminologia aqui:
$$
\text{$f$ invariável}
\askiff
\text{$f$ constante}.
$$
(Verifique ámbas as direcções.)

\hint
$\emptyset$.

\solution
Não.
Por exemplo a função vazia $f : \emptyset\to\emptyset$ é invariável
mas não constante.
Mas realmente temos que
$$
\text{$f$ invariável}
\impliedby
\text{$f$ constante}:
$$
Suponha $f : A \to B$ constante, e logo
seja $b\in B$ tal que $f = \kon b$.
Sejam $x,y \in A$ e calculamos:
$$
f(x) = \kon b (x) = b = \kon b (y) = f(y)
$$
e logo $f$ é invariável.

\endexercise
%}}}

%%{{{ x: constant_with_more_than_one_value 
\exercise.
Uma função $f : A \to B$ pode ser constante com valor $b$
e com valor $b'$ também, com $b \neq b'$?

\endexercise
%%}}}

%%{{{ x: constant_function_definitions_almost_agree 
\exercise.
\label{constant_function_definitions_almost_agree}%
Sejam $A \toby f B$ com $A \neq \emptyset$.
Prove que:
$$
\text{$f$ constante}
\iff
\pexists {b\in B}
\lforall {x\in A}
{f(x) = b}.
$$

\solution
\proofpart{\lrdir:}
Seja $a\in A$ ($A\neq\emptyset$).
Vamos mostrar que tomando $b\asseq f(a)$ a proposição na direita é satisfeita.
Observe que o $f(a)\in B$ e satisfaz
$$
\lforall {x\in A} {f(x) = f(a)}
$$
pela definição de constante.
\crproofpart{\rldir:}
Seja $b_0\in B$ tal que para todo $x\in A$, $f(x) = b_0$.
Agora para todo $x,y \in A$ temos $f(x) = b_0 = f(y)$ pela hipótese,
ou seja, $f$ é constante.

\endexercise
%%}}}

%%{{{ x: constant_function_which_definition_is_stronger 
\exercise.
\label{constant_function_which_definition_is_stronger}%
No caso geral, alguma das direções
da~\ref{constant_function_definitions_almost_agree} é valida ainda?

\solution
Sim, a {\rldir}.
Observe \emph{bem} que na prova dessa direção não precisamos $A\neq\emptyset$.
E pelo~\ref{constant_notiff_steady} já sabemos que a {\lrdir} não é
valida em geral.

\endexercise
%%}}}

%%{{{ x: gof_constant_does_not_imply 
\exercise.
\label{gof_constant_does_not_imply}%
Prove ou refute a afirmação seguinte:
\emph{se $(g \of f)$ é constante, então pelo menos uma das $f,g$ também é}.

\hint
Tente achar contraexemplo desenhando diagramas internos.

\solution
Falso.
Um contraexemplo é o seguinte:
$$
\tikzpicture
\tikzi gofconstantdoesnotimply;
\endtikzpicture
$$

\endexercise
%%}}}

%%{{{ x: wrong_order_of_quantifiers 
\exercise.
\label{wrong_order_of_quantifiers}%
O que é errado na definição seguinte de função constante?
$$
\text{$f:A\to B$ constante}
\defiff
\pforall {a \in A}
\lexists {b \in B} {f(a) = b}.
$$
Se substituir o $\exists$ por $\unique$, o problema tá resolvido?
Sugira uma outra resolução simples.

\hint
Siga essa definição e tente achar alguam função que não vai ser chamada
constante.

\solution
A definição tem o problema que vai aceitar toda função como constante,
pois o que ela exige é satisfeito por toda função.
Substituindo o $\exists$ por $\unique$ nada muda nesse sentido,
pois toda função satisfaz essa afirmação mais forte
(determinabilidade de função).
\endgraf
O problema é que os quantificadores estão na ordem errada!
Simplesmente trocando a ordem deles, chegamos numa
definição equivalente à do~\ref{constant_notiff_steady}:
$$
\text{$f:A\to B$ constante}
\defiff
\pexists {b \in B}
\lforall {a \in A}
{f(a) = b}.
$$

\endexercise
%%}}}

%%{{{ df: characteristic_funcion 
\definition Característica.
\label{characteristic_function}%
\tdefined{função}[característica]%
\iisee{característica}{função, característica}%
\sdefined {\chrdom {\sholed A} {\sholed C}} {a função característica do $C$ no $A$}%
\sdefined {\chr {\sholed C}} {a função característica do $C$ (com domínio implícito)}%
Sejam $A$ conjunto e $C \subset A$.
A \dterm{função característica do $C$ no $A$} é a função
$\chrdom A C : A \to \set{0,1}$ definida pela
$$
\chrdom A C (x) =
\knuthcases{
1, &se $x\in C$\cr
0, &se $x\notin C$.
}
$$
Escrevemos apenas $\chr C$ quando o domínio $A$ é implícito pelo
contexto---e na práctica esse é quase sempre o caso!
%%}}}

%%{{{ warning: characteristic_function_inverted_values 
\warning.
\label{characteristic_function_inverted_values}%
O uso de $1$ para representar ``true'' e o $0$ para o ``false'' é aleatório.
De fato, dependendo de caso, as vezes definimos a função característica
com esses valores invertidos!  Isso é muito comum em teoria de recursão
(veja~\cite{kleeneIM} por exemplo), mas não só:
nos shells de Unix\ii{Unix}[shell]\ii{main},
também o valor $0$ representa o ``true'' (ou ``deu certo'')
e cada valor positivo o ``false'' (ou ``deu errado'').%
\footnote{%
Nesse caso essa escolha é obviamente melhor, pois sabendo que ``deu certo'',
em geral não perguntamos <<por que deu certo?>>; mas se der errado, queremos
saber uma informação sobre o motivo que deu errado: talvez um arquivo não
existe, talvez uma conexão não pode ser feita, talvez faltou uma permissão,
etc., e cada um desses casos vai retornar um valor positivo diferente.
\endgraf
Esse ``retornar'' que eu tô me referindo aqui é o proprio $\code{return}$
que muitas vezes estudando programação o aluno acaba memorizando como
``regrinha'' que sua $\code{main}$ precisa terminar com um
``$\code{return 0}$''.  Por quê?  E pra quem que ta retornando isso?
Para o próprio sistema operacional.  No final das contas, foi ele que
chamou essa $\code{main}$.
}
\endgraf
\emph{A moral da história:}
sempre verifique a definição da função característica
usada---e se quiseres usar num texto teu, sempre bota sua definição junto!
Nesse texto, quando aparece a notação $\chr A$ sem definição,
denota a função que definimos acima na~\ref{characteristic_function}.
%%}}}

%%{{{ x: explain_unix_shell_connectives 
\exercise Para os Unixeiros.
\label{explain_unix_shell_connectives}%
{\ii{Unix}[shell]}%
Num shell de Unix (cujo ``prompt'' denoto aqui por \sq{$\code{\#}$})
escrevemos:
\shell
\code{\# cmd1 \&\& cmd2} && \\
\code{\# cmd1 || cmd2}   &&
\endshell
onde $\code{cmd1}$ e $\code{cmd2}$ são dois comandos.
Explique o comportamento sabendo que $\code{\&\&}$ é um
operador lógico de conjunção e que $\code{||}$ é um operador
lógico de disjunção.
Conclua que o shell de Unix é ``apenas'' um calculador de valores de verdade
nesse sentido.  Todas as coisas que vão acontecer executando isso ``no mundo real''
são nada mais que \dterm{side-effects} enquanto calculando os seus comandos,
para achar seus valores de verdade.
Como posso dar para o shell a ordem
<<executa o $\code{cmd1}$ e depois o $\code{cmd2}$>>?

\endexercise
%%}}}

%%{{{ remark: replacing_cases_by_characteristic_functions 
\remark.
\label{replacing_cases_by_characteristic_functions}%
Um dos usos comuns de funções características é definir funções num jeito mais
curto, aproveitando os fato que $0x = 0$ e $1x = x$ para todo $x\in\reals$.
Esse uso lembra das expressões $\namedfun{if-then-else}$ que usamos
em linguagens de programação.
%%}}}

%%{{{ eg: replacing_cases_by_characteristic_functions_example 
\example.
\label{replacing_cases_by_characteristic_functions_example}%
Considere a $f : \reals \to \reals$ definida pela
$$
f(x) = \knuthcases{
2\cbrt{x + \log_2 |x+1|} + x^2, & se $x \in \rats$ \cr
2\cbrt{x + \log_2 |x+1|} + e^x, & caso contrário.
}
$$
Usando as funções características de $\rats$ e $\reals\minus\rats$
podemos definir a $f$ com uma equação só, e ``sem repetição'':
$$
f(x) = 2\cbrt{x + \log_2 |x+1|} + x^2 \chr\rats (x) + e^x \chr{\reals\minus\rats} (x).
$$
Isso lembra um
$$
f(x) = 2\cbrt{x + \log_2 |x+1|} + \PIF x \in \rats \THEN x^2 \ELSE e^x \FIP.
$$
usado em linguagens de programação que suportam \dterm{if-then-else expressions}.
\endexample
%%}}}

%%{{{ warning: expressions_vs_statemets 
\warning expressions \vs statements.
\label{expressions_vs_statemets}%
\iipl C
\iipl Haskell
Uma \dterm{if-then-else expression} não é a mesma coisa com um
\dterm{if-branching statement} encontrado em muitas linguagens de
programação imperativas.  A idéia é que uma expressão denota um
valor; um statement é apenas uma ordem para ser executada.
A linguagem C por exemplo tem ambas mas o que escrevemos em C
com ``\code{if}\dots''~corresponde no branching \emph{statement}.
Nunca faria sentido em C, por exemplo, multiplicar um
\emph{if statement} por um número.
A \emph{expressão} if-then-else de C corresponde no seu único
operador ternário, com a sintaxe (bizarra)
$$
\text{\code(\thole\code?\thole\code:\thole\code)}.
$$
Em Haskell, no outro lado, escrevemos mesmo
$$
\text{\code{if}\thole\code{then}\thole\code{else}\thole}.
$$
%%}}}

%%{{{ x: char_compose_char 
\exercise.
Sejam $A,X$ conjuntos com $A\subset X$.
Suponha que $\chrdom X A \of \chrdom X A$ é definida.
O que podes concluir sobre o $X$?
Podemos concluir que a $\chr A \of \chr A$ é constante ou a identidade?

\hint
O fato que uma composição é definida dá informação sobre um domínio
e um codomínio envolvido.

\solution
Temos $\chr A : X \to \set{0,1}$.
Como a composição $\chr A \of \chr A$ é definida,
concluimos que $\cod(\chr A) = \dom(\chr A)$.
Ou seja, $X = \set{0,1}$.
\endgraf
O $A$ sendo um subconjunto de $\set{0,1}$ so tem 4 possibilidades:
$$
\xalignat4
A &= \emptyset; &
A &= \set{0};   &
A &= \set{1};   &
A &= \set{0,1} = X.
\endxalignat
$$
Calculamos em todos os casos:
$$
\align
A = \emptyset &\implies
\leftbrace{
\aligned
(\chr A \of \chr A)(0) &= \chr A(\chr A(0)) = 0 \\
(\chr A \of \chr A)(1) &= \chr A(\chr A(1)) = 0
\endaligned
} \\
A = \set{0} &\implies
\leftbrace{
\aligned
(\chr A \of \chr A)(0) &= \chr A(\chr A(0)) = \chr A(1) = 0 \\
(\chr A \of \chr A)(1) &= \chr A(\chr A(1)) = \chr A(0) = 1
\endaligned
} \\
A = \set{1} &\implies
\leftbrace{
\aligned
(\chr A \of \chr A)(0) &= \chr A(\chr A(0)) = \chr A(0) = 0 \\
(\chr A \of \chr A)(1) &= \chr A(\chr A(1)) = \chr A(1) = 1
\endaligned
} \\
A = X &\implies
\leftbrace{
\aligned
(\chr A \of \chr A)(0) &= \chr A(\chr A(0)) = 1 \\
(\chr A \of \chr A)(1) &= \chr A(\chr A(1)) = 1\,.
\endaligned
}
\endalign
$$
Sobre a $\chr A\of\chr A$ então concluimos que
se $A$ é um dos singletons $\set{0}$ ou $\set{1}$ então ela é a identidade.
Caso contrário, ela é uma constante:
se $A = \emptyset$, a constante $0$; se $A = X$, a constante $1$.

\endexercise
%%}}}

%%{{{ df: fresto 
\definition Restricção.
\label{fresto}%
\tdefined{função}[restricção]%
\sdefined {\sholed f \resto \sholed X} {a restricção de $f$ no $X$}%
\sdefined {\sholed f \restosub {\sholed X}} {$f \resto X$ (notação alternativa)}%
Sejam $f : A \to B$ e $X \subset A$.
A \dterm{restricção da $f$ no $X$}, denotada por
$\resfun f X$ é a função de $X$ para $B$ definida pela
$$
(\resfun f X)(x) = f(x).
$$
Também é usada a notação $\resfunsub f X$.
%%}}}

%%{{{ x: type_of_f_resto_X 
\exercise.
\label{type_of_f_resto_X}%
Sejam $f : A\to B$ e $X\subset A$.
Ache o tipo de:
$$
f\resto X \eqtype ?
$$

\solution
$f\resto X \eqtype X \to B$.

\endexercise
%%}}}

%%{{{ x: fresto_pointfree 
\exercise restrição sem pontos.
\label{fresto_pointfree}%
Sejam $A,B$ conjuntos e $X\subset A$.
Defina a função $f \resto X$ sem usar nenhuma referência aos membros desses conjuntos.
Na~\ref{fresto}, por exemplo, usamos esse $x$ para representar um mebro de $A$.
(Esqueça o ``sem pontos'' no rótulo desse exercício;
vai fazer sentido depois:~\refn{Functions_pointfree_style}.)

\hint
Defina como composição de funções conhecidas.

\hint
Inclusão.

\solution
$f\resto X = \incofin X A \of f$.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Composition_laws 
\section Leis de composição.
\label{Composition_laws}%

%%{{{ Composition as an operation 
\note Composição como operação.
\label{composition_as_an_operation}%
No mesmo jeito que o produto $3\ntimes 2$ denota um número,
a composição $g \of f$ de certas funções $f$ e $g$ denota uma função.
A $\of$ então realmente é uma operação (binária) nas funções,
e agora vamos investigar as leis que ela satisfaz, fazendo uma
comparação com a multiplicação nos números, procurando similaridades
e diferêncas.  Note que já começamos com uma ambigüidade com esse
``nos números'', pois as leis satisfeitas pela~$\ntimes$~dependem de
\emph{qual multiplicação} estamos considerando:
a multiplicação nos reais, por exemplo, satisfaz a uma lei de inversos
(viz.~<<cada número diferente de zero tem um inverso multiplicativo>>)
mas nos inteiros não.  Mais sobre isso depois.
%%}}}

%%{{{ Totality 
\note Totalidade.
Primeiramente observe uma grande diferença entre composição e multiplicação:
a multiplicação é uma operação \dterm{total}, ou seja, para todo número
$x, y$, seu produto $x\ntimes y$ é definido.
Mas como vimos na~\ref{fcompose}, para formar a composição $g\of f$
de duas funções $f$ e $g$ elas precisam satisfazer a condição
$\cod f = \dom g$.  Caso contrário, o $g\of f$ nem tem significado!
Continuamos investigando mais propriedades.
%%}}}

%%{{{ Intuition with tasks 
\note Intuição com tarefas.
Vamos agora imaginar funções como tarefas para ser feitas em algo,
e a composição como a idéia de ``seqüenciar as tarefas''.
Ou seja $g\of f$ seria a tarefa ``fazer a tarefa $f$ e depois a $g$''.
Com essa intuição, parecem óbvias as duas afirmações
\beginol
\li a composição é associativa;
\li a composição não é comutativa.
\endol
Mas intuição nunca provou nada sozinha, então bora provar essas afirmações!
%%}}}

%%{{{ Associativity 
\note Associatividade.
Suponha que temos funções
$$
A \toby f B \toby g C \toby h D.
$$
Podemos entao formar as composições $g\of f$ e $h\of g$.
Temos então:
$$
A \toby {g\of f} C \toby h D
\qqquad
A \toby f B \toby {h\of g} D.
$$
Compondo as funções do primeiro diagrama criamos a função $h\of(g\of f)$,
e compondo aquelas do segundo criamos a $(h\of g)\of f$:
$$
A \longtoby {h\of (g\of f)} D
\qqquad
A \longtoby {(h\of g)\of f} D.
$$
Queremos saber se as duas funções são iguais.
Vamos pensar sobre isso usando black boxes.
$$
\gathered
\tikzpicture
\tikzi blackboxfuncompassoc1;
\endtikzpicture
\\
\tikzpicture
\tikzi blackboxfuncompassoc2;
\endtikzpicture
\endgathered
$$
Primeiramente observe que os tipos delas são iguais.
Então basta verificar que concordam para todo ponto $x\in A$.
Pela definição de composição sabemos que ``internalmente''
elas funcionam assim:
$$
\gathered
\tikzpicture
\tikzi blackboxfuncompassoc3;
\endtikzpicture \\
\tikzpicture
\tikzi blackboxfuncompassoc4;
\endtikzpicture
\endgathered
$$
Agora pelas definições das $g\of f$ e $h\of g$,
o que precisamos comparar na verdade são as:
$$
\gathered
\tikzpicture
\tikzi blackboxfuncompassoc5;
\endtikzpicture
\\
\tikzpicture
\tikzi blackboxfuncompassoc6;
\endtikzpicture
\endgathered
$$
Agora que tá tudo transparente parece óbvio que as duas funções são iguais,
e comportam como a seguinte:
$$
\tikzpicture
\tikzi blackboxfuncompassoc0;
\endtikzpicture
$$
Mas para provar que as duas construções resultam na mesma função,
vamos precisar calcular os <<$?$>> do desenho acima, e seguir
fielmente as definições.
%%}}}

%%{{{ thm: fcom_associativity_law 
\theorem Lei de associatividade.
\label{fcom_associativity_law}%
Sejam
$$
A \toby f B \toby g C \toby h D.
$$
Então
$$
h \of (g \of f) = (h \of g) \of f.
$$
\sketch.
Mostramos que as duas funções são iguais seguindo a definição
de igualdade~\refn{f_eq_g}:
mostrando que elas tem o mesmo domínio $A$,
e que comportam igualmente para o arbitrário $a \in A$.
Observe que seus codomínios também são iguais, satisfazendo
assim a definição de igualdade~\refn{f_eq_g_catist} também.
Pegando cada lado da igualdade e aplicando a definição de $\of$
chegamos no mesmo valor.
\qes
\proof.
Primeiramente vamos verificar que as duas funções tem o mesmo domínio:
\compute
\dom\paren{ h \of (g \of f) }
&= \dom (g \of f)               \by {def.~$h\of(g\of f)$}
&= \dom f                       \by {def.~$g\of f$}
\intertext{e do lado direito}
\dom\paren{ (h \of g) \of f }
&= \dom f.                      \by {def.~$(h\of g)\of f$}
\endcompute
Similarmente elas tem os mesmos codomínios
(caso que seguimos a definição~\refn{f_eq_g_catist})
\compute
\cod\paren{ h \of (g \of f) }
&= \cod h                       \by {def.~$h\of(g\of f)$}
\intertext{e do lado direito}
\cod\paren{ (h \of g) \of f }
&= \cod (h \of g)               \by {def.~$(h\of g)\of f$}
&= \cod h.                      \by {def.~$h\of g$}
\endcompute
Agora precisamos mostrar que as duas funções comportam no mesmo jeito
para todos os elementos no $A$.
Suponha $a\in A$ então, e calcule:
\compute
\paren{h \of (g \of f)}(a)
&= h\paren{\paren{g \of f}(a)}  \by {def.~$h\of(g\of f)$}
&= h\paren{g \paren{f(a)}}      \by {def.~$g\of f$}
\intertext{e o lado direito:}
\paren{(h \of g) \of f}(a)
&= \paren{h \of g}\paren{f(a)}  \by {def.~$(h\of g)\of f$}
&= h\paren{g \paren{f(a)}}      \by {def.~$h\of g$}
\endcompute
\qed
%%}}}

%%{{{ Commutativity 
\note Comutatividade.
É fácil provar que a composição de funções \emph{não é comutativa}.
Faça isso agora no exercício seguinte!
%%}}}

%%{{{ x: non_commutativity_of_fcom 
\exercise.
\label{non_commutativity_of_fcom}%
Existem funções $f,g$ entre conjuntos $A,B$
tais que $f\of g$ e $g\of f$ são ambas definidas,
mas mesmo assim
$$
f\of g \neq g\of f.
$$
Mostre pelo menos dois exemplos diferentes:
um com $A\neq B$; outro com $A = B$.

\solution
{%
\DefFun flip
\DefFun zero
\DefFun one
Para o primeiro exemplo, escolhe $A = \set{0}$ e $B=\set{0,1}$.
Agora sejam $f : A \to B$ e $g : B \to A$ definidas pelas
$$
\xalignat2
f(0) &= 0  &  g(x) = 0
\endxalignat
$$
Ambas as $g\of f$ e $f\of g$ são definidas mas são diferentes
pois nem domínios iguais elas tem:
$$
\dom (g\of f) = \dom g = B \neq A = \dom f = \dom (f\of g).
$$
\endgraf
Para o segundo exemplo, tome $A=B=\set{0,1}$
e defina as funções $\flip,\zero,\one:A \to A$ pelas:
$$
\xalignat3
\flip(0) &= 1  &  \zero(0) &= 0  &  \one(0) &= 1\\
\flip(1) &= 0  &  \zero(1) &= 0  &  \one(1) &= 1.
\endxalignat
$$
Calculando temos $\flip\of\zero = \one$ mas $\zero\of\flip = \zero$.
De fato, quaisquer duas dessas três funções servem como um exemplo nesse caso!
}

\endexercise
%%}}}

%%{{{ Identity 
\note Identidades.
Investigamos agora se a operação de composição possui \emph{identidade}
mas primeiramente vamos lembrar o que isso significa.
Por enquanto não provamos nada a respeito disso, então trate
as funções que chamamos de identidades na~\refn{identity_function}
como uma coincidência.
%%}}}

%%{{{ Q: what_is_the_identity_of_composition 
\question.
\label{what_is_the_identity_of_composition}%
Chamamos o $1$ a \dterm{identidade} da operação $\ntimes$ nos reais, pois:
$$
1\ntimes x = x = x\ntimes 1, \qquad \text{para todo $x\in \reals$}.
$$
Tentando achar uma similaridade entre funções e números num lado, e composição e multiplicação no outro,
qual seria nosso $1$ aqui?
Ou seja,
procuramos objeto \holed?\ tal que
$$
\holed? \of f = f = f \of \holed?
$$
para toda função $f$.
%%}}}
\spoiler.

%%{{{ x: id_compose_practice 
\exercise.
\label{id_compose_practice}%
Sejam $A,B$ conjuntos diferentes, e $f : A \to B$.
Para cada uma das igualdades abaixo,
decida se ela é válida ou não, justificando tua resposta.
$$
\xalignat4
(1)\quad f &= {f \compose \idof A}; &
(2)\quad f &= {f \compose \idof B}; &
(3)\quad f &= {\idof A \compose f}; &
(4)\quad f &= {\idof B \compose f}.
\endxalignat
$$

\solution
\noindent (1)
Válida: a composição é definida, e se $a\in A$ então:
\compute
(f \of \idof A)(a)
&= f(\idof A (a))  \by {def.~$f\of\idof A$}
&= f(a).           \by {def.~$\idof A$}
\endcompute
\endgraf
\noindent (2) e (3): as composições não são definidas
\endgraf
\noindent (4) Similar com (1): a composição é definida e se $a \in A$ então:
\compute
(\idof B \of f)(a)
&= \idof B (f(a))  \by {def.~$\idof B\of f$}
&= f(a).           \by {def.~$\idof B$}
\endcompute

\endexercise
%%}}}

%%{{{ thm: fcom_identity_laws  
\theorem Leis de identidade.
\label{fcom_identity_laws}%
Para todo conjunto $A$,
existe unica função $\idof A : A \to A$ tal que:
$$
\align
\text{para toda $f : A \to B$},&\quad f \of \idof A = f; \\
\text{para toda $f : B \to A$},&\quad \idof A \of f = f.
\endalign
$$
\sketch.
Primeiramente verificamos que a identidade do $A$ (\ref{identity_function})
que ``coincidentalmente'' denotamos por $\idof A$ realmente satisfaz tudo isso.
Segundamente mostramos que qualquer outra possivel função $\id'$
com essas propriedades deve ser igual à $\idof A$.
\qes
\proof.
Observe que dado conjunto $A$, a $\idof A$ tem o domínio e codomínio certo.
Basta então verificar que ela tem as propriedades (i)--(ii) e que ela é única.
\crproofpart{$\idof A$ tem a primeira propriedade.}
Seja $f : A \to B$.
Preciso mostrar que $f \of \idof A = f$.
Primeiramente verifico que têm o mesmo domínio e---para satisfazer
até os categoristas---o mesmo codomínio:
$$
\align
\dom (f\of\idof A) &= \dom(\idof A) = A = \dom f; \\
\cod (f\of\idof A) &= \cod f.
\endalign
$$
Basta ver se tem o mesmo comportamento.
Seja $x\in A$ então, e calcule:
\compute
(f \of \idof A) x
&= f(\idof A x) \by {def.~$f \of \idof A$}
&= f(x).        \by {def.~$\idof A$}
\endcompute
\proofpart{$\idof A$ tem a segunda propriedade.}
Similar.
\crproofpart{$\idof A$ é única.}
Seja $\id' : A \to A$ função tal que
$$
\align
\text{para toda $f : A \to B$},&\quad f \of \id' = f; \\
\text{para toda $f : B \to A$},&\quad \id' \of f = f.
\endalign
$$
Preciso mostrar que $\idof A = \id'$.
Calculamos:
\compute
\idof A
&= \idof A \of \id'  \by {primeira propriedade da $\id'$ com $f \asseq \idof A$}
&= \id'.             \by {segunda propriedade da $\idof A$ com $f \asseq \id'$}
\endcompute
\qed
%%}}}

\blah.
Terminamos essa secção sobre composição com mais uma definição
interessante e uns exercícios para praticar.

%%{{{ df: idempotent_function 
\definition Idempotente.
\label{idempotent_function}%
\tdefined{função}[idempotente]%
\iisee{idempotente!função}{função idempotente}%
Seja $f : A \to A$ um endomapa.
Chamamos a $f$ \dterm{idempotente} sse
$$
f \of f = f.
$$
%%}}}

%%{{{ x: how_many_idempotents_on_AtoA_for_A_triset 
\exercise.
\label{how_many_idempotents_on_AtoA_for_A_triset}%
Seja $A$ conjunto com $\card A = 3$.
Quantas funções idempotentes podemos definir no $A$?

\hint
Use um diagrama interno para endomapas!

\hint
Observe que em geral, aparecem certos ``redemoinhos''
num diagrama interno de endomapa quando ela é idempotente.

\hint
Separe as funções idempotentes dependendo na quantidade
de ``redemoinhos'' que aparecem nos seus diagramas.

\solution
Vamos tentar definir uma $f$ idempotente e contar as escolhas que temos.
Observe que assim que mandamos um $x \mapsto y$, o $f(y)$ ``não tem mais
escolha'': precisa ser $f(y) = y$, pois $f$ deve ser idempotente.
Ou seja, $y$ vai ser um \dterm{ponto fixo} (ou \dterm{fixpoint}) da $f$
(mais sobre isso na~\refn{Fixpoints}).
A $f$ então deve ter pelo menos $1$ fixpoint, e no máximo $\card A = 3$.
Separamos então por casos, contamos as maneiras em cada caso e usamos
o Princípio da adição~(\refn{principle_of_addition}) para contar
quantidade total das maneiras.
Defina então
$$
F_i \defeq \setstt {f : A \to A} {$f$ tem exatamente $i$ fixpoints}.
$$
Queremos achar o $\card{F_1} + \card{F_2} + \card{F_3}$.
Calculamos separadamente.:
\endgraf
\proofpart{Quantas funções no $F_1$?}
Temos $3$ funções, uma para cada escolha de fixpoint, pois
assim que determinamos o único fixpoint, todos os outros membros
devem ser mapeados nele.
\endgraf
\proofpart{Quantas funções no $F_2$?}
Temos $\comb 3 2 = 3$ maneiras de escolher $2$ dos membros de $A$ para ser
os fixpoints da $f$.  Para cada uma dessas escolhas, temos $2$ opções para
o não-fixpoint (escolher em qual dos dois fixpoints vamos mandá-lo).
Pelo Princípio da multiplicação~(\refn{principle_of_multiplication}) então
temos $3\ntimes 2 = 6$ funções no $F_2$.
\endgraf
\proofpart{Quantas funções no $F_3$?}
Apenas uma: a identidade.
\endgraf
Finalmente podemos responder: existem $3 + 6 + 1 = 10$ funções idempotentes
num conjunto de cardinalidade $3$.

\endexercise
%%}}}

%%{{{ x: constant_implies_idempotent 
\exercise.
\label{constant_implies_idempotent}%
Seja $f : A \to A$.
Prove ou refute a implicação:
$$
\text{$f$ constante}
\implies
\text{$f$ idempotente}.
$$

\hint
A implicação é válida.
Prove!

\solution
Vamos provar a implicação.
Suponha que $f : A\to A$ é constante.
Caso $A=\emptyset$ a $f$ é a função vazia e a $f\of f$ também.
Caso $A\neq\emptyset$, usamos a definição alternativa
da~\ref{constant_function_definitions_almost_agree}.
Seja $c\in A$ tal que para todo $x\in A$, $f(x) = c$\fact1.
Queremos mostrar que $f\of f = f$, ou seja, que para todo $a\in A$,
$$(f\of f)(a) = f(a)$$
(definição de igualdade de funções~\refn{f_eq_g}).
Calculamos no lado esquerdo:
\compute
(f\of f)(a)
&= f\paren{f(a)}   \by {def.~$\fcom$}
&= f(c)            \by {pelo \byfact1, com $x \asseq a$}
&= c               \by {pelo \byfact1, com $x \asseq c$}
\intertext{e no lado direito:}
f(a)
&= c.              \by {pelo \byfact1, com $x \asseq a$}
\intertext{Logo, $f \of f = f$ como desejamos.
\endgraf
Alternativamente, podemos nos livrar dum passo no calculo do lado esquerdo assim:
}
(f\of f)(a)
&= f\paren{f(a)}   \by {def.~$\fcom$}
&= c.              \by {pelo \byfact1, com $x \asseq f(a)$}
\endcompute

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Partial application 
\section Aplicação parcial.

%%{{{ Partial application with black boxes 
\note Aplicação parcial com black boxes.
Suponha que temos uma função de aridade~$2$:
$$
f : (A\times B) \to C.
$$
Ou seja, nossa função ``para funcionar'', precisa receber
exatamente~2~argumentos: algum $a\in A$ e algum $b\in B$.
$$
\tikzpicture
\tikzi blackboxfunpartapp1;
\endtikzpicture
$$
para ``produzir'' o valor $f(a,b) \in C$.
Queremos utilizar essa função de aridade~$2$,
para criar duas outras, cada uma de aridade~$1$.
A idéia é a seguinte: vamos ``fixar'' uma das suas entradas
com um valor, e deixar a outra como entrada mesmo.
Imagine que fixamos um certo $b_0\in B$ no segundo ``cabo'' de entrada,
puxamos o outro cabo, e criamos uma nova caixa assim:
$$
\tikzpicture
\tikzi blackboxfunpartapp2;
\endtikzpicture
$$
E agora pintamos preta nossa caixa, escrevemos seus rótulos (seu tipo),
e pronto, construimos uma nova função de aridade $1$:
$$
\tikzpicture
\tikzi blackboxfunpartapp3;
\endtikzpicture
$$
Observe que temos $f(\dhole,b_0):A \to C$.
Vamos agora ver a mesma idéia usando buracos, sem black boxes.
%%}}}

%%{{{ Partial application using holes 
\note Aplicação parcial usando buracos.
Considere uma função $f$ de aridade 3:
$$
A \times B \times C \longtoby f D.
$$
Lembre-se que
$$
f(\dhole, \dhole, \dhole) :
A \times B \times C \to D
$$
e ainda mais $f(\dhole, \dhole, \dhole)$ é a própria $f$!
Queremos preencher uns desses buracos, mas não todos.
E nada especial sobre esse $3$.
Em geral, dada uma função $f$ de aridade $n$,
podemos \emph{fixar} $k$ dos seus argumentos
com certos valores, botar buracos nos ouros,
e criar assim uma função de aridade $n-k$.
Uns exemplos vão esclarecer esse processo.
%%}}}

%%{{{ eg: partial_application_holes_eg 
\example.
Considere a função $f : \reals^3 \to \reals$, definida pela
$$
f(x,y,z) = x + y^2 + z^3.
$$
Temos então
$$
\align
f(\dhole,\dhole,\dhole) &: \reals^3 \to \reals.
\intertext{Com aplicação parcial, fixando uns dos seus argumentos,
criamos então as funções seguintes:}
f(2,\dhole,\dhole)      &: \reals^2 \to \reals \\
f(2,\dhole,\sin(2))     &: \reals   \to \reals \\
f(\dhole,\sqrt2,\cbrt2) &: \reals   \to \reals \\
f(\dhole,0,0)           &: \reals   \to \reals.
\endalign
$$
A última, por exemplo, é a $\idof \reals$; a penúltima é a $\lam x {x+4}$.
\endexample
%%}}}

%%{{{ eg: partial_application_holes_infix_eg 
\example.
Aplicando a função de adição $+ : \nats^2 \to \nats$
parcialmente fixando seu segundo argumento no número $1$,
criamos a função
$$
\align
(\bhole + 1) &: \nats \to \nats
\intertext{que é a função $\namedfun{succ}$ de sucessor;
e fixando seu primeiro argumento no $0$ criamos a}
(0 + \bhole) &: \nats \to \nats
\endalign
$$
que é a $\idof \nats$.
\endexample
%%}}}

\endsection
%%}}}

%%{{{ Higher_order_functions 
\section Funções de ordem superior.
\label{Higher_order_functions}%

%%{{{ Holes again 
\note Buracos de novo.
Já encontramos a idéia de \emph{abstrair} certas partes de uma expressão,
botando \emph{buracos}, criando assim funções de várias aridades.
Além de buracos, trabalhamos com \emph{$\lambda$-abstracção} que nos
permitiu dar nomes para esses buracos, ligar (identificar) certos buracos, etc.
Considere novamente uma expressão como a
$$
\cos(1 + 5\cbrt2)^{2a} + \sin(5)
$$
onde $\cos : \reals\to\reals$, $\sin : \reals\to\reals$, e $a\in \reals$.
Botando uns buracos ou abstraindo com lambdas, criamos, por exemplo, as funções:
$$
\alignat2
f_1 &= \cos(1 + 5\cbrt2)^{\bhole a} + \sin(5)            &&\eqtype \reals   \to \reals\\
f_2 &= \cos(\bhole + 5\cbrt{\bhole})^{2a} + \sin(\bhole) &&\eqtype \reals^3 \to \reals\\
f_3 &= \cos(\bhole + \bhole\cbrt2)^{2\bhole} + \sin(5)   &&\eqtype \reals^3 \to \reals\\
f_4 &= \cos(\bhole + \bhole)^{\bhole} + \sin(5)          &&\eqtype \reals^3 \to \reals\\
f_5 &= \bhole + \sin(\bhole)                             &&\eqtype \reals^2 \to \reals\\
f_6 &= \lam x {\cos(1 + 5\cbrt2)^{2x} + \sin(5)}         &&\eqtype \reals   \to \reals\\
f_7 &= \lam {x,y} {\cos(1 + y\cbrt x)^{2a} + \sin(y)}    &&\eqtype \reals^2 \to \reals.
\endalignat
$$
%%}}}

%%{{{ x: verify_abstractions_of_expression 
\exercise.
\label{verify_abstractions_of_expression}%
Para quais entradas cada uma dessas funções retorna o valor da expressão inicial?

\hint
Respeite as aridades!

\solution
Temos
$$
\align
f_1&(2)\\
f_2&(1,2,5)\\
f_3&(1,5,a)\\
f_4&(1,5,2a)\\
f_5&(\cos(1 + 5\cbrt2)^{2a}, 5)\\
f_6&(a)\\
f_7&(2, 5).
\endalign
$$

\endexercise
%%}}}

%%{{{ Higher-order holes 
\note Buracos de ordem superior.
Em todos os exemplos acima, botamos os buracos para substituir
apenas termos cujos valores seriam números (reais).
Expressões tanto como as $2$, $1$, $5$, e $a$,
quanto como as $5\cbrt2$, $2a$, e $\cos(1 + 5\cbrt2)^{2a}$,
denotam, no final das contas, números reais.
Que tal botar um buraco assim:
$$
\cos(1 + 5\cbrt2)^{2a} + \bhole(5)
$$
O que substituimos aqui?  O próprio $\sin$!  Por que não?
E o que tipo de objetos podemos botar nesse buraco?
Um real, não serve: a expressão
$$
\cos(1 + 5\cbrt2)^{2a} + 7(5)
$$
não faz sentido: ela é \dterm{mal-tipada}.
O $7$ não pode receber um argumento como se fosse uma função, pois não é.
Que tipo de coisa então caiba nesse buraco?
Funções!
E não funções quaisquer, mas precisam ter um tipo compatível,
com a aridade certa, etc.
Esses buracos são \emph{de ordem superior}.
E com buracos de ordem superior, vêm funções de ordem superior.
%%}}}

%%{{{ pseudodf: higher_order_function 
\pseudodefinition.
\label{higher_order_function}%
\tdefined{função}[de ordem superior]%
Dizemos que uma função $f : A \to B$ é de \dterm{ordem superior}
se ela recebe ou retorna funções.
%%}}}

%%{{{ x: type_higher_order_holed_expressions 
\exercise.
\label{type_higher_order_holed_expressions}%
Escreva os tipos das funções seguintes:
$$
\align
F_1 &= \cos(1 + 5\cbrt2)^{2a} + \bhole(5)\\
F_2 &= \bhole(1 + 5\cbrt2)^{2a} + \sin(5)\\
F_3 &= \bhole(1 + 5\cbrt2)^{2a} + \bhole(5)\\
F_4 &= \cos(\bhole(1,5\cbrt2)^{2a} + \sin(5)\\
F_5 &= \cos(\bhole(1,5\cbrt2)^{2a} + \bhole(\bhole)\\
F_6 &= \lam {r,t,u} {\cos(1 + r(u,\cbrt2))^{r(t,a)} + \sin(u)}
\endalign
$$

\solution
Temos
\compute
F_1 &= \cos(1 + 5\cbrt2)^{2a} + \bhole(5)                       &&\eqtype (\reals\to\reals) \to \reals\\
F_2 &= \bhole(1 + 5\cbrt2)^{2a} + \sin(5)                       &&\eqtype (\reals\to\reals) \to \reals\\
F_3 &= \bhole(1 + 5\cbrt2)^{2a} + \bhole(5)                     &&\eqtype \paren{(\reals\to\reals)\times(\reals\to\reals)} \to \reals\\
F_4 &= \cos(\bhole(1,5\cbrt2)^{2a} + \sin(5)                    &&\eqtype (\reals^2\to\reals)\to\reals\\
F_5 &= \cos(\bhole(1,5\cbrt2)^{2a} + \bhole(\bhole)             &&\eqtype \paren{(\reals^2\to\reals)\times(\reals\to\reals)\times\reals}\to\reals\\
F_6 &= \lam {r,t,u} {\cos(1 + r(u,\cbrt2))^{r(t,a)} + \sin(u)}  &&\eqtype \paren{(\reals^2\to\reals)\times\reals\times\reals}\to\reals
\endcompute

\endexercise
%%}}}

%%{{{ Returning functions 
\note Retornando funções.
Até agora encontramos exemplos onde funções recebem como
argumentos outras funções, mas ainda não conhecemos alguma
função que \emph{retorna função}.
Ou será que conhecemos?
Se tu resolveu o~\ref{calculate_lambda_expressions},
tu já encontrou esse caso, na sua última expressão.
Seguem uns exemplos de operadores de ordem superior que
você talvez já encontrou e até usou na tua vida.
%%}}}

%%{{{ eg: Defining a higher-order functions 
\example Definindo uma função de ordem superior.
\ii{função!anônima}%
Considere a função $F : \nats \to (\nats \to \nats)$ definda pela
$$
\align
F(w) &= \text{aquela função $g : \nats \to \nats$ que quando recebe um $x$, retorna $w + x$}.
\intertext{%
Ou, equivalentemente:
}
F(w) &= \text{aquela função $g : \nats \to \nats$ definida pela $g(x) = w + x$}.
\intertext{%
Que tipo de objetos a função $F$ retorna?
Funções!  Nesse caso determinamos exatamente para qualquer entrada
dela, qual seria a função que vai ser retornada.
Observe que na definição de $F(w)$, apareceu a frase
``aquela função $g$\dots''.
Assim baptizamos temporariamente essa função com um nome (``$g$'') à toa:
apenas para referir a ela e retorná-la.
Usando a $\lambda$-notação, essa definição fica mais direta, mais elegante,
e (logo) mais legível:
}
F(w) &= \lam x {w + x} \eqtype \nats \to \nats.
\endalign
$$
Observe que no lado direito aparece uma função anônima.
\endexample
%%}}}

%%{{{ eg: in Python 
\example em Python.
\iipl Python
Em Python podemos (ainda bem\dots)~por exemplo escrever:
\sourcecode higher.py;
que corresponde na primeira maneira de definir a $F$, criando e nomeando
a função para ser retornada.
Podemos com $\lambda$ também:
\sourcecode higherlam.py;
Não ficou melhor?
\endexample
%%}}}

%%{{{ Q: what type of thing is F(25)? 
\question.
Que tipo de coisa é o $F(25)$?
%%}}}
\spoiler.

%%{{{ Answer 
\note.
Antes de responder nessa pergunta, vamos responder numa outra,
ainda mais específica: quem \emph{é} o $F(25)$?
Ou seja:
$$
F(25) = \dots?\dots
$$
Não precisamos pensar nada profundo!
Vamos apenas \emph{copiar fielmente} sua definição (no lado depois do ``$=$''), substituindo cada ocorrência de $w$, por $25$:
$$
F(25) = \text{aquela função $g : \nats \to \nats$ que quando recebe um $x\in\nats$, retorna o número $25 + x$}.
$$
Ou seja,
$$
F(25) : \nats\to\nats.
$$
Sendo função, podemos chamá-la com um argumento do certo tipo, por exemplo como o $3\in\nats$, e evaluá-la:
$$
\paren{F(25)}(3) = 28.
$$
%%}}}

%%{{{ x: where_did_28_come_from 
\exercise.
\label{where_did_28_come_from}%
De onde chegou esse $28$?

\solution
Seguindo a definição da $F(25)$ ela é a função que recebendo um valor
(agora tá recebendo o $3$), retorna a soma de $25$ e esse valor:
$25 + 3 = 28$.

\endexercise
%%}}}

%%{{{ x: find_expressions_with_given_types_higher_order 
\exercise.
\label{find_expressions_with_given_types_higher_order}%
Escreva $\lambda$-expressões que podem ser consideradas como funções com os
tipos seguintes:
$$
\align
F_1&\eqtype \reals \to \reals \\
F_2&\eqtype \reals \to (\reals \to \reals) \\
F_3&\eqtype (\reals \to \reals) \to \reals \\
F_4&\eqtype (\reals \to \reals) \to (\reals \to \reals) \\
F_5&\eqtype (\reals^2 \to \reals) \to \reals \\
F_6&\eqtype (\reals^2 \to \reals) \to (\reals \to (\reals \to \reals)).
\endalign
$$

\endexercise
%%}}}

%%{{{ x: find_expressions_with_given_types_higher_order_abstract 
\exercise.
\label{find_expressions_with_given_types_higher_order_abstract}%
Escreva $\lambda$-expressões que podem ser consideradas como funções com os
tipos seguintes, onde $A,B,C$ são conjuntos sobre quais tu não podes supor
absolutamente nada mais!
Para cada um dos tipos, tente escrever as mais $\lambda$-expressões realmente
diferentes que tu consegues.
Cuidado: para uns deles não é possível achar nenhuma!
$$
\align
&: A \to B \\
&: A \to (B \to A) \\
&: A \to (B \to B) \\
&: (A \to A) \to A \\
&: A \to (A \to A) \\
&: A \to \bigparen{B \to \paren{(A\to B) \times (A\union C) \times \nats}} \\
&: (A \to (B \to C) \to ((A\times B)\to C)) \\
&: ((A\times B)\to C) \to (A \to (B \to C))
\endalign
$$

\endexercise
%%}}}

%%{{{ first_class_citizens 
\note First-class citizens.
\label{first_class_citizens}%
{\ii{cidadão da primeira classe}}%
{\iisee{first-class citizen}{cidadão}}%
O slogan aqui é que funções são \emph{first-class citizens}.
Trabalhando no~\ref{calculate_lambda_expressions}, o último cálculo
chega no valor seguinte:
$$
\align
\plam x {\plam x {x + 1} \lapp 1 \ntimes \redex {\plam y {xy} \lapp 4}}
&\lstep \plam x {\redex {\plam x {x + 1} \lapp 1} \ntimes x\ntimes 4} \\
&\lstep \plam x {(1 + 1) \ntimes x \ntimes 4)} \\
&\isteq \plam x {8x}.
\endalign
$$
Como falei na resolução, se esse ``resultado'' (valor final)
não parece satisfatório, é por causa de um preconceito teu que
favorece os objetos de tipo ``número'' contra os objetos de tipo
``função''.
Os números têm o direito de ser valores finais; e as funções
também têm!  Esse ``preconceito'' é bastante alimentado por causa
de varias linguagens de programação que realmente não tratam
as funções em termos iguais com os outros tipos.
\iipl C
\iipl C++
\iipl Java
Em C, C++, ou Java, por exemplo, não é possível passar como
argumentos funções, nem retorná-las; mas claramente números
podem ser argumentos e também podem ser retornados como saída
de funções.
\iipl Haskell
\iipl PureScript
\iipl Idris
\iipl Agda
\iipl Racket
\iipl Clojure
\iipl Scala
\iipl Python
No outro lado, linguagens como Haskell, PureScript, Idris,
Agda, Racket, Clojure, Scala, Python, etc., adoptam o slogan
\standout
\emph{<<functions are first-class citizens>>}
\endstandout
ou seja, lá temos funções de ordem superior---e logo, felicidade.
%%}}}

\blah.
Funções de ordem superior não é algo tão desconhecido como
talvez parece.
O leitor já está acostumado com os operadores nos exemplos seguintes:

%%{{{ eg: higher_order_example_composition 
\example Composição.
\label{higher_order_example_composition}%
Sejam conjuntos $A,B,C$.
O operador da composição $\of$
(cuja notação decoramos aqui para especificar
o domínio e codomínio dele e dos seus argumentos)
é o seguinte:
$$
\dhole\oflab ABC\dhole : \bigparen{(B\to C) \times (A\to B)} \to (A\to C).
$$
Observe que ele é um operador de ordem superior, pois seus (dois) argumentos
são funcões, e também pois sua saída também é uma função.
\endexample
%%}}}

%%{{{ df: apply_operation 
\definition apply.
\label{apply_operation}%
\tdefined{função}[aplicação]%
\tdefined{função}[apply]%
\sdefined {\applydc {\sholed A} {\sholed B}} {a operação que aplica funções de tipo $A\to B$ em objetos de tipo $A$}%
\sdefined {{\sholed f} \at {\sholed x}} {notação infixa para o $\apply (f,x)$}%
Suponha $f : A \to B$ e seja $a \in A$.
Quando escrevemos \sqq{$f\fa a$} (ou \sqq{$f(a)$}),
estamos denotando a \dterm{aplicação} da $f$ no $a$.
O símbolo da aplicação é invisível, ou seja, a aplicação é denotada
pela juxtaposição da função e do seu argumento (já discutimos isso
no~\ref{lazier_clearer_functional_notation}).
Definimos aqui uma função $\apply$ que faz exatamente isso:
aplica seu primeiro argumento (uma função) no seu segundo
(um ponto do domínio do primeiro argumento).
Como fizemos na composição, decoramos essa operação
para esclarecer os conjuntos envolvidos:
dados conjuntos $A,B$ temos a
$$
\applydc A B : \bigparen{(A \to B) \times A} \to B
$$
definida pela
$$
\applydc A B (f, a) = f(a).
$$
Usamos também a notação infixa
$$
f \at x \sugdefeq \apply (f, x).
$$
%%}}}

%%{{{ eg: higher_order_example_apply 
\example.
Dados conjuntos $A,B$, a $\applydc A B$ é claramente uma
operação de ordem superior.
\endexample
%%}}}

%%{{{ x: type_of_restriction_op_with_hole 
\exercise.
\label{type_of_restriction_op_with_hole}%
Sejam $f : A\to B$ e $X\subset A$.
Ache o tipo dos:
$$
\align
f\resto \dhole  &\eqtype ?\\
(\dhole\resto X)\resto(A \to B)
                &\eqtype ?
\endalign
$$

\solution
Temos
$$
\align
f\resto \dhole  &\eqtype \pset A \to \Unionl_{X\in\pset A}(X\to B)\\
(\dhole\resto X)\resto (A \to B)
                &\eqtype \paren{(A \to B) \to (X \to B)}
\endalign
$$

\endexercise
%%}}}

%%{{{ eg: higher_order_example_derivation 
\example Derivação.
\label{higher_order_example_derivation}%
Considere o operador da derivação $D$
Por exemplo, se $f(x) = x^3 + 5x$, temos
$$
\align
D(f) &= g, \quad \text{onde $g(x) = 3x^2 + 5$}.
\intertext{%
Cuidado, não escrevemos aqui $D(f) = 3x^2 + 5$, mas podemos escrever
}
D(f) &= \lam x {3x^2 + 5}
\endalign
$$
sim.
Qual o típo da $D$?
Ela recebe e retorna funções de reais para reais, mas não podemos
tipá-la
$$
\align
D(\dhole) &: (\reals\to\reals) \to (\reals\to\reals)
\intertext{%
pois estariamos perdendo a totalidade da $D$:
existem funções no $(\reals\to\reals)$ que não são deriváveis.
Ainda mais, seria legal poder iterar o $D$ (\ref{function_iterations})
indefinitamente; e logo tipamos
}
D(\dhole) &: C^\infty \to C^\infty
\endalign
$$
onde $C^\infty$ é o conjunto de todas as funções infinitamente
deriváveis: são deriváveis, e suas derivadas também são, e suas
derivadas também, etc.
\endexample
%%}}}

%%{{{ remark: partial_functions_teaser 
\remark funções parciais: um teaser.
Mas talvez queremos mesmo considerar a $D$ como uma operação
que opera no espaço de funções $(\reals\to\reals)$
\emph{sacrificando} a totalidade.
Chegamos assim no conceito de \emph{função parcial}, que
voltamos a investigar na~\ref{Partial_functions}.
%%}}}

%%{{{ eg: higher_order_example_integration 
\example Integração.
\label{higher_order_example_integration}%
De novo uns exemplos de calculus: a integração definitiva e indefinitiva.
Sejam $a,b\in\reals$ com $a<b$ e seja
$$
R[a,b] \defeq \setstt {f : [a,b] \to \reals} {$f$ é \Riemann{}Riemann-integrável}.
$$
Observe que $R[a,b]$ é um conjunto de funções.
Definimos o operador
$$
\lam f {\lam x {\int_a^{x} f}} : R[a,b] \to ([a,b] \to \reals)
$$
cujo argumento é uma função---e ainda mais,
sua saída também é uma função---e logo ele é um operador de ordem superior
também.
Para a integração indefinita, seja
$$
R \defeq \setstt {f : \reals\to\reals} {$f$ é Riemann-integrável}
$$
e defina um operador
$$
\int\dhole : R \to \pset{(\reals\to\reals)}
$$
tal que
$$
\int f = \setst {F : \reals\to\reals} {D(F) = f}.
$$
Observe que a notação comum em análise é diferente: usamos por exemplo
$\int_a^x f(t)\, dt$, e o $\int f$ é visto como uma antiderivada
(que depende numa constante $C$) e não como o conjunto de todas
essas antiderivadas como definimos aqui.
\endexample
%%}}}

\endsection
%%}}}

%%{{{ Commutative diagrams 
\section Diagramas comutativos.
\label{Commutative_diagrams}%

\blah.
Começamos com uma definição complicada; leia agora, mas veja logo os exemplos
seguintes.

%%{{{ pseudodf: commutative_diagram 
\pseudodefinition diagrama comutativo.
\label{commutative_diagram}%
\tdefined{diagrama}[comutativo]%
Digamos que um diagrama externo de funções \dterm{comuta} ou que é um
\dterm{diagrama comutativo} sse: para todo par de ``caminhos'' feitos
por seguindo setas, \emph{se pelo menos um dos dois caminhos tem tamanho
maior que $1$}, então os dois caminhos são iguais.
%%}}}

%%{{{ eg: triangle 
\example.
O que significa que o diagrama seguinte comuta?
$$
\cdopt{sep=2cm}
A   \ar[r, "f"]\ar[dr, "h"'] \| B \ar[d, "g"] \\
                             \| C
\endcd
$$
Significa que $h = g\of f$.
\endexample
%%}}}

%%{{{ eg: square 
\example.
O que significa que o diagrama seguinte comuta?
$$
\cdopt{sep=2cm}
A   \ar[r, "f"]\ar[d, "h"'] \| B \ar[d, "g"] \\
D   \ar[r, "k"]             \| C
\endcd
$$
Significa que $g\of f  = k\of h$
\endexample
%%}}}

%%{{{ eg: cd_example_line 
\example.
\label{cd_example_line}%
O que significa que o diagrama seguinte comuta?
$$
\cdopt{sep=2cm}
A   \ar[r, shift left, "g"]\ar[r, shift right, "h"'] \| B \ar[r, "f"]  \|  C
\endcd
$$
Significa que $f\of g  = f\of h$.
\endexample
%%}}}

%%{{{ beware: at least one path must have length greater than 1 
\beware.
Graças à parte enfatizada na~\ref{commutative_diagram}, \emph{não podemos}
concluir no~\ref{cd_example_line} que $g = h$, pois mesmo que
existem esses dois caminhos de $A$ para $B$ (um seguindo a seta $g$, outro
seguindo a seta $h$), nenhum deles tem tamanho maior que 1.
%%}}}

%%{{{ eg: part of diagram commutes 
\example.
O que significa que o rectângulo no diagrama seguinte comuta?
$$
\cdopt{sep=2cm}
A   \ar[r, "f"]\ar[d, "k"'] \| B \ar[d, "g"]  \ar[dr, "i"] \\
D                           \| C \ar[l, "h"'] \ar[r, "j"] \| D 
\endcd
$$
Apenas que $h \of g \of f = k$.
Observe que isso não nos permite concluir nada especial sobre as
setas~$i$ e~$j$ do triângulo.  Se soubéssemos que o diagrama
comuta (e não apénas seu rectângulo), poderiamos concluir
que $i = j\of g$ também.
\endexample
%%}}}

\blah.
Afirmando a comutatividade de certos diagramas vira uma maneira curta de
afirmar proposições, como por exemplo essas duas leis que já encontramos
na~\refn{Composition_laws}.

%%{{{ eg: cd_associativity_law 
\example.
\label{cd_associativity_law}%
Afirme a lei da associatividade da~\refn{Composition_laws}
usando a comutatividade dum diagrama.

\solution
Sejam $A\toby f B \toby g C \toby h D$.
Basta desenhar um diagrama cuja comutatividade quis dizer
$h \of (g \of f) = (h \of g) \of f$.
É o seguinte:
$$
\cdopt{sep=2cm}
A   \ar[r, "f"]\ar[rr, bend left=30,  "g\of f"] \|
B   \ar[r, "g"]\ar[rr, bend right=30, "h\of g"'] \|
C   \ar[r, "h"] \|
D
\endcd
$$
Outra maneira para desenhar o mesmo diagrama seria a seguinte:
$$
\cdopt{sep=2cm}
A   \ar[r, "f"]\ar[rd, "g\of f"'] \| B \ar[d, "g"]  \ar[dr, "h\of g"] \\
                                  \| C \ar[r, "h"']      \| D
\endcd
$$
Questão de gosto.
\endexample
%%}}}

%%{{{ x: cd_id_laws 
\exercise.
\label{cd_id_laws}%
Como expressar as leis da identidade (\ref{Composition_laws}) usando
apenas a comutatividade dum diagrama?

\hint
Use uma $f : A \to B$, e as identidades $\idof A,\idof B$.

\solution
Assim:
$$
\cdopt{sep=2cm}
A   \ar[dr, "f"']\ar[r, "\idof A"] \| A \ar[d, "f"]  \ar[dr, "f"]   \\
                                   \| B \ar[r, "\idof B"'] \| B
\endcd
$$

\endexercise
%%}}}

%%{{{ x: cd_copy_paste 
\exercise.
\label{cd_copy_paste}%
Suponha que os quadrados no diagrama seguinte comutam:
$$
\cdopt{sep=2cm}
A   \ar[r, "f"] \ar[d, "i"] \| B \ar[r, "g"] \ar[d, "j"] \| C \ar[d, "k"] \\
P   \ar[r, "s"]             \| Q \ar[r, "t"]             \| R
\endcd
$$
Prove que o rectângulo grande também comuta.

\solution
Temos que os quadrados do
$$
\cdopt{sep=2cm}
A   \ar[r, "f"] \ar[d, "i"] \| B \ar[r, "g"] \ar[d, "j"] \| C \ar[d, "k"] \\
P   \ar[r, "s"]             \| Q \ar[r, "t"]             \| R
\endcd
$$
comutam.
Precisamos provar que o rectângulo também comuta, ou seja, que
\compute
k \of g \of f &= t \of s \of i.
\intertext{Calculamos:}
k \of g \of f
&= (k \of g) \of f   \by {assoc.~da~$\of$}
&= (t \of j) \of f   \by {comut.~do quad.~direito}
&= t \of (j \of f)   \by {assoc.~da~$\of$}
&= t \of (s \of i)   \by {comut.~do quad.~esquerdo}
&= t \of s \of i.    \by {assoc.~da~$\of$}
\endcompute

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ More constructions and operations on functions 
\section Mais construções e operações em funções.

%%{{{ df: function_iterations 
\definition iterações.
\label{function_iterations}%
\tdefined{função}[iteração]%
\sdefined {\sholed f^\sholed n} {a $n$-ésima iteração da $f$.}%
Seja $f : A \to A$.
Definimos as \dterm{iterações} de $f$ pela recursão
$$
\align
f^0     &= \idof A \\
f^{n+1} &= f\of f^n.
\endalign
$$
%%}}}

%%{{{ eg: calculate_iterate_3_fx 
\example.
Seja $f : A \to A$.  Calculamos:
\compute
f^3(x)
&= (f \of f^2)(x)                      \by {def.~$f^3$}
&= (f \of (f \of f^1))(x)              \by {def.~$f^2$}
&= (f \of (f \of (f \of f^0)))(x)      \by {def.~$f^1$}
&= (f \of (f \of (f \of \idof A)))(x)  \by {def.~$f^0$}
&\dotseq (f \of f \of f)(x)            \by {ass.~$\of$; lei da~$\idof A$}
&\dotseq f (f (f (x)))                 \by {def.~$\of$}
\endcompute
Em geral omitimos parenteses quando a expressão envolve apenas uma operação
associativa;
botamos aqui para enfatizar cada aplicação de definição nesse cálculo.
\endexample
%%}}}

%%{{{ x: succ3_is_plus_3 
\exercise.
\label{succ3_is_plus_3}%
Como definarias numa maneira simples a função $\succ^3$ para alguém
que não sabe (e sequer quer saber) o que são as iterações duma função?

\solution
Temos $\succ^3 = \lam x {x+3} \eqtype \nats\to\nats$.

\endexercise
%%}}}

%%{{{ beware: notation of functions with exponents 
\beware.
Em certos textos de matemática, aparece a notação $f^n(x)$ como
sinónimo de $(f(x))^n$.
Por exemplo:
$$
\text{quem escreveu\dots}
\quad
\sin^2 x + \cos^2 x
\quad
\aligned
&\text{\dots quis dizer\dots}\\
&\text{\dots mas aqui seria\dots}
\endaligned
\quad
\aligned
&(\sin x)^2   + (\cos x)^2    \\
&\sin(\sin x) + \cos(\cos x).
\endaligned
$$
%%}}}

%%{{{ remark: function_iterations_altdef 
\remark.
\label{function_iterations_altdef}%
Poderiamos ter escolhido definir as potências de $f$ pelas:
$$
\align
f^0     &= \idof A \\
f^{n+1} &= f^n \of f
\endalign
$$
em vez da recursão que usamos na~\ref{function_iterations}.
As duas definições são equivalentes, ou seja, as duas operações
de exponenciação definidas são iguais.
Por enquanto pode aceitar isso como um fato que vamos provar
depois (\ref{associative_with_identity_exp_defs_equiv}),
ou esquecer completamente essa definição alternativa.
%%}}}

%%{{{ thm: properties_of_function_iterations 
\theorem.
\label{properties_of_function_iterations}%
A operação de iteração definida
no~\ref{function_iterations}
satisfaz as leis:
\beginol
\item{\rm (1)} $\pforall {n,m\in\nats} \lforall {f : A \to A} {a^{m+n}        = a^m \of a^n}$;
\item{\rm (2)} $\pforall {n,m\in\nats} \lforall {f : A \to A} {a^{m\ntimes n} = (a^m)^n}$;
\item{\rm (3)} $\lforall {n\in\nats} {\id^n = \id}$.
\endol
\proof Já demonstrado.
Provamos por indução as três leis nos exercícios~\refn{law_of_natexp_1},
\refn{law_of_natexp_2}, e~\refn{law_of_natexp_3}---se tu não resolveu,
volte a resolver!
Verifique que nossas provas precisaram apenas a \emph{associatividade}
e a \emph{identidade} da multiplicação e \emph{nada da sua definição},
então podemos substituir a multiplicação por a nossa $\of$.
Sobre a outra operação envolvida nas provas, a adição, não precisamos
verificar nada, pois nos dois casos é a mesma operação:
a adição nos naturais.
\qed
%%}}}

%%{{{ df: fcross 
\definition cross.
\label{fcross}%
\tdefined{função}[cross]%
\tdefined{função}[produto]%
\sdefined {\sholed f \times \sholed g} {a função-produto e $f$ ``cross'' $g$}%
Sejam
$$
\gather
A \longtoby f C\\
B \longtoby g D
\endgather
$$
Chamamos \dterm{função-produto da $f$ ``cross'' $g$},
que denotamos por $f \cross g$,
a função
$$
A \times B \longtoby {f\cross g} C \times D
$$
definida pela
$$
(f \cross g)(x,y) = \tup{f(x), g(y)}.
$$
%%}}}

%%{{{ x: fcross_commutative_diagram 
\exercise.
\label{fcross_commutative_diagram}%
Bote nomes e direcções onde faltam e prove que o diagrama comuta:
$$
\cdopt{sep=2cm}
A \ar[d, "f"']   \|  A\times B \ar[l, dash, ""]\ar[r, dash, ""]\ar[d, dotted, ""]   \| B \ar[d, "g"]  \\
C                \|  C\times D \ar[l, dash, ""]\ar[r, dash, ""]                     \| D
\endcd
$$

\endexercise
%%}}}

%%{{{ remark: commutative_diagrams_as_puzzles 
\remark Um puzzle.
\label{commutative_diagrams_as_puzzles}%
Vamos fazer um ``rewind'' no momento exatamente antes de definir
nossa função de $A \cross B$ para $C \cross D$.
O diagrama parece como no~\ref{fcross_commutative_diagram}, exceto
sem a setinha pontilhada no meio.  E esse é o ``missing piece'' do nosso puzzle.
Procuramos então achar uma \emph{seta} que é \dterm{legal}.
O que significa ``legal'' aqui?
\emph{Uma seta que faz o diagrama comutar!}
%%}}}

%%{{{ x: fcross_practise 
\exercise.
\label{fcross_pratise}%
Para qualquer uma das expressões seguintes, calcule seu valor quando tiver.
$$
\xalignat2
(\sin \cross \cos) (\pi)        &= &
(\outl \cross \succ) (5, 6)     &= \\
(\sin \cross \cos) (\pi/2, \pi) &= &
(\idof\nats \cross \succ) (0,1) &= 
\endxalignat
$$
Pode ser que umas delas tem type errors, e logo nenhum valor.

\endexercise
%%}}}

%%{{{ x: fcross_is_total 
\exercise.
\label{fcross_is_total}%
O operador binário $(\dhole\cross\dhole)$ nas funções
que definimos no~\ref{fcross}, é um operador total?

\solution
Sim.
A gente não necessitou nenhuma propriedade especial
sobre nossas funções $f,g$ na definição.

\endexercise
%%}}}

%%{{{ df: fpair 
\definition pair.
\label{fpair}%
\tdefined{função}[par]%
\sdefined {\fpair {\sholed f} {\sholed g}} {a função-par $f$ ``pair'' $g$}%
Sejam
$$
A \longfromby f D \longtoby g B
$$
Chamamos \dterm{função-par da $f$ ``pair'' $g$},
que denotamos por $\fpair f g$,
a função
$$
D \longtoby {\fpair f g} A\times B
$$
definida pela
$$
\fpair f g (x) = \tup{f(x), g(x)}.
$$
%%}}}

%%{{{ x: fpair_commutative_diagram 
\exercise.
\label{fpair_commutative_diagram}%
Bote nomes e direcções onde faltam e prove que o diagrama comuta:
$$
\cdopt{sep=2cm}
A \| A\times B \ar[l, dash, ""]\ar[r, dash, ""] \| B \\
  \| D\ar[u, dotted, ""]\ar[ul, "f"]\ar[ur, "g"']
\endcd
$$

\endexercise
%%}}}

%%{{{ Q: Can you define the pointwise operation function? 
\question.
Dadas $f,g : A \to B$, e sabendo que no $B$ é definida uma operação
binária $\ast : B^2 \to B$, qual função interessante tu podes definir
de $A$ para $B$?  Qual notação tu gostaria de usar pra ela?
%%}}}
\spoiler.

%%{{{ df: pointwise_operation 
\definition pointwise.
\label{pointwise_operation}%
\tdefined{pointwise!operação}%
\iisee{função!pointwise operação}{pointwise, operação}%
Sejam $A,B$ conjuntos e $\ast$ uma operação binária no $B$.
Dadas funções $f,g : A \to B$, definimos a função
$f \ast g : A \to B$
pela
$$
(f \ast g)(x) = f(x) \ast g(x) , \qquad \text{para todo $x\in A$}.
$$
Chamamos a $(\dhole \ast \dhole)$ a \dterm{operação pointwise}
da $\ast$ no $(A \to B)$.
%%}}}

%%{{{ note: pointwise_operation_outside_the_forest 
\note Uma outra maneira de se inspirar.
\label{pointwise_operation_outside_the_forest}%
Se tu realmente tentou responder na pergunta acima, provavelmente
tu chegou nessa mesma definição.  Uma maneira de chegar nela é
realmente ``entrar na floresta'', e começar brincar com as arvores,
ate achar o que tu ta procurando.
Uma outra abordagem seria observar a floresta de longe, por fora.
Desenhar as setas que tu tens, e ver o que tu podes fazer
interessante com elas; pra onde elas te guiam.
Nesse caso temos $f, g : A \to B$, e também a $\ast : B^2 \to B$.
Nosso desafio é definir uma função \emph{interessante}
$\alert ? : A \to B$.%
\footnote{%
Claramente não é o desafio mais claro que tu já viu na vida,
mas isso faz parte do próprio desafio!
}
Desenhamos então:
$$
\phantom{A \longtoby ? {}} A \cross A \longtoby {f \cross g} B \cross B \longtoby {\ast} B.
$$
O que \emph{interessante} podemos definir agora?
Com certeza uma composição tem chances boas de ser interessante,
só que aqui a
$$
\ast \of \pfcross f g : A \cross A \longto B
$$
não tem o tipo desejado $A\to B$.
Agora podemos desistir dessa abordagem e entrar na floresta mesmo
para brincar com as arvores; \emph{ou podemos perceber que talvez
falta apenas uma setinha para nos ajudar}.
Se a gente tivesse uma setinha interessante assim:
$$
A \alert{{}\longtoby ?{}} A \cross A \longtoby {f \cross g} B \cross B \longtoby {\ast} B,
$$
a gente teria um candidato ótimo para algo interessante, pois
assim a composição de todas essas setinhas tem o tipo desejado.
Basta definir uma função interessante então de $A$ para $A\cross A$
e assim ganhar a
$$
A \xlongtoby {\ast \of \pfcross f g \of \alert ?} B.
$$
%%}}}

%%{{{ x: discover_diagonalizer 
\exercise.
\label{discover_diagonalizer}%
Dado conjunto $A$, define uma função interessante de $A$ para $A \cross A$.
Começa descrevendo sua alma com um $\lambda$; consegue defini-la sem
descrever explicitamente o seu comportamento?

\solution
Usando $\lambda$, a função que procuramos é a seguinte:
$$
A \longtoby {\lam x {\tup{x,x}}} A \cross A.
$$
Essa função é a $\fpair {\idof A} {\idof A}$.

\endexercise
%%}}}

%%{{{ x: pointwise_operation_two_paths_to_solution_same_or_not 
\exercise.
\label{pointwise_operation_two_paths_to_solution_same_or_not}%
Verifique se as duas funções definidas na~\ref{pointwise_operation}
e no fim do~\ref{pointwise_operation_outside_the_forest}
(com o~\ref{discover_diagonalizer}) são as mesmas.

\endexercise
%%}}}

\blah.
A função que tu definiu no~\ref{discover_diagonalizer} é muito útil
e freqüentemente usada e sim, tem seu próprio nome e sua própria notação:

%%{{{ df: diagonal_function 
\definition Função diagonal.
\label{diagonal_function}%
\tdefined{função}[diagonal]%
\sdefined {\diagdom {\sholed A}} {a função diagonal do $A$}%
\sdefined {\diag} {a função diagonal do conjunto implicito pelo contexto}%
Seja $A$ conjunto.
Definimos sua \dterm{função diagonal} $\diagdom A : A \to A \times A$
pela
$$
\diagdom A (x) = \tup{x,x}.
$$
Equivalentemente:
$$
\diagdom A \defeq \fpair {\idof A} {\idof A}.
$$
Quando o conjunto $A$ é implícito pelo contexto escrevemos apenas $\diag$.
%}}}

\blah.
Com o que já temos na nossa disposição podemos definir umas funções
interessantes apenas usando composições, e \emph{diretamente} definindo
a função (sem utilizar um ponto do seu domínio nem a $\lambda$-notação).
Vamos investigar isso no~\ref{Pointfree_style}.

\endsection
%%}}}

%%{{{ Jections : Injections, surjections, bijections 
\section Injecções, sobrejecções, bijecções.
\label{Jections}%

%%{{{ noneg: not_injective 
\nonexample.
Nenhuma dessas funções é injetora:
$$
\xxalignat3
&
\tikzpicture
\tikzi not_injective0;
\draw[->] (0.5,2.0) -- (2.5,2.0) node[midway,below] {$f$};
\draw[|->] (a1) -- (b3);
\draw[|->] (a2) -- (b1);
\draw[|->] (a3) -- (b2);
\draw[|->,color=red] (a4) -- (b4);
\draw[|->,color=red] (a5) -- (b4);
\node[color=red] (a4) at (0,-.5)   {$\bullet$};
\node[color=red] (a5) at (0,-1)    {$\bullet$};
\endtikzpicture
&&
\tikzpicture
\tikzi not_injective0;
\draw[->] (0.5,2.0) -- (2.5,2.0) node[midway,below] {$g$};
\draw[|->,color=red] (a1) -- (b3);
\draw[|->]           (a2) -- (b3);
\draw[|->]           (a3) -- (b3);
\draw[|->,color=red] (a4) -- (b3);
\draw[|->]           (a5) -- (b3);
\node[color=red] (a1) at (0,1)     {$\bullet$};
\node[color=red] (a4) at (0,-.5)   {$\bullet$};
\endtikzpicture
&&
\tikzpicture
\tikzi not_injective0;
\draw[->] (0.5,2.0) -- (2.5,2.0) node[midway,below] {$h$};
\draw[|->,color=red] (a1) -- (b2);
\draw[|->,color=red] (a2) -- (b2);
\draw[|->] (a3) -- (b2);
\draw[|->] (a4) -- (b4);
\draw[|->] (a5) -- (b4);
\node[color=red] (a1) at (0,1)     {$\bullet$};
\node[color=red] (a2) at (0,.5)    {$\bullet$};
\endtikzpicture
\endxxalignat
$$
Em cada caso \emph{uma} razão é enfatizada com cor.
\endnonexample
%%}}}

%%{{{ noneg: not_surjective 
\nonexample.
E aqui nenhuma dessas funções é sobrejetora:
$$
\xxalignat3
&
\tikzpicture
\draw (0,2.0) node {$A$};
\draw (3,2.0) node {$B$};
\draw[->] (0.5,2.0) -- (2.5,2.0) node[midway,below] {$f$};
\draw (0,0) ellipse (-.85cm and 1.5cm);
\draw (3,0) ellipse (-.85cm and 1.5cm);
\node (a1) at (0,.666)    {$\bullet$};
\node (a2) at (0,0)       {$\bullet$};
\node (a3) at (0,-.666)   {$\bullet$};
\node (b1) at (3,1)       {$\bullet$};
\node (b2) at (3.2,.333)  {$\bullet$};
\node (b3) at (3.1,-.333) {$\bullet$};
\node (b4) at (2.8,-1)    {$\bullet$};
\draw[|->] (a1) -- (b1);
\draw[|->] (a2) -- (b2);
\draw[|->] (a3) -- (b3);
\node[color=red] (b4c) at (b4) {$\bullet$};
\endtikzpicture
&&
\tikzpicture
\draw (0,2.0) node {$A$};
\draw (3,2.0) node {$C$};
\draw[->] (0.5,2.0) -- (2.5,2.0) node[midway,below] {$g$};
\draw (0,0) ellipse (-.85cm and 1.5cm);
\draw (3,0) ellipse (-.85cm and 1.5cm);
\node (a1) at (0,.666)  {$\bullet$};
\node (a2) at (0,0)     {$\bullet$};
\node (a3) at (0,-.666) {$\bullet$};
\node (b1) at (3,1)     {$\bullet$};
\node (b2) at (2.9,.7)  {$\bullet$};
\node (b3) at (3.1,0.1) {$\bullet$};
\node (b4) at (2.8,-.5) {$\bullet$};
\node (b5) at (3,-1)    {$\bullet$};
\node (b6) at (3.2,-0.8){$\bullet$};
\draw[|->] (a1) -- (b2);
\draw[|->] (a2) -- (b2);
\draw[|->] (a3) -- (b5);
\node[color=red] (b4c) at (b4) {$\bullet$};
\endtikzpicture
&&
\tikzpicture
\draw (0,2.0) node {$\emptyset$};
\draw (3,2.0) node {$D$};
\draw[->] (0.5,2.0) -- (2.5,2.0) node[midway,below] {$h$};
\draw (0,0) ellipse (-.85cm and 1.5cm);
\draw (3,0) ellipse (-.85cm and 1.5cm);
\node (b1) at (3.0,.333)  {$\bullet$};
\node (b2) at (3.0,-.333) {$\bullet$};
\node[color=red] (b2c) at (b2) {$\bullet$};
\endtikzpicture
\endxxalignat
$$
Novamente em cada caso \emph{uma} razão é enfatizada com cor.
\endnonexample
%%}}}

%%{{{ Q: how would you define injective and surjective? 
\question.
Como tu definirias os conceitos de função injetora e sobrejetora?
%%}}}
\spoiler.

%%{{{ df: jective_function 
\definition.
\label{jective_function}%
\tdefined{função}[injectiva]%
\tdefined{função}[sobrecjetiva]%
\tdefined{função}[bijectiva]%
\sdefined {\sholed f : \sholed A \injto \sholed B} {$f : A \to B$ injectiva}%
\sdefined {\sholed f : \sholed A \surto \sholed B} {$f : A \to B$ sobrejectiva}%
\sdefined {\sholed f : \sholed A \bijto \sholed B} {$f : A \to B$ bijectiva}%
\iisee{injecção}{função injectiva}%
\iisee{sobrejecção}{função sobrejectiva}%
\iisee{bijecção}{função bijectiva}%
Seja $f : A \to B$.
Chamamos a $f$ \dterm{injectiva} (ou \dterm{injetora}) sse
$$
\text{para todo $x,y \in A$, se $f(x) = f(y)$ então $x = y$}.
$$
Chamamos a $f$ \dterm{sobrejectiva} (ou \dterm{sobrejetora}) sse
$$
\text{para todo $b \in B$, existe $a\in A$ tal que $f(a) = b$}.
$$
Chamamos a $f$ \dterm{bijectiva} (ou \dterm{bijetora}, ou \dterm{correspondência}), sse
$f$ é injectiva e sobrejectiva.
Formulamente,
$$
\align
\text{$f$ injectiva}    &\defiff \lforall {x,y \in A} {f(x) = f(y) \implies x = y}; \\
\text{$f$ sobrejectiva} &\defiff \pforall {b \in B} \lexists {a \in A} {f(a) = b}; \\
\text{$f$ bijectiva}    &\defiff \text{$f$ injetora} \mland \text{$f$ sobrejetora}.
\endalign
$$
Usamos as notações
$$
\align
f : A \injto B &\defiff \text{$f:A\to B$ injectiva};\\
f : A \surto B &\defiff \text{$f:A\to B$ sobrejectiva};\\
f : A \bijto B &\defiff \text{$f:A\to B$ bijectiva}.
\endalign
$$
As palavras ``injectiva'', ``sobrejectiva'', e ``bijectiva''
são adjectivos.  Os substantivos correspondentes são os:
\dterm{injecção}, \dterm{sobrejecção}, \dterm{bijecção}.
Dizemos por exemplo que <<$f$ é uma bijecção>>, que significa
que <<$f$ é uma função bijectiva>>.
%%}}}

%%{{{ remark: contrapositive of injective 
\remark.
\iiseealso{respeitar}{preservar}%
\iiseealso{preservar}{respeitar}%
\ii{preservar}[as distincções]%
\ii{respeitar}[as distincções]%
A seguinte afirmação equivalente de $f : A \injto B$ é muito útil:
$$
\text{para todo $x,y \in A$, se $x\neq y$ então $f(x) \neq f(y)$}.
$$
(É a sua contrapositiva.)
Vamos traduzir essa afirmação mais perto ``no nível coração'':
\standout
<<$f$ \dterm{preserva} as distincções do seu domínio.>>
\endstandout
Também digamos que $f$ \dterm{respeita} as distincções.
Assim podemos pensar que uma função injetora embute seu domínio
no seu codomínio, criando uma \emph{cópia fiel} dele,
só que com nomes diferentes para seus membros.
%%}}}

%%{{{ remark: Setist vs. Categorist 
\remark Conjuntista \vs Categorista.
Observe que o conjuntista pode realmente se perguntar se uma função é
injetora ou não, pois a definição de ser injetora não mexe com o codomínio
da função. Mas pra ele, ser sobrejetora ou não, não é uma propriedade
da função ``sozinha''; ele afirma que <<a função $f$ é \dterm{sobre} o $B$>>,
e é isso que ele quis dizer quando ele afirma
<<a função $f : A\to B$ é sobrejetora>>.
Pense na diferença que suas caixas pretas têm:
como decidir se uma caixa preta dum conjuntista é sobrejetora
ou não?  Mas tem como decidir se ela é injetora sim.
Então o ``ser injetora'' é um predicado de aridade $1$ para ambos,
mas o predicado ``ser sobrejetora'' já difere dependendo da fé:
para o categorista tem aridade $1$;
para o conjuntista tem aridade $2$,
o segundo argumento sendo o conjunto $B$ nesse caso.
%%}}}

%%{{{ x: double_or_reverse_string_inj_or_surj 
\exercise.
\label{double_or_reverse_string_inj_or_surj}%
Seja~$S$ o conjunto de todos os strings \emph{não vazios}
dum alfabeto $\Sigma$, com $\card{\Sigma} \geq 2$.
Considere a função
$f : S \times \set{0,1} \to S$ definida pela:
$$
f(w,i) =
\knuthcases{
ww, &se $i = 0$\cr
w', &se $i = 1$
}
$$
onde $w'$ é o string reverso de $w$,
e onde denotamos a concatenação de strings por juxtaposição.
(1) A $f$ é injetora?
(2) A $f$ é sobrejetora?

\hint
Quais são o domínio e o codomínio da $f$?

\solution
\proofpart{(1)}
Não, $f$ não é injetora.
Tome uma letra do alfabeto $a\in\Sigma$ e observe que
$$
f(a, 0) = aa = f(aa,1).
$$
Como $(a,0) \neq (aa,1)$, a $f$ não é injetora.
\crproofpart{(2)}
Sim, $f$ é sobrejetora.
Tome um aleatório string $w\in S$,
e seja $w'$ o string reverso de $w$.
Temos
$$
f(w',1) = (w')' = w.
$$

\endexercise 
%%}}}

%%{{{ x: touch_of_godel_encoding 
\exercise.
\label{touch_of_godel_encoding_pairs}%
Considere as $g,h : \nats^2 \to \nats$
definidas pelas
$$
\xalignat2
g (x,y) &= 2^x 3^y &
h (x,y) &= 2^x 6^y.
\endxalignat
$$
Para cada uma, decida se é injetora, e se é sobrejetora.

\hint
A $g$ é injetora mais não sobrejetora;
a $h$ não é nem injetora nem sobrejetora.
Demonstre tudo isso.

\hint
Para refutar que $h$ é injetora, observe que $6 = 2\ntimes 3$.

\endexercise
%%}}}

%%{{{ df: jection_spaces 
\definition.
\label{jection_spaces}%
\sdefined {(\sholed A \injto \sholed B)} {o conjunto de todas as injecções  de $A$ para $B$}%
\sdefined {(\sholed A \surto \sholed B)} {o conjunto de todas as surjecções de $A$ para $B$}%
\sdefined {(\sholed A \bijto \sholed B)} {o conjunto de todas as bijecções  de $A$ para $B$}%
Sejam $A,B$ conjuntos.  Definimos os conjuntos:
$$
\align
(A \injto B) &\defeq \setstt {f : A \to B} {$f$ injetora} \\
(A \surto B) &\defeq \setstt {f : A \to B} {$f$ sobrejetora} \\
(A \bijto B) &\defeq \setstt {f : A \to B} {$f$ bijetora}
\endalign
$$
%%}}}

%%{{{ x: cardinalities_of_jection_spaces 
\exercise.
Ache a cardinalidade dos conjuntos da~\ref{jection_spaces}
em termos das cardinalidades dos $A$ e $B$, supondo que
são finitas.

\endexercise
%%}}}

%%{{{ x: fcom_respects_jections 
\exercise Composição respeita ``-jectividade''.
\label{fcom_respects_jections}%
Sejam $f : A\to B$ e $g : B \to C$.
Prove:
\item{(1)} Se $f$ e $g$ são injetoras, então $g\fcom f$ também é;
\item{(2)} Se $f$ e $g$ são sobrejetoras, então $g\fcom f$ também é;
\item{(3)} Se $f$ e $g$ são bijetoras, então $g\fcom f$ também é.

\endexercise
%%}}}

%%{{{ x: converse_to_gof_bij_conclusions 
\exercise.
Se $g\compose f$ é bijetora, o que podemos concluir sobre as $f,g$?  Justifique.

\endexercise
%%}}}

%%{{{ x: converse_to_gof_bij_conclusions 
\exercise.
Se $f$ é injetora e $g$ sobrejetora, a $g\compose f$ é necessariamente bijetora?

\solution
Não.
Aqui um contraexemplo:
$$
\tikzpicture
\draw (0,0) ellipse (-.75cm and 1.25cm);
\draw (3,0) ellipse (-.75cm and 1.25cm);
\draw (6,0) ellipse (-.75cm and 1.25cm);
\draw (0,-.5) node {$\bullet$};
\draw (3,.5)  node {$\bullet$};
\draw (3,-.5) node {$\bullet$};
\draw (6,.5)  node {$\bullet$};
\draw (6,-.5) node {$\bullet$};
\draw[|->] (0.2,-.5) -- (2.8,-.5);
\draw[|->] (3.2,-.5) -- (5.8,-.5);
\draw[|->] (3.2,.5) -- (5.8,.5);
\draw[->]  (0.5,1.5) -- (2.5,1.5);
\draw[->]  (3.5,1.5) -- (5.5,1.5);
\draw (0,1.5) node {$A$};
\draw (3,1.5) node {$B$};
\draw (6,1.5) node {$C$};
\draw (1.5,1.20) node {$f$};
\draw (4.5,1.20) node {$g$};
\endtikzpicture
$$

\endexercise
%%}}}

%%{{{ x: x_mapsto_singleton_x_properties 
\exercise.
\label{x_mapsto_singleton_x_properties}%
Sejam $A\neq\emptyset$ um conjunto e $f : A \to \pset A$ definida pela equação
$$
f(a) = \set a.
$$
Investigue:
(i) A $f$ é injetora?
(ii) A $f$ é sobrejetora?

\solution
\noindent
(i) Sim: se $x,y\in A$, então
$$
f(x) = f(y)
    \implies \set x = \set y
    \implies x = y.
$$
\endgraf
\noindent
(ii) Não: para todo $a\in A$ temos
$f(a) = \set a \neq \emptyset \in \pset A$.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Problems intermission 
\problems Intervalo de problemas.

%%{{{ how_many_idempotents_on_AtoA_for_A_finite 
\problem.
\label{how_many_idempotents_on_AtoA_for_A_finite}%
Generalize o~\ref{how_many_idempotents_on_AtoA_for_A_triset} para
um arbitrário conjunto finito $A$.

\hint
Seja $n = \card A$.

\endproblem
%%}}}

%%{{{ constant_function_why_did_we_omit_unique 
\problem.
\label{constant_function_why_did_we_omit_unique}%
Na definição do~\ref{constant_notiff_steady}
não escrevemos ``existe único'', mas apenas ``existe''.
O que mudaria com esse ``único''?
Prove tua afirmação.

\hint
Lembra se que a definição é apenas aplicável numa \emph{função}.
Mas cuidado com os casos especiais que envolvem o $\emptyset$.

\solution
\emph{Quase} nada!
Parece ser redundante, pois a definição é aplicavel numa \emph{função}
e graças à determinabilidade sabemos que se existe, tem que ser
único---mas!
Vamos tentar provar para achar algo interessante.
\endgraf
Suponha que temos $b,b'\in B$ que satisfazem a condição, ou seja,
temos:
$$
\align
\text{para todo $x \in A$,}& f(x) = b \\
\text{para todo $x \in A$,}& f(x) = b'
\endalign
$$
Logo tomando um $x\in A$, temos
$$
b = f(x) = b',
$$
ou seja, unicidade mesmo desse $b$,
dado qualquer $x\in A$.
Mas isso é, supondo que $A\neq\emptyset$.
O que acontece se $A=\emptyset$ e $B\neq\emptyset$?
Botando esse ``único'' na definição, uma função
$$
\emptyset\toby f B
$$
vai ser constante com valor $b$ sse $B$ é um singleton
e $b$ é seu único membro.
Sem o ``único'', ela vai ser constante sse $B\neq\emptyset$.
Veja também o exercício 

\endproblem
%}}}

%%{{{ touch_of_godel_encoding_strings 
\problem.
\label{touch_of_godel_encoding_srings}%
Seja $\kstar \nats = \Union_n \nats^n$ o conjunto de todos
os strings finitos feitos por naturais.
Considere a $f : \kstar \nats \to \nats_{>0}$ definida pela
$$
f (x_0,\dotsc,x_{n-1}) = \Prod_{i=0}^{n-1} p_i^{x_i}
$$
onde $\seqn p n$ é a seqüência dos números primos
($p_0 = 2$, $p_1 = 3$, $p_2 = 5$, \dots).
(1) Explique por que $f$ não é injetora.
(2) Demonstre que $f$ é sobrejetora.
(3) O que acontece se substituir os exponentes $x_i$ por $x_i + 1$?

\solution
\proofpart{(1) $f$ não é injetora}
pois
$$
f(1) = 2 = f(1,0).
$$
\proofpart{(2) $f$ é sobrejetora.}
Seja $y \in \nats_{>0}$.
Pelo teorema fundamental de aritmética~\refn{fundamental_theorem_of_arithmetic}
$y$ pode ser escrito como produtório de primos
$$
y = q_0^{y_i}
$$
\proofpart{(3) Acontece}
que ganha injectividade
(veja o~\ref{encoding_of_finite_sequences} e sua resolução)
e perde sobrejectividade:
nenhuma entrada é mapeada para o $3$, pois o único ímpar
que realmente está no $\range f$ é o $1$ ($f() = 1$ pela definição
do produtório vazio); todos os outros pontos do domínio da $f$
são múltiplos de $2$ pela sua definição.
Observe que tem números pares que faltam também, por exemplo o
$$
10 = 2^1 \ntimes 3^0 \ntimes 5^1.
$$

\endproblem
%%}}}

%%{{{ first_contact_with_initial_and_terminal_objects 
\problem Objetos iniciais e terminais.
\label{first_contact_with_initial_and_terminal_objects}%
(1) Quais conjuntos $S$ (se algum) têm a propriedade seguinte?:
$$
\text{para todo conjunto $A$, existe única função $f:S \to A$.}
$$
(2) Quais conjuntos $T$ (se algum) têm a propriedade seguinte?:
$$
\text{para todo conjunto $A$, existe única função $f:A \to T$.}
$$

\solution
(1) Apenas o conjunto vazio:
a única função que existe de $\emptyset$ para $A$,
é a função vazia.
Se $S \neq \emptyset$ tome $s\in S$ e considere
o conjunto $A = \set{0,1}$.
Já temos duas funções diferentes $f,g : S \to A$:
basta apenas diferenciar elas no $s$.
Tome por exemplo $f = \lam x 0$ e $g = \lam x 1$.
Como $f(s) = 0 \neq 1 = g(s)$, temos $f\neq g$.
(2) Todos os singletons.
Se $T = \emptyset$, tome $A\neq\emptyset$ e observe
que não existe nenhuma função $f : A \to T$.
E se $\card T > 1$, tome $u,v\in T$ com $u\neq v$
e considere o $A = \set 0$.
Já temos duas funções $f,g : A \set T$:
a $f = \lam x u$ e a $g = \lam x v$.
Elas são realmente distintas,
pois $f(0) = u \neq v = g(0)$, e logo $f\neq g$.

\endproblem
%%}}}

%%{{{ epimono_factorization_teaser 
\problem.
\label{epimono_factorization_teaser}%
Sejam $A \toby f B$.
Então existem: injecção $m$, surjecção $e$, e conjunto $C$
tais que o diagrama seguinte comuta:
$$
\cdopt{sep=1cm}
A \ar[rr, "f"]\ar[dr, twoheadrightarrow, "e"'] \| \| B \\
                                                  \| C \ar[ur, rightarrowtail, "m"']
\endcd
$$
Em outras palavras, mostre que qualquer função $f : A \to B$
pode ser ``decomposta'' em
$$
f = m \of e
$$
onde $e$ é uma função sobrejetora e $m$ uma função injetora.

\hint
Para garantir que $e$ é sobrejetora escolher como $C$ 
o próprio $\range(f)$.

\solution
Sejam
$$
\align
C &= \range(f) \\
e &= \lam x {f x} : A \to C \\
m &= \inc : C \incto B
\endalign
$$
Basta demonstrar que $f = m \of e$.
Seja $x \in A$.
Calculamos:
\compute
(m \of e) x
&= m (e x)  \by {def.~$m \of e$}
&= m (f x)  \by {def.~$e$}
&= f x.     \by {def.~$m$}
\endcompute

\endproblem
%%}}}

%%{{{ injto_surfrom_powerset 
\problem.
\label{injto_surfrom_powerset}%
Seja conjunto $A\neq\emptyset$.
Defina funções $f,g$ com os tipos seguintes:
$$
\align
f &: A \injto \pset A \\
g &: \pset A \surto A.
\endalign
$$
Prove que:
(i) a $f$ é injetora;
(ii) a $f$ não é sobrejetora;
(iii) a $g$ é sobrejetora;
(iv) a $g$ não é sobrejetora.
Como eu posso pedir pra tu demonstrar tudo isso (as (ii) e (iv))
sem sequer saber quais são as $f,g$ que tu escolheu definir?
(Essa pergunta não é retórica.)

\hint
Cuidado: sobre o $A$ não podes supor nada mais que $A\neq\emptyset$.

\hint
A parte do problema sobre a $f : A \injto \pset A$ foi resolvida
no~\ref{x_mapsto_singleton_x_properties}.
Falta a parte sobre a $g : \pset \surto A$.

\hint
É para a parte do problema sobre a $g : \pset A \surto A$
que precisas o $A\neq\emptyset$.

\hint
Seja $a_0 \in A$.  Defina a $g : \pset A \to A$ pela
$$
g(X) = \knuthcases{
\dots?\dots, & $\dots?\dots$ \cr
\dots?\dots, & caso contrário.
}
$$
Novamente: cuidado para não supor nada mais que $A\neq\emptyset$
sobre o $A$.  Por exemplo: não sabemos se $A$ tem \emph{mais}
que um elemento (sabemos apenas que tem \emph{pelo menos} um);
não sabemos se os membros dele são ordenados; etc.
Se a gente soubesse que os membros de $A$ são \emph{bem ordenados}
a gente poderia definir o primeiro caso acima pela
$$
g(X) = \knuthcases{
\min X, & se $X \neq \emptyset$ \cr
\dots?\dots, & caso contrário.
}
$$
mas sem a informação que o $A$ é bem ordenado a $g$ não seria
bem-definida.
Por enquanto: um conjunto é chamado \dterm{bem ordenado} sse todo
$\emptyset\subsetneq X \subset A$ possui elemento mínimo.
No~\ref{Wellorderings_and_transfinite_induction}
estudamos conjuntos bem ordenados e suas propriedades.

\hint
Seja $a_0 \in A$.  Defina a $g : \pset A \to A$ pela
$$
g(X) = \knuthcases{
x,   & se $X$ é o singleton $\set{x}$ \cr
a_0, & caso contrário.
}
$$
Falta provar que ela é sobrejetora e que não é injetora.

\solution
A parte do problema sobre a $f : A \injto \pset A$ foi resolvida
no~\ref{x_mapsto_singleton_x_properties}, onde definimos a
$f : A \to \pset A$ pela $f(x) = \set{x}$ e provamos as (i)--(ii).
\endgraf
Fixe $a_0 \in A$ ($A\neq\emptyset$) e defina a $g : \pset A \to A$ pela
$$
g(X) = \knuthcases{
x,   & se $X$ é o singleton $\set{x}$\cr
a_0, & caso contrário.
}
$$
\endgraf
(iii) \proofpart{A $g$ é sobrejetora.}
Seja $y \in A$.  Observe que $g(\set{y}) = y$.
Como $\set{y}\in\pset A$, temos que $g$ é sobrejetora.
\endgraf
(iv) \proofpart{A $g$ não é injetora.}
Observe que $\emptyset, \set{a_0} \in \pset A$ e que $\emptyset \neq \set{a_0}$,
mas mesmo assim $g(\emptyset) = a_0 = g(\set{a_0})$.
Logo, $g$ não é injetora.
\crproofpart{Para responder na pergunta não retórica}
precisamos \emph{demonstrar} que não existe nenhuma função
$A \bijto \pset A$ e nenhuma função $\pset A \bijto A$.
Na verdade basta apenas demonstrar apenas uma das duas afirmações,
pois quando temos uma função bijetora de $A$ para $\pset A$
também temos ``de graça'' uma bijetora de $\pset A$ para $A$:
sua \emph{inversa}, que vamos conhecer logo, na~\ref{Inverse_functions}.
Mas como conseguimos então \emph{demonstrar} que não existe bijecção
entre o $A$ e o $\pset A$?
Isso eu vou te deixar pensar.
Mas te aviso: é algo \emph{muito difícil de pensar}.
(Seria fácil se tivermos que $A$ é finito, mas pode ser que não é.)
Mas dê uma chance nele!
E não se preocupe: no~\ref{Cantors_paradise} estudamos umas
idéias de {\Cantor[teorema]}Cantor; foi ele que se perguntou
sobre isso, e foi ele que deu a resposta mesmo
(teorema de Cantor~\refn{cantor_theorem},
\refn{Cantors_theorem_and_its_consequences}).
As conseqüências do seu teorema são{\dots}
Brutais!
Paciência.

\endproblem
%%}}}

%%{{{ projection_inj_or_surj 
\problem.
\label{projection_inj_or_surj}%
Sejam $A\neq\emptyset$ conjunto, $n\in\nats_{>0}$,
e $I = \setst {i\in\nats} {i < n}$.
Considere a função $\pi : I \times A^n \to A$ definida por
$$
\pi(i, \alpha)
= \pi_i(\alpha)
\qquad\Bigparen{
= \text{o $i$-ésimo membro da tupla $\alpha$}
}
$$
onde consideramos o primeiro membro duma tupla seu
``$0$-ésimo'' membro, etc.
Investigue a injectividade e a sobrejectividade da $\pi$.

\hint
Calcule uns valores primeiro.  Por exemplo,
$$
\xalignat3
\pi (2, \tup{2,3,5,7}) &= 5 &
\pi (0, \tup{2})       &= 2 &
\pi (3, \tup{2,0,0,1}) &= 1
\endxalignat
$$

\solution
\proofpart{Injectividade.}
A injectividade da $\pi$ depende no $n$:
\crcase{Caso $n>1$}, não é:
pois tomando $a\in A$,
$$
\pi(0,\tup{a,\dotsc,a}) = a = \pi(1,\tup{a,\dotsc,a}).
$$
\case{Caso $n=1$}, é:
tomando $w, w' \in I\times A^n$ com $w\neq w'$, temos
que $w = \tup{ 0, \tup{a} }$ e $w' = \tup{ 0, \tup{a'} }$
para alguns $a,a'\in A$.
Agora como $w\neq w'$ concluimos que $a\neq a'$ e logo
$\pi(0,w) \neq \pi(0,w')$, ou seja, $\pi$ é injetora
nesse caso.
\crproofpart{Sobrejectividade.}
A $\pi$ é sobrejetora sim:
pois para qualquer $a\in A$, $\pi(0,\tup{a,\dotsc,a}) = a$.

\endproblem
%%}}}

%%{{{ funion 
\problem união de funções.
\label{funion}%
Sejam $f : A \to C$ e $g : B \to D$.
Queremos definir a $f\union g : A\union B \to C\union D$,
consultando as $f$ e $g$, numa maneira parecida com aquela da
definição de $f\cross g$ (\refn{fcross}).
Uma definição razoável deve fazer o diagrama seguinte comutar:
$$
\cdopt{sep=2cm}
A \ar[d, "f"']\ar[r, hook] \| A\union B \ar[d, dashed, ""] \| B \ar[l,hook']\ar[d, "g"] \\
C \ar[r,hook]              \| C\union D                    \| D \ar[l,hook']
\endcd
$$
Explique quais são as condições necessárias para definir
a $f\union g$, e defina-a.

\solution
Chame as $f$ e $g$ \dterm{compatíveis} sse:
$$
\text{para todo $x\in\dom f \inter \dom g$, $f(x) = g(x)$}.
$$
Agora dadas compatíveis $f : A \to C$ e $g : B \to D$,
definimos a $f \union g : A\union B \to C\union D$ pela
$$
(f \union g)(x) =
\knuthcases{
f(x), & se $x \in A$ \cr
g(x), & se $x \in B$.
}
$$
Equivalentemente, podemos definir a $f\union g$ definindo seu gráfico:
$$
\graph (f\union g) \defeq \graph f \union \graph g.
$$
Observe que nas duas maneiras precisamos a condição de
compatibilidade para a $f\union g$ ser bem-definida.
\crproofalt{Resolução alternativa:}
Usamos a mesma definição mas exigimos que os $A,C$ são disjuntos.
A primeira resolução consegue definir a $f \union g$ em mais casos
que essa, mas no outro lado, essa seria aceitável também; e é mais
simples e ``arrumada''.

\endproblem
%%}}}

%%{{{ prob: succiter_for_dummies 
\problem.
\label{succiter_for_dummies}%
Supondo que teu leitor não sabe o que são as iterações duma função
(\ref{function_iterations}) e que \emph{sequer quer saber},
defina a função $\succ^n$ numa maneira simples.
Demonstre tua afirmação, que a $\succ^n$ (oficial) realmente é igual
à função que tu escreveste para teu leitor.

\hint
Fez o~\ref{succ3_is_plus_3} né?

\hint
Basta provar que para todo $n\in\nats$
$$
\lforall {x\in\nats} {\succ^n(x) = x + n}
$$
e como $\succ^n$ (oficial) foi definida recursivamente,
como tu vai provar isso?

\hint
Indução!

\solution
Seja $n\in\nats$.
A $\succ^n : \nats\to\nats$ é a função definida pela
$$
    \succ^n(x) = x + n.
$$
Basta demonstrar que para todo $n\in\nats$
$$
\lforall {x\in\nats} {\succ^n(x) = x + n}
$$
algo que vou provar por indução no $n$.
\crproofpart{Base.}
Seja $x\in\nats$.
Calculamos:
\compute
\succ^0 (x)
&= \idof\nats (x)   \by {pela def.~da $\succ^0$}
&= x                \by {pela def.~da $1_A$}
&= x + 0.           \by {pelo ensino fundamental}
\endcompute
\crproofpart{Passo indutivo.}
Suponha $k\in\nats$ tal que
$$
\lforall {x\in\nats} {\succ^k(x) = x + k}. \tag{H.I.}
$$
Basta provar que
$$
\lforall {y\in\nats} {\succ^{k+1}(y) = y + (k+1)}.
$$
Seja $y\in\nats$ então.
Calculamos:
\compute
\succ^{k+1}(y)
&= \paren{\succ\of\succ^{k}}(y) \by {pela def.~de $\succ^{k+1}$}
&= \succ\big( \succ^k(y) \big)  \by {pela def.~de $\succ\of \succ^k$}
&= \succ(y + k)                 \by {pela HI com $x := y$}
&= (y + k) + 1                  \by {pela def.~de $\succ$}
&= y + (k + 1).                 \by {pelo ensino fundamental}
\endcompute

\endproblem
%%}}}

\endproblems
%%}}}

%%{{{ Inverse_functions 
\section Funções inversas.
\label{Inverse_functions}%

\blah.
Informalmente, para construir a inversa duma função
pegamos o seu diagrama interno, e viramos todas
as setinhas barradas para a direção oposta.
Vamos estudar essa idéia formalmente agora.

%%{{{ df: finverse 
\definition função inversa.
\label{finverse}%
\tdefined{função}[inversa]%
\sdefined {\finv {\sholed f}} {a função inversa da $f$}%
Seja função bijetora $f : A \bijto B$.
Definimos a função $\finv f : B \to A$ pela
$$
\finv f (y) \defeq \text{aquele $x\in A$ que $x \mapstoby f y$}.
$$
Ou, \emph{equivalentemente}, pela
$$
\finv f (y) = x \defiff f(x) = y.
$$
Com outra notação:
$$
y \mapstoby {\finv f} x \defiff x \mapstoby f y.
$$
Chamamos a $\finv f$ a \dterm{função inversa} da $f$.
%%}}}

%%{{{ remark: human_eyes_are_not_symmetric 
\remark Os olhos humanos não são simétricos.
\label{human_eyes_are_not_symmetric}%
Às vezes a direção em que a gente olha para uma igualdade faz diferença:
$$
\alpha = \beta \iff \beta = \alpha
$$
sim, ou seja, \sq{$=$} é simétrica,
mas nossos olhos humanos conseguem enxergar certas informações melhor na
forma $\alpha = \beta$, e outras na forma $\beta = \alpha$!
(Talvez nossos olhos não são tão simétricos.)
A mesma coisa é sobre relações ``direcionadas'' como por exemplo:
$$
\alpha \leq \beta \iff \beta \geq \alpha
$$
que também são afirmações equivalentes,
mas muitas vezes a gente enxerga uma numa maneira diferente da outra!
\endgraf
Na~\ref{finverse} acima, por exemplo, reescrevendo a igualdade
na outra direção temos:
$$
\finv f (y) = x \defiff y = f(x)
$$
que possivelmente nos permite enxergar a situação numa maneira diferente.
Similarmente, usando a notação das setinhas barradas podemos enxergar
a equivalência assim:
$$
x \mapsfromby {\finv f} y \defiff x \mapstoby f y.
$$
%%}}}

%%{{{ x: finv_is_well_defined 
\exercise A inversa é bem-definida.
\label{finv_is_well_defined}%
Prove que a função $\finv f$ foi bem-definida.
O que precisas provar?

\solution
Pelo menos um tal $x\in A$ existe, pois a $f$ é sobrejetora.
E como $f$ é injetora, existe no máximo um.
Provamos assim a unicidade, algo que nos permite
\emph{definir a função} no jeito que definimos
na~\ref{finverse}.

\endexercise
%%}}}

%%{{{ x: finv_is_bij 
\exercise A inversa é bijetora.
\label{finv_is_bij}%
Prove que quando a função inversa $\finv f$ é definida, ela é bijetora.

\hint
O que exatamente garanta a injectividade da $\finv f$, e o que a sua sobrejectividade?

\hint
Considere:
$$
\align
\text{totalidade da $f$}      &\implies \text{$\finv f$ sobrejetora} \\
\text{determinabilidade da $f$} &\implies \text{$\finv f$ injetora}.
\endalign
$$

\endexercise
%%}}}

%%{{{ x: finv_of_finv 
\exercise Inversa da inversa.
\label{finv_of_finv}%
Prove que se a função inversa $\finv f$ é definida,
então a sua inversa $\finvp{\finv f}$ também é
e temos $\finvp{\finv f} = f$.

\hint
Quando a função inversa é definida?

\hint
Aplique duas vezes a~\ref{finverse} de função inversa para provar
que as duas funções são iguais.

\solution
Pelo~\ref{finv_is_bij} temos que $\finv f$ é bijetora,
então sua inversa $\finvp{\finv f}$ é definida sim
(e pelo~\ref{finv_is_bij} de novo ela é bijetora também).
As $f$ e $\finvp{\finv f}$ têm domínios e codomínios iguais.
Basta verificar que concordam em todo o seu domínio.
Seja $x \in \dom f$ então.
Calculamos
\compute
\finvp{\finv f}(x)    = f(x)
&\iff {\finv f}(f(x)) = x   \by {def.~$\finvp{\finv f}$}
&\iff f(x) = f(x)           \by {def.~$\finv f$}
\endcompute
e a última igualdade é trivialmente válida,
e logo $\finvp{\finv f} = f$.

\endexercise
%%}}}

%%{{{ x: finv_laws_pointful 
\exercise Leis da inversa (com pontos).
\label{finv_laws_pointful}%
Seja $f: A \bijto B$.
Para todo $a\in A$ e todo $b\in B$, temos:
$$
\xxalignat4
\textrm{(L)} && \finv f (f a) &= a &
f (\finv f b) &= b. &&\textrm{(R)}
\endxxalignat
$$
(Esqueça o ``com pontos'' no rótulo desse exercício;
vai fazer sentido depois.)

\solution
Seja $a\in A$ e $b\in B$.
Calculamos:
\compute
\finv f (f(a))
&= \text{aquele $x\in A$ que $f(x) = f(a)$} \\
&= a.          \by {$f$ inj.}
\endcompute
Agora tomando $y\in B$ calculamos a outra numa maneira diferente:
\compute
f(\finv f(b)) = y
&\iff \finv f (b) = \finv f (y) \\
&\iff b = y    \by {$\finv f$ inj.~(\refn{finv_is_bij})}
&\iff \idof B (b) = y.
\endcompute

\endexercise
%%}}}

%%{{{ x: finv_of_id 
\exercise Inversa da identidade.
Para todo conjunto $A$, $\finv {\idof A} = \idof A$.

\solution
Temos $\idof A, \finv{\idof A} : A \bijto A$ então basta
verificar que comportam igualmente.
\crproofalt{Jeito 1.}
Seja $a \in A$ então e calculamos:
\compute
\finv{\idof A} a
&= \text{aquele $v\in A$ que $\idof A v = a$}  \by {def.~$\finv{\idof A}$}
&= a                                           \by {def.~$\idof A$}
&= \idof A a.                                  \by {def.~$\idof A$}
\endcompute
\proofalt{Jeito 2.}
Sejam $a,a'\in A$.
Calculamos:
\compute
\finv{\idof A} a = v
&\iff a = \idof A v     \by {def.~$\finv{\idof A}$}
&\iff a = v             \by {def.~$\idof A$}
&\iff \idof A a = v.    \by {def.~$\idof A$}
\endcompute

\endexercise
%%}}}

%%{{{ finv_of_fcompose_error 
\note Inversa da composição: um erro.
\label{finv_of_fcompose_error}%
Queremos descrever a inversa duma composição de bijecções em termos
das inversas dessas bijecções.
Ou seja, temos
Um erro comum é afirmar que $\finvp{g\of f} = \finv g \of \finv f$.
Pense em funções como ``processos'' e na $g\of f$ como o processo
<<faça $f$ e depois faça $g$>>.
Como exemplo, considere $f$ o <<botar cueca>> e $g$ o
<<botar shorts>>.
Logo $g\of f$ é o processo <<botar cueca e depois botar shorts>>.
Assim, qual processo seria o $\finv g \of \finv f$?
Se eu quero desfazer o $g\of f$ mesmo, o que preciso fazer?
%%}}}

%%{{{ x: finv_of_fcompose 
\exercise Inversa da composição.
\label{finv_of_fcompose}%
Sejam
$
\cd
A \ar[r, tail, two heads, "f"] \| B \ar[r, tail, two heads, "g"] \| C
\endcd
$\!.
Descreva a $\finvp{g\of f}$ em termos das $\finv f$ e $\finv g$ e prove
tua afirmação.

\hint
$\finvp{g\of f} = \finv f \of \finv g$.

\hint
Para provar a $\finvp{g\of f} = \finv f \of \finv g$,
tome $x\in C$ e $z\in A$ e mostre a equivalência
$$
\finvp{g\of f}(x) = z
\iff
\paren{\finv f \of \finv g}(x) = z.
$$

\hint
Calcule cada lado separadamente:
\compute
\finvp{g\of f}(x) = z
&\iff (g\of f)(z) = x  \by {def.~$\finvp{g\of f}$}
&\dotsiff \dots \\
\paren{\finv f \of \finv g}(x) = z
&\iff \finv f \funparen{\finv g (x)} = z  \by {def.~$\finv f \of \finv g$}
&\dotsiff \dots
\endcompute

\solution
Vamos provar que
$$
\finvp{g\of f} = \finv f \of \finv g.
$$
Tome $x \in C$ e $z \in A$.  Basta provar que
$$
\finvp{g\of f}(x) = z
\iff
\paren{\finv f \of \finv g}(x) = z.
$$
pois isso quis dizer que as duas funções concordam em todo o seu domínio.
Calculamos:
\compute
\finvp{g\of f}(x) = z
&\iff x = (g\of f)(z)                     \by {def.~$\finvp{g\of f}$}
&\iff x = g(f(z))                         \by {def.~$g\of f$}
&\iff \finv g (x) = f(z)                  \by {def.~$\finv g$}
&\iff \finv f \funparen{\finv g (x)} = z  \by {def.~$\finv f$}
&\iff \paren{\finv f \of \finv g}(x) = z. \by {def.~$\finv f \of \finv g$}
\endcompute

\endexercise
%%}}}

%%{{{ x: finv_atleastonelaw_if_f_bij 
\exercise Basta uma lei.
\label{finv_atleastonelaw_if_f_bij}%
Seja $f : A \bijto B$.
Se uma $f' : B \to A$ satisfaz pelo menos uma das duas leis
do~\ref{finv_laws_pointful}, então $f'$ é a própria $\finv f$.

\solution
Sejam $b\in B$, $a\in A$.
Caso que $f'$ satisfaz a (L)
calculamos:
\compute
\finv f b = a
&\iff b = f a               \by {def.~$\finv f$}
&\iff f' b = f' (f a)       \by {$f'$ inj.}
&\iff f' b = (f' f) \fa a   \by {def.~$(f'f)$}
&\iff f' b = a.             \by {(L) da $f'$ (com $w \asseq a$)}
\intertext{E caso que $f'$ satisfaz a (R):}
f' b = a
&\iff f (f' b) = f a        \by {$f$ inj.}
&\iff (f f') \fa b = f a    \by {def.~$(f f')$}
&\iff b = f a               \by {(R) da $f'$ (com $w \asseq b$)}
&\iff \finv f b = a.        \by {def.~$\finv f$}
\endcompute

\endexercise
%%}}}

%%{{{ Boring, innit? 
\blah É chato, né?.
Mergulhar nos domínios e codomínios das funções, mexendo com os
bichinhos que tem lá, tanto para enunciar teoremas quanto para
demonstrá-los espero que foi uma experiência não exatamente divertida.
Logo vamos ver uma outra maneira para enunciar e demonstrar
essas propriedades, ``de longe'', sem olhar os detalhes internos.
%%}}}

\endsection
%%}}}

%%{{{ An_epic_trip 
\section Uma viagem épica.
\label{An_epic_trip}%

%%{{{ mathematical_OCD: Something irritating 
\note Algo irritante.
\label{mathematical_OCD}%
{\ii{TOC}[matemático]}%
Seria bom desenvolver um certo ``TOC'' matemático:
ganhar certas frescuras matemáticas úteis, e sentir
\emph{matematicamente irritados} quando sentir algo bizarro.
E algo bizarro já aconteceu recentemente:
tá bem ali na~\ref{jective_function} de injetora e sobrejetora:
$$
\matrix
\format
\l & \;\c\; & \l\, & \l\, & \l \\
\text{$f$ injetora}    & \defiff & \pforall {x \in A} & \pforall {y \in A} & \bracket{\;f\fa x = f \fa y \implies x = y\;}; \\
\text{$f$ sobrejetora} & \defiff & \pforall {b \in B} & \pexists {a \in A} & \bracket{\;f \fa a = b\;}.
\endmatrix
$$
Consegues ver algo irritante?
\spoiler.
Injectividade e sobrejectividade têm cara de conceitos que
deveriam ser intimamente relacionados.
Simétricos, duais, espelhados, sei lá o que,
algo que com certeza não parece olhando para suas definições!
A primeira começa com dois quantificadores do mesmo tipo,
universais, ambos no domínio, e acaba com uma implicação;
a segunda começa com dois quantificadores de tipos diferentes:
um existencial, agora no codomínio, o outro universal no domínio,
e acaba com uma igualdade!
\emph{Nada a ver}, pelo jeito!%
\footnote{%
Existe uma justificativa muito boa sobre isso:
na própria idéia do que é uma função, não tratamos
seu domínio e seu codomínio numa maneira parecida:
a função foi ``total no seu domínio'' mas não no seu
codomínio, e foi ``univoca'', ou seja, do mesmo ponto
do seu domínio não podem sair duas setinhas (barrada),
mas estamos de boas se nuns pontos do seu codomínio
chegam mais que uma setinhas.
Esqueça esse ponto de vista para viajar comigo aqui;
prometo que no~\ref{Relations} tu pode voltar
a repensar nesse assunto.
}
Isso deveria te dar pelo menos uns arrepeios;
e no pior---melhor?---dos casos te deixar acordado até encontrar
definições desses dois conceitos que realmente são intimamente
relacionadas.
Agora calma---podes dormir tranqüilamente---pois vamos chegar
nessa satisfacção logo.
%%}}}

%%{{{ let_us_trip_1 
\note Bora viajar.
\label{let_us_trip_1}%
Começamos na~\ref{Composition_laws} procurar conexões entre
a composição e a multiplicação e realmente achamos muitas
similaridades e essa influência já se tornou muito útil.
Vamos começar dando uma olhada novamente numa propriedade
de funções, a injectividade.
Pela sua definição, $f$ é injetora exatamente quando
$$
\text{para todo $x,y$,} \quad f\fa x = f\fa y \implies x=y.
$$
Isso até parece pouco com cancelamento:
$$
\cancelspc f x = \cancelspc f y \implies x = y.
$$
Queremos investigar se e quando podemos cancelar uma
função quando operada com composições:
$$
\align
f \of g = f \of h &\askimplies g = h
\intertext{e como nossa operação já sabemos que não
é comutativa precisamos tratar essa questões similares separadamente:}
g \of f = h \of f &\askimplies g = h\\
g \of f = f \of h &\askimplies g = h.
\endalign
$$
Vamos voltar no
$$
\cancelspc f x = \cancelspc f y \implies x = y
$$
mas agora vamos fingir que os $f,x,y$ são números reais!
E logo as expressões $f x$ e $f y$ denotam apenas os produtos
$f\ntimes x$ e $f\ntimes y$.
Bem.
O que podemos concluir sabendo que
$$
f \fa x = f \fa y ?
$$
Caso $f\neq0$, podemos cancelá-lo:
$$
\cancelspc f x = \cancelspc f y
$$
chegando assim na
$$
x = y.
$$
Caso $f=0$, a $f$ não é cancelável.%
\footnote{Por que não?
Se tu aprendeu numa maneira religiosa algum poeminha
do tipo ``não cancelarás $0$ nas multiplicações'', esqueça;
ninguém se importa com que teu padre falou.
A gente vai voltar nessa questão mais tarde
(\ref{Algebraic_structures} (\refn{Rings});
\ref{Real_numbers}).}
\endgraf
Parece ótimo: exatamente o tipo da coisa que estamos procurando!
Será que podemos já trazer essa sabedoria da $\ntimes$
nos números para a $\of$ nas funções?
O que seria nosso ``zero'' nas funções?
Uma resposta boba seria <<a função constante 0>>.
Com certeza para funções numéricas
a função constante $\kon 0 = \lam x 0$ não é nada de cancelável.
(Veja~\ref{kon_is_not_cancellable_in_general}.)
Por que boba então?
Pois dizendo isso já perdemos a generalidade:
\emph{queremos algo descrevível para qualquer
função e não algo que serve apenas para funções cujos codomínios
tem o $0$ como membro.}
Mas peraí.
Talvez não é o ``ser zero'' que é importante nesse ponto de
cancelamento!
Realmente: por que esse ``se $f \neq 0$'' acima?
<<É que se $f=0$ então $f$ não é cancelável.>>
Mas essa resposta não é exatamente luminosa.
O que nos permite cancelar números na multiplicação?
Vamos tentar algo mais cuidadoso e formal:%
\footnote{Mesmo sendo cedo neste momento para essa abordagem
creio que o leitor vai conseguir acompanhar a idéia.
Estudando algebra abstrata nos capítulos~\refn{Group_theory}
e~\refn{Algebraic_structures} tudo isso vai aparecer
bem tranqüilo e natural.  Prometo.}
\compute
f x = f y
&\implies f^{-1} (f x) = f^{-1} (f y)   \by {multiplicando por $f^{-1}$}
&\implies (f^{-1} f) x = (f^{-1} f) y   \by {pela associatividade da $\ntimes$}
&\implies 1 x = 1 y                     \by {pela def.~da $f^{-1}$}
&\implies x = y.                        \by {pela def.~de $1$}
\endcompute
O único passo duvidoso seria o primeiro:
como sabemos que existe esse inverso?
\emph{Não sabemos.}
Então talvez é isso que estamos procurando!
Talvez
$$
\text{$f$ tem inversa} \iff \text{$f$ é cancelável}!
$$
Para provar essa afirmação precisamos saber
o que ``cancelável'' significa formalmente aqui.
Qual das três implicações que consideramos acima vamos escolher?:
$$
\text{$f$ é cancelável}
\askiff
\leftbrace{
\aligned
f \of g = f \of h &\implies g = h \\
g \of f = h \of f &\implies g = h \\
g \of f = f \of h &\implies g = h.
\endaligned
}
$$
A $\ntimes$ nos números, sendo uma operação \emph{comutativa},
não consegue diferenciar entre essas afirmações.
Ou seja, por causa da riquesa das leis que temos
na multiplicação nos números, certas distinções desaparecem,
``se desabam''---algo que podemos pensar como pobresa também!
E vice versa: com menos leis ganhamos mais distinções---riquesa!
No mundo dos reais, um certo $x$ ou tem inverso
ou não.  De qual lado inverso?  Não faz sentido perguntar
isso nos números pois o lado não importa.
Quando importa, não vamos falar apenas sobre ``inverso'' mas sim sobre
\dterm{inverso esquerdo} e \dterm{inverso direito}.
Similarmente, nos números só tem uma $1$ para considerar;
nas funções, cada conjunto $A$ chega com sua própria $1_A$!
\emph{O mundo das funções é suficientemente rico para enxergar
essas noções inenxergáveis no mundo dos números!}
%%}}}

%%{{{ x: kon_is_not_cancellable_in_general 
\exercise.
\label{kon_is_not_cancellable_in_general}%
Demonstre que a função constante $\kon 0 : \reals \to \reals$
em geral não é cancelável nem pela direita nem pela esquerda.

\solution
\proofpart{Incancelável pela esquerda.}
Tome por exemplo as
$$
\cdopt{sep=2cm}
\reals \ar[r, shift left, "\sin"]\ar[r, shift right, "\cos"']
\| \reals \ar[r, "\kon 0"]
\| \reals
\endcd
$$
que obviamente comuta; ou seja $\kon 0 \sin = \kon 0 \cos (= \kon 0)$)
mas mesmo assim $\sin \neq \cos$.
\crproofpart{Incancelável pela direita.}
Tome por exemplo as
$$
\cdopt{sep=2cm}
\reals \ar[r, "\kon 0"]
\|\reals \ar[r, shift left, "\sin"]\ar[r, shift right, "\id"']
\|\reals
\endcd
$$
que obviamente comuta; ou seja $\sin \kon 0 = \id \kon 0 (= \kon 0)$)
mas mesmo assim $\sin \neq \id$.

\endexercise
%%}}}

%%{{{ let_us_trip_2 
\note.
\label{let_us_trip_2}%
Olhe de novo na implicação que tem na definição da injetora:
$$
f \fa x = f \fa y \implies x = y. \tag{L-canc}
$$
Ela lembra muito do que acabamos de demonstrar, mas nosso objectivo
foi investigar a composição $\of$ usando a multiplicação $\ntimes$.
Quando escrevi a (L-canc) em números, a juxtaposição denotou
a $\ntimes$ mesmo; mas na definição da injetora que temos,
a juxtaposição não denota a $\of$, mas a $\apply$!
Então vamos ver o que acontece se mudar para a $\of$, obviamente
tomando cuidado para usar objetos dos certos tipos:
$$
f \of g = f \of h \askimplies g = h
$$
que escrevemos por juxtaposição sem confusão:
$$
f \of g = f \of h \askimplies g = h.
$$
Vamos tentar imitar a demonstração anterior:
\compute
f g = f h
&\implies {\finv f} (f g) = {\finv f} (f h) \by {??}
&\implies ({\finv f} f) g = ({\finv f} f) h \by {(F-Ass)}
&\implies \idoneof A g = \idoneof A h       \by {(F-Inv)}
&\implies g = h                             \by {(F-Id)}
\endcompute
O que precisamos no \sqq{??} acima?
%%}}}
\spoiler.

%%{{{ let_us_trip_3 
\note.
\label{let_us_trip_3}%
Uma resposta ``de preguiça'' seria <<preciso $f$ bijetora>>.
Claro que isso é \emph{suficiente}, mas é \emph{necessário}
também?  Começamos pensanso que <<$f$ injetora>> é algo que
corresponde nesse cancelamento aí, então será que basta só
isso?
Mas parece que precisei a existência de $\finv f$,
ou seja, precisamos que $f$ seja invertível.  Ou não?
Lembre que o inverso $\finv f$ de $f$ é um objeto que
satisfaz \emph{ambas} as
$$
\xxalignat3
&\text{LInv} & \finv f f &= \idoneof A;  & f \finv f &= \idoneof B & \text{RInv}
\endxxalignat
$$
mas, olhando de novo para nosso caminho, a gente precisou
apenas a (LInv).
Então não necessitamos mesmo que $f$ tem um inverso $\finv f$;
basta ter um inverso-esquerdo $\labL f$ e a prova rola:
\compute
f g = f h
&\implies {\labL f} (f g) = {\labL f} (f h) \by {$f$ é L-invertível}
&\implies ({\labL f} f) g = ({\labL f} f) h \by {(F-Ass)}
&\implies \idoneof A g = \idoneof A h       \by {(F-LInv)}
&\implies g = h                             \by {(F-Id)}
\endcompute
Já temos descoberto umas idéias interessantes:
L-cancelável e L-invertível, e obviamente temos as noções
laterais de R-cancelável e R-invertível.
%%}}}

\blah.
Influenciados por toda essa viagem, podemos chegar nuns resultados
muito importantes e interessantes sobre as ``jectividades''
(`in-' e `sobre-'); as invertibilidades laterais;
e as cancelabilidades laterais das funções.

%%{{{ Q: guess the theory that's about to come 
\question.
Quais resultados tu acha que vamos provar?
Consegues prová-los?
%%}}}
\spoiler.

%%{{{ A 
\blah Resposta.
Pare ser o seguinte:
$$
\matrix
\format
\l & \c & \l & \c & \l & \c & \l \\
\text{$f$ mono} & \defiff & \text{$f$ L-cancelável} & \askiff & \text{$f$ L-invertível} & \askiff & \text{$f$ injetora} \\
\text{$f$ epí}  & \defiff & \text{$f$ R-cancelável} & \askiff & \text{$f$ R-invertível} & \askiff & \text{$f$ sobrejetora}.
\endmatrix
$$
Sim, tem esses nomes ``chique'' mesmo:
%%}}}

%%{{{ df: mono_epi_functions
\definition mono, epi.
\label{mono_epi_functions}%
\tdefined{função}[mono]%
\tdefined{função}[epi]%
\iisee{mônica}{função, mono}%
\iisee{épica}{função, epí}%
Seja $f : A \to B$.
Dizemos que $f$ é uma função \dterm{mônica}
(ou simplesmente que $f$ é uma \dterm{mono}) sse $f$ é $\of$-cancelável pela esquerda.
Dizemos que $f$ é uma função \dterm{épica}
(ou simplesmente que $f$ é uma \dterm{epí}\/) sse $f$ é $\of$-cancelável pela direita.
%%}}}

\blah.
Bora investigar então!

%%{{{ thm: injection_iff_mono 
\theorem.
\label{injection_iff_mono}%
Sejam $B \toby f C$.
A $f$ é injetora sse ela é \dterm{$\of$-cancelável pela esquerda:}
$$
f\of g = f \of h \implies g = h
$$
para todas as $g,h$ tais que as composições acima são definidas.
\sketch.
A direção {\lrdir} é o~\ref{injection_iff_mono_lrproof}.
Para a direção {\rldir}, tome $b,b'\in B$ tais que $f(b)=f(b')$.
Basta demonstrar que $b=b'$.
Tome $A\asseq\set{0}$ e defina $g,h$ no diagrama
$$
\cdopt{sep=2cm}
\set{0}   \ar[r, shift left, "g"]\ar[r, shift right, "h"'] \| B \ar[r, "f"]  \|  C
\endcd
$$
em tal maneira que o diagrama comuta (tem que definir mesmo as $g,h$).
Usamos agora a hipótese para concluir que $b=b'$.
\qes
\proof.
\proofpart{\lrdir:} \ref{injection_iff_mono_lrproof}.
\crproofpart{\rldir:}
Suponha $b,b' \in B$ tais que $f(b) = f(b')$.
Basta mostrar que $b = b'$.
Temos então o diagrama interno seguinte:
$$
\tikzpicture
\tikzi mono_implies_inj0;
\endtikzpicture
$$
Seja $A = \set{0}$ e defina as $g,h$ no diagrama
$$
\cdopt{sep=2cm}
\set{0}   \ar[r, shift left, "g"]\ar[r, shift right, "h"'] \| B \ar[r, "f"]  \|  C
\endcd
$$
como as funções constantes definidas pelas 
$$
g(0) = b
\qqtext{e}
h(0) = b'.
$$
Então agora estamos com o diagrama interno assim:
$$
\tikzpicture
\tikzi mono_implies_inj1;
\endtikzpicture
$$
Observe que como
$$
\align
(f\of g)(0) &= f(g(0)) = f(b) \\
(f\of h)(0) &= f(h(0)) = f(b')
\endalign
$$
e $f(b) = f(b')$, temos
$f\of g = f\of h$ e agora usamos a hipótese para ganhar $g = h$.
Logo as $g,h$ concordam no $0$, ou seja, $b = b'$.
\qed
%%}}}

%%{{{ x: injection_iff_mono_lrproof 
\exercise.
\label{injection_iff_mono_lrproof}%
Prove a direção {\lrdir} do~\ref{injection_iff_mono}.

\solution
Suponha então que $f\of g = f\of h$.
Vamos mostrar que $g = h$.
Seja $x \in A$.
Pela hipótese,
$$
(f\of g)(x) = (f\of h)(x)
$$
logo $f(g(x)) = f(h(x))$
e como $f$ injetora, chegamos no desejado $g(x) = h(x)$.

\endexercise
%%}}}

%%{{{ thm: surjection_iff_epic 
\theorem.
\label{surjection_iff_epic}%
Sejam $B \toby f C$.
A $f$ é sobrejetora sse ela é \dterm{$\of$-cancelável pela direita:}
$$
g\of f = h\of f \implies g = h
$$
para todas as $g,h$ tais que as composições acima são definidas.
Digamos então que $f$ é \dterm{$\of$-cancelável pela direita}.
\sketch.
A direção {\lrdir} é o~\ref{surjection_iff_epic_lrproof}.
Para a direção {\rldir}, tomamos $c \in C$ e procuramos achar
$b\in B$ tal que $f(b) = c$.
Defina o $D$ (cuidado: aqui não ajuda tomar $D=\set{0}$)
e as $g,h$ no diagrama
$$
\cdopt{sep=2cm}
B  \ar[r, "f"] \|  C   \ar[r, shift left, "g"]\ar[r, shift right, "h"'] \| D
\endcd
$$
em tal maneira que $g\neq h$,
mas mesmo assim \emph{concordam em todo o $C$ exceto no ponto $c$}.
Usando a contrapositiva da hipótese ganhamos
$g\of f \neq h\of f$, mas isso só pode acontecer se a $f$ mandou pelo
menos um ponto do domínio dela para o $c$.
\qes
\proof.
\lrdir:
\ref{surjection_iff_epic_lrproof}.
\endgraf
\rldir:
Suponha $c\in C$.
Procuramos $b\in B$ tal que $f(b) = c$.
Começamos então com o diagrama interno seguinte:
$$
\tikzpicture
\tikzi epic_implies_surj0;
\endtikzpicture
$$
Seja $D=\set{0,1}$ e defina as funções $g,h:C\to D$ pelas
$$
g(y) = 0
\qqtext{e}
h(y) = \knuthcases{
1, &se $y = c$; \cr
0, &se $y \neq c$.
}
$$
Logo $g(c) \neq h(c)$, mas $g(y)=h(y)$ para todo $y\neq c$.
Agora estamos assim:
$$
\tikzpicture
\tikzi epic_implies_surj1;
\endtikzpicture
$$
Como $g\neq h$ então, pela hipótese concluimos que $g\of f \neq h\of f$, ou seja,
as $g\of f$ e $h\of f$ discordam em pelo menos um membro de $B$,
e seja $b$ um tal membro:
$$
(g\of f)(b) \neq (h\of f)(b).
$$
Logo
$$
g(f(b)) \neq h(f(b)),
$$
ou seja, $g$ e $h$ discordam no $f(b)$.
Mas $g$ e $h$ discordam apenas no $c$; ou seja,
$f(b) = c$ como desejamos.
\qed
%%}}}

%%{{{ x: surjection_iff_epic_lrproof 
\exercise.
\label{surjection_iff_epic_lrproof}%
Prove a direção {\lrdir} do~\ref{surjection_iff_epic}.

\solution
Suponha que $g\of f = h\of f$.  Vamos mostrar que $g = h$.
Seja $c\in C$.
Logo existe $b\in B$ tal que $f(b) = c$.
Como
$$
(g\of f)(b) = (h\of f)(b)
$$
temos $g(f(b)) = h(f(b))$; e, pela escolha de $b$, $g(c) = h(c)$.
Logo $g = h$.

\endexercise
%%}}}

%%{{{ x: mono_epi_commutative_diagrams 
\exercise Mono e epí com diagramas comutativos.
\label{mono_epi_commutative_diagrams}%
Descreva as propriedades das definições de mono e
epi~(\refn{mono_epi_functions}) usando diagramas comutativos.

\solution
\proofpart{A função $f$ é mônica sse} em todo diagrama comutativo da forma
$$
\cdopt{sep=2cm}
A   \ar[r, shift left, "g"]\ar[r, shift right, "h"'] \| B \ar[r, "f"]  \|  C
\endcd
$$
temos $g=h$.
\crproofpart{A função $f$ é épica sse} em todo diagrama comutativo da forma
$$
\cdopt{sep=2cm}
B  \ar[r, "f"] \|  C   \ar[r, shift left, "g"]\ar[r, shift right, "h"'] \| D
\endcd
$$
temos $g=h$.

\endexercise
%%}}}

%%{{{ df: isomorphic_sets 
\definition conjuntos isómorfos.
\label{isomorphic_sets}%
\tdefined{isomorfismo}[de conjuntos]%
\sdefined {\sholed A \iso \sholed B} {os conjuntos $A,B$ são isómorfos}%
\sdefined {\sholed f : \sholed A \isoto \sholed B} {$f$ é um isomorfismo do $A$ para o $B$}%
\sdefined {\sholed f : \sholed A \iso \sholed B} {$f : A \isoto B$ (notação alternativa)}%
Sejam $A,B$ conjuntos.
Chamamos os $A,B$ \dterm{conjuntos isómorfos} (ou \dterm{isomórficos})
sse existe bijecção $f : A \bijto B$.
Nesse caso chamamos a $f$ um \dterm{isomorfismo de conjuntos}.
Escrevemos $A \iso B$, e também
$f : A \iso B$ ou $f : A \isomorphismto B$ para denotar que
$f$ é um isomorfismo do conjunto $A$ para o conjunto $B$.
%%}}}

%%{{{ remark: etymology_of_isomorphic 
\remark etimologia.
\label{etymology_of_isomorphic}%
As palavras vêm do grego \emph{ίσο}
que significa ``igual'' e \emph{μορφή} que significa ``forma''.
Isómorfos então são aqueles que têm a mesma forma; ``a mesma cara''.
Mas o que significa forma, cara?
Depende do contexto!
Aqui nos conjuntos, podemos pensar que $A\iso B$ quis dizer
que os $A$ e $B$ só podem variar nos \emph{nomes} usados para
seus membros e em nada mais: um isomorfismo seria um renomeamento,
uma tradução \emph{fiel} de $A$ para $B$.  Podemos considerar
então o $B$ como uma \emph{cópia} do $A$ onde apenas re-rotulámos
seus membros.
Começando no~\ref{Group_theory} vamos estudar tipos de coisas
onde sua forma é bem mais rica que isso, e lá ``isómorfos'' vai
acabar sendo uma noção bem mais forte.
%%}}}

\blah.
Já tivemos definido os conceitos de inversa e de identidade
antes de fazer essa viagem que fizemos aqui.
Mas com essa experiência podemos voltar e repensar
em mais motivações e influências para chegar nesses
conceitos, e mais provas para demonstrar nossos
teoremas.
Pode viajar a vontade!
Graças a tudo isso, já podemos dormir tranqüilamente
pois encontramos finalmente umas definições para satisfazer
nossas frescuras.

\endsection
%%}}}

%%{{{ Functions_pointfree_style 
\section Funções estilo pointfree---``de fora''.
\label{Functions_pointfree_style}%

%%{{{ Defining concepts 
\note Definindo conceitos.
%%}}}

\TODO Elaborar.

%%{{{ function_laws 
\note Leis de funções (com equações).
\label{function_laws}%
As configurações na esquerda implicam as identidades na direita:
$$
\align
A \toby f B \toby g C \toby h D
& \;\;\implies\;\;
(h \of g) \of f = h \of (g \of f)
\tag{F-Ass}\\
A \toby f B
& \;\;\implies\;\;
\leftbrace{
\aligned
f \of \idof A &= f \\
\idof B \of f &= f
\endaligned
}
\tag{F-Id} \\
A \bijtoby f B
& \;\;\implies\;\;
\leftbrace{
\aligned
\finv f \of f &= \idof A \\
f \of \finv f &= \idof B
\endaligned
}
\tag{F-Inv}
\endalign
$$
%%}}}

%%{{{ x: cd_finv_laws 
\exercise.
\label{cd_finv_laws}%
Como expressar as leis da inversa (F-Inv)
usando apenas a comutatividade dum diagrama?

\hint
A forma do diagrama parece com o diagrama das
leis de identidade (\ref{cd_id_laws}).

\solution
Assim:
$$
\cdopt{sep=2cm}
A   \ar[dr, "\id"']\ar[r, "f"] \| B \ar[d, "\finv f"]  \ar[dr, "\id"]   \\
                               \| A \ar[r, "f"'] \| B
\endcd
$$

\endexercise
%%}}}

%%{{{ Defining functions 
\note Definindo funções.
%%}}}

\TODO Elaborar.

%%{{{ eg: two_x_plus_one 
\example.
\label{two_x_plus_one}%
Defina a função $f = \lam x {2x+1} : \nats\to\nats$ diretamente como
composição de funções sem usar $\lambda$-notação.
Desenha o diagrama externo da configuração e confirme tua resolução.
\solution
Temos as funções
$$
\cdopt{sep=1.666cm}
\nats
\ar[r, "\dsize\diag"]   \| \nats\cross\nats
\ar[r, "\dsize\ntimes"] \| \nats
\ar[r, "\dsize\succ"]   \| \nats.
\endcd
$$
Assim defino
$$
f = \paren{{\succ} \of \mathord{\nplus} \of {\diagdom\nats}} : \nats \to \nats
$$
e tomando um $x\in\nats$ calculo:
\compute
f(x)
&= \paren{\succ \of \mathord{\nplus} \of \diag} (x) \by {def.~$f$}
&= \succ(\mathord{\nplus}(\diag(x)))                \by {def.~$\of$}
&= \succ(\mathord{\nplus}(x,x))                     \by {def.~$\diag$}
&= \succ(2x)                                        \\
&= 2x+1                                             \by {def.~$\succ$}
\endcompute
confirmando assim que minha definição foi correta.
\endexample
%%}}}

%%{{{ x: two_x_squared_pointfree 
\exercise.
\label{two_x_squared_pointfree}%
Faça a mesma coisa para a função $f = \lam x {2x^2} : \nats\to\nats$.

\solution
Temos as funções
$$
\cd
\nats
\ar[r, "\diag"]   \| \nats\cross\nats
\ar[r, "\ntimes"] \| \nats
\ar[r, "\diag"]   \| \nats\cross\nats
\ar[r, "+"]       \| \nats.
\endcd
$$
Assim defino
$$
f = \paren{{+} \of \diagdom\nats \of {\ntimes} \of \diagdom\nats} : \nats \to \nats
$$
e tomando um $x\in\nats$ confirmo:
\compute
f(x)
&= \paren{\mathord{+} \of \diag \of \mathord{\ntimes} \of \diag} (x) \by {def.~$f$}
&= \mathord{+}(\diag(\mathord{\ntimes}(\diag(x))))                   \by {def.~$\of$}
&= \mathord{+}(\diag(\mathord{\ntimes}(x,x)))                        \by {def.~$\diag$}
&= \mathord{+}(\diag(x^2))                                           \\
&= \mathord{+}(x^2,x^2)                                              \by {def.~$\diag$}
&= x^2 + x^2                                                         \\
&= 2x^2.
\endcompute

\endexercise
%%}}}

%%{{{ df: retractions_sections 
\definition Retracções, secções.
\label{retractions_sections}%
\label{retraction}%
\tdefined{função}[retracção]%
\tdefined{função}[secção]%
\tdefined{função}[inversa esquerda]%
\tdefined{função}[inversa direita]%
Seja $f : A \to B$.
Se $r : B \to A$ satisfaz a
$$
r \of f = \idof A
$$
dizemos que $r$ é uma \dterm{retracção} ou uma
\dterm{$\of$-inversa esquerda} da $f$.
Se $s : B \to A$ satisfaz a
$$
f \of s = \idof B
$$
dizemos que $s$ é uma \dterm{secção} ou uma
\dterm{$\of$-inversa direita} da $f$.
Observe que no primeiro caso, $f$ é uma secção da $r$;
e no segundo caso $f$ é uma retracção da $s$.
%%}}}

\blah.
Ganhamos imediatamente dois corolários fáceis dos teoremas
\refn{injection_iff_mono}--\refn{surjection_iff_epic}.

%%{{{ cor: retraction_implies_injection 
\corollary.
\label{retraction_implies_injection}%
Se $f : A \to B$ tem retracção, então $f$ é injetora.
\proof.
Seja $r$ uma retracção da $f$.
Temos
$$
f \of g = f \of h
\implies r \of f \of g = r \of f \of h
\implies \idof A \of g = \idof A \of h
\implies g = h
$$
e logo $f$ é injetora pelo~\ref{injection_iff_mono}.
\qed
%%}}}

%%{{{ cor: section_implies_surjection 
\corollary.
\label{section_implies_surjection}%
Se $f : A \to B$ tem secção, então $f$ é sobrejetora.
\proof.
Seja $s$ uma secção da $f$.
Temos
$$
g \of f = h \of f
\implies g \of f \of s = h \of f \of s
\implies g \of \idof B = h \of \idof B
\implies g = h
$$
e logo $f$ é sobrejetora pelo~\ref{surjection_iff_epic}.
\qed
%%}}}

%%{{{ x: retraction_implies_injection_elementary_proof 
\exercise.
\label{retraction_implies_injection_elementary_proof}%
Prove o~\ref{retraction_implies_injection} elementariamente
(sem o~\refn{injection_iff_mono}).

\solution
Suponha que $f : A \to B$ e que $r : B \to A$ é uma retracção da $f$.
Tome $x, x' \in A$ tais que $f(x) = f(x')$.
Logo $r(f(x)) = r(f(x'))$.
Logo $(r\of f)(x) = (r\of f)(x')$.
Como $r$ é retracção, temos $\idof A(x) = \idof A(x')$,
ou seja, $x = x'$ e $f$ é injetora.

\endexercise
%%}}}

%%{{{ x: section_implies_surjection_elementary_proof 
\exercise.
\label{section_implies_surjection_elementary_proof}%
Prove o~\ref{section_implies_surjection} elementariamente
(sem o~\refn{surjection_iff_epic}).

\solution
Suponha que $f : A \to B$ e que $s : B \to A$ é uma secção da $f$.
Tome $b \in B$.
Logo $s(b) \in A$, e como $s$ secção, temos $f(s(b)) = b$, ou seja
a $f$ é sobrejetora pois mapeia $s(b) \mapstoby f b$.

\endexercise
%%}}}

\TODO Como chegar na definição alternativa.
% Exceto um detalhe que ainda falta verificar:

%%{{{ x: finv_altdef_missing_detail 
\exercise.
\label{finv_altdef_missing_detail}%
O que mais falta demonstrar?
Apenas enuncie o que é, sem demonstrar.

\hint
A $\finv f$ foi definida apenas quando $f$ é bijetora.

\endexercise
%%}}}

%%{{{ thm: finv_atleastonelaw_if_f_bij_pointless 
\theorem Basta uma lei: agora sem pontos.
\label{finv_atleastonelaw_if_f_bij_pointless}%
Seja $f : A \bijto B$.
Se uma $f' : B \to A$ satisfaz pelo menos uma das duas leis da
inversa~(\ref{function_laws}), então $f' = \finv f$.
\proof.
Caso que $f'$ satisfaz a (L):
\compute
f'
&= f' \of \idof B          \by {lei da $\idof B$}
&= f' \of (f \of \finv f)  \by {(R) da $\finv f$}
&= (f' \of f) \of \finv f  \by {assoc.}
&= \idof A \of \finv f     \by {(L) da $f'$}
&= \finv f.                \by {lei da $\idof A$}
\intertext{E caso que $f'$ satisfaz a (R):}
f'
&= \idof A \of f'          \by {lei da $\idof A$}
&= (\finv f \of f) \of f'  \by {(L) da $\finv f$}
&= \finv f \of (f \of f')  \by {assoc.}
&= \finv f \of \idof B     \by {(R) da $f'$}
&= \finv f.                \by {lei da $\idof B$}
\endcompute
\qed
%%}}}

%%{{{ x: retraction_and_section_implies_inverse 
\exercise.
Seja $f : A \to B$ tal que $r,s : A \from B$ são retracção
e secção da $f$ respectivamente.
Podemos concluir a afirmação seguinte?:
$$
\text{$f$ é bijetora}
\quad\mland\quad
\text{$r = \finv f = s$}.
$$
Se sim, prove; se não, refute.

\hint
Primeiramente observe:
$$
\rightbrace{
\aligned
\text{$f$ tem retracção} &\implies   \text{$f$ é injetora} \\
\text{$f$ tem secção}    &\implies   \text{$f$ é sobrejetora}
\endaligned
}
\implies \text{$f$ bijetora}.
$$

\solution
Como $f$ tem retracção, ela é injetora;
e como ela tem secção, ela é sobrejetora;
logo $f$ é bijetora e a $\finv f$ é definida.
Aplicamos então o~\ref{finv_atleastonelaw_if_f_bij} com $f'\asseq r$
e com $f'\asseq s$ e ganhamos:
$$
r = \finv f = s.
$$

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Images, preimages 
\section Imagens, preimagens.
\label{Images_preimages}%

%%{{{ Two important subsets 
\note Dois subconjuntos importantes.
Sejam $A,B$ conjuntos e $f:A \to B$.
$$
\tikzpicture[scale=0.75,node distance=0mm]
\tikzi imgpreimgbase;
\endtikzpicture
$$
Vamos associar, com qualquer subconjunto $X$ de $A$, um certo subconjunto de $B$, que vamos chamá-lo a \emph{imagem} de $X$ através da $f$.
Similarmente, com qualquer subconjunto $Y$ de $B$, vamos associar um certo subconjunto de $A$, que vamos chamá-lo a \emph{preimagem} de $Y$ através da $f$.
Bem informalmente, parece que estamos ``elevando'' a função $f$ do nível ``membros'' para para o nível ``subconjuntos''.
Vamos ver como.
%%}}}

%%{{{ eg: sketches of image and preimage 
\example.
Nas figuras seguintes mostramos com azul o subconjunto com que começamos,
e com vermelho o subconjunto que associamos com ele.
Considere o $X\subset A$ como aparece no desenho abaixo,
e veja qual é o subconjunto $\img f X$ de $B$ que vamos associar com o $X$:
$$
\gathered
\tikzpicture[scale=0.75,node distance=0mm]
\draw [fill=blue!25] (0,-.5) ellipse (0.9cm and 1.6cm);
\tikzi imgpreimgbase;
\node [color=blue] (subset-X) at (-0.7,-2.1) {$X$};
\endtikzpicture
\endgathered
\quad
\leadsto
\quad
\gathered
\tikzpicture[scale=0.75,node distance=0mm]
\draw [fill=blue!25] (0,-.5) ellipse (0.9cm and 1.6cm);
\draw [fill=red!25] (4.9,-0.45) ellipse (0.7cm and 2cm);
\tikzi imgpreimgbase;
\node [color=blue] (subset-X) at (-0.7,-2.1) {$X$};
\node [color=red] (subset-fX) at (5.9,-2.05) {$\img f X$};
\endtikzpicture
\endgathered
$$
Na direção oposta, comece por exemplo com esse $Y\subset B$
e observe qual é o subconjunto $\pre f Y$ de $A$ que queremos associar com o $Y$:
$$
\gathered
\tikzpicture[scale=0.75,node distance=0mm]
\draw [fill=blue!25] (4.9,1.45) ellipse (1.1cm and 1.2cm);
\tikzi imgpreimgbase;
\node [color=blue] (subset-Y) at (5.95,0.4) {$Y$};
\endtikzpicture
\endgathered
\quad
\leadsto
\quad
\gathered
\tikzpicture[scale=0.75,node distance=0mm]
\draw [fill=blue!25] (4.9,1.45) ellipse (1.1cm and 1.2cm);
\draw [fill=red!25]  (0,1.0) ellipse (0.8cm and 2.0cm);
\tikzi imgpreimgbase;
\node [color=blue] (subset-Y)     at (5.95,0.4)  {$Y$};
\node [color=red]  (subset-fpreY) at (-0.9,-1.1) {$\pre f Y$};
\endtikzpicture
\endgathered
$$
\endexample
%%}}}

%%{{{ remark: just a function from A to B is enough 
\remark.
Observe que na discussão acima não supusemos \emph{nada mais} além da
existência de uma função $f$ dum conjunto $A$ para um conjunto $B$.
%%}}}

\question.
Como podemos definir formalmente os conjuntos indicados nos desenhos acima?
\spoiler.

%%{{{ df: img_and_pre 
\definition.
\label{img_and_pre}%
\tdefined{função!imagem}%
\tdefined{função!preimagem}%
\sdefined {\img {\sholed f} {\sholed X}} {a imagem de $X$ através da $f$}%
\sdefined {\pre {\sholed f} {\sholed Y}} {a preimagem de $Y$ através da $f$}%
Seja $f : A \to B$, e sejam subconjuntos $X\subset A$ e $Y\subset B$.
Definimos:
$$
\align
\img f X &\defeq \setst {f(x)} {x \in X}\\
\pre f Y &\defeq \setst {a \in A} {f(a) \in Y}.
\endalign
$$
Lembrando a notação set-builder~(\ref{set_builder}), temos as definições:
$$
\align
y \in \img f X &\defiff \lexists{x\in X} {f(x) = y} \\
x \in \pre f Y &\defiff f(x) \in Y.
\endalign
$$
Chamamos o conjunto $\img f X$ \dterm{imagem} do $X$ através da $f$ ou,
mais curtamente, a $f$-\dterm{imagem} do $X$.  O conjunto $\pre f Y$
é a \dterm{preimagem} do $Y$ através da $f$; ou a $f$-\dterm{preimagem}
do $Y$.
%%}}}

%%{{{ x: type_of_img_f_hole_and_pre_f_hole  
\exercise.
\label{type_of_img_f_hole_and_pre_f_hole}%
Quais os tipos das $\img f {\dhole}$ e $\pre f {\dhole}$?

\solution
$$
\align
\img f {\dhole} &\eqtype \pset X \to \pset Y \\
\pre f {\dhole} &\eqtype \pset Y \to \pset X
\endalign
$$

\endexercise
%%}}}

%%{{{ x: img_and_pre_of_emptyset 
\exercise.
\label{img_and_pre_of_emptyset}%
Seja $f : X \to Y$.
Verifique:
$$
\img f \emptyset = \emptyset
\qqtext{e}
\pre f \emptyset = \emptyset.
$$

\solution
As duas afirmações seguem diretamente pelas definições:
$$
\align
\img f \emptyset &= \setst {f(x)}   {x \in \emptyset}    = \emptyset \\
\pre f \emptyset &= \setst {x\in X} {f(x) \in \emptyset} = \emptyset.
\endalign
$$

\endexercise
%%}}}

%%{{{ remark: range and surjection with f[-] notation 
\remark.
Se $f : A \to B$ então, temos que:
\beginol
\li $\range f = \img f A$;
\li $\img f A = B \iff \text{$f$ é sobrejetora}$.
\endol
As duas afirmações são conseqüências imediatas das definições envolvidas.
%%}}}

%%{{{ x: our_img_notation_is_better 
\exercise.
\label{our_img_notation_is_better}%
Em matemática as vezes aparece a notação $f(X)$ para denotar a imagem do
$X\subset \dom f$ através da função $f$.
Aqui usamos a notação $\img f X$.
\emph{Sem usar o conjunto vazio em lugar nenhum na tua resposta},
dê um exemplo (completo) que mostre que a notação $f(X)$ pode ser problemática
(e logo nossa notação $\img f X$ é melhor).
Explique curtamente.

\hint
Pode acontecer que $X \in A$ e também $X \subset A$?

\hint
Vamos adoptar temporariamente a notação $f(X)$.
Daí, te pergunto: se $f : \nats\to\nats$ é o sucessor,
tem como calcular os seguinte?:
$$
f(5);\qquad
f(8);\qquad
f(\set{1,7});\qquad
f(2\nats);
$$
onde $2\nats \subset \nats$ é o conjunto dos pares naturais.
``Fácil'' tu pensou (certo?), e explicou:
$$
\align
f(5) &\ \text{\dots é o valor da $f$ no $5$, definido pois $5\in\dom f$} \\
\intertext{e similarmente sobre o $f(8)$, mas}
f(\set{1,7}) &\ \text{\dots não pode ser o valor da $f$ no $\set{1,7}$, pois $\set{1,7}\notin\dom f$.}
\endalign
$$
Então $f(\set{1,7})$ só pode ser a $f$-imagem do $\set{1,7}$ que realmente é um subconjunto do $\dom f$;
e similarmente sobre o $f(2\nats)$.
E assim tu calculou as respostas:
$$
\xalignat4
f(5) &= 6; & f(8) &= 9; & f(\set{1,7}) &= \set{2,8}; & f(2\nats) &= \set{1,3,5,\dots}.
\endxalignat
$$
Beleza, mas acontece que o $\nats$ é um conjunto homogênico.
Imagine que o domínio da $f$ tem todos os objetos seguintes como membros:
$$
1,\quad
7,\quad
\set{1,7}.
$$
Agora, se eu perguntar qual é o $f(\set{1,7})$ tu tens um dilemma:
$$
f(\set{1,7}) \askeq
\paths{
\text{a $f$-imagem do $\set{1,7}$}   & (que realmente é um subconjunto do seu domínio) \cr
\pathween {\dots\orword\dots}
\text{o valor da $f$ no $\set{1,7}$} & (que realmente é um membro do seu domínio)?
}
$$

\solution
Sejam $A = \set{ 1, 7, \set{1,7} }$, e $X = \set{1,7}$.
Observe que $X\in A$ e $X \subset A$.
Seja $f : A \to \set{3}$ a função constante definida pela $f(x) = 3$.
Assim a notação $f(X)$ fica ambígua: a $f$-imagem de $X\subset A$ é o $\set 3$,
mas o valor da $f$ no $X$ é o $3$.
E $3 \neq \set{3}$!

\endexercise
%%}}}

%%{{{ x: erroneous_definition_of_pre 
\exercise.
\label{erroneous_definition_of_pre}%
Podemos definir a preimagem de $Y$ através de $f$ assim?:
$$
\pre f Y \defeq \setst {\finv f (y)} {y \in Y}
$$

\solution
Não!
O símbolo $\finv f (y)$ nem é definido no caso geral:
o definimos \emph{apenas para funções bijetoras}.

\endexercise
%%}}}

%%{{{ x: when_erroneous_definition_of_pre_is_valid 
\exercise.
\label{when_erroneous_definition_of_pre_is_valid}%
Sejam $f: A \bijto B$, e $Y \subset B$.
Mostre que
$$
\pre f Y = \setst {\finv f (y)} {y \in Y}.
$$

\hint
É um igualdade de conjuntos, então mostre cada uma das~{\lrdirset}
e~{\rldirset} separadamente.

\solution
Caso $\pre f Y = \emptyset$, necessariamente $Y=\emptyset$ também
(pois $f$ é sobrejetora) e logo
$$
\setst {\finv f (y)} {y \in Y}=\emptyset
$$
também.
Caso contrário, mostramos as duas direções separadamente:
\crtabproofpart{\lrdirset:}
Seja $x\in \pre f Y$ e logo
seja $y_x\in Y$ tal que $f(x) = y_x$ (pela def.~$\pre f Y$).
Logo $x = \finv f (y_x)$ pela definição da função inversa (\refn{finverse}),
ou seja $x \in \setst {\finv f (y)} {y \in Y}$.
\crtabproofpart{\rldirset:}
É só seguir os passos da {\lrdirset} em reverso.

\endexercise
%%}}}

%%{{{ x: pre_notation_problem 
\exercise.
\label{pre_notation_problem}%
Qual o problema com a~\ref{img_and_pre}?

\hint
Quando $f$ \emph{não} é bijetora, nenhum.

\hint
Se $f$ é bijetora, o símbolo $\pre f Y$ pode ter duas interpretações diferentes.

\solution
Se $f$ é bijetora, o símbolo $\pre f Y$ pode ter duas interpretações diferentes:
$$
\pre f Y \askeq
\paths{
\pre {\alert{(f)}} {\alertb Y}
& a preimagem de $\alertb Y$ através da função $\alert f$ \cr
\pathween {\dots\orword\dots}
\img {\alert{(\finv f)}} {\alertb Y}
& a imagem de $\alertb Y$ através da função $\alert{\finv f}$
}
$$
onde usamos cores e parenteses para enfatizar o ``parsing'' diferente
de cada interpretação.
Observe que a segunda alternativa não é possível quando $f$ não é bijetora,
pois a função $\finv f$ nem é definida nesse caso!

\endexercise
%%}}}

%%{{{ x: correctness_of_pre_notation 
\exercise.
\label{correctness_of_pre_notation}%
Depois de resolver o~\ref{pre_notation_problem}, justifique a corretude
da~\ref{img_and_pre}:
explique o que precisas provar, e prove!

\hint
Precisamos provar que no caso que $f:A\bijto B$ as duas
interpretações do símbolo $\pre f Y$ \emph{denotam o mesmo objeto}.

\hint
Temporariamente mude tua notação para ajudar teus olhos distinguir
entre as duas interpretações melhor.
Use, por exemplo, $f_{-1}\bracket{\dhole}$ para denotar
a preimagem através da $f$.
Assim teu alvo fica enxergável:
$$
\lforall {Y \subset B} {\img {\finv f} Y = f_{-1}\bracket Y}.
$$

\solution
Seja $f : A \bijto B$.
Introduzimos temporariamente a notação
$$
f_{-1}\bracket Y \defeq \text{a $f$-preimagem de $Y$}.
$$
Com essa notação precisamos demonstrar que
$$
\text{para todo $Y\subset B$,}\quad
\img {\finv f} Y = f_{-1}\bracket Y
$$
Seja $Y \subset B$.
\crtabproofpart{\lrdirset}.
Seja $x \in \img {\finv f} Y$\fact1.
Para mostrar que $x \in f_{-1}\bracket Y$ basta verificar que $f(x) \in Y$\fact1.
Seja $y_x \in Y$ tal que $\finv f y_x = x$ (pela~\byfact1).
Logo $y_x = f(x)$ pela definição de $\finv f$ e logo pertence ao $Y$
pela~\byfact2.
\crtabproofpart{\rldirset}.
Seja $x \in f_{-1}\bracket Y$\fact1.
Como $f x \in Y$ (pelo~\byfact1) e $f x \mapstoby {\finv f} x$
(pela definição da $\finv f$), logo $x \in \img {\finv f} Y$.

\endexercise
%%}}}

%%{{{ x: img_f_singleton_x_eq_singleton_f_x 
\exercise.
\label{img_f_singleton_x_eq_singleton_f_x}%
Verdade ou fálso?:
para toda função $f$ e todo $x$ no seu domínio temos
$$
\img f {\set{x}} = \set{f(x)}.
$$

\solution
Verdade:
$$
\img f {\set{x}}
= \setst {f(z)} {z \in \set{x}}
= \set{f(x)}.
$$

\endexercise
%%}}}

%%{{{ x: is any of img f, pre f, guaranteed to be inj or surj? 
\exercise.
É alguma das $\img f {\dhole}$, $\pre f {\dhole}$ garantidamente
injetora ou sobrejetora?

\endexercise
%%}}}

%%{{{ x: bij_iff_all_pre_are_singletons 
\exercise.
\label{bij_iff_all_pre_are_singletons}%
Seja $f : A \to B$.
Prove que
$$
\text{$f$ bijetora} \iff \text{para todo $b \in B$, $\pre f {\set b}$ é um conjunto unitário}.
$$

\hint
Pense\dots
Como podes matar um alvo que um conjunto $S$ é unitário?
Como podes usar um fato que um conjunto $S$ é unitário?

\hint
Como matar o alvo que um conjunto $S$ é unitário?
Basta mostrar duas coisas:
(1) $S$ tem pelo menos um membro (ou seja: $S\neq\emptyset$);
(2) $S$ tem no máximo um membro (ou seja: para todo $s,s' \in S$,
temos $s=s'$).
E como usar o fato que um conjunto $S$ é unitário?
Para todos os $s, s' \in S$, ganhamos que $s=s'$.

\solution
\proofpart{\lrdir}.
Suponha que $f$ bijetora, e seja $b\in B$.
Vou demonstrar que $\pre f {\set b}$ é unitário.
Vamos chamá-lo de $A_b$.
Como $f$ é sobrejetora, logo seja $a_b \in A$ tal que $f(a_b) = b$.
Logo $a_b \in A_b$ pela definição da preimagem,
e logo $A_b \neq\emptyset$ (pois tem pelo menos um membro).
Basta mostrar que tem no máximo um membro.
Sejam $a, a' \in A_b$ então e vamos mostrar que $a=a'$.
Pela escolha dos $a,a'$, temos $f(a) = f(a') = b$;
e agora pela injectividade da $f$ temos o desejado $a=a'$.
\crtabproofpart{\rldir}.
Suponha que para todo $b \in B$, o $\pre f {\set b}$ é unitário.
Preciso mostrar que $f$ é injetora e sobrejetora.
\crproofpart{$f$ injetora:}
Suponha que temos $x,y\in A$ tais que $f(x) = f(y)$ e chame esse valor comum de $b$.
Basta provar que $x=y$.
Pela hipótese, o $\pre f {\set b}$ é unitário,
e pela escolha dos $x,y$ sabemos que $x,y$ pertencem a ele.
Logo $x=y$.
\crproofpart{$f$ sobrejetora:}
Seja $b\in B$.
Procuramos $a\in A$ tal que $f(a) = b$.
Pela hipótese, o conjunto $\pre f {\set b}$ é unitário (e logo não vazio).
Tome $a$ o (único) membro desse conjunto e observe que pela definição
de preimagem temos que $f(a) = b$.

\endexercise
%%}}}

%%{{{ x: composition_with_inverse_subsets 
\exercise.
\label{composition_with_inverse_subsets}%
Sejam conjuntos $X$ e $Y$, $f : X\to Y$, e $A\subset X$ e $B\subset Y$.
Prove as afirmações:
$$
\align
A &\subset \pre f {\img f A}\\
B &\supset \img f {\pre f B}.
\endalign
$$

\solution
Vamos provar as duas afirmações.
\endgraf\indent
\proofpart{{\proofname} de $A \subset \pre f {\img f A}$.}
Suponha $a\in A$.
Logo $f(a) \in \img f A$ pela definição da função-imagem,
e logo $a \in \pre f {\img f A}$ pela definição da função-preimagem.
\endgraf\indent
\proofpart{{\proofname} de $B \supset \img f {\pre f B}$.}
Suponha $y_0 \in \img f {\pre f B}$.
Logo tome $x_0 \in \pre f B$ tal que $y_0 = f(x_0)$\fact1.
Pela definição da função-preimagem $f(x_0) \in B$,
e agora pela~\byfact1~temos $y_0 \in B$.

\endexercise
%%}}}

%%{{{ x: composition_with_inverse 
\exercise.
\label{composition_with_inverse}%
Sejam conjuntos $X$ e $Y$, $f : X\to Y$, e $A\subset X$ e $B\subset Y$.
Considere as afirmações:
$$
\align
A &\askeq \pre f {\img f A}\\
B &\askeq \img f {\pre f B}.
\endalign
$$
Para cada uma delas: se podemos concluí-la, prove;
e caso contrário, mostre um contraexemplo.

\hint
Nenhuma é válida em geral.
Procure contraexemplos.

\hint
O enunciado do~\ref{jection_iff_composition_with_inverse}
pode te ajudar pensar em contraexemplos.

\solution
Mostramos dois contraexemplos, um para cada afirmação.
$$
\tikzpicture
\draw (0,0) ellipse (1cm and 15mm);
\draw (3,0) ellipse (1cm and 12mm);
\draw (0,0.666) ellipse (5mm and 5mm);
\draw (-0.6,0.1) node {$A$};
\draw (0,0.666)  node {$1\,\bullet$};
\draw (0,-0.666) node {$2\,\bullet$};
\draw (3,0)  node {$\bullet\,3$};
\draw[|->] (0.3,0.6) -- (2.7,0.1);
\draw[|->] (0.3,-0.6) -- (2.7,-0.1);
\draw (0,2.0) node {$X$};
\draw (3,2.0) node {$Y$};
\draw (1.5,1.70) node {$f$};
\draw[->]  (0.5,2.0) -- (2.5,2.0);
\endtikzpicture
\qqqquad
\tikzpicture
\draw (0,0) ellipse (1cm and 12mm);
\draw (3,0) ellipse (1cm and 15mm);
\draw (3,0) ellipse (8mm and 10mm);
\draw (2.4,0.1) node {$B$};
\draw (3,0.666)  node {$\bullet\,2$};
\draw (3,-0.666) node {$\bullet\,3$};
\draw (0,0)  node {$1\,\bullet$};
\draw[|->] (0.35,0.05) -- (2.7,0.6);
\draw (0,2.0) node {$X$};
\draw (3,2.0) node {$Y$};
\draw (1.5,1.70) node {$f$};
\draw[->]  (0.5,2.0) -- (2.5,2.0);
\endtikzpicture
$$
No primeiro contraexemplo temos:
$A=\set{1}$;
$\img f A = \set {3}$; e
$\pre f {\set 3} = \set {1,2}$.
Logo
$$
A = \set{ 1 } \neq \set {1, 2} = \pre f {\img f A}.
$$
No segundo contraexemplo temos:
$B = \set{2,3}$;
$\pre f B = \set {1}$; e
$\img f {\set 1} = \set {2}$.
Logo
$$
B = \set{ 2,3 } \neq \set {2} = \img f {\pre f B}.
$$

\endexercise
%%}}}

%%{{{ Q: what changes if f is inj or surj? 
\question.
O que muda no~\ref{composition_with_inverse} se $f$ é injetora?  Se é sobrejetora?
%%}}}
\spoiler.

%%{{{ jection_iff_composition_with_inverse 
\theorem.
\label{jection_iff_composition_with_inverse}%
Seja $f : X \to Y$.
$$
\align
\text{$f$ injetora}    &\iff \text{para todo $A \subset X$, $A = \pre f {\img f A}$}  \tag{1}\\
\text{$f$ sobrejetora} &\iff \text{para todo $B \subset Y$, $B = \img f {\pre f B}$}. \tag{2}
\endalign
$$
\proof.
As idas tu provarás (agora!)~no~\refn{jection_implies_composition_with_inverse};
as voltas no~\ref{jection_iff_composition_with_inverse_proof} (pode ser depois).
\qed
%%}}}

%%{{{ x: jection_implies_composition_with_inverse 
\exercise.
\label{jection_implies_composition_with_inverse}%
Prove as idas do~\ref{jection_iff_composition_with_inverse}.

\solution
Temos duas implicações para provar.
\crtabproofpart{Ida da (i).}
Suponha que $f$ é injetora, e seja $A\subset X$.
Já temos a
$$
A \subset \pre f {\img f A}
$$
pelo~\ref{composition_with_inverse_subsets}, então basta mostrar
$$
\pre f {\img f A} \subset A.
$$
Tome então $x_0 \in \pre f {\img f A}$.
Logo $f(x_0) \in \img f A$.
Logo $f(a) = f(x_0)$ para algum $a \in A$ (pela definição da função-imagem).
Mas $f$ é injetora, então $a = x_0$ e logo $x_0\in A$.
\crtabproofpart{Ida da (ii).}
Suponha que $f$ é sobrejetora, e seja $Y\subset B$.
Já temos a
$$
\img f {\pre f B} \subset B
$$
pelo~\ref{composition_with_inverse_subsets}, então basta mostrar
$$
B \subset \img f {\pre f B}
$$
Tome então $b \in B$.
Agora seja $x_b \in X$ tal que $f(x_b) = b$ (pois $f$ é sobrejetora).
Então $x_b \in \pre f B$.
Logo $f(x_b) \in \img f {\pre f B}$.
Logo $b \in \img f {\pre f B}$.

\endexercise
%%}}}

\blah.
Vamos ver agora como essas operações comportam
em combinação com as operações de conjuntos.

%%{{{ x: operations_respected_by_img 
\exercise.
\label{operations_respected_by_img}%
Sejam $f : X \to Y$, $A,B\subset X$.
Mostre que:
$$
\align
\img f {A\union B} &=       \img f A \union \img f B\\
\img f {A\inter B} &\askeq  \img f A \inter \img f B\\
\img f {A\minus B} &\askeq  \img f A \minus \img f B
\endalign
$$
onde nas $\askeq$ prove que a igualdade em geral não é válida,
mas uma das~\lrdirset~e~\rldirset, é.

\hint
Ataque cada direção ({\lrdirset} e {\rldirset}) da primeira separadamente.
Das duas $\askeq$, são válidas as inclusões:
$$
\align
\img f {A\inter B} &\subset \img f A \inter \img f B\\
\img f {A\minus B} &\supset \img f A \minus \img f B
\endalign
$$
Prove; e mostre contraexemplos que demonstram que as reversas
inclusões não são válidas em geral.

\solution
Vamos primeiramente provar a
$\img f {A\union B} = \img f A \union \img f B$.
\proofpart{\lrdirset}:
Tome $y \in \img f {A\union B}$.
Logo seja $x \in A\union B$ tal que $f(x) = y$.
\case{Caso $x \in A$,} temos $f(x)\in \img f A$
e logo $f(x)$ pertence na união $\img f A \union \img f B$.
\case{Caso $x \in B$,} concluímos similarmente
que $f(x) \in \img f B \subset \img f A \union \img f B$.
\endgraf
\proofpart{\rldirset}:
Tome $y \in \img f A \union \img f B$.
\case{Caso $y \in \img f A$,} seja $a\in A$ tal que $f(a)=y$.
Mas $a \in A\union B$, logo $y\in \img f {A\union B}$.
\case{O caso $y \in \img f B$} é similar.
\endgraf
Vamos provar a
$\img f {A\inter B} \subset \img f A \inter \img f B$ agora.
Tome $y \in \img f {A\inter B}$ e
seja $d \in A\inter B$ tal que $f(d) = y$.
Mas $d \in A$ e $d \in B$, ou seja $y \in \img f A$ e $y \in \img f B$,
e logo $y \in \img f A \inter \img f B$.
\endgraf
Vamos provar a
$\img f {A\minus B} \supset \img f A \minus \img f B$ agora.
Tome $y \in \img f A \minus \img f B$ então, ou seja
$y \in \img f A$ e $y \notin \img f B$.
Traduzindo:
$$
\lexists {a\in A} {f(a) = y}
\qquad\mland\qquad
\lforall {b\in B} {f(b) \neq y}.
$$
Usando a primeira afirmação abaixo tome $a\in A$ tal que $f(a) = y$,
e observe que graças à segunda, $a \notin B$.
Logo $a \in A\minus B$, e chegamos no desejado
$y \in \img f {A\minus B}$.
\endgraf
Finalmente, usamos apenas um contraexemplo para refutar simultaneamente
as duas inclusões que são inválidas no caso geral:
$$
\tikzpicture
\draw (0,0) ellipse (1cm and 15mm);
\draw (3,0) ellipse (1cm and 12mm);
\draw (0,.666) ellipse (5mm and 5mm);
\draw (0,-.666) ellipse (5mm and 5mm);
\draw (-0.6,0.25)  node {$A$};
\draw (-0.6,-0.25) node {$B$};
\draw (0,0.666)  node {$1\,\bullet$};
\draw (0,-0.666) node {$2\,\bullet$};
\draw (3,0)  node {$\bullet\,3$};
\draw[|->] (0.3,0.6) -- (2.7,0.1);
\draw[|->] (0.3,-0.6) -- (2.7,-0.1);
\node (X) at (0,2.0) {$X$};
\node (Y) at (3,2.0) {$Y$};
\draw[->]  (0.5,2.0) -- (2.5,2.0) node[midway, below] {$f$};
\endtikzpicture
$$
Calculamos para verificar:
$$
\aligned
\img f {A \inter B}
&= \img f \emptyset
= \emptyset \\
\img f A \inter \img f B
&= \set{3} \inter \set{3}
= \set{3}
\endaligned
\qquad
\aligned
\img f {A \minus B}
&= \img f A
= \set {3}\\
\img f A \minus \img f B
&= \set {3} \minus \set {3}
= \emptyset.
\endaligned
$$
Um contraexemplo mais pictorial seria considerar uma função $f$
que mapeia pontos do plano $\reals^2$
para pontos da reta $\reals$, mandando cada
entrada $\tup{x,y}$ para sua ``sombra'' $x$.
Já conhecemos essa função: é a primeira projecção: $f = \pi_0$.
Observe que a $\img {\pi_0} {\dhole}$ manda cada subconjunto de $\reals^2$
para sua ``sombra'':
$$
\tikzpicture
\draw [rounded corners=8mm, fill=gray!10] (1,3)--(1,5)--(4,5)--(4,3)--cycle;
\node at (2.5,4) {$A$};
\draw [rounded corners=0mm, fill=black]   (1,-0.1)--(1,0.1)--(4,0.1)--(4,-0.1)--cycle;
\node at (2.5,-0.4) {$\img {\pi_0} A$};
\draw[-]  (-1,0) -- (6,0);
\draw[|->] (2,2.6) -- (2,0.5);
\endtikzpicture
$$
Para achar o contraexemplo agora, basta só escolher dois subconjuntos de
$\reals^2$ como esses:
$$
\tikzpicture
\draw [rounded corners=8mm, fill=gray!10] (1,3)--(1,5)--(4,5)--(4,3)--cycle;
\node at (2.5,4) {$A$};
\draw [rounded corners=3mm, fill=gray!10] (1,1)--(1,2)--(4,2)--(4,1)--cycle;
\node at (2.5,1.5) {$B$};
\draw [rounded corners=0mm, fill=black]   (1,-0.1)--(1,0.1)--(4,0.1)--(4,-0.1)--cycle;
\node at (2.5,-0.4) {$\img {\pi_0} A = \img {\pi_0} B$};
\draw[-]  (-1,0) -- (6,0);
\endtikzpicture
$$
Verifique que isso é um contraexemplo que refuta as duas igualdades
que queremos refutar.

\endexercise
%%}}}

%%{{{ x: operations_respected_by_img_of_inj 
\exercise.
\label{operations_respected_by_img_of_inj}%
Sejam $f : X \injto Y$ injetora, e $A,B\subset X$.
Mostre que:
$$
\align
\img f {A\inter B} &= \img f A \inter \img f B\\
\img f {A\minus B} &= \img f A \minus \img f B.
\endalign
$$

\hint
Já provou metade de cada igualdade no~\ref{operations_respected_by_img}
até sem a hipótese que $f$ é injetora.
Basta então provar as duas inclusões:
$$
\align
\img f {A\inter B} &\supset \img f A \inter \img f B\\
\img f {A\minus B} &\subset \img f A \minus \img f B.
\endalign
$$

\solution
Já provamos metade de cada igualdade no~\ref{operations_respected_by_img}
para qualquer função, então para nossa injetora $f$ também.
Basta então provar as duas inclusões:
$$
\align
\img f {A\inter B} &\supset \img f A \inter \img f B\\
\img f {A\minus B} &\subset \img f A \minus \img f B.
\endalign
$$
\proofpart{{\proofname} de $\img f {A\inter B} \supset \img f A \inter \img f B$}:
Suponha $y \in \img f A \inter \img f B$.
Logo $y \in \img f A$ e $y \in \img f B$.
Tome então $a\in A$ tal que $f(a) = y$ e $b \in B$ tal que $f(b) = y$.
Juntando as duas igualdades temos $f(a) = f(b)$.
Mas $f$ é injetora, e logo $a = b$.
Ou seja, $a \in A\inter B$, e chegamos no desejado
$y \in \img f {A \inter B}$.
\endgraf\noindent
\proofpart{{\proofname} de $\img f {A\minus B} \subset \img f A \minus \img f B$}:
Suponha $y \in \img f {A\minus B}$.
Tome então $a_0 \in A\minus B$ tal que $f(a_0) = y$.
Logo $a_0 \in A$ e $a_0 \notin B$.
Já sabemos então que $y \in \img f A$.
Agora usamos a injectividade da $f$ para provar que $y \notin \img f B$.
Se $y$ fosse um membro de $\img f B$, existiria $b\in B$ com $f(b) = y$.
Mas já temos o único ($f$ injetora) membro do domínio $X$ que $f$ mapeia no $y$,
o $a_0$, e sabemos que $a_0 \notin B$!
Logo $y \notin \img f B$ e chegamos no $y\in \img f A \minus \img f B$.

\endexercise
%%}}}

\blah.
A preimagem comporta bem melhor que a imagem: ela respeita
todas essas operações mesmo quando $f$ não é injetora,
algo que tu provarás agora.

%%{{{ x: operations_respected_by_pre 
\exercise.
\label{operations_respected_by_pre}%
Sejam $f : X \to Y$, $A,B\subset Y$.
Mostre que:
$$
\align
\pre f {A\union B} &= \pre f A \union \pre f B\\
\pre f {A\inter B} &= \pre f A \inter \pre f B\\
\pre f {A\minus B} &= \pre f A \minus \pre f B
\endalign
$$

\endexercise
%%}}}

\blah.
Essas propriedades generalizam naturalmente para uniões e intersecções
de seqüências e famílias de conjuntos;
veja por exemplo o~\ref{big_operations_respected_by_img_and_pre}.

\endsection
%%}}}

%%{{{ Partial functions 
\section Funções parciais.
\label{Partial_functions}%

\blah.
A restricção que uma função $f : A \to B$ precisa ser \emph{totalmente}
definida no $A$, não nos permite considerer naturalmente situações onde
um certo programa, por exemplo, retorna valores para certas entradas
aceitáveis, e para as outras não:
talvez ele fica num \emph{loop infinito}; ou ele faz a máquina explodir;
ou simplesmente não termina com uma saída---não importa o porquê.
Definimos então o conceito de \emph{função parcial}, que é exatamente
isso: funções que para certas entradas aceitáveis delas, possivelmente
\dterm{divergem}.

%%{{{ df: partial_function 
\definition.
\label{partial_function}%
\tdefined{função}[parcial]%
\sdefined {\sholed f : \sholed A \parto \sholed B} {$f$ é uma função parcial de $A$ para $B$}%
\sdefined {(\sholed A \parto \sholed B)} {o conjunto das funções parciais de $A$ para $B$}%
Sejam $A,B$ conjuntos.
Chamamos a $f$ uma \dterm{função parcial} de $A$ para $B$ sse:
$$
\text{para todo $x\in A$, se $f(x)$ é definido então $f(x) \in B$.}
$$
Nesse caso, chamamos \dterm{domínio} o conjunto
$$
\dom f \defeq \setstt {x \in A} {$f(x)$ é definido}
$$
e \dterm{codomínio} o $B$ mesmo.
Escrevemos $f : A \parto B$ para ``$f$ é uma função parcial de $A$ para $B$''.
Naturalmente denotamos o conjunto de todas as funções parciais de $A$ para $B$ por
$$
(A \parto B) \defeq \setst f {f : A \parto B}.
$$
%%}}}

%%{{{ remark: total vs partial: default 
\remark.
Com essas definições cada função total é uma função parcial.
Escrevemos esse ``total'' quando queremos enfatizar, mas normalmente
``função'' sem o adjectivo ``parcial'' significa ``função total''.
Claramente, quando trabalhamos principalmente com funções parciais,
seguimos a convenção oposta.
%%}}}

%%{{{ remark: partial function conditions 
\remark Condições.
Encontramos então aqui o que acontece se apagar a primeira das
condições~\refn{functionhood_conditions}:
\beginil
\item{}\strikeout{(1)~totalidade};
\item{}(2)~determinabilidade.
\endil
e ficar só com a (2).
No~\ref{Relations} vamos estudar também o caso onde apagamos ambas as condições.
%%}}}

\endsection
%%}}}

%%{{{ Currying 
\section Currificação.
\label{Currying}%

%%{{{ Ha-ha!  My language is better than yours 
\note Ha-ha!  Minha linguagem é melhor que a tua.
Imagine que um amigo definiu uma função $f : \ints^2\to\ints$
trabalhando numa linguagem de programação que não permite
definições de funções de ordem superior.
Queremos escrever um programa equivalente ao programa do nosso amigo
numa outra linguagem que permite sim definir funções de ordem superior
mas não funções de aridade maior que $1$.
Mesmo assim nossas funções podem \emph{chamar} a função $f$ do nosso amigo nos seus corpos.
%%}}}

%%{{{ Q: How can we do this? 
\question.
Como fazer isso?
%%}}}
\spoiler.

%%{{{ Answer in Python 
\note Resposta em Python.
\label{currying_in_python}%
\iipl Python
Aqui uma resposta, escrita em Python.
\sourcecode currying.py;
Para computar a $\code{f(x,y)}$ usando a $\code{F}$,
usamos a $\code{F(x)(y)}$, ou seja, $\code{(F(x))(y)}$.
%%}}}

\TODO Explicar o que acontece.

%%{{{ x: uncurry first exercise
\exercise.
Resolva o problema converso:
começando com a função de ordem superior $F$,
defina sua versão $f$ (de aridade 2).

\solution
Dados a $F : \ints\to(\ints\to\ints)$,
é só definir a $f : \ints^2\to\ints$ pela $f(x,y) = F(x)(y)$.
Note que a expressão ``$F(x)(y)$'' quis dizer ``$\bigparen{F(x)}(y)$'' mesmo.

\endexercise
%%}}}

%%{{{ Currying 
\note Currificação.
\tdefined{currificação}%
A maneira que conseguimos utilizar funções de ordem
superior mas de aridade $1$, para ``emular'' funções
de aridades maiores é chamada \emph{currificação},
em homenagem ao Haskell~\Curry[currificação]{}Curry.%
\footnote{%
O próprio \Curry{}Curry atribuiu o conceito
ao \Schonfinkel[currificação]{}Schönfinkel,
mas \Frege[currificação]{}Frege já tinha usado isso antes.
}
No exemplo acima digamos que $F$ é a \dterm{currificação}
da $f$, ou sua versão currificada.
%%}}}

%%{{{ Q: How can we define the generic curry and uncurry functions? 
\question.
Usando a $\lambda$-notação como podemos definir funções
$\curry, \uncurry$ para a situação mais genérica onde
a função de dois argumentos é do tipo $(A \times B) \to C$?
%%}}}
\spoiler.

%%{{{ how_to_construct_curry_inhabitant 
\note Resposta.
\label{how_to_construct_curry_inhabitant}%
Primeiramente vamos nos preocupar com os tipos dessas funções.
São assim:
$$
\cdopt{sep=2cm}
\paren{(A\times B)\to C}  \ar[r, shift left, "\curry"] \| \paren{A \to (B\to C)} \ar[l, shift left, "\uncurry"]
\endcd
$$
Temos então
$$
\curry : \paren{(A\times B)\to C} \longto \paren{A \to (B\to C)}
$$
definida pela
$$
\curry(\alert{\dots?}
$$
Como denotar o arbitrário membro do seu domínio $\paren{(A\times B)\to C}$?
Sendo uma função, vou escolher denotá-lo por $f$.  Ajuda.
Voltamos então:
$$
\curry(f) = \alert{\dots?}
$$
Que tipo de coisa estamos tentando \emph{construir} no lado direito?
Pelo tipo da $\curry$, deve ser uma função de $A$ para $(B\to C)$.
E o que tenho na minha disposição?  Neste ponto apenas a $f$.
Facilita escrever claramente todas as coisas disponíveis e seus típos.
Então por enquanto tenho apenas
$$
f : (A\times B) \to C.
$$
E eu quero construir uma função de tipo $A\to (B \to C)$.
Para defini-la preciso deixar claro o seu comportamento então:
$$
\curry(f) = \lam {\alert{\dots?}} {\dots}
$$
Como denotar a arbitrária entrada dessa função?
Bem, sendo uma função com domínio $A$, vou escolher denotar
seu argumento por $a$:
$$
\curry(f) = \lam {a} {\alert{\dots?}}
$$
A mesma pergunta: o que eu ganhei e o que tipo de coisa preciso construir agora?
Ganhei um $a : A$, e preciso construir
algo do tipo $B\to C$, ou seja, uma função (então vou começar com um $\lambda$\dots)
que recebe $B$'s (então $\lam b {\dots}$ e retorna $C$'s:
$$
\curry(f) = \lam {a} {\lam {b} {\alert{\dots?}}}
$$
Aqui preciso construir um $C$'zinho e eu tenho:
$$
\align
f &: (A\times B) \to C \\
a &: A \\
b &: B
\intertext{%
Fácil!  Pois eu tenho um fornecedor de $C$'s, e ele só
precisa de um par de um $A$'zinho e um $B$'zinho para
funcionar---pun intended---e felizmente eu tenho ambos, e logo
}
f(a,b) &: C
\endalign
$$
Com isso consego finalmente terminar:
$$
\curry(f) = \lam {a} {\lam {b} {f(a,b)}}.
$$
Deixo a definição da $\uncurry$ pra ti:
%%}}}

%%{{{ x: uncurry_using_lambdas 
\exercise.
\label{uncurry_using_lambdas}%
Defina a $\uncurry$.

\hint
Queremos definir a
$$
\uncurry : \paren{A \to (B\to C)} \to \paren{(A\times B) \to C}
$$
então sabemos já como começar: basta definir o
$$
\uncurry(\alert{\dots?}\phantom)
$$
Peraí: qual seria uma opção boa para denotar esse argumento?

\hint
Que tipo de coisa é esse argumento?
Uma função $A \to (B\to C)$, ou seja, uma função de ordem
superior; vou escolher $F$ aqui, para me lembrar desse fato.
Voltando então:
$$
\uncurry(F) = \alert{\dots?}
$$
O que eu ganhei e o que eu preciso construir?
Ganhei
$$
F : A \to (B\to C)
$$
e preciso algo do tipo $(A\times B) \to C$.
Então já sei como começar.
Como?

\hint
Sendo uma função, vou já escrever:
$$
\uncurry(F) = \lam {\alert{\dots?}} {\dots}
$$
e preciso escolher como denotar a sua entrada.
E aqui tenho duas abordagens razoáveis:
ou escolher alguma variável como $w,t,\vec w, \vec t$, etc.,
onde ela terá o tipo $A\times B$;
ou usar a $\lambda$-notação de aridades maiores escrevendo
$\tup{a,b}$ para a arbitrária entrada dessa função.
Vamos escolher segunda opção (se quiser, pode escolher a primeira).
Continue!

\hint
Estamos aqui então:
$$
\uncurry(F) =
\lam {\tup{a,b}} {\alert{\dots?}}
$$
e o que precisamos construir aqui?
Sendo a ``saída'' duma função com tipo $(A\times B)\to C$,
eu preciso construir uma coisa do tipo $C$.
Mas o que mais eu tenho agora?
Meus dados tem aumentado:
$$
\align
F &: A\to (B \to C) \\
\tup{a,b} &: (A\times B)
\intertext{e logo}
a &: A \\
b &: B \\
\alert{??} &: C\\
\endalign
$$
Como posso usá-los para construir algo do tipo $C$?
Eu não tenho um ``fornecedor'' de $C$'s imediato,
mas percebo que tenho um\dots\ fornecedor de fornecedores
de $C$'s!  (Minha $F$.)
E para ela funcionar
preciso oferecer $A$'zinho, e pronto, ela vai fornecer
um fornecedor de $C$'s.
Felizmente temos um $a : A$.
Então temos:
$$
F(a) : ??
$$

\hint
Temos
$$
\align
F &: A\to (B \to C) \\
\tup{a,b} &: (A\times B) \\
a &: A \\
b &: B \\
F(a)    &: B \to C
\intertext{e logo}
F(a)(b) &: ??
\endalign
$$
Termine!

\solution
Queremos definir a
$$
\uncurry : \paren{A \to (B\to C)} \to \paren{(A\times B) \to C}
$$
e \emph{seguindo as dicas} chegamos em:
$$
\uncurry(F) = \lam {\tup{a,b}} {\bigparen{F(a)}(b)}.
$$

\endexercise
%%}}}

%%{{{ type_inference_tree_for_curry 
\note Arvore de inferência de tipo.
A última parte da argumentação acima corresponde na arvore de inferência
seguinte:
$$
\Proofm{
\A {f \is A \cross B \to C}      \A {x \is A}  \A {y \is B}
                               \I2------------------------- {}
                                   {(x,y) \is A \cross B}
\I2------------------------------------------------------- {}
                        {f(x,y) \is C}
}
$$
Verifique cada passo, e acostume-se com essa forma!
%%}}}

%%{{{ x: type_inference_tree_for_uncurry 
\exercise Acostume-se mesmo.
\label{type_inference_tree_for_uncurry}%
Construa a arvore que corresponde na última parte da
tua resolução do~\ref{uncurry_using_lambdas} caso que
tu não fez isso já enquanto o resolvendo.

\solution
$$
\Proofm{
\A {f \is A \to (B \to C)}     \A {t \is A \cross B}
                               \I1------------------ {}
                                   {\outl t \is A}
\I2------------------------------------------------- {}
               {f (\outl t) \is B\to C}
                                               \A {t \is A \cross B}
                                               \I1------------------ {}
                                                   {\outr t \is B}
\I2---------------------------------------------------------------- {}
                     {f (\outl t) (\outr t) \is C}
}
$$

\endexercise
%%}}}

%%{{{ syntactic_associativity 
\note Associatividade sintáctica.
\label{syntactic_associativity}%
Considere que temos uma operação binária $\heartop$.
A frase
$$
\text{<<$\heartop$ é associativa>>}
$$
é uma \emph{afirmação matemática:}
$$
\text{para todo $x,y,z$},
\quad
(x \heartop y) \heartop z
=
x \heartop (y \heartop z).
$$
Isso é algo que pode ser demonstrado, suposto, refutado, etc.
No outro lado, considere as frases seguintes:
$$
\xalignat2
&\aligned
&\text{<<$\heartop$ é associativa na esquerda>>} \\
&\text{<<$\heartop$ associa na esquerda>>} \\
&\text{<<$\heartop$ é L-associativa>>}
\endaligned
&
&\aligned
&\text{<<$\heartop$ é associativa na direita>>} \\
&\text{<<$\heartop$ associa na direita>>} \\
&\text{<<$\heartop$ é R-associativa>>}
\endaligned
\intertext{%
Nenhuma dessas frases é algo que podemos demonstrar, refutar, ou supor!
O que significam então?
Apenas uma convenção sintáctica, que dá significado
às expressões como a \sqq{$x \heartop y \heartop z$}
que sem uma associatividade sintáctica não denotam
absolutamente nada (pois têm um erro de aridade).
As frases acima então correspondem respectivamente nas:
}
&x \heartop y \heartop z \syndefeq (x \heartop y) \heartop z &
&x \heartop y \heartop z \syndefeq x \heartop (y \heartop z).
\endxalignat
$$
%%}}}

%%{{{ notational_abuse_curried 
\warning.
\label{notational_abuse_curried}%
Às vezes abusarei essa idéia e escrever o nome duma função
currificada mas usá-la como se ela não fosse; e vice-versa.
Por exemplo, defini (\refn{apply_operation}) a $\applydc A B$
como uma função
$$
\applydc A B : \pfcross {(A \to B)} A \to B.
$$
Ou seja, para chamá-la escrevemos
$$
\applydc A B (f,a).
$$
Mas abusando a notação posso consider o mesmo símbolo
$\applydc A B$ para denotar sua currificação
$$
\applydc A B : {(A \to B)} \to A \to B
$$
que \emph{é uma função diferente sim}, nesse caso escrevendo
$$
\applydc A B \fa f \fa a.
$$
Tudo isso apenas no caso que pelo contexto tá claríssimo qual
das duas funções tá sendo denotada.
%%}}}

\TODO notação de ``aridades maiores'' currificada.

%%{{{ human_eyes_and_ho_types 
\note Olhos humanos e os tipos higher-order.
\label{human_eyes_and_ho_types}%
%%}}}

\TODO Escrever.

%%{{{ partial_application_and_currying 
\note Aplicação parcial e currificação.
\label{partial_application_and_currying}%
%%}}} 

\TODO Escrever.

%%{{{ eg: powTwo 
\example powTwo.
\label{powTwo}%
Definimos a função $\namedfun{powTwo} : \nats\to\reals$ pela
$$
\namedfun{powTwo} = \namedfun{exp} \fa 2.
$$
Assim $powTwo\fa 0 = 1$, $\namedfun{powTwo} \fa 10 = 1024$, etc.
\endexample
%%}}}

%%{{{ remark: looks_like_cancellation 
\remark Parece cancelamento.
\label{looks_like_cancellation}%
%%}}}

\TODO Escrever.

\blah.
Já entramos bastante to território de programação funcional;
paramos aqui agora, e voltamos re-visitar e expandir tudo isso
no~\ref{Functional_programming}.

\endsection
%%}}}

%%{{{ Implementations_seq_fam 
\section Novas implementações: seqüências e famílias.
\label{Implementations_seq_fam}%

%%{{{ Q: Can you implement sequences and indexed families? 
\question.
Suponha que alguem robou de ti os típos (primitivos) de seqüências e de famílias
indexadas.  Dá para se virar sem esses?  Ou seja, tem como defini-los em termos
dos outros tipos que tu (ainda) tens?
%%}}}
\spoiler.

%%{{{ A 
\blah Resposta.
Agora que sabemos o que é uma função, podemos apreciar
que qualquer seqüência $\seqn a n$
\emph{pode ser representada por uma função} com domínio $\nats$
e codomínio o conjunto de todos membros da $\seqn a n$.
Similarmente, uma família $\famst {a_i} {i \in \cal I}$
indexada por um conjunto $\cal I$ \emph{pode ser representada por uma função}
com domínio $\cal I$ e codomínio o conjunto de todos membros da $\family {a_i} i$.
%%}}}

%%{{{ impl: sequences_as_functions 
\implementation Seqüências como funções.
\label{sequences_as_functions}%
Chamamos qualquer $a : \nats \to A$.
de \dterm{seqüência}.
Introduzimos como açúcar sintáctico o
$$
a_n \sugdefeq a(n).
$$
Com esse ponto de vista, quando duas \emph{seqüências} são iguais?
Elas precisam concordar em cada $n \in \dom a$;
e esse ponto de vista atende a especificação pois concorda com
a definição de igualdade do típo que estamos implementando
(\ref{sequences_equality}).
%%}}}

%%{{{ impl: indexed_families_as_functions 
\implementation Famílias indexadas como funções.
\label{indexed_families_as_functions}%
Chamamos qualquer $a : \cal I \to A$.
de \dterm{família indexada por $\cal I$}.
Introduzimos como açúcar sintáctico o
$$
a_i \sugdefeq a(i).
$$
Com esse ponto de vista, quando duas \emph{famílias} indexadas são iguais?
Os conjuntos de índices têm que ser iguais, e as famílias precisam
concordar em cada índice.
Esse ponto de vista atende a especificação pois concorda com
a definição de igualdade do típo que estamos implementando
(\ref{indexed_families_equality}).
%%}}}

%%{{{ x: implement_tuples 
\exercise.
Implemente as tuplas;
tome cuidado para deixar claro como usá-las;
lembre-se o~\refn{tuples_interface_and_equality} da~\ref{Tuples}.

\endexercise
%%}}}

%%{{{ x: implement_multisets 
\exercise.
\label{implement_multisets}%
Implemente os multiset (\refn{Multisets});
tome cuidado para deixar claro como usá-las;
lembre-se o~\refn{multisets_equality}.

\endexercise
%%}}}

%%{{{ df: indexed_sets_adult_version 
\definition Conjuntos indexados: versão adulta.
\label{indexed_sets_adult_version}%
\tdefined{conjunto}[indexado por conjunto]%
Já conhecemos o quesignifica que um conjunto $A$ é indexado
por um conjunto $B$~(\ref{indexed_set}).
Isso praticamente quis dizer que o $A$ pode ser escrito na forma
$$
A = \setst {\dots b \dots} {b \in B},
$$
ou, mais ``adultamente'' e plenamente:
$$
\text{$A$ é indexado por $B$}
\defiff
\text{existe função sobrejetora $f : B \surto A$}.
$$
%%}}}

\endsection
%%}}}

%%{{{ Recursive_definitions_as_systems 
\section Definições recursivas.
\label{Recursive_definitions_as_systems}%

\blah.
Já encontramos várias definições recursivas.
Agora vamos analizar com que precisamos tomar cuidado para garantir
que nossas ``funções'' realmente são funções bem-definidas.
Vamos começar lembrando como exemplo duas funções recursivas famosas demais.

%%{{{ eg: fact_and_fib_recursive_eg 
\example.
\label{fact_and_fib_recursive_eg}%
Sejam $a:\nats\to\nats$ definida pelas
$$
\align
a(0) &= 1\\
a(n) &= n \ntimes a(n-1), \quad\text{para todo $n>0$};
\intertext{e $b:\nats\to\nats$ definida pelas}
b(0) &= 1\\
b(1) &= 1\\
b(n) &= b(n-1) + b(n-2), \quad\text{para todo $n>1$}.
\endalign
$$
Muitas vezes deixamos as frases ``para todo $n>0$'' como
implícitas pelo contexto---mas entenda que elas precisam estar lá,
e \emph{estão} lá mesmo quando escolhemos omiti-las.
\endexample
%%}}}

\blah.
Agora, assuma que tu aceita ambas as $a,b : \nats\to\nats$ do
exemplo assima como funções \emph{bem-definidas}, e continue lendo.

%%{{{ mutual_recursion 
\note Recursão mutual.
\label{mutual_recursion}%
Podemos definir duas ou mais funções, cada uma chamando recursivamente
outras, tomando certos cuidados como sempre para garantir que realmente
todas as funções vão ser definidas mesmo para todas as entradas
aceitas pelos domínios delas.
%%}}}

%%{{{ eg: mutual_recursion_even_odd 
\example.
\label{mutual_recursion_even_odd}%
Vamos definir as funções $\even,\odd:\nats\to\set{0,1}$ pelas
$$
\xalignat2
\even(0)   &= 1       & \odd(0)   &= 0 \\
\even(n+1) &= \odd(n) & \odd(n+1) &= \even(n)
\endxalignat
$$
Calculamos, por exemplo:
$$
\align
\even(3) &
= \odd(2)
= \even(1)
= \odd(0)
= 0 \\
odd(3) &
= \even(2)
= \odd(1)
= \even(0)
= 1
\endalign
$$
\endexample
%%}}}

%%{{{ Safe recursion 
\note Recursão segura.
Na maioria das vezes que definimos funções recursivamente
existe ``algo''---muitas vezes esse ``algo'' é o próprio
argumento da função (como no~\ref{fact_and_fib_recursive_eg})
mas não sempre---que com cada ``chamada recursiva''
da função fica menor e menor, até cair num valor que garanta
uma ``saída da recursão''.
(Essa descrição é bem vaga sim.)
%%}}}

%%{{{ eg: recursion_with_powers_of_two 
\example.
\label{recursion_with_powers_of_two}%
Seja $p : \nats\to\nats$ a função definida pela:
$$
p(x) =
\knuthcases{
\log_2(x), & se $x$ é uma potência de $2$;\cr
p(x+1), & se não.
}
$$
Aqui nas chamadas recursivas não é o próprio argumento que é
``cada vez menor''---pelo contrário: as chamadas recursivas
estão sendo cada vez com argumento maior!
Mesmo assim, a recursão ``sempre termina'', e a $f$ realmente
é bem-definida.
Calculamos como exemplo uns valores:
$$
\align
p(0) &= p(1) = \log_2(1) = 0 \\
p(4) &= \log_2(4) = 2 \\
p(5) &= p(6) = p(7) = p(8) = \log_2(8) = 3 \\
p(1020) &= p(1021) = p(1022) = p(1023) = p(1024) = \log_2(1024) = 10.
\endalign
$$
\endexample
%%}}}

%%{{{ x: find invariant 
\exercise.
Ache um ``algo'' que fica cada vez menor com cada chamada recursiva
da $p$ do~\ref{recursion_with_powers_of_two}.

\hint
Uma ``distância'' está sendo cada vez menor.  Qual?

\solution
Com cada chamada com entrada $x$, o número $b - x$ é cada vez menor,
onde
$$
b = \min \setst {2^n} {x \leq 2^n, \ n\in\nats}.
$$

\endexercise
%%}}}

%%{{{ Dangerous recursion 
\note Recursão perigosa.
Não é cada equação recursiva que realmente defina uma função!
Vamos ver agora uns exemplos que mostram exatamente isso.
%%}}}

%%{{{ eg: dangerous_recursion_f 
\example.
\label{dangerous_recursion_f}%
Seja $f : \nats\to\nats$ a função definida pela
$$
f(n) = f(n),
\quad\text{para todo $n\in\nats$}.
$$
É óbvio que isso não \emph{determina} uma função.
Mas por quê?
\endexample
%%}}}

%%{{{ eg: dangerous_recursion_g 
\example.
\label{dangerous_recursion_g}%
Seja $g : \nats\to\nats$ a função definida pela
$$
\align
g(0) &= 1 \\
g(n) &= g(n)+1, \quad\text{para todo $n>0$}.
\endalign
$$
Isso também não \emph{determina} uma função.
Por quê?
\endexample
%%}}}

%%{{{ eg: dangerous_recursion_h 
\example.
\label{dangerous_recursion_h}%
Seja $h : \nats\to\nats$ a função definida pela
$$
h(n) = h(n+1), \quad\text{para todo $n\in\nats$}.
$$
Isso também não \emph{determina} uma função---mas por quê?
\endexample
%%}}}

%%{{{ x: what_is_the_problem_with_those_recursive_definitions 
\exercise.
\label{what_is_the_problem_with_those_recursive_definitions}%
As perguntas sobre as $f,g,h$ acima não foram rhetóricas!

\endexercise
%%}}}

%%{{{ eg: pre_collatz_safe 
\example.
\label{pre_collatz_safe}%
Considere a função $k : \nats \to \nats$ definida pela recursão
$$
\align
k(0) &= 1\\
k(1) &= 1\\
k(n) &=
\knuthcases{
k(n/2), & se $n$ é potência de $2$\cr
k(n+1), & caso contrário
}\quad\text{(para todo $n > 1$)}.
\endalign
$$
Aceitaria isso como uma definição duma função $k : \nats\to\nats$?
\endexample
%%}}}

%%{{{ eg: pre_collatz_unsafe 
\example.
\label{pre_collatz_unsafe}%
Considere a função $d : \nats \to \nats$ definida pela recursão
$$
\align
d(0) &= 1\\
d(1) &= 1\\
d(n) &=
\knuthcases{
d(n/2), & se $n$ é potência de $2$\cr
d(n+3), & caso contrário
}\quad\text{(para todo $n > 1$)}.
\endalign
$$
Aceitaria isso como uma definição duma função $d : \nats\to\nats$?
\endexample
%%}}}

%%{{{ x: reply 
\exercise.
Responda nas perguntas dos exemplos acima~(\refn{pre_collatz_safe}
e~\refn{pre_collatz_unsafe}).

\endexercise
%%}}}

%%{{{ x: calculate_pre_collatz 
\exercise.
\label{calculate_pre_collatz}%
Usando as $k,d : \nats\to\nats$ dos exemplos \refn{pre_collatz_safe}
e~\refn{pre_collatz_safe} acima calcule os:
$$
k(6); \quad
k(9); \quad
d(5); \quad
d(11);\quad
d(6).
$$
(Confira teus resultados com minha dica e minha resolução!)

\hint
Se tu achou valores para todas as expressões,
tu errou (pelo menos uma vez).
Todos eles são definidos exceto um!

\solution
Calculamos:
$$
\align
k(6)  &= k(7) = k(8) = k(4) = k(2) = k(1) = 1 \\
k(9)  &= k(10) = k(11) = k(12) = \dotsb = k(16) = k(8) \dotseq 1 \\
d(5)  &= d(8) = d(4) = d(2) = d(1) = 1 \\
d(11) &= d(14) = d(17) = d(20) = d(23) = d(26) = d(29) = d(32) = d(16) \dotseq 1 \\
d(6)  &= d(9) = d(12) = d(15) = d(18) = d(21) = d(24) = d(27) = d(30) = d(33) = d(36) = \dotsb
\endalign
$$
onde parece que o último cálculo \emph{nunca terminará}.
Deixo você se preocupar com a veracidade dessa afirmação
no~\ref{why_pre_collatz_unsafe_diverges_on_6}.

\endexercise
%%}}}

%%{{{ x: k_is_the_constant_one 
\exercise.
Qual é a função $k$ do~\ref{pre_collatz_safe}?
(Tu deves saber um nome dela bem simples.)

\solution
Ela é a função constante do $\nats$ com valor $1$.

\endexercise
%%}}}

%%{{{ eg: collatz_recursive 
\example.
\label{collatz_recursive}%
Considere a função $c : \nats \to \nats$ definida pela recursão
$$
\align
c(0) &= 1\\
c(1) &= 1\\
c(n) &=
\knuthcases{
c(n/2),  & se $n$ é par\cr
c(3n+1), & caso contrário
}\quad\text{(para $n > 1$)}.
\endalign
$$
E a mesma pergunta: aceita?
\endexample
%%}}}

%%{{{ x: calculate three values 
\exercise.
Calcule os valores $c(8), c(3), c(7)$ da função $c$ acima.

\endexercise
%%}}}

%%{{{ What's going on? 
\note O que tá acontecendo?.
\label{what_is_going_on_with_recursive_definitions}%
Já deve ser claro que apenas escrevendo umas equações que envolvem
a função que queremos definir não é uma maneira segura que garanta
que realmente nossas equações \emph{determinam} (definam) uma função.
Umas vezes deu certo, outras não.
Mas em todos os casos, a ``definição'' da função foi apenas uma
\emph{lista de equações}.%
\footnote{Foi mesmo?
Não exatamente: mas deixe isso para
depois~(\ref{not_exactly_a_list_of_equations}).}
Estamos procurando entender melhor essa situação:
um cara chega com um um bocado de equações como uma suposta definição
recursiva duma função, e a gente da uma olhada nelas, e aceita isso como
definição mesmo;
outro cara chega com \emph{o mesmo tipo de coisa} (um bocado de equações)
e no caso dele a gente falou ``desculpa mas isso não serve como
definição de função''.
O que tá acontecendo?
%%}}}

%%{{{ Do you remember school "math"? 
\note Lembra da ``matemática'' na escola?.
Lembra os \emph{sistemas de equações} em um ou mais
\emph{incógnitos} que tu precisou \emph{resolver}
estudando matemática básica?%
\footnote{Presumo aqui que o leitor já teve contato com esse
tipo de exercícios desde criança; mas caso contrário, espero
que a conversa vai continuar fazendo sentido.}
Por exemplo, um exercício pode pedir para o aluno:
\emph{resolva o sistema} seguinte nos reais ($x\in\reals$):
$$
\system{
x^2     &= 64 \\
10 + 2x &= 2 + x
}
$$
O aluno vai responder que
$$
\text{<<o sistema tem uma resolução única: $x = -8$>>}
$$
e vai ganhar um biscoito.
Esses sistemas são mais comuns em espaços de dimenções superiores
($\reals^2$, $\reals^n$, $\complex^n$, etc.).
Mas no final das contas, qual é o objectivo?
O que significa resolver um sistema deles?
Bem, significa dar uma das seguintes respostas:
\beginol
\li O sistema é impossível;
\li O sistema é possível e indeterminado;
\li O sistema é possível e determinado;
\endol
e nos dois últimos casos, queremos descrever todas as resoluções
se for indeterminado, ou achar sua única resolução caso que é determinado.
Uns sistemas no $\reals^2$ por exemplo são os:
$$
\xxalignat4
\text{(A)}&
\lsystem{
x^2 + y^2 &= 1 \\
y         &= 2x
}&
\text{(B)}&
\lsystem{
y &= x^2 + 8 \\
x &= y + 1
}&
\text{(C)}&
\lsystem{
x       &= 2y + 1 \\
3x - 6y &= 3
}&
\text{(D)}&
\lsystem{
x &= y^2 \\
y &= \sin(x).
}&
\endxxalignat
$$
Aqui o aluno deu umas respostas interessantes.
(A) O sistema é possível mas indeterminado: tem duas resoluções:
$\tupp{x,y} = \tupp{\sqrt3/2, 1/2}$
e
$\tupp{x,y} = \tupp{1/2,\sqrt3/2}$.
(B) O sistema é impossível: nenhum par $\tupp{x,y}\in\reals^2$
satisfaz ambas as equações.
(C) O sistema é possível mas indeterminado: todos os membros do
conjunto
$
\setst {\tupp{t, 2t+1} \in\reals^2} {t\in \reals}
$
satisfazem o sistema (e tem pelo menos dois membros nesse conjunto---na
verdade tem uma infinidade deles).
(D) O sistema é possível e determinado: tem resolução única, o
$\tupp{x,y} = \tupp{0,0}$.

%%{{{ remark: infinite_does_not_mean_all_eg_systems 
\remark.
\label{infinite_does_not_mean_all_eg_systems}%
O fato que um sistema tem uma infinidade de resoluções, não quis
dizer que \emph{todos} os possíveis candidatos são resoluções.
Por exemplo o sistema~(3) acima tem uma infinidade de resoluções,
mas não são todos os membros do $\reals^2$ que servem: considere
o $\tupp{x,y} \asseq \tupp{1,1}$ por exemplo.
%%}}}

%%}}}

%%{{{ Recursive definitions as systems to solve 
\note Definições recursivas como sistemas para resolver.
O que isso tem a ver com as definições recursivas?
No primeiro sistema acima estamos procurando \emph{números reais},
ou seja, estamos procurando determinar o \alert{incógnito}
$\alert x\in\reals$ que consegue satisfazer todas as suas equações.
$$
\align
\system{
\alert x^2     &= 64 \\
10 + 2\alert x &= 2 + \alert x
}&
\intertext{%
Podemos pensar então que todos os reais são candidatos consideráveis
aqui, e nosso trabalho é achar quem serve para o sistema (se é possível)
e quem não.
Testando então para o $\alert x\asseq 8$ temos:
}
\system{
\alert x^2            &= 64 \\
10 + 2\ntimes\alert x &= 2 + \alert x
}&\quad\leadsto\quad
\system{
\alert 8^2            &= 64 \\
10 + 2\ntimes\alert 8 &= 2 + \alert 8
}
\endalign
$$
e assim percebemos que o $8$ \emph{não} serve pois tem pelo menos uma
equação que ele não satisfaz.
E a situação é similar resolvendo sistemas com incógnitos membros
de $\reals^2$ ou $\complex^n$, etc., onde procuramos um par de números
reais no primeiro caso, ou $n$ números complexos no segundo, etc.
Testamos então o $(\sqrt 2, 0)$ nos sistemas
$$
\xxalignat4
\text{(A)}&
\lsystem{
\alert x^2 + \alert y^2 &= 1 \\
\alert y         &= 2\alert x
}&
\text{(B)}&
\lsystem{
\alert y &= \alert x^2 + 8 \\
\alert x &= \alert y + 1
}&
\text{(C)}&
\lsystem{
\alert x       &= 2\alert y + 1 \\
3\alert x - 6\alert y &= 3
}&
\text{(D)}&
\lsystem{
\alert x &= \alert y^2 \\
\alert y &= \sin(\alert x).
}&
\endxxalignat
$$
etc., etc.
\endgraf
Agora te convido olhar para todas as definições recursivas que a gente
encontrou aqui com uma maneira similar:
\emph{como sistemas}, onde agora \emph{o incógnito não é um número real
mas uma função no $(\nats\to\nats)$}.
%%}}}

%%{{{ eg: fibs again 
\example.
Considere o sistema que usamos para definir a função $b$
do~\ref{fact_and_fib_recursive_eg}.
$$
\system{
\alert b(0) &= 0 \\
\alert b(1) &= 1 \\
\alert b(n) &= \alert b(n-1) + \alert b(n-2), \quad\text{para todo $n>1$}.
}
$$
Agora o incógnito é uma função $b : \nats\to\nats$.
Vamos testar uns candidatos consideráveis:
tome $b \asseq \idof \nats$:
$$
\align
\rsystem{
\alert {\idof \nats}(0) &= 0\\
\alert {\idof \nats}(1) &= 1\\
\alert {\idof \nats}(n) &= \alert {\idof \nats}(n-1) + \alert {\idof \nats}(n-2)
}
&\iff
\lsystem{
0 &= 0\\
1 &= 1\\
n &= (n-1) + (n-2),\quad\text{para todo $n>1$}.
}
\intertext{%
Legal!  As duas primeiras linhas do sistema são satisfeitas.
Para a terceira, testando com o $n\asseq 3$ dá certo, pois realmente
$3 = 2 + 1$
mas é muito fácil perceber que essa igualdade não é satisfeita em geral.
Tome $n\asseq 4$ e já temos problema, pois
$4 \neq 3 + 2$.
O candidato $\idof \nats$ então não satisfaz o sistema.
Próximo!
Vamos tentar com $b \asseq \succ$, essa vez divulgando a notação
mais econômica, sem parenteses:
}
\rsystem{
\alert {\succ}\fa 0 &= 0\\
\alert {\succ}\fa 1 &= 1\\
\alert {\succ}\fa n &= \alert {\succ} \fap {n-1} + \alert {\succ} \fap {n-2}
}
&\iff
\lsystem{
1   &= 0\\
2   &= 1\\
n+1 &= n + (n-1),\quad\text{para todo $n>1$}.
}
\endalign
$$
Fuen-fuen-fuen!
Bem, então nem a $\idof \nats$ nem a $\succ$ satisfazem esse sistema.
\endexample
%%}}}

%%{{{ remark: not_exactly_a_list_of_equations 
\remark.
\label{not_exactly_a_list_of_equations}%
No~\ref{what_is_going_on_with_recursive_definitions}
afirmei que cada suposta definição de função foi ``apenas
uma lista de equações''.
São realmente listas de \emph{equações?}
Umas dessas afirmações não são equações não;
pois em vez de ter a forma ``\,${\lthole} = {\lthole}$\,''
elas têm a forma ``\,$\forall n {\lthole}$\,''.
Ou seja, correspondem em proposições universais
(quantificadas universalmente) e não em proposições
(atômicas) de equações.
Mas não seria errado considerar que essas são listas de
equações sim, com o acordo que\dots são listas infinitas!
Pois sim, podemos ver cada uma dessas como um \emph{esquema}
de equações que fornece uma equação para cada escolha de $n\in\nats$.
%%}}}

%%{{{ When a system serves as a definition.
\note Quando um sistema serve para definir.
Quando um sistema cujos incógnitos são números tem resolução
única isso quis dizer que o sistema \emph{determina}
um certo número.  Ou seja, \emph{podemos usar o próprio sistema
para definir um número real} como a resolução dele.
Por exemplo, escrevemos
<<seja $r\in\reals$ \emph{a} resolução do sistema tal>>, etc.
Observe o artigo definido!
No outro lado, se o sistema tem várias resoluções,
\emph{não pode servir como definição;} mas pelo menos
sabendo que o conjunto das suas resoluções não é vazio
podemos escrever, por exemplo,
<<seja $t\in\reals$ \emph{uma} resolução do sistema tal>>.
E nada muda com sistemas cujos incognitos são funções!
E por que mudaria?  No final das contas é a existência
e unicidade de algo que nos permite defini-lo!
%%}}}

\blah.
Voltamos agora para o sistema que usamos para definir
as funções $a,b$ do~\ref{fact_and_fib_recursive_eg}.

%%{{{ Q: Do you know of a solution to a or b's systems ?
\question.
Tu conhece alguma função que satisfaz o sistema da $a$?
Alguma que satisfaz o sistema da $b$?
%%}}}
\spoiler.

%%{{{ A: Common answer 
\blah Resposta comum.
\emph{Possivelmente} o leitor respondeu
\quote
<<Sim:
o factorial para o primeiro, e a função fibonacci para o segundo.>>
\endquote
ou algo similar.
Só que: eu esqueci quais são essas funções.
Pode lembrar pra mim, por exemplo, qual é essa função ``fibonacci''
que tu tá afirmando que é uma resolução do sistema da $b$?
\quote
<<Claro.  Vou escrever esse poeminho mágico para dar a sua\dots>>
\endquote
%%}}}

%%{{{ df: fibonacci_dangerous_def 
\definition.
\label{fibonacci_dangerous_def}%
Seja $\fib:\nats\to\nats$ definda pelas
$$
\text{(FIB)}\ \lsystem{
\fib \fa 0 &= 0\\
\fib \fa 1 &= 1\\
\fib \fa n &= \fib\fap {n-1} + \fib\fap {n-2}, \quad\text{para todo $n>1$}.
}
$$
\mistake
%%}}}

%%{{{ Q: Is there a problem? 
\question.
Tem problema?
%%}}}
\spoiler.

%%{{{ A: We used fib to justify its own definition!
\blah Resposta.
Usamos a própria coisa que queremos definir (a função fibonacci)
para justificar sua própria definição (ou seja, para argumentar
que o sistema (FIB) tem resolução única)!
(E sobre o factorial seria a mesma coisa.)
Como a $\fib$ foi definida pelas equações recursivas do (FIB),
sua definição \emph{depende da existência e unicidade da
resolução do sistema}, então não podemos usá-la antes
de provar isso!
%%}}}

%%{{{ We can't prove existence yet; assume it and prove uniqueness 
\note.
{\Fibonacci[função]}%
Infelizmente, caro Fibonacci, não estamos prontos neste momento
para provar que esse sistema tem \emph{pelo menos} uma resolução!%
\footnote{%
Mas calma, daqui uns capítulos estaremos!
}
Atrás desse fato fica o poderoso
Teorema\ii{teorema}[de recursão]\ de Recursão~\refn{recursion_theorem}.
Mas pelo menos deve ser fácil provar que tem \emph{no máximo}
uma resolução:
%%}}}

%%{{{ x: fib_system_has_at_most_one_solution 
\exercise.
\label{fib_system_has_at_most_one_solution}%
Prove que se o sistema (FIB) da~\ref{fibonacci_dangerous_def}
tem resolução, então ela é única.

\hint
Por ``fight club'':
suponha que $f,f'$ são resoluções do sistema (FIB);
demonstre que $f=f'$.

\hint
Ou seja, basta demonstrar que para todo $n\in\nats$, $f n = f'n$.

\hint
Indução!

\hint
Vai precisar de duas bases.

\solution
Sejam $f,f'$ resoluções do sistema (FIB).
Vou provar por indução que:
$$
\lforall {n\in \nats} {f n = f'n}.
$$
Vou provar duas bases, ganhando assim 2 hipoteses indutivas.
\crproofpart{Base 0:}
Calculamos:
\compute
f(0)  &= 1 \by {$f$ resolução de (FIB)}
f'(0) &= 1 \by {$f'$ resolução de (FIB)}
\endcompute
\crproofpart{Base 1:}
Mesma coisa: $f(1) = 1 = f'(1)$.
\crproofpart{Passo indutivo.}
Seja $k\in \nats$ tal que $f,f'$ concordam nos pontos $k-1$ e $k-2$:
$$
\xxalignat4
\text{(H.I.1)} & & f(k-1) &= f'(k-1) & f(k-2) &= f'(k-2). & & \text{(H.I.2)}
\endxxalignat
$$
Preciso demonstrar que elas concordam no ponto $k$ também:
\compute
f(k)
&= f(k-1) + f(k-2)   \by {$f$ resolução de (FIB)}
&= f'(k-1) + f'(k-2) \by {(H.I.1) e (H.I.2)}
&= f'(k).            \by {$f'$ resolução de (FIB)}
\endcompute
Pronto.

\endexercise
%%}}}

%%{{{ x: why_each_of_the_non_definitions_fails 
\exercise.
\label{why_each_of_the_non_definitions_fails}%
Com esse novo ponto de vista, para cada uma
das supostas definições das funções $f,g,h:\nats\to\nats$
(dos exemplos~\refn{dangerous_recursion_f},
\refn{dangerous_recursion_g}, e~\refn{dangerous_recursion_h})
responda na pergunta: por que não deu certo?
$$
\xalignat3
(1)~&\lsystem{
f(n) &= f(n)
}&
(2)~&\lsystem{
g(0) &= 1 \\
g(n) &= g(n)+1
}&
(3)~&\lsystem{
h(n) &= h(n+1)
}
\endxalignat
$$
Foi porque o sistema não tem resoluções?
Ou porque tem várias?  Tem infinítas?  Tem todas?

\solution
Sobre a $f$:
toda função $f : \nats\to\nats$ satisfaz essa equação,
então não podemos usá-la como definição!
\endgraf
Sobre a $g$:
nenhuma função $g : \nats\to\nats$ satisfaz essa equação,
então não podemos usá-la como definição!
\endgraf
Sobre a $h$:
mais que uma função $h : \nats \to \nats$ satisfaz essa equação,
então não podemos usá-la como definição!

\endexercise
%%}}}

%%{{{ x: which_functions_satisfy_the_equations_of_h 
\exercise.
\label{which_functions_satisfy_the_equations_of_h}%
Quais são exatamente as funções que satisfazem a ``definição''
da $h$ acima?

\hint
Suponha que uma $h : \nats\to\nats$ satisfaz essa
definição, e suponha que seu valor $h(5) = v$
para algum $v\in\nats$.  O que podes concluir
sobre os valores da $h$ para suas outra entradas?

\solution
Todas as funções constantes.

\endexercise
%%}}}

%%{{{ x: why_recursive_collatz_does_not_define_a_function 
\exercise.
\label{why_recursive_collatz_does_not_define_a_function}%
Qual o problema com a definição da função $c$ do~\ref{collatz_recursive}?

\hint
Por que termina a recursão para toda entrada?

\solution
Não sabemos se ela satisfaz a totalidade de função, ou seja,
se ela é realmente definida em todo o seu domínio.
Ate agora, ninguém sabe dizer!
Essa é exatamente a conjectura de
\Collatz[conjectura]{}Collatz~(\ref{collatz_conjecture}).

\endexercise
%%}}}

\blah.
Deixamos esse assunto por enquanto (até o~\ref{Theory_of_recursive_functions}),
supondo que temos já um entendimento de como definições recursivas
funcionam.

\endsection
%%}}}

%%{{{ Fixpoints 
\section Fixpoints.
\label{Fixpoints}%

%%{{{ df: fixpoint 
\definition Fixpoint.
\label{fixpoint}%
\tdefined{fixpoint}%
\iisee{função!fixpoint}{fixpoint}%
Seja $f : A \to A$ um endomapa num conjunto $A$.
Chamamos \dterm{fixpoint} da $f$ qualquer $x\in A$ tal que
$f(x) = x$.
%%}}}

%%{{{ x: fixpoint_iff_iterations 
\exercise.
\label{fixpoint_iff_iterations}%
Prove a afirmação:
$$
\text{$x$ é um fixpoint da $f$}
\iff
\text{para todo $n\in\nats$, $x$ é um fixpoint da $f^n$}.
$$

\hint
A {\rldir} é muito fácil; para a {\lrdir} use indução.

\solution
\proofpart{\lrdir}:
Suponha $x$ é um fixpoint da $f$.
Vamos provar o que precisamos por indução no $n$.
\proofpart{Base:}
Calculamos:
\compute
f^0 (x)
&= 1_A (x)  \by {pela def.~da $f^0$}
&= x        \by {pela def.~da $1_A$}
\endcompute
e logo $x$ é um fixpoint da $f^0$.
\proofpart{Passo indutivo:}
Suponha $k\in\nats$ tal que $x$ é um fixpoint da $f^k$ (H.I.).
Calculamos:
\compute
f^{k+1}(x)
&= (f \of f^k)(x)   \by {pela def.~de $f^{k+1}$}
&= f\paren{f^k(x)}  \by {pela def.~de $f\of f^k$}
&= f( x )           \by {pois $x$ é um fixpoint da $f^k$ (H.I.)}
&= x                \by {pois $x$ é um fixpoint da $f$}
\endcompute
e logo $x$ é um fixpoint da $f^{k+1}$.
\crproofpart{\rldir}:
Usando nossa hipótese com $n \asseq 1$, temos que $x$ é um fixpoint da $f^1$.
Mas $f^1$ é a própria $f$ (pois $f^1 = f \of f^0 = f \of 1_A = f$)
e logo $x$ é um fixpoint da $f$.

\endexercise
%%}}}

%%{{{ x: fix_f_properties 
\exercise.
\label{fix_f_properties}%
Seja $f : A \to A$,
e seja $F$ o conjunto de todos os fixpoints da $f$.
$$
F = \setstt {x \in A} {$x$ é um fixpoint da $f$}
$$
Quais das igualdades seguintes podemos concluir?:
$$
\xalignat2
\img f F &= F &
\pre f F &= F
\endxalignat
$$
Prove aquelas que sim; mostre um contraexemplo daquelas que não,
mas verifique se alguma das duas inclusões
{\lrdirset} ou {\rldirset} é válida.
O que muda se $f$ é injetora?

\solution
Sempre temos $\img f F = F$ e $\pre f F \supset F$.
Se $f$ é injetora, ganhamos a $\pre f F \subset F$ também.
\endgraf
\proofpart{{\proofname} de $\img f F \subset F$.}
Seja $y\in\img f F$.
Logo tome $p\in F$ tal que $f(p) = y$\fact1 (pela definição da função-imagem).
Logo $p$ é um fixpoint da $f$, ou seja, $f(p) = p$\fact2.
Juntando as {\byfact1} e~{\byfact2}, ganhamos $p = y$, ou seja $y$ é um fixpoint da $f$, e logo $y\in F$.
\endgraf
\proofpart{{\proofname} de $\img f F \supset F$.}
Seja $p \in F$.
Logo $f(p) \in \img f F$ (pela definição da função-imagem).
Mas $p$ é um fixpoint da $f$ (pois $p\in F$), ou seja $f(p) = p$.
Logo $p \in \img f F$.
\endgraf
\proofpart{{\proofname} de $\pre f F \supset F$.}
Seja $p \in F$, ou seja $p$ é um fixpoint da $f$.
Logo $f(p) = p \in F$, e logo $p \in \pre f F$.
\endgraf
\proofpart{Contraexemplo para $\pre f F \subset F$.}
Tome $A = \set{0,1}$ e defina $f$ pela $f(x) = 0$.
Nesse caso temos $F = \set{0}$, mas $\pre f F = \set{0,1}$.
\endgraf
\proofpart{{\proofname} da $\pre f F \subset F$ quando $f$ injetora.}
Seja $a\in \pre f F$.
Logo $f(a)$ é um fixpoint da $f$.
Ou seja, $f(f(a)) = f(a)$
Agora, como $f$ é injetora, temos $f(a) = a$, ou seja,
$a$ é um fixpoint também e logo $a\in F$.

\endexercise
%%}}}

\blah.
Ok, eu sei: parece estranho dedicar uma secção só pra isso.
Mas os fixpoints vão fazer um papel importantíssimo depois,
e logo queria destacá-los desde já.  Paciência.

\endsection
%%}}}

%%{{{ Coproduct; disjoint union 
\section Coproduto; união disjunta.
\label{Coproduct}%

\blah.
Vamos voltar no~\ref{funion}.
(Se tu não resolveu ainda, volte a resolver agora, antes de continuar.)
Definimos o $f \union g$ a partir de duas funções $f$ e $g$ mas a
situação não foi tão agradável como esperamos (cf.~$f \cross g$):
necessitamos restrições adicionais.

%%{{{ Q: Whose fault is it? 
\question.
Quem é o culpado?
%%}}}
\spoiler.

%%{{{ A: The union! 
\note Resposta.
A união!
O conjunto que $\union$ construiu, ο $A\union B$, não é útil aqui.
Nem se compara com o $A \cross B$, em questão de
utilidade e elegância.
Alem disso---caso que os conjuntos são finitos por enquanto---%
com o produto tivemos a lei bacana
$$
\align
\card{A \cross B} &= \card A \ntimes \card B.
\intertext{%
A união não é tão legal, pois não consegue garantir igualdade
mas apenas
}
\card{A \union B} &\leq \card A + \card B.
\endalign
$$
Decepção de novo!
Será que podemos descobrir um outro operador binário
que comportaria numa maneira tão legal como o~$\cross$?
%%}}}

%%{{{ constructing the coproduct 
\note Contruindo o coproduto.
$$
\tikzpicture
\tikzi disjunion0;
\endtikzpicture
$$
unindo:
$$
\tikzpicture
\tikzi disjunion1;
\endtikzpicture
$$
Em vez disso, vamos criar cópias $A',B'$ dos $A,B$ numa maneira
que garanta que os $A',B'$ são disjuntos.
Por exemplo, pintamos todos os membros de $A$ azuis e de $B$ vermelhos:%
\footnote{%
Leitores sem acesso nessas cores neste texto vão ficar confusos aqui;
mas paciência pois uma definição formal tá chegando já já; uma que
não necessita telas e impressoras (e olhos?)~chiques.
}
$$
\tikzpicture
\tikzi disjunion2;
\endtikzpicture
$$
Os conjuntos agora são disjuntos
(observe que $\alertB 4 \neq \alertR 4$ e $\alertB5 \neq \alertR 5$)
então vamos simplesmente uni-los:
$$
\tikzpicture
\tikzi disjunion3;
\endtikzpicture
$$
e nesse caso vamos tomar $A \disjunion B \asseq A' \union B'$.
Observe que esse processo descrito aqui garanta mesmo que
\compute
\card{A \disjunion B}
&= \card{A' \union B'}      \by {def.~$A\disjunion B$}
&= \card {A'} + \card {B'}  \by {$A',B'$ disjuntos}
&= \card A + \card B.       \by {$\card A = \card A'$ e $\card B = \card B'$}
\endcompute
Parece então que conseguimos definir o operador de união disjunta.
%%}}}

%%{{{ the or one? 
\note ``O'' ou ``um''?.
A descrição acima envolve um passo bem ambiguo:
a \emph{contruição das cópias} $A', B'$.
Com certeza existem muitas maneiras diferentes de conseguir essas
cópias e a gente so descreveu uma---inclusive nem formalmente, mas
dá pra fazer (\ref{formal_equivalent_of_painting}).
Precisamos escolher uma pra realmente definir nosso operador.
%%}}}

%%{{{ x: formal_equivalent_of_painting 
\exercise.
\label{formal_equivalent_of_painting}%
Ache algo matematicamente formal que podes usar em vez do informal
<<pintar os membros do $A$ de azul e do $B$ de vermelho>>.

\solution
Em vez de cores, tagamos cada membro de $A$ com um $0$ e cada
membro de $B$ com um $1$:
$$
\alignat2
A' &\asseq \set{0} \cross A = \setst {(0,a)} {a \in A} &
B' &\asseq \set{1} \cross B = \setst {(1,b)} {b \in B}.
\endalignat
$$

\endexercise
%%}}}

%%{{{ df: disjunion_aka_coproduct 
\definition união disjunta ou coproduto.
\label{disjunion_aka_coproduct}%
\tdefined{coproduto}%
\tdefined{união disjunta}%
\sdefined {\sholed A \coprod \sholed B} {o coproduto de $A$ e $B$}
\sdefined {\sholed A \disjunion \sholed B} {a união disjunta de $A$ e $B$}
Sejam $A,B$ conjuntos.
Definimos o \dterm{coproduto}
$$
A \coprod B \defeq \paren{\set{0} \cross A} \union \paren{\set{1} \cross B}.
$$
Generalizmos para qualquer família indexada $\famil A i {\cal I}$:
$$
\tsize\Coprod_i A_i \defeq \Union_i \paren{\set{i} \cross A_i}.
$$
Também usamos o termo \dterm{união disjunta};
e a notações correspondente $A \dunion B$ para o caso binário;
e a $\Dunion_i A_i$ para famílias.
%%}}}

%%{{{ remark: sum type notation teaser 
\remark.
No contexto de teoria dos tipos (\ref{Type_theory}) o tipo correspondente
é chamado \dterm{sum type} e usamos as notações $A \plus B$ e $\Sum_i A_i$.
%%}}}

%%{{{ choosers_coproduct 
\note Nível coração: escolhedores.
\tdefined{escolhedor}[coproduto]%
Seja $\famil A i {\cal I}$ família de conjuntos.
Lembre-se que enxergamos (\refn{choosers_product}) cada membro
do produto $\Prod_i A_i$ como um escolhedor:
ele escolhe exatamente um membro \emph{de cada $A_i$}.
Podemos enxergar um membro do coproduto como um escolhedor
também.
Mas antes disso, vamos ver se podemos enxergar o arbitrário
membro do $\Union_i A_i$ como escolhedor.
Sim: o $a\in\Union_i A_i$ representa o escolhedor que escolha
o $a$ de todos os membros que pertencem em qualquer um dos $A_i$'s.
No coproduto a situação é mais informativa e interessante:
o arbitrário membro do $\Coprod_i A_i$ parece assim:
$(j, a)$, onde $j\in\cal I$ e $a \in A_j$.
Ou seja, parece uma escolha rotulada, que selecionou um membro do
conjunto com seu rótulo e nada mais.
Vamos comparar três escolhedores $P,C,U$ então:
$$
\xalignat3
\vphantom{\Coprod_i}
P &\tsize\in \Prod_i A_i &
C &\tsize\in \Coprod_i A_i &
U &\tsize\in \Union_i A_i.
\endxalignat
$$
Podemos perguntar ao $P$:
\dialogue
\say Qual foi tua escolha do $A_j$?
\say Do $A_j$ escolhi o $u$.
\say E do $A_k$?
\say Do $A_k$ escolhi o $v$.
\enddialogue
etc., e vamos ter uma resposta para cada um dos $A_i$'s.
Ao $C$ perguntamos:
\dialogue
\say Quem tu escolheu?
\say Escolhi o $x$ por dentro do $A_w$.
\enddialogue
E ao $U$ perguntamos:
\dialogue
\say Quem tu escolheu?
\say Escolhi o $x$.
\say Donde?
\say Como assim?
\say Onde tu achou esse $x$, em qual dos $A_i$'s?
\say Sei-lá!  Foi num deles.  Não lembro.  Não quero dizer.
\enddialogue
%%}}}

%%{{{ x: fpair_for_union_and_coprod 
\exercise.
\label{fpair_for_union_and_coprod}%
Imite a idéia da construcção do $\fpair f g$ (\ref{fpair}) que baseamos no
$\cross$ para construir algo parecido baseado no $\union$, e algo baseado
no $\coprod$.
Qual dos dois parece comportar melhor?
(Nossa referência de comportamento aqui é a construcção baseada no $\cross$.)

\endexercise
%%}}}

%%{{{ x: product_vs_coproduct_diagrams 
\exercise.
\label{product_vs_coproduct_diagrams}%
O que tu percebes sobre os diagramas comutativos
do $\cross$ (\ref{fpair}) e do $\coprod$ que desenhou
no~\ref{fpair_for_funion_and_coprod}?

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ From a solution to a problem to a theory 
\section Duma resolução para um problema para uma teoria.

%%{{{ from a solution to a problem 
\note Duma resolução para o problema.
\label{from_a_solution_to_a_problem_first_uniprop}%
Aqui o produto cartesiano $A\cross B$ que chega junto com suas projecções
$\outl : A \cross B \to A$ e $\outr : A \cross B \to B$:
$$
\cdopt{sep=1cm}
                                                                          \| A \\
A\cross B \ar[ur, bend left=15, "\outl"] \ar[dr, bend right=15, "\outr"'] \|   \\
                                                                          \| B
\endcd
$$
Esse bicho junto com suas duas setinhas, $\tupp{\outl, A\cross B, \outr}$
tem uma propriedade \emph{muito interessante:}
para cada \dterm{impostor} $\tupp{f_1,F,f_2}$:
$$
\cdopt{sep=1cm}
                                                              \| A \\
F \ar[ur, bend left=15, "f_1"] \ar[dr, bend right=15, "f_2"'] \|   \\
                                                              \| B
\endcd
\quad\implies\quad
\cdopt{sep=1cm}
                                   \| \|                                  \| A \\
F
\ar[rr, dotted, "\unique"]
\ar[urrr, bend left=24,  "f_1"]
\ar[drrr, bend right=24, "f_2"']   \| \| A\cross B
                                         \ar[ur, bend left=15, "\outl"]
                                         \ar[dr, bend right=15, "\outr"'] \|   \\
                                   \| \|                                  \| B
\endcd
$$
A partir dessa \emph{resolução}, vamos descobrir um \emph{problema:}
determine os $\alertR?$ no
$$
\cdopt{sep=1cm}
                                                                               \| A \\
\alertR? \ar[ur, bend left=15, "\alertR?"] \ar[dr, bend right=15, "\alertR?"'] \|   \\
                                                                               \| B
\endcd
$$
tais que para todo $\tupp{f_1,F,f_2}$,
$$
\cdopt{sep=1cm}
                                                              \| A \\
F \ar[ur, bend left=15, "f_1"] \ar[dr, bend right=15, "f_2"'] \|   \\
                                                              \| B
\endcd
\quad\implies\quad
\cdopt{sep=1cm}
                                   \| \|                                     \| A \\
F
\ar[rr, dotted, "\alertB\unique"]
\ar[urrr, bend left=24,  "f_1"]
\ar[drrr, bend right=24, "f_2"']   \| \| \alertR?
                                         \ar[ur, bend left=15, "\alertR?"]
                                         \ar[dr, bend right=15, "\alertR?"'] \|   \\
                                   \| \|                                     \| B
\endcd
$$
Observe que realmente o $\tupp{\alertR\outl, \alertR{A\cross B}, \alertR\outr}$
é uma resolução desse problema.
%%}}}

\TODO Escrever.

\endsection
%%}}}

%%{{{ Categories 
\section Pouco de cats---um primeiro toque de categorias.
\label{Categories_a_first_taste}%

\blah.
Podemos \emph{finalmente} introduzir pouca da linguagem e das
idéias principais das \emph{categorias} para ter na nossa disposição
antes de chegar no~\ref{Category_theory} onde vamos fazer mesmo
nossos primeiros passos na teoria das categorias.
O que é uma categoria?

%%{{{ df: category_first_def 
\definition categoria.
\label{category_first_def}%
Uma \dterm{categoria} $\cat C$ é composta por duas colecções de coisas:
\beginul
\li $\Obj {\cat C}$: os \dterm{objetos} da $\cat C$, que denotamos por $A,B,C,\dots$;
\li $\Arr {\cat C}$: as \dterm{setas} da $\cat C$, que denotamos por $f,g,h,\dots$;
\endul
tais que:
\beginol
\li Para toda seta $f$ do $\Arr {\cat C}$, são determinados dois objetos:
    o \dterm{source} da $f$ e o \dterm{target} da $f$, denotados por
    $\src f$ e $\tgt f$ respectivamente.
    Escrevemos $f : A \to B$ para afirmar que $f$ é uma seta,
    e que $\src f = A$ e $\tgt f = B$.
    Denotamos por $\Hom(A,B)$ a colecção de todas as setas de $A$ para $B$.
\li Para cada objeto $A$ da $\cat C$ é determinada uma seta $\oneof A : A \to A$
    chamada \dterm{a identidade do $A$}.
\li Dados objetos $A,B,C$ e setas $A \toby f B \toby g C$ é determinada uma seta
    $g \of f : A \to C$ chamada \dterm{a composição da $g,f$}
    (ou \dterm{``$g$ de $f$''}\/; ou \dterm{``$g$ seguindo $f$''}\/)
    que freqüentemente denotamos por $gf$ ou $f \dcom g$.
    Ou seja, dados quaisquer objetos $A,B,C$ temos um operador de composição
    $$
    \oflab ABC : \Hom(B,C) \times \Hom(A,B) \to \Hom(A,C).
    $$
\endol
Tudo isso é o que temos numa categoria.
Mas apenas \emph{ter} tudo isso não é suficiente.
Essas coisas todas devem satisfazer as \dterm{leis de categoria:}
\beginul
\li
Para todas as setas $A \toby f B \toby g C \toby h D$ temos:
$$
(hg)f = h(gf). \tag{C-Ass}
$$
\li
Para toda seta $A \toby f B$ temos:
$$
f \oneof A = f = \oneof B f. \tag{C-Id}
$$
\endil
%%}}}

%%{{{ remark: operations from the definition of a category 
\remark.
Observe que a~\ref{category_first_def} está nos dando operações:
$$
\cd
\Arr{\cat C}
\ar[r, shift left, "\src"]
\ar[r, shift right, "\tgt"'] \| \Obj{\cat C}.
\endcd
$$
E também
$$
\cd
\Obj{\cat C} \ar[r, "\id"] \| \Arr{\cat C} \\
A   \ar[r, maps to, "\id"] \| \oneof A
\endcd
\qquad
\cd
\Hom(B,C) \cross \Hom(A,B) \ar[r, "\of"]          \| \Hom(A,C) \\
\tup{g,f}                  \ar[r, maps to, "\of"] \| gf
\endcd
$$
%%}}}

%%{{{ eg: SET 
\example conjuntos.
\label{SET}%
\sdefined {\SET} {a categoria dos conjuntos e suas funções}%
A $\SET$ com objetos os conjuntos e setas as funções entre conjuntos
é uma categoria.
\endexample
%%}}}

%%{{{ x: SET_is_a_cat 
\exercise.
\label{SET_is_a_cat}%
Verifique.

\endexercise
%%}}}

%%{{{ eg: INTLEQ 
\example inteiros com ordem.
\label{INTLEQ}%
Denotamos por $\INTLEQ$ a categoria cujos objetos são os inteiros
e entre dois objetos $A,B$ existe seta $f$ sse $A \leq B$.
Observe que o que são mesmo as setas não importa, mas caso que
insista para defini-las podemos considerar a única seta de $A$
para $B$ pra ser o par $\tup{A,B}$.

\endexample
%%}}}

%%{{{ x: INTLEQ_is_a_cat 
\exercise.
\label{INTLEQ_is_a_cat}%
Demonstre que a suposta categoria do \ref{INTLEQ}
realmente é uma categoria mesmo.
Deixe claro o que precisas demonstrar mesmo; e demonstre.

\endexercise
%%}}}

%%{{{ eg: INTDIV 
\example inteiros com divide.
\label{INTDIV}%
Similarmente definimos a $\INTDIV$:
aqui temos seta $f : A \to B$ sse $A \divides B$.
\endexample
%%}}}

%%{{{ x: INTDIV_is_a_cat 
\exercise.
\label{INTDIV_is_a_cat}%
Demonstre que a suposta categoria do \ref{INTDIV} realmente
é uma categoria.

\endexercise
%%}}}

\blah.
Queremos trazer o conceito de isomorfismo pra cá, pra ser aplicável
em qualquer categoria.  Observe que não podemos usá-lo mesmo,
pois na $\SET$ definimos o isomorfismo pra ser sinônimo de bijecção.
E não temos como falar ``bijecção'' no contexto abstrato de categorias.

%%{{{ x: why_cannot_use_bijective_in_cat 
\exercise.
Por que não?

\solution
Pois a definição de função bijectiva (como injectiva e surjectiva) usou
a natureza dos objetos e das setas e não apenas suas propriedades
categóricas.  (Dependeu dos \emph{pontos} dos domínio e do codomínio.)

\endexercise
%%}}}

\blah.
Mesmo assim, podemos definir o que significa que uma seta é \emph{iso},
numa maneira que acaba sendo equivalente a ser bijectiva quando aplicada
na $\SET$:

%%{{{ df: iso 
\definition iso.
\tdefined{iso}%
Seja $\cat C$ uma categoria e $f : A \to B$ uma das suas setas.
Chamamos a $f$ de \dterm{iso} sse $f$ é invertível:
$$
\text{$f$ iso}
\defiff
\lexists {f' : B \to A} {f'f = \oneof A \mland ff' = \oneof B}.
$$
Nesse caso chamamos os objetos $A,B$ isómorfos ou isomórficos
e as vezes escrevemos $f : A \isoto B$.
%%}}}

%%{{{ df: initial_terminal_null_objects 
\definition iniciais, terminais.
\label{initial_terminal_null_objects}%
Numa categoria $\cat C$, um objeto $S$ é \dterm{inicial} sse
para todo objeto $X$, existe única seta $S \toby ! X$.
Similarmente, um objeto $T$ é \dterm{terminal} sse
para todo objeto $X$, existe única seta $X \toby ! T$.
Sinônimos de terminal: \dterm{final}, \dterm{terminador};
sinônimos de inicial: \dterm{coterminal}, \dterm{coterminador}.
Um objeto inicial e terminal é chamado \dterm{nulo}.
%%}}}

%%{{{ x: null_unique_up_to_iso 
\exercise.
\label{null_unique_up_to_iso}%
Todos os objetos nulos duma categoria $\cat C$
são isómorfos.
Em outras palavras, se $\cat C$ tem objeto nulo,
ele é \emph{único a menos de isomorfismos}.

\endexercise
%%}}}

%%{{{ x: zero_arrow 
\exercise seta zero.
\label{zero_arrow}%
Seja $Z$ um objeto nulo duma categoria $\cat C$.
Dados quaisquer objetos $A,B$ existe uma única seta
que ``passa pelo $Z$'':
$$
A \toby! Z \toby! B
$$
(a composição das setas acima)
onde entendemos que os $!$ nas setas indicam que
essa seta é \emph{a única seta} desse objeto para
aquele objeto.

\endexercise
%%}}}

%%{{{ beware: some use terminal for either term 
\beware.
Na literatura as vezes aparece o termo ``terminal'' para
significar tanto ``inicial'' quanto ``final''.
Se o contexto deixa claro qual dos dois é, procure
a definição.
%%}}}

%%{{{ eg: initial_and_terminal_of_SET 
\example.
\label{initial_and_terminal_of_SET}%
A categoria $\SET$ possui iniciais?  Terminais?  Quais?

\solution
Sim e sim.
Demonstraste isso no~\ref{first_contact_with_initial_and_terminal_objects}:
$\emptyset$ é seu único objeto inicial; e cada singleton é um final.
\endexample
%%}}}

%%{{{ x: initial_terminal_of_INTLEQ 
\exercise.
\label{initial_terminal_of_INTLEQ}%
A categoria $\INTLEQ$ tem iniciais?  Terminais?  Se sim, quais são?

\endexercise
%%}}}

%%{{{ x: initial_terminal_of_INTDIV 
\exercise.
\label{initial_terminal_of_INTDIV}%
A $\INTDIV$?

\endexercise
%%}}}

%%{{{ df: product_in_category 
\definition produto.
\label{product_in_category}%
Sejam $A,B$ objetos numa categoria $\cat C$.
Uma tripla $\tupp{p_1,P,p_2}$ é um \dterm{produto} dos $A,B$, sse:
\beginul
\li $A \fromby {p_1} P \toby {p_2} B$;
\li para toda tripla $\tupp{f_1,F,f_2}$ com $A \fromby {f_1} F \toby {f_2} B$,
existe única seta $!$ que faz o diagrama
$$
\cdopt{sep=1cm}
                                  \| \|                                \| A \\
F
\ar[rr, dotted, "\unique"]
\ar[urrr, bend left=24,  "f_1"]
\ar[drrr, bend right=24, "f_2"']  \| \| P
                                        \ar[ur, bend left=15,  "p_1"]
                                        \ar[dr, bend right=15, "p_2"'] \| \\
                                  \| \|                                \| B
\endcd
$$
comutar.
Quando as setas são óbvias usamos apenas o objeto $P$ para representar
a tripla $\tupp{p_1,P,p_2}$.
\endul
%%}}}

%%{{{ x: product_is_a_product 
\exercise o produto é um produto.
\label{product_is_a_product}%
Dados conjuntos $A,B$ na $\SET$, demonstre que $A\cross B$
é um produto.
Entenda que literalmente o produto não é o $A \cross B$,
mas a tripla $\tupp{\outl, A \cross B, \outr}$.

\endexercise
%%}}}

%%{{{ x: products_are_not_unique 
\exercise produtos não são únicos.
\label{products_are_not_unique}%
Dados conjuntos $A,B$ na $\SET$, ache um outro conjunto,
alem do $A \cross B$ que também é produto dos $A,B$.
Pode achar mais?

\endexercise
%%}}}

%%{{{ x: products_are_unique_up_to_unique_isomorphism 
\exercise são únicos a menos de isomorfismo.
\label{products_are_unique_up_to_unique_isomorphism}%
Demonstre que em qualquer categoria, dois produtos dos $A,B$
são necessariamente isómorfos.

\endexercise
%%}}}

%%{{{ remark: another way to design the diagram 
\remark.
Outras maneira para desenhar o diagrama acima são as seguintes:
$$
\cdopt{sep=1cm}
A \| P
     \ar[l, "p_1"']
     \ar[r, "p_2"]             \| B \\
  \| F
     \ar[ul, "f_1"]
     \ar[ur, "f_2"']
     \ar[u, dotted, "\unique"] \|
\endcd
\qqquad
\cdopt{sep=1cm}
  \| P
     \ar[dl, "p_1"']
     \ar[dr, "p_2"]            \|   \\
A \| F
     \ar[l, "f_1"]
     \ar[r, "f_2"']
     \ar[u, dotted, "\unique"] \| B
\endcd
$$
Obviamente é a mesma coisa.  Use qualquer delas, ou qualquer outra
equivalente.
%%}}}

%%{{{ x: does_INTLEQ_have_products 
\exercise.
\label{does_INTLEQ_have_products}%
A categoria $\INTLEQ$ do~\ref{INTLEQ}
tem produtos?  Se sim, dados dois objetos nela $A,B$, qual
seria o seu produto $A\cross B$?

\endexercise
%%}}}

%%{{{ x: does_INTDIV_have_products 
\exercise.
\label{does_INTDIV_have_products}%
A categoria $\INTDIV$ do~\ref{INTDIV}
tem produtos?  Se sim, dados dois objetos nela $A,B$, qual
seria o seu produto $A\cross B$?

\endexercise
%%}}}

\TODO Escrever.

\endsection
%%}}}

%%{{{ Problems 
\problems.

%%{{{ cancellable_stereo 
\problem.
\label{cancellable_stereo}%
Sabemos que bijecções tem inversa e logo são canceláveis
pela esquerda, e também canceláveis pela direita.
Mas no~\refn{let_us_trip_1} da viagem da~\refn{An_epic_trip}
encontramos mais uma versão de cancelável: ``cancelável stereo'',
que---para motivos óbvios---desconsideramos na discussão.
Então: existe bijecção $f$ e funções $g,h$ tais que
$$
f \of g = h \of f \nimplies g = h\, ?
$$
Se sim mostre um exemplo;
se não, refute mesmo a afirmação.

\endproblem
%%}}}

%%{{{ jection_iff_composition_with_inverse_proof
\problem.
\label{jection_iff_composition_with_inverse_proof}%
Prove o~\ref{jection_iff_composition_with_inverse}.

\solution
Já provou as idas no~\refn{jection_implies_composition_with_inverse}.
Vamos provar as voltas.
\endgraf
\proofpart{Volta da (1).}
Suponha a hipótese:
$$
\text{para todo $A \subset X$, $A = \pre f {\img f A}$}.
$$
Para mostrar que $f$ é injetora, suponha que $x,x'\in X$ tais que $f(x) = f(x')$.
Basta verificar que $x = x'$.
Considere o conjunto $A = \set{x}$.
Observe que $A \subset X$, e logo pela hipótese temos
$$
A = \pre f {\img f A}.\tag{A}
$$
Temos $f(x) \in \img f A$ pela definição da função-imagem.
Como $f(x') = f(x)$ temos também $f(x') \in \img f A$.
Logo
$$
x, x' \in \pre f {\img f A} \eqlabel A A = \set{x}.
$$
Como $x, x' \in \set{x}$, logo $x = x'$.
\endgraf
\proofpart{Volta da (2).}
Suponha a hipótese:
$$
\text{para todo $B \subset Y$, $B = \img f {\pre f B}$}.
$$
Tome $y_0\in Y$.
Para mostrar que $f$ é sobrejetora
basta mostrar que $\pre f {\set{y_0}} \neq \emptyset$.
Considere o
$$
B = \set{y_0} \subset Y
$$
e logo pela hipótese temos
$$
B = \img f {\pre f B}.\tag{B}
$$
Ou seja, $\pre f B \neq \emptyset$
(caso contrário teriamos
$$
B
\eqlabel B \img f {\pre f B}
= \img f {\emptyset}
= \emptyset
$$
que é absurdo pois $B = \set{y_0}$).
Isso mostra que $f$ é sobrejetora.

\endproblem
%%}}}

%%{{{ big_intersection_respected_by_img_wrong_proof 
\problem.
\label{big_intersection_respected_by_img_wrong_proof}%
Um aluno ``demonstrou'' que se $f : A \to B$ e $\seqn A n$ é uma
seqüência de subconjuntos de $A$, então
$$
\img f {\Interl_{n=0}^\infty A_n} = \Interl_{n=0}^\infty \img f {A_n}.
$$
Sua ``prova'' foi a seguinte:
\quote
<<Calculamos:
\compute
b \in \img f {\Interl_{n=0}^\infty A_n}
&\ifflabel1 \lexists {a \in \Interl_{n=0}^\infty A_n} {f(a) = b}            \by {def.~$\img f {\dhole}$}
&\ifflabel2 \exists a \paren{a \in \Interl_{n=0}^\infty A_n \land f(a) = b} \by {lógica}
&\ifflabel3 \exists a \paren{\forall n \paren{a \in A_n} \land f(a) = b}    \by {def.~$\Interl_{n=0}^\infty$}
&\ifflabel4 \exists a \paren{\forall n \paren{a \in A_n \land f(a) = b}}    \by {lógica}
&\ifflabel5 \exists a \forall n \paren{a \in A_n \land f(a) = b}            \by {lógica}
&\ifflabel6 \forall n \exists a \paren{a \in A_n \land f(a) = b}            \by {lógica}
&\ifflabel7 \forall n \lexists {a \in A_n} {f(a) = b}                       \by {lógica}
&\ifflabel8 \forall n \paren{b \in \img f {A_n}}                            \by {def.~$\img f {\dhole}$}
&\ifflabel9 b \in \Interl_{n=0}^\infty {\img f {A_n}}                       \by {def.~$\Interl_{n=0}^\infty$}
\endcompute
Logo temos
$\img f {\Interl_{n=0}^\infty A_n} = \Interl_{n=0}^\infty \img f {A_n}$
pela definição de igualdade de conjuntos.>>
\endquote
Ache os seus erros.

\hint
O problema está na $\ifflabel6$.
Uma da suas direções não é válida.

\solution
O problema é com a direção {\rldir} da $\ifflabel6$:
\compute
\cdots\iff  \exists a \forall n \paren{a \in A_n \land f(a) = b}
&\ifflabel6 \forall n \exists a \paren{a \in A_n \land f(a) = b} \by {lógica}
\endcompute
Saber que
\emph{existe $a$ tal que para todo $n$ algo $P(a,n)$ acontece}
é uma afirmação bem mais forte do que saber que
\emph{para todo $n$ existe algum $a$ tal que $P(a,n)$ acontece}.
Na primeira temos pelo menos um $a$ que serve para todo $n$,
mas na segunda pode ser que para cada $n$, o $a$ ``que serve''
é diferente.  Para enfatizar essa dependência podemos escrever:
\emph{para todo $n$ existe algum $a_n$ tal que $P(a_n, n)$}.
É por isso que a ida é válida mas a vólta, em geral, não é.
Compare com o~\ref{wrong_order_of_quantifiers}.

\endproblem
%%}}}

%%{{{ big_operations_respected_by_img_and_pre 
\problem.
\label{big_operations_respected_by_img_and_pre}%
{%
\def\I{{\cal I}}%
\def\J{{\cal J}}%
Sejam $f : A \to B$, e duas famílias indexadas de conjuntos:
$\famil A i \I$ feita por subconjuntos de $A$, e
$\famil B j \J$ feita por subconjuntos de $B$.
Ou seja, par todo $i\in \I$, e todo $j \in \J$,
temos $A_i \subset A$ e $B_j \subset B$.
Mostre que:
$$
\align
\img f {\Unionl_{i \in \I} A_i} &=      \Unionl_{i \in \I} \img f {A_i} \tag1\\
\img f {\Interl_{i \in \I} A_i} &\askeq \Interl_{i \in \I} \img f {A_i} \tag2\\
\pre f {\Unionl_{j \in \J} B_j} &=      \Unionl_{j \in \J} \pre f {B_j} \tag3\\
\pre f {\Interl_{j \in \J} B_j} &=      \Interl_{j \in \J} \pre f {B_j} \tag4
\endalign
$$
onde na $\askeq$ prove que a igualdade em geral não é válida,
mas uma das~{\lrdirset}~e~{\rldirset} é.
A demonstre, e, supondo que $f$ é injetora, demonstre a outra também.
}

\solution
{%
\def\I{{\cal I}}%
\def\J{{\cal J}}%
\proofpart{(1)}:
Provamos cada direção separadamente.
{\lrdirset}:
Seja $b \in \img f {\Union_{i\in\I} A_i}$.
Seja $a\in\Union_{i\in\I} A_i$ tal que $f(a) = b$\fact1 (pela definição de função-imagem).
Agora tome $i\in\I$ tal que $a\in A_i$\fact2.
Agora pelas~\byfact1,\byfact2~temos que $b\in\img f {A_i}$.
Ou seja, $b \in \Union_{i\in\I} \img f {A_i}$.
{\rldirset}:
Seja $b \in \Union_{i\in\I} \img f {A_i}$.
Seja $i\in\I$ tal que $b\in \img f {A_i}$.
Tome $a\in A_i$ tal que $f(a) = b$\fact1.
Como $a\in A_i$, logo $a\in\Union_{i\in\I} A_i$ e agora pela~\byfact1
ganhamos $b \in \img f {\Union_{i\in\I} A_i}$.
\endgraf
\proofpart{(2)}:
Provamos primeiro a {\lrdirset} que é verdade para toda $f$,
e mostramos que se $f$ é injetora, a {\rldirset} também é válida.
{\lrdirset}:
Seja $b \in \img f {\Inter_{i\in\I} A_i}$.
Logo tome $a \in \Inter_{i\in\I} A_i$\fact1 tal que $f(a) = b$\fact2.
Agora, como $a$ pertence a todos os $A_i$'s e $f(a) = b$,
então para cada $i\in\I$, $b\in\img f {A_i}$.
Ou seja, $b$ pertence a todos os $\img f {A_i}$'s.
Chegamos então no desejado $b\in\Inter_{i\in\I} \img f {A_i}$.
\endgraf
{\rldirset}:
Para essa direção vamos supor que $f$ é injetora.
Tome $b\in\Inter_{i\in\I} \img f {A_i}$, ou seja $b$
pertence a todos os $\img f {A_i}$'s.
Ou seja, para cada um dos $A_i$'s, existe $a_i\in A_i$
tal que $f(a_i) = b$.
Mas a $f$ é injetora, então todos esses $a_i$'s são iguais;
seja $a$ então esse membro comum dos $A_i$'s.
Temos então que:
$a \in \Inter_{i\in\I} {A_i}$ e $f(a) = b$.
Ou seja, $b \in \img f {\Inter_{i\in\I} A_i}$.
\endgraf
\proofpart{(3)}:
Calculamos:
\compute
a \in \pre f {\Unionl_{j\in\J} B_j}
&\iff f(a) \in \Unionl_{j\in\J} B_j           \by {def.~$\pre f {\Unionl_{j\in\J} B_j}$}
&\iff \lexists {j\in\J} {f(a) \in B_j}        \by {def.~$\Unionl_{j\in\J} B_j$}
&\iff \lexists {j\in\J} {a \in \pre f {B_j}}  \by {def.~$\pre f {B_j}$}
&\iff a \in \Unionl_{j\in\J} {\pre f {B_j}}.  \by {def.~$\Unionl_{j\in\J} {\pre f {B_j}}$}
\endcompute
Ou seja, $\pre f {\Unionl_{j \in \J} B_j} = \Unionl_{j \in \J} \pre f {B_j}$.
\endgraf
\proofpart{(4)}:
{\lrdirset}:
Seja $a \in \pre f {\Inter_{i\in\J}^\infty B_j}$.
Logo $f(a) \in {\Inter_{i\in\J}^\infty B_j}$,
ou seja, para todo $i\in\J$, $f(a) \in B_j$.
Logo $a \in \pre f {B_j}$ para todo $i\in\J$, ou seja,
$a \in {\Inter_{i\in\J}^\infty \pre f {B_j}}$.
{\rldirset}.
Similar: é só seguir os passos da {\lrdirset} em reverso.
}

\endproblem
%%}}}

%%{{{ f_surj_iff_pre_f_inj 
\problem.
\label{f_surj_iff_pre_f_inj}%
Seja $f : A \to B$.
Considere a afirmação seguinte:
$$
\text{$f(\dhole)$ sobrejetora}
\askiff
\text{$\pre f {\dhole}$ injetora}.
$$
Para cada uma das direções responda\dots
(1) ``sim'', e prove;
(2) ``não'', e refute; ou
(3) ``depende'', e mostre dois exemplos:
um onde a implicação é valida, e outro onde não é.

\hint
Ambas as implicações são válidas.
(Observe que $f(\dhole)$ é a própria $f$.)

\solution
Ambas as direcções são válidas.
\crtabproofpart{\lrdir}:
Suponha $f$ sobrejetora e sejam $Y,Y'$ no $\dom(\pre f {\dhole})$
tais que $Y\neq Y'$.
(Temos então $Y,Y'\subset B$.)
Basta provar que $\pre f {Y} \neq \pre f {Y'}$.
Como $Y\neq Y'$, sem perda de generalidade, seja $d \in Y \setminus Y'$.
Como $f$ é sobrejetora, seja $a_d \in A$ tal que $f(a_d) = d$.
Observe que $f(a_d) \in Y$ e que $f(a_d) \notin Y'$.
Logo $a_d \in \pre f Y$ e $a_d \notin \pre f {Y'}$,
pela definição da $\pre f {\dhole}$.
Logo $\pre f Y \neq \pre f Y'$.
\crtabproofpart{\rldir}:
Vou provar a contrapositiva da afirmação.
Suponha então que $f$ não é sobrejetora.
Vou demonstrar que $\pre f {\dhole}$ não é injetora.
Basta então achar dois membros distintos no seu domínio
mapeados no mesmo objeto.
Como $f$ não é sobrejetora, seja $t\in B$ tal que
$t \notin \range(f)$, ou seja, tal que
para todo $a \in A$, $f(a) \neq t$.
Agora considere os: $\emptyset$ e $\set{t}$.
Ambos são subconjuntos de $B$, e eles são distintos,
mas mesmo assim
$$
\pre f {\emptyset} = \emptyset = \pre f {\set{t}}.
$$
Ou seja, a $\pre f {\dhole}$ não é injetora.

\endproblem
%}}}

%%{{{ Halmos_advice_f_surj_iff_pre_f_inj 
\problem Don't just read it; fight it.
\label{Halmos_advice_f_surj_iff_pre_f_inj}%
Ache a coisa mais óbvia para se perguntar depois
do~\ref{f_surj_iff_pre_f_inj}; pergunte-se; responda (demonstra ou refuta).

\hint
$$
f(\dhole)
\brace{%
\gathered
\text{injetora} \\
\text{sobrejetora}
\endgathered
}
\askiff
\brace{%
\gathered
\img f \dhole \\
\pre f \dhole
\endgathered
}
\brace{%
\gathered
\text{injetora} \\
\text{sobrejetora}
\endgathered
}
$$

\endproblem
%%}}}

%%{{{ succiter_for_dummies_returns 
\problem.
\label{succiter_for_dummies_returns}%
(Continuação do~\ref{succiter_for_dummies}.)
Qual é (a extensão d)o conjunto
$$
\Inter_{n=0}^\infty \img {\succ^n} {\nats}\,?
$$
Prove tua afirmação.

\hint
$\Inter_{n=0}^\infty \img {\succ^n} {\nats} = \emptyset$.

\hint
Suponha que tem $w \in \Inter_{n=0}^\infty \img {\succ^n} {\nats} = \emptyset$
e chegue numa contradicção.

\solution
Eu vou demonstrar que
$$
\Inter_{n=0}^\infty \img {\succ^n} {\nats}=\emptyset.
$$
Para chegar num absurdo,
suponha que $w \in \Inter_{n=0}^\infty \img {\succ^n} {\nats}$.
Logo, para todo $n\in\nats$, $w \in \img {\succ^n} {\nats}$.
Logo, para todo $n\in\nats$, existe $m\in\nats$ tal que $\succ^n(m) = w$.
Mas $\succ^n(m) = n + m$ (\ref{succiter_for_dummies}).
Ou seja:
$$
\text{para todo $n\in\nats$, existe $m\in\nats$ tal que $n + m = w$}.
$$
Ou seja,
$$
\text{para todo $n\in\nats$, $n \leq w$ (\ref{natops_leq_def})}. \tag{*}
$$
Ou seja, $w$ é o máximo do $\nats$; absurdo pois $\nats$ não tem máximo!
\crproofalt{Alternativamente,}
bote $n := w+1$ na (*) para chegar no absurdo $w + 1 \leq w$.

\endproblem
%%}}}

%%{{{ implement_partial_functions 
\problem Implementação: funções parciais.
\label{implement_partial_functions}%
\tdefined{função}[partial]%
Pense numa maneira de \emph{implementar} o tipo das
\dterm{funções parciais} (\ref{Partial_functions})
usando conceitos (tipos) que encontramos até agora:
conjuntos, tuplas, seqüências, famílias indexadas, funções, etc.
\endgraf
Para implementar um conceito não basta apenas definir o que são os
objetos desse tipo em termos de já conhecidos.
Precisamos implementar também a interface desejada, em termos de
operações e relações que já temos em nossa disposição.

\hint
Cada função parcial $f : A \parto B$ pode ser representada
como uma função total $f : A \to B'$ onde $B'$ é um outro
conjunto.
Qual $B'$ serve?

\hint
Uma idéia seria adicionar no $B$ um objeto ``fresco'' para representar
a falta de valor; outra idéia seria tomar como $B'$ um subconjunto do $\pset B$.
Qual?

\hint
A primeira idéia não precisa de mais dicas.
Sobre a segunda: $B' \asseq \setst {X \subset B} {\card X \leq 1}$.

\endproblem
%%}}}

%%{{{ implement_nondeterministic_functions 
\problem Implementação: funções não-determinísticas.
\label{implement_nondeterministic_functions}%
\tdefined{função}[não-determinística]%
Na~\ref{Partial_functions} definimos um conceito mais geral de
``função'':
as \emph{funções parciais}, onde apagamos a primeira das
condições~\refn{functionhood_conditions}:
\beginil
\item{}\strikeout{(1)~totalidade};
\item{}(2)~determinabilidade.
\endil
Neste problema, encontramos \dterm{funções não-determinísticas}, ou seja,
``funções'' que não respeitam necessariamente a determinabilidade;
apenas a totalidade.  Ou seja, agora apagamos a outra condição:
\beginil
\item{}(1)~totalidade;
\item{}\strikeout{(2)~determinabilidade}.
\endil
O objectivo desse problema é \emph{implementar o tipo de função não-determinística}.
\endgraf
Como definarias a composição $g \cdot f$ de duas funções não-determinísticas?
Use a notação $f : A \ndeto B$ para <<$f$ é uma função não-determinística
de $A$ para $B$>>.
Que mais tu poderias fazer para tua implementação ser uma implementação boa?

\solution
Podemos representar a $f : A \ndeto B$ pela função
$\bar f : A \to \pset B\setminus\set{\emptyset}$ definida pela
$$
\bar f(x) = \setst {y\in B} {x\mapstoby f y}.
$$
Sejam~$f : A \ndeto B$ e~$g : B \ndeto C$ funções não-determinísticas.
Logo temos $\bar f : A \to \pset B\setminus\set{\emptyset}$
e          $\bar g : B \to \pset C\setminus\set{\emptyset}$.
Definimos sua composição
$g\cdot f : A \ndeto C$ pela
$$
(\overline{g\cdot f})(x) = \Union \img {\bar g} {\bar f (x)}.
$$
O que mais seria legal definir e mostrar para nossa implementação?
Bem, seria bom definir pelo menos a identidade não-determinística
$id_A : A \ndeto A$, e investigar se as leis que provamos sobre
o caso de funções que conectam composição e identidades estão válidas
para nossas funções não-determinísticas também.

\endproblem
%%}}}

%%{{{ why_pre_collatz_unsafe_diverges_on_6 
\problem.
\label{why_pre_collatz_unsafe_diverges_on_6}%
Calculando para resolver o~\ref{calculate_pre_collatz}
pareceu que o cálculo do $d(6)$ não ia terminar.
Prove que realmente não termina.

\hint
Botei esse problema para desenferrujar tuas armas
de teoria dos números (capítulos~\refn{Number_theory_divisibility}
e~\refn{Number_theory_congruences}).

\hint
Observe que a seqüência desses valores começa com 6, assim:
$$
6
\leadsto 9
\leadsto 12
\leadsto 15
\leadsto 18
\leadsto 21
\leadsto \dotsb
$$
Mas, somando $+3$ num número par, sabemos já que o próximo
número será ímpar e logo não pode ser potência de $2$,
e logo já sabemos que o próximo passo será somar $+3$ novamente.
Então podemos pular os ímpares acima, e reduzir nosso trabalho
focando nessa seqüência:
$$
6
\leadsto 12
\leadsto 18
\leadsto 24
\leadsto 30
\leadsto 36
\leadsto \dotsb
$$
De $6$ para $12$ ela ``pulou'' a potência (de $2$) $8$.
E de $12$ para $18$ também pulou o $16$.
A próxima potência é o $32$, que nossa seqüência tambem
conseguiu pular ($30\leadsto 36$).
Teu objectivo é \emph{demonstrar} que ela consegue ``pular''
\emph{todas} as potências de $2$.

\hint
Módulo $6$.

\hint
Como parecem \emph{todas} as potências de $2$ dentro do ``módulo-$6$''?

\hint
A seqüência de todas as potências de $2$ é:
$$
1, 2, 4, 8, 16, 32, 64, \dotsc
$$
que, módulo $6$ fica:
$$
1, 2, 4, 2, 4, 2, 4, 2, \dotsc \pmod 6.
$$
Isso é fácil para provar: então prove.

\hint
Observe que somando $+6$ num número não o muda ``módulo $6$''.
(Lembre que $6 \cong 0 \pmod 6$.)

\hint
Ou seja: começando com qualquer número $m$ que módulo $6$
é um dos $0,3,5$ sabemos que $d(m)$ \emph{diverge}, ou seja,
o $d(m)$ não é definido.
E se $m$ é $1$ módulo $6$?
A única potência de $2$ que é $1$ módulo $6$ é o próprio $1$,
e logo qualquer outro inteiro que é $1$ módulo $6$ não
pode ser uma potência de $2$.

\endproblem
%%}}}

%%{{{ fcom_respects_jections_pointfree 
\problem.
\label{fcom_respects_jections_pointfree}%
Demonstre que a composição respeita injectividade e sobrejectividade
num estilo pointfree (\ref{fcom_respects_jections}).
Ou seja, tu vai ter que usar as ``versões pointfree'' dessas noções.

\endproblem
%%}}}

%%{{{ define_constant_function_pointfree 
\problem.
\label{define_constant_function_pointfree}%
Descreva a afirmação <<$f$ é constante>> numa maneira pointfree.

\hint
Vai precisar de usar um singleton, $\set{\ast}$, não importa
qual é o seu único membro.

\endproblem
%%}}}

%%{{{ flip_definition 
\problem flip.
\label{flip_definition}%
No \ref{powTwo} da~\refn{Currying} definimos a função $\namedfun{powTwo}$
diretamente como aplicação parcial da função $\namedfun{exp}$
$$
\namedfun{powTwo} = \namedfun{exp} \fa 2
$$
evitando o uso de pontos ou lambdas:
$$
\xalignat2
\namedfun{powTwo} \fa n &= \namedfun{exp} \fa 2 \fa n; &
\namedfun{powTwo}       &= \lam n {\namedfun{exp} \fa 2 \fa n}.
\endxalignat
$$
Similarmente podemos definir a função que corresponde seqüência das potências
de qualquer outro número real.
Mas parece que não podemos criar com a mesma laconicidade (apenas como
aplicação parcial) uma função $\namedfun{square}$ ou $\namedfun{cube}$,
pois os argumentos da $\namedfun{exp}$ estão ``na ordem errada''.
O objectivo desse problema é fazer exatamente isso.
\endgraf
Defina uma função de ordem superior $\namedfun{flip}$, que recebe qualquer
função binária currificada, e retorna a função binária currificada que
comporta no mesmo jeito mas recebendo seus argumentos na ordem oposta.
Por exemplo:
$$
\xalignat2
\namedfun{exp} \fa 2 \fa 3 &= 8; &
\paren{\namedfun{flip} \fa \namedfun{exp}} \fa 2 \fa 3 &= 9
\endxalignat
$$
Começa escrevendo o tipo da $\namedfun{flip}$ e o lendo com as duas
maneiras diferentes que discutimos na~\ref{human_eyes_and_ho_types}.

\endproblem
%%}}}

%%{{{ prob: coproduct_in_category 
\problem Definição: coproduto em categoria.
\label{coproduct_in_category}%
Defina formalmente o que significa \dterm{coproduto} numa categoria.

\endproblem
%%}}}

%%{{{ prob: disjunion_is_a_coproduct 
\problem o coproduto é um coproduto ué.
\label{disjunion_is_a_coproduct}%
Demonstre que a \emph{união disjunta} $A \disjunion B$ que encontramos
na~\ref{disjunion_aka_coproduct}, conhecida por seus amigos
algebristas e categoristas como \emph{coproduto} e denotado por
$A \coprod B$, merece seu apelido:
``ele'' realmente é um coproduto dos $A,B$ na $\SET$.
Por que o ``ele'' está em aspas?

\endproblem
%%}}}

%%{{{ prob: coproducts_in_INTLEQ_and_INTDIV 
\problem mais coprodutos.
\label{coproducts_in_INTLEQ_and_INTDIV}%
As $\INTLEQ$ e $\INTDIV$ têm coprodutos?
Quais são?

\endproblem
%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

O \cite[Cap.~5]{velleman} defina e trata funções
como casos especiais de relações (veja~\ref{Relations}),
algo que não fazemos nesse texto.
Muitos livros seguem essa abordagem, então o leitor é conselhado
tomar o cuidado necessário enquanto estudando esses assuntos.

Um livro excelente para auto-estudo é o~\cite{babylawvere}.
\emph{Não pule seus exercícios e problemas!}

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Functional_programming 
\chapter Programação funcional.
\label{Functional_programming}%

%%{{{ Problems 
\problems.

%%{{{ prob: stretch_countdown_take 
{%
\DefFpf stretch
\DefFpf countdown
\DefFpf take
\problem.
Defina as funções com equações (recursivas):
$$
\xalignat3
\stretch    &\eqtype \nats \to [\nats] \to [\nats] &
\countdown  &\eqtype \nats \to [\nats] &
\take       &\eqtype \nats \to [\nats] \to [\nats].\\
\endxalignat
$$
Exemplos de uso:
$$
\align
\stretch \fa 3 \fa [2,8]        &= [2,2,2,8,8,8]    \\
\stretch \fa 2 \fa [1,9,8,3]    &= [1,1,9,9,8,8,3,3]\\
\countdown \fa 3                &= [3,2,1,0]        \\
\countdown \fa 1                &= [1,0]            \\
\take \fa 3 \fa [2,3,5,7,11]    &= [2,3,5]          \\
\take \fa 8 \fa [0,1,2,4]       &= [0,1,2,4]
\endalign
$$

\endproblem
}
%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite{huttonhaskell},
\cite{lyah};
\cite{birdthinking},
\cite{thompsonhaskell};
\cite{birdfphaskell}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Relations 
\chapter Relações.
\label{Relations}%

%%{{{ intro 
\chapintro
Nesse capítulo estudamos então mais um \emph{tipo} importante para matemática:
a \emph{relação}.
Se pensamos em funções como construtores (ou ``apontadores'') de objetos,
então as relações são \emph{construtores de afirmações}.
Podemos pensar que uma relação é como um \emph{verbo}, ou um \emph{predicado}
duma afirmação.
Como no~\ref{Functions}, nosso objectivo é entender \emph{o que são}
as coisas desse tipo (relações) e não como defini-las formalmente como
objetos matemáticos---sobre isso, paciência até o~\ref{Axiomatic_set_theory}.
%%}}}

%%{{{ Concept, notation, equality 
\section Conceito, notação, igualdade.

%%{{{ eg: leq_geq_lt_gt_example 
\example.
\label{leq_geq_lt_gt_example}%
Nos números, estamos bem acostumados com as relações de ordem
($\leq$, $\geq$, $<$, $>$).
Nos inteiros já estudamos bastante a relação binária de ``divide''
($\dhole\divides\dhole$) e a relação ternária de ``congruência modular''
($\dhole \cong \dhole \pmod \dhole$).
\endexample
%%}}}

%%{{{ eg: mother_parents_love_example 
\example.
\label{mother_parents_love_example}%
No nossa vida, conhecemos várias relações também:
$$
\align
\Mother (x,y)     &\defiff \text{$x$ é a mãe de $y$}\\
\Parents (x,y,z)  &\defiff \text{$x$ e $y$ são os pais de $z$}\\
\Love (x,y)       &\defiff \text{$x$ ama $y$}.
\endalign
$$
\endexample
%%}}}

%%{{{ Black boxes 
\note Black boxes.
\label{blackbox_rel}%
\tdefined{black box}[de relação]%
\iisee{relação!como black box}{black box}%
Visualizamos uma relação $R$ de aridade $n$ como um black box com $n$ entradas
e uma lâmpada que pisca sim ou não (como o black box dum conjunto), dependendo
de se os objetos-entradas $x_1,\dotsc,x_n$ são relacionados pela $R$.
Nesse caso dizemos que os $x_1,\dotsc,x_n$ \dterm{satisfazem} a $R$
e escrevemos
$$
R(x_1,\dotsc,x_n)
$$
para denotar isso e, quando $R$ é binária, em vez de escrever
$R(x,y)$ preferimos usar o $R$ com notação \emph{infixa}:
$$
x \rel R y \syndefiff R(x,y).
$$
Podemos então visualizar uma relação binária assim:
$$
\tikzpicture
\tikzi blackboxrel;
\endtikzpicture
$$
Como nas funções, se suas entradas são rotuladas ou não é questão de
religião: para o Conjuntista o black box parece como esse acima,
e para o Categorista como esse abaixo:
$$
\tikzpicture
\tikzi blackboxrelcat;
\endtikzpicture
$$
Ele escreveria $R : \reltype{A,B}$ para deixar claro o tipo dessa relação.
%%}}}

\blah.
Relações podem relacionar tipos diferentes:

%%{{{ eg: born_author_read_example 
\example.
\label{born_author_read_example}%
Considere as relações seguintes, cujos argumentos não têm o mesmo tipo.
$$
\align
\Born (x,w)       &\defiff \text{$x$ nasceu no ano $w$} \\
\Author (x,k)     &\defiff \text{$x$ escreveu o livro $k$} \\
\Read (x,k)       &\defiff \text{$x$ leu o livro $k$}
\endalign
$$
O primeiro argumento da primeira relação é uma pessoa
mas o segundo é um ano; e as relações $\namedrel{Author}$
e $\namedrel{Read}$ são ambas entre pessoas e livros.
\endexample
%%}}}

%%{{{ eg: equalities 
\example Igualdades.
Para cada tipo, sua igualdade é uma relação, de aridade $2$.
Nos números naturais por exemplo, se $n,m\in\nats$, $n = m$ é uma afirmação:
$$
\align
n = m &\pseudodefiff \text{os $n$ e $m$ denotam o mesmo número natural}.
\intertext{Similarmente nos conjuntos: se $A,B$ são conjuntos, $A = B$ é a afimação seguinte:}
A = B &\pseudodefiff \text{os $A$ e $B$ denotam o mesmo conjunto}.
\endalign
$$
Etc., etc.
Observe que podemos fazer uma \ii{aplicação!parcial}\emph{aplicação parcial},
nas relações como fazemos nas funções.
Fixando um objeto de nosso tipo, por exemplo o natural $0\in\nats$
em qualquer um dos dois lados da igualdade (vamos fixar na direita nesse exemplo),
chegamos numa relação de aridade $1$:
$$
\align
\bhole &= 0
\intertext{%
onde aplicando a relação para qualquer $x\in\nats$ chegamos na afirmação
}
x &= 0.
\endalign
$$
\endexample
%%}}}

%%{{{ The type of a relation 
\definition O tipo duma relação.
\tdefined{tipo}[duma relação]%
\sdefined {\sholed R : \reltype{\sholed{A_1,\dotsc,A_n}}} {$R$ é uma relação entre os conjuntos $A_1,\dotsc,A_n$}%
Com cada relação associamos o seu \dterm{tipo} (pedimos emprestada aqui
a terminologia usada em funções) que é apenas a informação de qual é o tipo
de cada uma das suas entradas.
Escrevemos
$$
R : \reltype{A_1,\dotsc,A_n}
$$
para afirmar que $R$ é uma relação $n$-ária
entre os conjuntos $A_1,\dotsc,A_n$.
As relações dos exemplos~\refn{mother_parents_love_example}
e~\refn{born_author_read_example} têm os tipos seguintes:
$$
\xalignat2
\namedrel{Mother}  &: \reltype{\cal P, \cal P}         & \namedrel{Born}   &: \reltype{\cal P, \cal Y} \\
\namedrel{Parents} &: \reltype{\cal P, \cal P, \cal P} & \namedrel{Author} &: \reltype{\cal P, \cal B} \\
\namedrel{Love}    &: \reltype{\cal P, \cal P}         & \namedrel{Read}   &: \reltype{\cal P, \cal B}
\endxalignat
$$
onde $\cal P, \cal Y, \cal B$ são os conjuntos de pessoas, anos, livros
(respectivamente).
%%}}}

%%{{{ funlike_notation_for_relations 
\note Notação funcionista.
\label{funlike_notation_for_relations}%
Relações de aridade $2$ são as mais comuns, e usamos certa notação
e terminologia especialmente só para elas.
Nesse caso, podemos ver o conceito de relação como uma generalização de função,
onde nos livramos das duas condições do~\refn{functionhood_conditions}.
Por isso, quando temos uma relação no $\relspace{A,B}$
usamos a frase <<relação \emph{de} $A$ \emph{para} $B$>>.
Vamos criar uma notação parecida com aquala das funções para dizer que $R$
é uma relação do conjunto $A$ para o conjunto $B$.
Escrevemos, equivalentemente:
$$
R : A \relto B
\qqqquad
R : B \relfrom A
\qqqquad
A \reltoby R B
\qqqquad
B \relfromby R A.
$$
Tudo isso quis dizer apenas que $R$ é uma relação binária entre $A$ e $B$.
Ou seja, tudo isso é sinónimo com o $R : \reltype{A,B}$.
%%}}}

%%{{{ beware: this notation is not standard 
\beware.
A notação ``$\relto$'' definida no~\refn{funlike_notation_for_relations}
\emph{não} é padrão.
%%}}}

%%{{{ setlike_notation_for_relations 
\note Notação conjuntista.
\label{setlike_notation_for_relations}%
Vestindo nosso chapéu de conjuntista, abusamos a notação e escrevemos
também $\tupp{x,y} \in R$ para dizer que $R(x,y)$.
E para afirmar que $R : \reltype{A,B}$, escrevemos
até $R \subset A \cross B$.
É importante entender bem neste momento que essas são apenas
\emph{notações}.  Uma relação $R$ \emph{não é} um conjunto,
então nada pertence a ela, e conseqüentemente ela não é
subconjunto de ninguém!
Mesmo assim escrevemos coisas como
$$
\xalignat2
\namedrel{Author}  &\subset \cal P \cross \cal B &
\namedrel{Parents} &\subset \cal P^3
\intertext{%
\emph{entendendo} como:
}
\namedrel{Author}  &\eqtype \reltype{\cal P, \cal B} &
\namedrel{Parents} &\eqtype \reltype{\cal P, \cal P, \cal P}.
\endxalignat
$$
É muito conveniente tratar relações \emph{como se fossem} conjuntos
---mas mais uma vez: relações \emph{não são} conjuntos.
%%}}}

%%{{{ x: repeat_after_me_relations_are_not_sets 
\exercise.
\label{repeat_after_me_relations_are_not_sets}%
Repita!

\hint
Relações \emph{não são}\dots

\solution
Relações \emph{não são} conjuntos!

\endexercise
%%}}}

\blah.
Cada vez que introduzimos um tipo novo, precisamos definir quando dois
objetos desse tipo são iguais.  Vamos fazer isso agora.
Novamente, vamos optar para identificar relações cujos comportamentos
são indistinguíveis usando apenas as suas interfaces.

%%{{{ df: R_eq_S_bin_on_single_set_case 
\definition igualdade.
\label{R_eq_S_bin_on_single_set_case}%
Sejam $R,S$ relações binárias num conjunto $A$.
Definimos
$$
R=S
\defiff
\lforall {x,y \in A} {x \rel R y \iff x \rel S y}.
$$
%%}}}

\blah.
Principalmente vamos trabalhar com relações binárias definidas
num conjunto só, então a definição de
igualdade~\refn{R_eq_S_bin_on_single_set_case} que
acabamos de ver nos serve bem.
No~\ref{R_eq_S_bin_on_different_sets_case}
e no~\ref{R_eq_S} tu vai estender essa definição para
os casos mais gerais.

%%{{{ x: R_eq_S_bin_on_different_sets_case 
\exercise igualdade.
\label{R_eq_S_bin_on_different_sets_case}%
Como tu estenderia a~\ref{R_eq_S_bin_on_single_set_case}
para o caso que as $R,S$ não são relações num conjunto só?
Ou seja, tendo relações binárias~$R,S$, a~$R$ de~$A$ para~$B$,
e a~$S$ de~$C$ para~$D$, como tu definirias a igualdade~$R=S$ nesse caso?

\solution
Digamos que $R=S$ sse para todo $x\in A\union C$,
e todo $y \in B\union D$, temos $x \rel R y \iff x \rel S y$.

\endexercise
%%}}}

%%{{{ x: R_eq_S 
\exercise igualdade (agnóstica).
\label{R_eq_S}%
Defina a igualdade para o caso mais geral de relações,
numa maneira ``agnóstica'' como fizemos nas funções (\ref{f_eq_g}).

\endexercise
%%}}}

%%{{{ Intension vs. Extension 
\note Intensão vs{.}~extensão.
Com nossa experiência com \emph{intensão} e \emph{extensão} de
conjuntos~(\refn{Intension_vs_extension_in_sets}) e de
funções~(\refn{intension_vs_extension_in_functions}
e~\refn{programs_vs_functions}), não precisamos esclarecer
muita coisa sobre relações, pois a idéia continua a mesma.
%%}}}

%%{{{ eg: R(n) vs T(n) intensionally and extensionally 
\example.
Considere as relações no $\nats$:
$$
\align
R(n) &\defiff \Prime(n) \mland \Even(n) \\
T(n) &\defiff n = 2.
\endalign
$$
As \emph{intensões} das relações $R$ e $T$ são diferentes,
mas a \emph{extensão} é comum:
$$
\lforall {n\in\nats} {R(n) \iff T(n)}.
$$
\endexample
%%}}}

\blah.
Para capturar a extensão duma relação, definimos o seu gráfico,
na mesma forma que definimos no caso de funções~(\ref{function_graph}).

%%{{{ df: relation_graph 
\definition gráfico.
\label{relation_graph}%
\label{truth_set}%
\tdefined{relação!gráfico}%
\tdefined{truth set}%
\iisee{gráfico}{relação, gráfico}%
\iisee{gráfico}{função, gráfico}%
\sdefined {\graph{\sholed R}} {o gráfico da relação $R$}%
Dado relação $R : \reltype{A_1,\dotsc,A_n}$,
o \dterm{gráfico da $R$} é o conjunto
$$
\graph R \defeq \setst {\vec a \in A_1\cross\dotsb\cross A_n} {R(\vec a)},
$$
também conhecido como \dterm{truth set} da $R$.
%%}}}

%%{{{ remark: graph R = graph T and setlike notation 
\remark.
Agora temos uma maneira formal para afirmar que $R$ e $T$ tem
a mesma extensão: $\graph R = \graph T$.
E agora a notação conjuntista do~\refn{setlike_notation_for_relations}
vira literalmente até correta se substituir as relações por seus gráficos.
%%}}}

\endsection
%%}}}

%%{{{ Defining relations 
\section Definindo relações.

%%{{{ with holes 
\note Com buracos.
Começando com uma expressão que denota um \emph{objeto}
e botando $n$ buracos em certas subexpressões dela, criamos
uma \emph{função} de aridade $n$.
Se fizer a mesma coisa numa expressão que denota uma \emph{afirmação},
então criamos uma \emph{relação} de aridade $n$.
%%}}}

%%{{{ eg: john_loves_mary_holes 
\example.
Considere a frase \trel{João ama Maria}.
Criamos assim as relações:
$$
\align
L &\defeq \mtrel{{\thole} ama {\thole}} \\
J &\defeq \mtrel{João ama {\thole}} \\
M &\defeq \mtrel{{\thole} ama Maria}.
\endalign
$$
A primeira é uma relação no $\cal P \times \cal P$ e as outras duas no $\cal P$.
Usando variáveis em vez de buracos, escrevemos:
$$
\align
L(x,y) &\defiff \mtrel{$x$ ama $y$} \\
J(x)   &\defiff \mtrel{João ama $x$} \\
M(x)   &\defiff \mtrel{$x$ ama Maria}.
\endalign
$$
\endexample
%%}}}

%%{{{ other ways of defining relations 
\note Outras maneiras de definir relações.
Em vez de explicar todas as maneiras seguintes em detalhe,
eu acho que um exemplo é suficiente para cada caso, pois
todas essas maneiras são já bem conhecidas graças à nossa
experiência com funções no~\ref{Functions}.
%%}}}

%%{{{ eg: with formulas 
\example formulamente.
Considere os conjuntos $\cal P$ de todas as pessoas
e $\cal B$ de todos os livros.
Sejam as relações
$$
\xalignat4
P &: \reltype {\ints}, &
R &: \reltype {\ints, \ints}, &
Q &: \reltype {\cal P \times \cal B}, &
M &: \reltype {\ints,\ints,\ints},
\endxalignat
$$
definidas pelas fórmulas:
$$
\align
P(n)     &\defiff \lforall {x,y\in\ints} {xy = n \limplies \paren{|x| = 1 \lor |y| = 1}} \\
R(n,m)   &\defiff \lnot\lexists {k \in \ints} {\Prime(k) \land 2^n < k < 3^m}; \\
Q(p,b)   &\defiff \lexists {b' \in \cal B} {b \neq b' \land \namedrel{Read}(p,b') \land \lexists {a \in \cal P} {\namedrel{Author}(a,b) \land \namedrel{Author}(a,b')}} \\
C(a,b,m) &\defiff \lexists {k \in \ints} {mk = a-b}
\endalign
$$
Tente expressar cada uma delas em lingua natural.
\endexample
%%}}}

%%{{{ eg: relations_with_text_example 
\example Com texto.
\label{relations_with_text_example}%
Sejam as relações $\namedrel{Coauthors}$ (binária, entre pessoas)
e $\namedrel{SameCard}$ (unária, nos conjuntos), definidas pelas:
$$
\align
\namedrel{Coauthors}(x,y) &\defiff \text{$x$ e $y$ já escreveram algum livro juntos}; \\
\namedrel{SameCard}(x)    &\defiff \text{todos os membros de $x$ são conjuntos com a mesma cardinalidade}.
\endalign
$$
Por exempo: $\namedrel{Coauthors}(\textrm{Birkhoff}, \textrm{Mac Lane})$
e $\namedrel{SameCard}(\set{ \set{0,1}, \set{\nats,\set{42}}, \set{\emptyset, \set{\emptyset}}})$.
\endexample
%%}}}

%%{{{ beware: definitive text 
\beware.
Como sempre, tomamos cuidado quando definimos coisas com texto:
tem que ser uma afirmação definitiva, sem ambigüidades, etc.
%%}}}

%%{{{ x: do_nats_ints_rats_reals_have_the_same_cardinality 
\exercise.
\label{do_nats_ints_rats_reals_have_the_same_cardinality}%
Com a definição de $\namedrel{SameCard}$ do~\ref{relations_with_text_example},
$\namedrel{SameCard}(\set{\nats,\ints,\rats,\reals})$?
Responda com ``sim'' ou ``não'', com uma curtíssima explicação (sem prova).

\hint
Lembre a~\ref{naive_cardinality}.

\solution
Infelizmente não podemos ainda responder nessa pergunta:
sua resposta é um dos assuntos principais do~\ref{Cantors_paradise}.
Paciência!
Se tu respondeste ``sim, pois todos são conjuntos infinitos'',
fizeste bem, pois é uma resposta aceitável \emph{neste momento}.
Só que\dots~não é uma resposta correta!
Aliás, seguindo a~\ref{naive_cardinality} é uma resposta correta sim,
porém vamos ter que redefinir o conceito de cardinalidade logo.

\endexercise
%%}}}

%%{{{ eg: partial_application_in_relations_example 
\example Aplicação parcial.
\label{partial_application_in_relations_example}%
\DefRel EqParity
\DefRel Neg
Sejam as relações $\EqParity$ (binária entre inteiros),
$B$ (unária em pessoas), e $\Neg$ (unária em inteiros), definidas pelas:
$$
\align
\EqParity(a,b) &\defiff a \cong b \pmod 2 \\
B(y)           &\defiff \Coauthors(\mathrm{Birkhoff}, y) \\
\Neg(x)        &\defiff x < 0.
\endalign
$$
Assim temos por exemplo:
$\EqParity(103,11)$ mas não $\EqParity(21,42)$;
$B(\mathrm{Mac~Lane})$ mas não $B(\mathrm{Thanos})$;
$\Neg(-23)$ mas não $\Neg(0)$.
\endexample
%%}}}

\endsection
%%}}}

%%{{{ Internal diagrams 
\section Diagramas internos.

%%{{{ Relation as a generalization of function 
\note Relação como uma generalização de função.
Um jeito de olhar para uma relação é como uma ``função'' sem as restricções
de totalidade e de determinabilidade que encontramos no~\refn{functionhood_conditions}.
Então: lembra dos conjuntos $A,B$ que encontramos na~\ref{Images_preimages}?
Aqui são duas relações $R,Q$ de $A$ para $B$, determinadas por seus
diagramas internos:
$$
\xxalignat2
&
\tikzpicture[>=stealth,node distance=0mm,scale=0.8]
\tikzi imgpreimgpointsetsbase;
\draw[-{Latex[length=6pt,open]}]  (0.5,4.5) -- (4.5,4.5);
\node (arrow-R) at (2.5,4) {$R$};
\draw[->] (elem-b) -- (elem-1);
\draw[->] (elem-b) -- (elem-2);
\draw[->] (elem-c) -- (elem-2);
\draw[->] (elem-e) -- (elem-5);
\draw[->] (elem-e) -- (elem-6);
\draw[->] (elem-e) -- (elem-5);
\draw[->] (elem-e) -- (elem-2);
\endtikzpicture
&&
\tikzpicture[>=stealth,node distance=0mm,scale=0.8]
\tikzi imgpreimgpointsetsbase;
\draw[-{Latex[length=6pt,open]}]  (0.5,4.5) -- (4.5,4.5);
\node (arrow-Q) at (2.5,4) {$Q$};
\draw[->] (elem-a) -- (elem-1);
\draw[->] (elem-b) -- (elem-1);
\draw[->] (elem-c) -- (elem-1);
\draw[->] (elem-d) -- (elem-3);
\draw[->] (elem-d) -- (elem-4);
\draw[->] (elem-d) -- (elem-5);
\draw[->] (elem-d) -- (elem-6);
\draw[->] (elem-f) -- (elem-6);
\endtikzpicture
\endxxalignat
$$
%%}}}

\blah.
A situação sobre relações binárias definidas num conjunto $A$
é mais divertida.

%%{{{ Relation as a directed graph 
\note Relação como grafo direcionado.
Seja $A$ um conjunto e $R$ uma relação binária nele.
Podemos representar a $R$ como um \emph{grafo direcionado},
onde, para todos $x,y\in A$, desenhamos uma setinha
$x\longrightarrow y$ sse $x \rel R y$.
%%}}}

%%{{{ eg: first_internal_diagrams_for_rel 
\example.
\label{first_internal_diagrams_for_rel}%
Seja $A = \set{1, 2, 3, 4, 5, 6, 7, 8}$.
Desenhamos os diagramas de três relações binárias no $A$:
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi internaldiagramrel0;
\draw[->] (elem-1) to [bend left=20]  (elem-2);
\draw[->] (elem-2) to [bend left=20]  (elem-1);
\draw[->] (elem-8) to                 (elem-6);
\draw[->] (elem-5) to                 (elem-7);
\draw[->] (elem-5) to                 (elem-8);
\draw[->] ([shift={(0,.2)}]elem-4) arc (10:290:0.25);
\draw[->] ([shift={(0,.2)}]elem-5) arc (10:290:0.25);
\draw (rellabel) node {$R$};
\endtikzpicture
\quad
\tikzpicture[>=stealth, scale=0.84]
\tikzi internaldiagramrel0;
\draw[->] (elem-1) to                 (elem-2);
\draw[->] (elem-8) to                 (elem-6);
\draw[->] (elem-7) to                 (elem-5);
\draw[->] (elem-5) to                 (elem-8);
\draw[->] (elem-6) to                 (elem-5);
\draw (rellabel) node {$S$};
\endtikzpicture
\quad
\tikzpicture[>=stealth, scale=0.84]
\tikzi internaldiagramrel0;
\draw[->] (elem-1) to [bend left=20]  (elem-2);
\draw[->] (elem-2) to [bend left=20]  (elem-1);
\draw[->] (elem-5) to [bend left=20]  (elem-8);
\draw[->] (elem-8) to [bend left=20]  (elem-5);
\draw[->] (elem-3) to [bend left=20]  (elem-4);
\draw[->] (elem-4) to [bend left=20]  (elem-3);
\draw[->] (elem-7) to [bend left=10]  (elem-6);
\draw[->] (elem-6) to [bend left=10]  (elem-7);
\draw[->] ([shift={(0,.2)}]elem-5) arc (10:290:0.25);
\draw (rellabel) node {$Q$};
\endtikzpicture
$$
Os gráficos delas então são os
$$
\align
\graph R &= \set{ (1,2), (2,1), (4,4), (5,5), (5,7), (5,8), (8,6) } \\
\graph S &= \set{ (1,2), (5,8), (6,5), (7,5), (8,6) } \\
\graph Q &= \set{ (1,2), (2,1), (3,4), (4,3), (5,5), (5,8), (6,7), (7,6), (8,5) }.
\endalign
$$
Mais uma vez, aviso que é comum identificar uma relação $R$ com seu gráfico
$\graph R$, escrevendo por exemplo $R = \set { (1,2), (2,1), \dotsc }$.
Já fez o~\ref{repeat_after_me_relations_are_not_sets}, né?
\endexample
%%}}}

%%{{{ x: empty_and_true_relation 
\exercise.
\label{empty_and_true_relation}%
No mesmo conjunto $A = \set{1,2,3,4,5,6,7,8}$, como parecem os diagramas
das relações $F,T$ com gráficos $\graph F = \emptyset$ e $\graph T = A^2$?

\solution
O diagrama da $F$ parece assim:
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi internaldiagramrel0;
\draw (0,-3.0) node {$F$};
\endtikzpicture
$$
E o diagrama da $T$ parece uma bagunça.

\endexercise
%%}}}

%%{{{ x: we_cannot_draw_two_parallel_arrows_on_a_rel_diagram 
\exercise.
\label{we_cannot_draw_two_parallel_arrows_on_a_rel_diagram}%
Para quais relações podemos ter \emph{duas} setinhas do objeto $x$
para o objeto $y$?

\solution
Para nenhuma!
Exatamente como um conjunto não tem noção de \emph{quantas vezes}
um certo objeto pertence nele, uma relação também não tem noção
de \emph{quantas vezes} um certo objeto relaciona com um certo outro.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Constructions and operations on relations 
\section Construções e operações em relações.

\blah.
Todas as relações que consideramos nessa secção serão binárias.

%%{{{ df: ropposite 
\definition.
\label{ropposite}%
\tdefined{relação}[oposta]%
\tdefined{relação}[dual]%
\sdefined {\rop {\sholed R}} {a relação oposta da $R$}%
{\iisee{relação!dual}{oposta}}%
{\iisee{relação!inversa}{oposta}}%
Seja $R$ uma relação de $A$ para $B$.
Definimos a sua \dterm{relação oposta} (ou \dterm{relação dual})
$\rop R$ de $B$ para $A$ pela:
$$
x \rop R y \defiff y \rel R x.
$$
Também é conhecida como a \emph{relação inversa da $R$},
e a galera que a chama assim usa notação $\rinv R$,
\emph{mas não vamos usá-la nesse texto}---explicarei o porquê
no~\ref{rinv_is_not_inverse}.
%%}}}

%%{{{ x: rop_is_an_involution 
\exercise.
\label{rop_is_an_involution}%
\tdefined{involução}%
A operação $\rop{\dhole}$ é uma \dterm{involução}:
$$
\text{para toda relação binária $R$, $\ropp {\rop R} = R$}.
$$

\solution
$
x \ropp{\rop R} y
\iff y \rop R x
\iff x \rel R y
$.

\endexercise
%%}}}

%%{{{ eg: opposite_relations_of_common_orders 
\example.
Nos $\reals$, a relação oposta $\rop<$ da $<$ é a $>$,
e a $\rop\leq$ é a $\geq$.
\endexample
%%}}}

%%{{{ Composition 
\note Composição.
Dadas relações compatíveis, podemos formar sua composição
$R\rcom S$ numa forma natural.  Vamos ver uns exemplos
antes de chegar na definição formal.
%%}}}

%%{{{ eg: persons_books_words 
\example.
\label{persons_books_words}%
Sejam os conjuntos $\cal P$ de pessoas, $\cal B$ de livros, e $\cal W$ de palavras.
Considere as relações:
$$
\align
\Author(x,y)    &\defiff \text{$x$ é um escritor do livro $y$}\\
\Read(x,y)      &\defiff \text{$x$ leu o livro $y$}\\
\Contains(x,y)  &\defiff \text{a palavra $y$ aparece no livro $x$}
\endalign
$$
Observe que $\Author$ e $\Read$ são relações de $\cal P$ para $\cal B$,
e $\Contains$ de $\cal B$ para $\cal W$.
O que seria a relação $\Author\rcom\Read$, o que a $\Author\rcom\Contains$,
e o que a $\Read\rcom\Contains$?
Antes de defini-las, vamos primeiramente pensar se faz sentido compor essas
relações.
Realmente $\Read$ é componível com $\Contains$
(gráças ao $\cal B$ ``no meio'') e
similarmente sobre a $\Author$ com $\Contains$.
No outro lado, não podemos compor as $\Author$ e $\Read$ em nenhuma
ordem!
Bem, então $\Author\rcom\Contains$ e $\Read\rcom\Contains$ são ambas
relações de $\cal P$ para $\cal W$.
Mas quais?
Lembre que para definir uma relação, precisamos determinar
completamente quando dois arbitrários $x,y$ são relacionados pela
relação.
Precisamos então completar as:
$$
\align
x \relp{\Author\rcom\Contains} y &\iff \text{\dots?\dots}\\
x \relp{\Read\rcom\Contains}   y &\iff \text{\dots?\dots}
\endalign
$$
mas como?
\spoiler.
Bem, botamos:
$$
\align
x \relp{\Author\rcom\Contains} y &\iff \text{a pessoa $x$ escreveu algum livro que contem a palavra $y$}\\
x \relp{\Read\rcom\Contains}   y &\iff \text{a pessoa $x$ leu algum livro que contem a palavra $y$}
\endalign
$$
\endexample
%%}}}

%%{{{ x: comparison_of_statements_about_reading_books 
\exercise.
\label{comparison_of_statements_about_reading_books}%
A relação $R$ de $\cal P$ para $\cal W$ definida pela
$$
R(p,w) \defiff \text{a pessoa $p$ leu a palavra $w$ num livro}
$$
é a mesma relação com a $\Read\rcom\Contains$?
Em outras palavras:
$$
R \askeq \Read\rcom\Contains
$$

\hint
As afirmações:
$$
\gather
\text{a pessoa $p$ leu a palavra $w$ num livro}\\
\text{a pessoa $p$ leu um livro onde a palavra $w$ aparece}
\endgather
$$
estão afirmando a mesma coisa?

\solution
Não.
Pode ser que a pessoa leu uma palavra $w$ num livro $b$ mas nunca chegou
a ler um livro inteiro que contem a $w$.
Nesse caso temos apenas
$$
p \relp{\Read\rcom\Contains} w \implies p \rel R y
$$
pois se $p$ leu um livro que tem a palavra $w$ com certeza $p$ leu $w$ num livro.

\endexercise
%%}}}

\blah.
Já observamos que não podemos compor as $\Author$ e $\Read$ em nenhuma ordem,
mas podemos aplicar o operador $\rop\dhole$ e compor depois:

%%{{{ x: using_rop_to_compose 
\exercise.
\label{using_rop_to_compose}%
Como definarias as relações $\Author\rcom{\rop\Read}$ e
$\Read\rcom{\rop\Author}$?
São iguais?

\solution
Temos:
$$
\align
x \relp{\Author\rcom{\rop\Read}} y &\iff \text{$x$ escreveu um livro que $y$ leu}\\
x \relp{\Read\rcom{\rop\Author}} y &\iff \text{$x$ leu um livro que $y$ escreveu}.
\endalign
$$
Não são iguais: uma é a oposta da outra.

\endexercise
%%}}}

\blah.
Segue mais um exemplo, essa vez usando apenas um conjunto---e
logo todas as relações são gratuitamente compatíveis para composição.

%%{{{ x: grandparents_grandchildren_siblings_and_couples_with_children 
\exercise.
\label{grandparents_grandchildren_siblings_and_couples_with_children}%
Seja $\cal P$ o conjunto de todas as pessoas, e considere as relações
$$
\align
\Parent(x,y) &\defiff \text{$x$ é a mãe ou o pai de $y$}\\
\Child(x,y)  &\defiff \text{$x$ é filho ou filha de $y$}.
\endalign
$$
Como tu definirias diretamente as relações seguintes?:
$$
\Parent\rcom\Parent
\qqquad
\Child\rcom\Child
\qqquad
\Parent\rcom\Child
\qqquad
\Child\rcom\Parent
$$

\solution
Temos:
$$
\align
x \relp{\Parent\rcom\Parent} y &\defiff \text{$x$ é um avô ou uma avó de $y$}\\
x \relp{\Child\rcom\Child}   y &\defiff \text{$x$ é um neto ou uma neta de $y$}\\
x \relp{\Parent\rcom\Child}  y &\defiff \text{$x$ e $y$ tem um filho ou uma filha juntos}\\
x \relp{\Child\rcom\Parent}  y &\defiff \text{$x$ e $y$ são irmã(o)s ou a mesma pessoa}
\endalign
$$

\endexercise
%%}}}

%%{{{ Q: How can we define composition of relations? 
\question.
Como tu imaginas o interior desse black box?
$$
\tikzpicture
\tikzi blackboxrelcompb;
\endtikzpicture
$$
E, como tu definarias a composição de relações?
%%}}}
\spoiler.

%%{{{ Composition with black boxes 
\note Composição com black boxes.
Talvez as imagens seguintes com black boxes ajudam a pensar numa definição formal.
$$
\tikzpicture
\tikzi blackboxrelcompt;
\endtikzpicture
$$
%%}}}

%%{{{ df: rcompose 
\definition.
\label{rcompose}%
\tdefined{relação}[composição]%
\iisee{composição!de relações}{relação, composição}%
Sejam conjuntos $A,B,C$ e as relações~$R$ de~$A$ para~$B$
e~$S$ de~$B$ para~$C$.
Definimos a relação~$R\rcom S$ de~$A$ para~$C$ pela
$$
a\rel{(R \rcom S)}c
\defiff
\text{existe $b \in B$ tal que $a \rel R b$ \& $b \rel S c$}.
$$
Chamamos a $R \rcom S$ a \dterm{composição} da $R$ \emph{com} a $S$.
Quando não existe possibilidade de confusão escrevemos a composição
com várias outras notações.
Todas as expressões seguintes podem ser usadas:
$$
\xalignat5
& R \rcom S &
& R \com  S &
& R \dcom S &
& R \cdot S &
& RS
\endxalignat
$$
%%}}}

%%{{{ beware: RoS_not_SoR 
\beware.
\label{RoS_not_SoR}%
Não existe um consensus para a ordem de escrever os $R,S$
usando o símbolo $\compose$.
Tome cuidado então enquanto lendo a notação $R \com S$,
pois o que um autor escreve como $R \com S$, outro pode escrever
como $S \com R$.
Quando a composição é denotada por $\dcom$ a ordem concorda com nossa:
$$
a\rel{(R \dcom S)}c
\defiff
\text{existe $y \in B$ tal que $a \rel R y$ \& $y \rel S c$}.
$$
Veja também o~\ref{gof_not_fog}.
%%}}}

%%{{{ prop: associativity_of_rcom 
\property.
\label{associativity_of_rcom}%
Sejam conjuntos $A,B,C,D$ e relações binárias
$R : \reltype{A,B}$,
$S : \reltype{B,C}$, e
$T : \reltype{C,D}$.
Então
$$
(R\rcom S)\rcom T = R \rcom (S\rcom T),
$$
e logo podemos escrever apenas $R\rcom S\rcom T$.
\sketch.
Supomos $a \in A$ e $d\in D$, e mostramos a equivalência
$$
a \relp{(R\rcom S)\rcom T} d
\iff
a \relp{R\rcom (S\rcom T)} d.
$$
\qes
\proof.
Demonstrarei em detalhe a
$$
a \relp{(R\rcom S)\rcom T} d
\implies
a \relp{R\rcom (S\rcom T)} d.
$$
A {\rldir} é similar.  Temos:
\stepproof
\proofsteptnb {Suponha $a\in A$ e $d\in D$ tais que $a \rel{(RS)T} d$.}
\thereforetnb {Seja $c \in C$ tal que $a \rel {RS} c\fact1 \mland c \rel T d\fact2$.}
\thereforetby {Seja $b \in B$ tal que $a \rel R b\fact3 \mland b \rel S c\fact4$.}
              {pelo~\byfact1}
\thereforetby {$b \rel {ST} d$\fact5.} {pelos~\byfact4 e~\byfact2}
\thereforetby {$a \rel {R(ST)} d$.}    {pelos~\byfact3 e~\byfact5}
\endstepproof
\qed
%%}}}

%%{{{ x: associativity_of_rcom_nat_lang 
\exercise.
\label{associativity_of_rcom_nat_lang}%
Escreva uma prova em linguagem natural da~\ref{associativity_of_rcom}.

\solution
\lrdir:
Suponha $a \in A$ e $d \in D$ tais que
$a \rel{((R\rcom S)\rcom T)} d$.
Logo, para algum $c\in C$, temos $a \rel{(R\rcom S)} c$\fact1\ e
$c \rel{T} d$\fact2,
e usando a \byfact1\ ganhamos um $b\in B$ tal que $a \rel{R} b$\fact3
e $b \rel{S} c$\fact4.
Juntando as \byfact4~e~\byfact2 temos $b \rel{(S \rcom T)} d$, e agora
junto com a \byfact3~chegamos em
$a \rel{((R\rcom S)\rcom T)} d$.
\endgraf
A direção \rldir\ é similar.

\endexercise
%%}}}

%%{{{ x: only_if_incest 
\exercise.
\label{only_if_incest}%
Prove ou refute:
$$
\Child\rcom\Parent
\askeq
\Parent\rcom\Child.
$$

\hint
$\Child\rcom\Parent\neq\Parent\rcom\Child$.
Agora refute!

\solution
Temos $\Child\rcom\Parent\neq\Parent\rcom\Child$:
\endgraf
Tome $x,y\in \cal P$ dois irmãos que não têm filhos (juntos).
Logo
$$
x \relp{\Parent\rcom\Child} y
\qqtext{mas não}
x \relp{\Child\rcom\Parent} y.
$$
Demonstramos assim que as duas relações são diferentes.

\endexercise
%%}}}

%%{{{ x: id_of_rcom 
\exercise.
\label{id_of_rcom}%
Considere a $\rcom$ como uma operação binária nas relações binárias num conjunto $A$.
Ela tem \dterm{identidade}?  Ou seja, existe alguma relação binária $I$ no $A$,
tal que
$$
\text{para toda relação $R$ no $A$,}\quad
I \rcom R = R = R \rcom I\,?
$$
Se sim, defina essa relação $I$ e prove que realmente é.
Se não, prove que não existe.

\hint
Sem pensar, dois candidatos prováveis para considerar seriam a igualdade no $A$
e a relação trivial $\True$ satisfeita por todos os pares de elementos de $A$:
$$
\text{ou}
\knuthcases{
x \rel I y \defiff \True\cr
x \rel I y \defiff x = y
}
$$

\solution
Existe sim: a $I$ é a igualdade $\eqof A$ no $A$.
Vamos mostrar que para todos $a,b \in A$
$$
a \rel R b \iff a \relp{I \rcom R} b.
$$
Tratamos cada direção separadamente.
\endgraf
\lrdir.
Suponha que $a \rel R b$.
Precisamos mostrar que
existe $w\in A$ tal que $a \rel I w$ e $w \rel R b$.
Tome $w \asseq a$.  Realmente temos $a \rel I a$ (pois $I$ é a igualdade),
e $a \rel R b$ que é nossa hipótese.
\endgraf
\rldir.
Suponha que $a \relp{I \rcom R} b$.
Logo, existe $w\in A$ tal que $a \rel I w$\fact1 e $w \rel R b$\fact2.
Mas, como $I$ é a igualdade, o único $w$ que satisfaz a~\reffact1 é o próprio~$a$.
Ou seja, $w = a$.
Substituindo na~\byfact2, ganhamos o desejado $a \rel R b$.
\endgraf
A outra equivalência,
$$
a \rel R b \iff a \relp{R \rcom I} b,
$$
é similar.

\endexercise
%%}}}

\blah.
Tendo uma operação binária (composição) e sua identidade (\ref{id_of_rcom})
podemos já definir as suas potências.

%%{{{ x: R_exp_n 
\exercise Potências.
\label{R_exp_n}%
Defina formalmente as ``potências'' $R^n$ duma dada relação binária $R$
num conjunto $A$, informalmente definida por:
$$
x \relp{R^n} y \pseudodefiff
x \rel{\Big(\tunderbrace{R \rcom\dotsb\rcom R}{$n$ vezes}\Big)} y,
$$
valida \emph{para todo $n\in\nats$}.

\hint
Questão: o que precisa achar para tua definição servir para o caso $n=0$ também?

\hint
Resposta: precisa achar o elemento neutro da operação $\rcompose$.
Já fez o~\ref{id_of_rcom}, né?

\solution
Definimos:
$$
\align
x \relp{R^0} y     &\defiff x=y \\
x \relp{R^{n+1}} y &\defiff x \relp{R \rcom {R^n}} y
\endalign
$$
ou, direitamente, em estilo ``point-free'':
$$
\align
R^0     &\defeq \Eq \\
R^{n+1} &\defeq R^n \rcom R,
\endalign
$$
onde escrevemos $\Eq$ para a relação $\eqof A$ de igualdade no $A$.

\endexercise
%%}}}

%%{{{ x: operation_with_opposite_does_not_yield_identity 
\exercise.
\label{operation_with_opposite_does_not_yield_identity}%
Prove ou refute:
\emph{para toda relação binária $R$ num conjunto $A$,
$R \rcom {\rop R} = \Eq = {\rop R} \rcom R$}.

\hint
\ref{grandparents_grandchildren_siblings_and_couples_with_children}.

\hint
\ref{only_if_incest}

\hint
Temos $\Parent = \rop \Child$ (e logo $\Child = \rop \Parent$ também).

\solution
Não, como o contraexemplo do~\ref{only_if_incest} mostra, pois
$$
{\Parent} = {\rop \Child} \qquad\mland\qquad {\Child} = {\rop \Parent}.
$$

\endexercise
%%}}}

%%{{{ x: describe_coauthors_in_terms_of_author 
\exercise.
\label{describe_coauthors_in_terms_of_author}%
Descreva a $\namedrel{Coauthors}$ do \ref{relations_with_text_example}
em termos da $\namedrel{Author}$.

\solution
Considerando que um escritor é coescritor com ele mesmo,
$$
\namedrel{Coauthors} = \namedrel{Author}\rcom\rop{\namedrel{Author}}.
$$

\endexercise
%%}}}

%%{{{ beware: rinv_is_not_inverse 
\beware A inversa não é inversa.
\label{rinv_is_not_inverse}%
Depois dos exercícios~\refn{operation_with_opposite_does_not_yield_identity}
e~\refn{describe_coauthors_in_terms_of_author}, deve ser claro porque eu
preferi chamar a $\rop R$ a relação \emph{oposta} da $R$, e usar essa notação
em vez de $\rinv R$ e o nome \emph{inversa}.
(Que também usamos pois são os mais comuns!)
Se usar a notação $\rinv R$, cuidado para não confundir que
$R \rcom {\rinv R} = \namedrel{Eq} = {\rinv R} \rcom R$,
pois em geral isso não é verdade.
Ou seja: a relação ``inversa'' $\rinv R$,
\emph{não é a $\rcom$-inversa} da $R$!
%%}}}

%%{{{ x: rop_of_rcompose 
\exercise.
\label{rop_of_rcompose}%
Sejam $R,S$ relações binárias tais que a $R\rcom S$ é definida.
Descreva a $\ropp{R\rcom S}$ em termos das $\rop R$ e $\rop S$
e prove tua afirmação.

\hint
${\ropp{R \rcom S}} = {\rop S \rcom \rop R}$.
Demonstre!

\solution
Vou demonstrar que $\ropp{R \rcom S} = \rop S \rcom \rop R$.
Calculo:
\compute
x \ropp{RS} y
&\iff y \rel{RS} x                                              \by {def.~$\ropp{RS}$}
&\iff \text{existe $w$ tal que $y \rel R w \mland w \rel S x$}  \by {def.~$RS$}
&\iff \text{existe $w$ tal que $w \rop R y \mland x \rop S w$}  \by {def.~$\rop R$ e~$\rop S$}
&\iff \text{existe $w$ tal que $x \rop S w \mland w \rop R y$}  \\
&\iff x \rel{{\rop S}{\rop R}} y.                               \by {def.~${\rop S}{\rop R}$}
\endcompute

\endexercise
%%}}}

%%{{{ df: union_and_inter_of_rels 
\definition união; intersecção.
\label{union_and_inter_of_rels}%
Sejam $R,S\subset A\times B$ relações binárias.
Definimos as relações $R\union S$ e $R\inter S$ no $\relspace{A,B}$
pelas
$$
\align
x \relp{R \union S} y &\defiff x \rel R y \mlor  x \rel S y \\
x \relp{R \inter S} y &\defiff x \rel R y \mland x \rel S y.
\endalign
$$
Observe que, identificando as relações com seus gráficos,
as $R \union S$ e $R \inter S$ acabam sendo a união
e intersecção deles mesmo:
$$
\align
\graphP {R \union S} &= \graph R \union \graph S \\
\graphP {R \inter S} &= \graph R \inter \graph S.
\endalign
$$
Claramente generalizamos para famílias de relações $\scr R$,
e assim temos as relações
$$
\xalignat2
\tsize \Union \scr R &: \reltype{A,B} &
\tsize x \relp{\Union \scr R} y & \defiff \lexists {R \in \scr R} {x \rel R y} \\
\tsize \Inter \scr R &: \reltype{A,B} &
\tsize x \relp{\Inter \scr R} y & \defiff \lforall {R \in \scr R} {x \rel R y}.
\endxalignat
$$
%%}}}

%%{{{ eg: union_and_inter_of_orders 
\example.
Nos reais, a $\mathop{<}\union\mathop{=}$ é a relação $\leq$,
e a $\mathop{\leq}\inter\mathop{\geq}$ é a relação $=$.
Substituindo o ``é a relação'' com o símbolo \sq{$=$} que usamos
normalmente a gente acabaria escrevendo essas coisas horrorosas:
$$
\xalignat2
\mathord{\mathop{<}\union\mathop{=}} &= \mathord{\leq} &
\mathord{\mathop{\leq}\inter\mathop{\geq}} &= \mathord{=}.
\intertext{%
Isso fica \emph{muito} esquisito no olho para parsear;
botando parenteses ajuda:
}
\paren{\mathord{\paren{\mathop{<}}\union\paren{\mathop{=}}}} &= \paren{\mathord{\leq}} &
\paren{\mathord{\paren{\mathop{\leq}}\inter\paren{\mathop{\geq}}}} &= \paren{\mathord{=}}.
\endxalignat
$$
Tente sempre escrever na maneira mais legível e entendível.
\endexample
%%}}}

\endsection
%%}}}

%%{{{ Properties of relations 
\section Propriedades de relações.

Aqui aumentamos nossa terminologia, identificando certas propriedades
interessantes que uma relação binária $R$ no $X$ pode ter.

%%{{{ Reflection 
\note Reflexão.
\label{reflexion_terminology}%
\tdefined{relação!reflexiva}%
\tdefined{relação!irreflexiva}%
Olhamos como cada elemento do $X$ relaciona com ele mesmo.
Dois casos notáveis aparecem:
(i) pode ser que para todo $x$ temos $x\rel R x$;
(ii) pode ser que para nenhum $x$ temos $x\rel R x$.
No primeiro caso, chamamos $R$ \dterm{reflexiva}; no segundo, \dterm{irreflexiva}.
Observe que ``irreflexiva'' não significa ``não reflexiva'', etc:
$$
\alignat 2
\text{$R$ é reflexiva}      &\iff \phantom\lnot\forall x R(x,x)        &&\iff \lnot\exists x \lnot R(x,x)\\
\text{$R$ não é reflexiva}  &\iff \lnot\forall x R(x,x)                &&\iff \phantom\lnot\exists x \lnot R(x,x)\\
\text{$R$ é irreflexiva}    &\iff \phantom\lnot\forall x \lnot R(x,x)  &&\iff \lnot\exists x R(x,x)\\
\text{$R$ não é irreflexiva}&\iff \lnot\forall x \lnot R(x,x)          &&\iff \phantom\lnot\exists x R(x,x)
\endalignat
$$
onde os quantificadores quantificam sobre o $X$.
%%}}}

%%{{{ eg 
\example.
As relações $=$, $\leq$, $\geq$, nos números e $=$, $\subset$, $\supset$ nos conjuntos são todas reflexivas.
Também reflexivas são as relações
\trel{\thole\ nasceu no mesmo pais que \thole},
\trel{\thole\ tem o mesmo primeiro nome com \thole}, etc.,
definidas entre pessoas.
Típicos exemplos de irreflexivas são as $\neq$, $<$, $>$, $\subsetneq$, $\supsetneq$,
\trel{\thole\ é mais baixo que \thole},
\trel{\thole\ e \thole\ nunca estiveram em distância de 2 metros entre si},
etc.
\endexample
%%}}}

%%{{{ Symmetry 
\note Simetria.
\label{symmetry_terminology}%
\tdefined{relação!simétrica}%
\tdefined{relação!assimétrica}%
\tdefined{relação!antissimétrica}%
Agora examinamos a relação $R$ com respeito à ordem dos seus argumentos.
Novamente, certos casos notáveis aparecem:
(i) $R$ pode comportar sempre no mesmo jeito independente da ordem dos seus argumentos; nesse caso a chamamos \dterm{simétrica}.
(ii) O $R$-relacionamento dum objeto $x$ com outro $y$ pode garantir que o $y$ não esta $R$-relacionado com o $x$; a chamamos \dterm{asimmétrica}.
(iii) O único caso onde a $R$ relaciona os mesmos argumentos com as duas possíveis órdens, é quando os dois argumentos são iguais; chamamos a $R$ \dterm{antisimmétrica}.
%%}}}

%%{{{ eg 
\example.
Simétricas:
$=$, $\neq$,
\trel{\thole\ e \thole\ são irmãos},
\trel{\thole\ e \thole\ são cidades do mesmo país},
etc.
\endgraf\noindent
Asimétricas:
$<$, $\subsetneq$, $>$, $\supsetneq$,
\trel{\thole\ deve dinheiro para \thole},
\trel{\thole\ está andando na mesma direção e no lado esquerdo de \thole},
\trel{\thole\ é a mãe de \thole},
etc.
\endgraf\noindent
Antissimétricas:
$\leq$, $\subset$, $\geq$, $\supset$, $=$,
\trel{a palavra \thole\ aparece, mas não depois da palavra \thole\ no dicionário},
etc.
\endexample
%%}}}

%%{{{ x: not_symmetric_notequiv_asymmetric 
\exercise.
\label{not_symmetric_notequiv_asymmetric}%
Verifique que ``não simétrica'' não significa nem ``assimétrica''
nem ``antissimétrica'', escrevendo todas as fórmulas envolvidas e suas negações,
como no~\refn{reflexion_terminology}.

\endexercise
%%}}}

%%{{{ x: check_reflexion_and_symmetry 
\exercise.
\label{check_reflexion_and_symmetry}%
Decida a ``reflexão'' e a ``simetria'' das relações seguintes:
$$
\align
R(A, B) &\letiff \text{os conjuntos $A$ e $B$ são disjuntos}\\
S(A, B) &\letiff |A\setminus B| > 1\\
T(A, B) &\letiff A\symdiff B \neq \emptyset.
\endalign
$$
Isso quis dizer: para cada uma dessas relações, decida se ela é:
reflexiva, irreflexiva, simétrica, asimétrica, antisimétrica.

\endexercise
%%}}}

%%{{{ x: asymmetric_implies_irreflexive 
\exercise.
\label{asymmetric_implies_irreflexive}%
Mostre que:
$$
\text{$R$ assimétrica} \implies \text{$R$ irreflexiva}.
$$

\hint
Contrapositivo.

\solution
Mostramos o contrapositivo.
Suponha que $R$ não é irreflexiva.
Então existe $s$ com $R(s,s)$,
e logo é impossível que a $R$ seja assimétrica,
pois achamos $x$ e $y$ ($x,y\asseq s$) que satisfazem ambas
$R(x,y)$ e $R(y,x)$.

\endexercise
%%}}}

%%{{{ x: asymetric_implies_antisymmetric 
\exercise.
\label{asymetric_implies_antisymmetric}%
Uma das duas direções abaixo é válida:
$$
\text{$R$ assimétrica} \askiff \text{$R$ antissimétrica}.
$$
Prove-a, e mostre que a oposta não é.

\hint
Como uma relação assimétrica poderia não ser antissimétrica?
(O que significa ``não ser antissimétrica''?)

\hint
Procure contraexemplo nos exemplos típicos de relação antissimétrica.

\solution
Para provar a \lrdir, observe que $R$ não é antissimétrica
sse existem $x$ e $y$ tais que:
$$
\underbrace{R(x,y)
\land
R(y,x)}_{\text{impossível por assimetria}}
{}\land\ \ 
{x\neq y}.
$$
Para refutar a \rldir, considere o contraexemplo da antissimétrica $\leq$
no $\nats$, que não é assimétrica, pois é reflexiva.

\endexercise
%%}}}

%%{{{ x: rop_of_symmetric 
\exercise.
\label{rop_of_symmetric}%
Seja $R : \reltype{X,X}$.
Logo
$$
\text{$R$ simétrica}
\iff
R = \rop R.
$$

\solution
\proofpart{\lrdir.}
Suponha $R$ simétrica.
\compute
x \rel R y
&\implies y \rel R x  \by {hipótese}
&\implies x \rop R y. \by {def.~$\rop R$}
\endcompute
\proofpart{\rldir.}
Suponha $R = \rop R$.
\compute
x \rel R y
&\implies y \rop R x  \by {def.~$\rop R$}
&\implies y \rel R x. \by {hipótese}
\endcompute

\endexercise
%%}}}

%%{{{ Transitions 
\note Transições.
\tdefined{relação!transitiva}%
\tdefined{relação!circular}%
\tdefined{relação!left-euclidean}%
\tdefined{relação!right-euclidean}%
Às vezes queremos garantir a existência de alguma seta dadas duas ou mais setas.
Suponha que $x\rel R y$ e $y \rel R z$.
Se isso garanta que $x\rel R z$ chamamos a $R$ \dterm{transitiva};
e se isso garanta que $z \rel R x$, \dterm{circular}.
Suponha agora que temos dois objetos cada um relacionado com um terceiro.
Se isso já é suficiente para garantir que eles também são relacionados,
chamamos a relação \dterm{left-euclidean}.
Similarmente, se a relação de um objeto com dois outros garanta que os outros
também relacionam entre si, chamamos a relação \dterm{right-euclidean}.
%%}}}

%%{{{ Why the names -euclidean? 
\note Por que ``euclidean''?.
O primeiro axioma de \Euclid{}Euclides no seu ``Elementos'' é:
\emph{coisas iguais com outra coisa, são iguais entre si também}.
Podemos visualizar isso tanto como
<<$a=c$ e $b=c$ implica $a=b$>>
(left-euclidean pois a conclusão aconteceu no lado esquerdo); 
quanto como
<<$a=b$ e $a=c$ implica $b=c$>>
(right-euclidean pois a conclusão aconteceu no lado direito).
%%}}}

%%{{{ Totalities 
\note Totalidades.
\tdefined{relação!total}%
\tdefined{relação!tricotômica}%
Tem duas noções onde uma relação pode ``dominar'' um conjunto, no sentido
de ``opiniar'' sobre quaisquer $x,y$ nele.
A primeira só usa a relação em questão $R$ mesmo:
dizemos que $R$ é \dterm{total} sse quaisquer $x,y$ são relacionados em pelo
menos uma ordem: $x \rel R y$ ou $y \rel R x$.
A segunda usa a ajuda da igualdade:
dizemos que $R$ é \dterm{tricotômica} sse para quaisquer $x,y$ exatamente
uma das três possibilidades é válida: $x \rel R y$; $y \rel R x$; $x = y$.
%%}}}

%%{{{ Glossary: relations_glossary 
\note Glossário.
\label{relations_glossary}%
Resumimos aqui as propriedades que encontramos.
Seja $X$ conjunto e $R$ uma relação binária nele.
Definimos as seguintes propriedades:
$$
\alignat2
&x \rel R x                                         \called {reflexiva}
&x \not\rel R x                                     \called {irreflexiva}
&x \rel R y  \implies  y \rel R x                   \called {simétrica}
&x \rel R y  \implies  y \not\rel R x               \called {assimétrica}
&x \rel R y  \mland y \rel R x \implies x = y       \called {antissimétrica}
&x \rel R y  \mland  y \rel R z \implies x \rel R z \called {transitiva}
&x \rel R y  \mland  y \rel R z \implies z \rel R x \called {circular}
&x \rel R y  \mland  x \rel R z \implies y \rel R z \called {right-euclidean}
&x \rel R z  \mland  y \rel R z \implies x \rel R y \called {left-euclidean}
&x \rel R y  \mlor   y \rel R x                     \called {total}
\text{exatamente uma das:}\quad
&x \rel R y\, ; \ \  y \rel R x\, ; \ \  x = y      \called {tricotômica}
\endalignat
$$
Para o caso mais geral onde $R$ é uma relação binária de $X$ para $Y$, temos:
$$
\alignat2
&\pforall {x \in X} \lexists {y \in Y} {x \rel R y} \called {left-total}
&\pforall {y \in Y} \lexists {x \in X} {x \rel R y} \called {right-total ou surjectiva}
&y \rel R x  \mland  z \rel R x \implies y = z      \called {left-unique ou injectiva}
&x \rel R y  \mland  x \rel R z \implies y = z      \called {right-unique ou funcional}
\endalignat
$$
%%}}}

%%{{{ x: investigate_rel_properties_of_three_diags 
\exercise.
\label{investigate_rel_properties_of_three_diags}%
Para cada uma das relações $R,S,Q,F,T$ do~\refn{first_internal_diagrams_for_rel}
e do~\ref{empty_and_true_relation} decida se ela têm ou não, cada uma das
propriedades do glossário no~\refn{relations_glossary}.

\hint
Cuidado: nas propriedades que acabam ser implicações, as variáveis que aparecem
nas suas premissas não denotam obrigatoriamente objetos distintos!

\endexercise
%%}}}

%%{{{ prop: wrong_property_of_sym_and_trans_implies_refl 
\proposition.
\label{wrong_property_of_sym_and_trans_implies_refl}%
Seja $X\neq\emptyset$ e $\sim$ uma relação no $X$.
Se $\sim$ é simétrica e transitiva, então ela é reflexiva.
\wrongproof.
Como ela é simétrica, de $x\sim y$ concluimos que $y\sim x$ também.
E agora usando a transitividade, de $x\sim y$ e $y\sim x$, concluimos a $x\sim x$,
que mostra que $\sim$ é reflexiva também.
\mistaqed
%%}}}

%%{{{ x: find the error and prove that the proposition is false 
\exercise.
Ache o erro na prova acima e \emph{prove} que a proposição é falsa!

\endexercise
%%}}}

%%{{{ remark: conventions_for_internal_diagrams_of_rel 
\remark Convenções para diagramas internos.
\label{conventions_for_internal_diagrams_of_rel}%
Quando queremos desenhar o diagrama duma relação que
sabemos que tem uma certa propriedade, podemos preguiçar
e não desenhar todas as suas setas.
\crtabcase{Reflexiva:}
não precisamos botar nenhuma das setinhas-redemoinhos,
pois graças à reflexividade são todas implicitas.
\crtabcase{Simétrica:}
não precisamos botar cabeças nas setas, pois para
cada seta já é garantida a sua seta-oposta, então
botamos apenas uma linha entre dois objetos e já
entendemos que existem as setas das duas direções
entre si.
\crtabcase{Transitiva:}
não precisamos desenhar setas entre objetos se já
existe um caminho entre eles usando outras setas
já desenhadas.
\crtabcase{Relação de equivalência:}
não precisamos desenhar nem linhas entre os objetos
que relacionam; apenas desenhar regiões por volta
de todos os relacionados, algo que vai virar óbvio
na~\ref{Quotient_set}.
\crtabcase{Relação de ordem:}
desenhamos diagramas de~{\Hasse{}}Hasse, que vamos
encontrar depois (pouco
na~\ref{hasse_diagrams_first_encounter} e muito
no~\ref{Posets}).
%%}}}

\endsection
%%}}}

%%{{{ Closures 
\section Fechos.
\label{Closures}%

\blah.
Antes de definir formalmente o conceito importante de fechos,
começamos com uns exemplos ilustrativos para os três fechos mais comuns:
reflexivo, simétrico, transitivo.
A idéia é sempre a mesma, e vamos descrevê-la como um algoritmo.

%%{{{ The idea 
\note A idéia.
\label{Closure_informal_bottom_up}%
Começamos com uma relação $R$, e fixamos uma propriedade
desejada (por exemplo, a transitividade).
Vamos construir uma nova relação $\bar R$, que chamamos o \dterm{fecho}
da $R$ pela propriedade escolhida.
Pense na $R$ como o seu diagrama interno, com suas setinhas.
Primeiramente nós nos perguntamos:
<<a relação já tem essa propriedade?>>
Caso que sim, não precisamos fazer nada, a relação que temos é
o fecho $\bar R$ que queriamos construir.
Caso que não, quis dizer que tem setinhas que
\emph{deveriam estar} no diagrama, mas não estão.
(Essas setinhas são as testemunhas que refutam a nossa propriedade.)
Vamos adicioná-las na nossa relação.
E agora voltamos a perguntar a mesma pergunta,
e continuar no mesmo jeito, até finalmente chegar numa
relação $\bar R$ que realmente satisfaz a propriedade escolhida.
Essa relação $\bar R$ é o fecho da $R$ pelessa propriedade.
%%}}}

%%{{{ eg: reflexive_closure_example 
\example Fecho reflexivo.
\label{reflexive_closure_example}%
Seja $R$ a relação no $A$ com o diagrama seguinte:
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\endtikzpicture
$$
Qual é o fecho reflexivo dela?
Bem, primeiramente nós nos perguntamos:
será que a relação já é reflexiva?
Ela não é.
Identificamos então as setinhas-testemunhas desse fato:
são as $(1,1)$, $(3,3)$, $(7,7)$, e $(8,8)$.
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\node[color=blue] (elem-1b) at (elem-1) {$1$};
\node[color=blue] (elem-3b) at (elem-3) {$3$};
\node[color=blue] (elem-7b) at (elem-7) {$7$};
\node[color=blue] (elem-8b) at (elem-8) {$8$};
\draw[->, color=red, ultra thick, dotted] ([shift={(0,0.2)}]elem-3) arc (10:290:0.25);
\draw[->, color=red, ultra thick, dotted] ([shift={(0,0.2)}]elem-7) arc (10:290:0.25);
\draw[->, color=red, ultra thick, dotted] ([shift={(0,-.2)}]elem-1) arc (-170:120:0.25);
\draw[->, color=red, ultra thick, dotted] ([shift={(-.2,0)}]elem-8) arc (80:350:0.25);
\endtikzpicture
$$
As adicionamos na relação e chegamos em:
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\draw[->] ([shift={(0,0.2)}]elem-3) arc (10:290:0.25);
\draw[->] ([shift={(0,0.2)}]elem-7) arc (10:290:0.25);
\draw[->] ([shift={(0,-.2)}]elem-1) arc (-170:120:0.25);
\draw[->] ([shift={(-.2,0)}]elem-8) arc (80:350:0.25);
\endtikzpicture
$$
\dots e perguntamos a mesma pergunta:
será que ela é reflexiva?
Agora é sim!
Essa relação então é o \emph{fecho reflexivo} da $R$.
\endexample
%%}}}

%%{{{ eg: symmetric_closure_example 
\example Fecho simétrico.
\label{symmetric_closure_example}%
Vamos calcular agora o fecho simétrico da mesma relação $R$
do~\ref{reflexive_closure_example}:
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\endtikzpicture
$$
Será que ela já é simétrica?
Ela não é por causa das três setinhas seguintes,
onde para cada uma mostro em azul a setinha-razão que obriga
a setinha-faltante (em vermelho) ser adicionada:
$$
\xxalignat3
&
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\draw[->, color=blue, ultra thick        ] (elem-8) to                 (elem-6);
\draw[->, color=red , ultra thick, dotted] (elem-6) to [bend left=30]  (elem-8);
\endtikzpicture
&&
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\draw[->, color=blue, ultra thick        ] (elem-6) to                 (elem-7);
\draw[->, color=red , ultra thick, dotted] (elem-7) to [bend left=15]  (elem-6);
\endtikzpicture
&&
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\draw[->, color=blue, ultra thick        ] (elem-5) to                 (elem-8);
\draw[->, color=red , ultra thick, dotted] (elem-8) to [bend right=30] (elem-5);
\endtikzpicture
\endxxalignat
$$
Então adicionamos todas essas setinhas necessárias:
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\draw[->            ] (elem-8) to                 (elem-6);
\draw[->            ] (elem-6) to                 (elem-7);
\draw[->            ] (elem-5) to                 (elem-8);
\draw[->            ] (elem-6) to [bend left=30]  (elem-8);
\draw[->            ] (elem-7) to [bend left=15]  (elem-6);
\draw[->            ] (elem-8) to [bend right=30] (elem-5);
\endtikzpicture
$$
Agora perguntamos novamente: a relação é simétrica?
Ela é sim, então paramos aqui.
A relação criada é o \emph{fecho simétrico} da $R$.
\endexample
%%}}}

%%{{{ eg: transitive_closure_example 
\example Fecho transitivo.
\label{transitive_closure_example}%
Para ser original, seja $R$ a mesma relação dos
exemplos~\refn{reflexive_closure_example}--\refn{symmetric_closure_example}:
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\endtikzpicture
$$
Essa vez vamos calcular o fecho transitivo dela, então começamos com a pergunta:
será que a relação já é transitiva?
Não é!
Então precisamos achar todas as setinhas que deveriam estar nela e não estão
e adicioná-las:
$$
\xxalignat3
&
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\draw[->, color=blue, ultra thick        ] (elem-5) to (elem-8);
\draw[->, color=blue, ultra thick        ] (elem-8) to (elem-6);
\draw[->, color=red , ultra thick, dotted] (elem-5) to (elem-6);
\endtikzpicture
&&
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\draw[->, color=blue, ultra thick        ] (elem-8) to (elem-6);
\draw[->, color=blue, ultra thick        ] (elem-6) to (elem-7);
\draw[->, color=red , ultra thick, dotted] (elem-8) to (elem-7);
\endtikzpicture
&&
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\draw[->, color=blue, ultra thick        ] (elem-1) to [bend left=20] (elem-2);
\draw[->, color=blue, ultra thick        ] (elem-2) to [bend left=20] (elem-1);
\draw[->, color=red , ultra thick, dotted] ([shift={(0,-.2)}]elem-1) arc (-170:120:0.25);
\endtikzpicture
\endxxalignat
$$
Adicionando todas essas setas necessárias, chegamos na relação:
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosurest1;
\endtikzpicture
$$
E perguntamos: ela é transitiva?
\emph{Ainda não!}
Pois, as novas setinhas que adicionamos criaram novos caminhos que
obrigam mais uma setinha estar na relação (dois caminhos diferentes
explicam a adição dessa mesma setinha nesse caso):
$$
\xalignat2
&
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosurest1;
\draw[->, color=blue, ultra thick        ] (elem-5) to (elem-6);
\draw[->, color=blue, ultra thick        ] (elem-6) to (elem-7);
\draw[->, color=red , ultra thick, dotted] (elem-5) to (elem-7);
\endtikzpicture
&&
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosurest1;
\draw[->, color=blue, ultra thick        ] (elem-5) to (elem-8);
\draw[->, color=blue, ultra thick        ] (elem-8) to (elem-7);
\draw[->, color=red , ultra thick, dotted] (elem-5) to (elem-7);
\endtikzpicture
\endxalignat
$$
Adicionamos então a setinha $(5,7)$:
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosurest1;
\draw[->] (elem-5) to (elem-7);
\endtikzpicture
$$
Ela é transitiva agora?  Sim, finalmente!
Então esse é o \emph{fecho transitivo} da $R$.
\endexample
%%}}}

%%{{{ pseudodf: fecho_pseudodefinition 
\pseudodefinition.
\label{closure_pseudodefinition}%
\tdefined{fecho!de relação}%
Seja $R$ uma relação binária num conjunto $A$,
e fixe uma propriedade \emph{razoável}
daquelas que aparecem no~glossário~\refn{relations_glossary}.
Definimos o fecho da $R$ pela propriedade para ser a relação que criamos se
\emph{adicionar} numa maneira \emph{justa} todas as setinhas \emph{necessárias}
no diagrama da $R$ até ela virar uma relação com a propriedade
desejada.
%%}}}

%%{{{ remark: we may add but never remove 
\remark Podemos botar mas não retirar.
Note então que o fecho $\bar R$ de uma relação $R$ tem todas
as setinhas que $R$ tem, e possivelmente mais ainda.
Ou seja, temos
$$
\graph R \subset \graph \bar R
$$
para qualquer fecho escolhido.
%%}}}

\blah.
Na~\ref{closure_pseudodefinition} enfatizei as palavras ``razoável'',
``justa'' e ``necessárias''.
Vamos ver o que cada uma delas quis dizer mesmo.

%%{{{ Necessary arrows 
\note Setinhas necessárias.
``Adicionar apenas as setinhas \emph{necessárias}'' quis dizer que
a falta de cada uma dessas setinhas é uma razão que nossa relação não
satisfaz a propriedade escolhida.
Caso contrário não vamos adiciona-la, \emph{mesmo se sua adição não afeta nada}.
%%}}}

%%{{{ Fair way 
\note Maneira justa.
``Adicionar setinhas numa maneira \emph{justa}'' quis dizer que em
nenhum ponto vamos ter que escolher entre duas ou mais setinhas-testemunhas
\emph{tais que a adição de apenas uma} seria suficiente para satisfazer
a propriedade.
Imagine que nesse caso, nossa escolha não seria justa para a setinha
não-escolhida (ou para a setinha escolhida, dependendo o ponto de vista).
Formar o fecho duma relação deve ser uma operação, e sendo isso deve
ser determinística.
Imagina entao que temos uma propriedade estranha, dizendo que:
$$
x \rel R x \mland y \rel R y \implies x \rel R y \mlor y \rel R x.
$$
(Nem adianta tentar achar um nome razoável para essa propriedade.)
Agora, a relação $R$ no $\nats$ com $\graph R = \set{ (0,0), (1,1) }$
claramente não satisfaz essa propriedade.
Tentando formar o fecho através dessa propriedade, já na primeira etapa,
temos duas ``setinhas-testemunhas'' que podemos escolher para adicionar:
a $(0,1)$ e a $(1,0)$.  Graças à restricção de ``necessárias'', não podemos
adicionar ambas, pois assim que adicionar uma, a propriedade já é satisfeita.
No outro lado, não podemos escolher uma das duas numa maneira justa:
as duas servem igualmente bem.
\emph{Para esse tipo de propriedade então não podemos definir um fecho.}
Espero que isso explica também o que eu quis dizer com a palavra ``razoável''.
O~\ref{unreasonable_properties_for_closures_of_relations} esclarecerá
isso ainda mais.
%%}}}

%%{{{ x: unreasonable_properties_for_closures_of_relations 
\exercise.
\label{unreasonable_properties_for_closures_of_relations}%
Por que não falamos de fecho total, irreflexivo, e asimétrico?

\hint
Seja justo.

\solution
Fechando através da totalidade a gente deveria tomar umas decisões
injustas.
Fechando através da irreflexividade a gente deveria retirar setinhas
quando fechando podemos apenas adicionar.
Fechando através da asimetria, a gente deveria retirar setinhas
também e inclusive isso seria numa maneira injusta:
dadas setinhas $(0,1)$ e $(1,0)$ qual das duas tu vai escolher para retirar?

\endexercise
%%}}}

%%{{{ x: order_of_closures_matters 
\exercise.
\label{order_of_closures_matters}%
Seja $R$ relação num conjunto $A$.
Podemos concluir alguma das afirmações seguintes?:
\beginil
\item{(i)}   $t(r(R)) \askeq r(t(R))$
\item{(ii)}  $t(s(R)) \askeq s(t(R))$
\item{(iii)} $r(s(R)) \askeq s(r(R))$
\endil
Aqui $r, s, t$ são os fechos reflexivo, simétrico, transitivo respectivamente.

\hint
Use diagramas internos.

\hint
Tente achar um contraexemplo para o (ii).
Qual a dificuldade de achar contraexemplo para o (i) e qual para o (iii)?

\endexercise
%%}}}

%%{{{ Q: How would you define the reflexive and symmetric closures of R? 
\question.
Como tu definarias formalmente o fecho reflexivo e o fecho simétrico duma relação $R$?
%%}}}
\spoiler.

%%{{{ df: rclosure 
\definition Fecho reflexivo.
\label{rclosure}%
\tdefined{fecho!reflexivo}%
\sdefined {\rclosure {\sholed R}} {o fecho reflexivo da $R$}%
\sdefined {\rclo {\sholed R}} {o fecho reflexivo da $R$}%
Seja $R$ relação num conjunto $A$.
Definimos a relação $\rclosure R$ pela
$$
x \rclosure R y \defiff x \rel R y \mlor x = y
$$
Chamamos a $\rclosure R$ o \dterm{fecho reflexivo} da $R$.
Também usamos a notação $\rel {R^=}$.
%%}}}

%%{{{ x: wrong_sclosure_definition 
\exercise.
Alguém definiu o fecho simétrico assim:
\quotepar
<<Seja $R$ relação binária num conjunto $A$.
Seu fecho simétrico é a relação $\sclosure R$ definida pela
$$
x \sclosure R y \pseudodefiff x \rel R y \mland y \rel R x\;\text{.>>}
$$
\endquote
Ache o erro na definição e mostre que a definição realmente é errada.

\hint
Aplique fielmente essa definição na relação do~\ref{symmetric_closure_example}.

\hint
Essa definição pode acabar apagando setas!

\solution
Tome a relação $R$ nos $\nats$ com gráfico $\set{(0,1)}$.
Aplicando essa suposta definição da $\sclosure R$ então temos:
$$
x \sclosure R y \iff x \rel R y \mland y \rel R x \iff \False
$$
ou seja, a $x \sclosure R y$ acaba sendo a relação vazia.
Assim acabamos apagando setinhas, algo contra do nosso conceito de fecho!

\endexercise
%%}}}

%%{{{ df: sclosure 
\definition Fecho simétrico.
\label{sclosure}%
\tdefined{fecho!simétrico}%
\sdefined {\sclosure {\sholed R}} {o fecho simétrico da $R$}%
\sdefined {\sclo {\sholed R}} {o fecho simétrico da $R$}%
Seja $R$ relação num conjunto $A$.
Definimos a relação $\sclosure R$ pela
$$
x \sclosure R y \defiff x \rel R y \mlor y \rel R x.
$$
Chamamos a $\sclosure R$ o \dterm{fecho simétrico} da $R$.
Também usamos a notação $\rel {R^\leftrightarrow}$.
%%}}}

%%{{{ x: wrong_tclosure_definition 
\exercise.
Alguém definiu o fecho transitivo assim.
\emph{Seja $R$ relação binária num conjunto $A$.
Seu fecho transitivo é a relação $\tclosure R$ definida pela}
$$
x \tclosure R y \pseudodefiff \text{existe $w\in A$ tal que $x \rel R w \mland w \rel R y$}.
$$
Mas isso não é o fecho transitivo da $R$.  O que é mesmo?

\solution
A relação definida é a $R^2$, ou seja, a $R \rcom R$.

\endexercise
%%}}}

%%{{{ Q: How would you define the transitive closures of R? 
\question.
Como tu definarias formalmente o fecho transitivo duma relação $R$?
%%}}}
\spoiler.

%%{{{ df: tclosure and rtclosure 
\definition Fecho transitivo.
\label{tclosure}%
\label{rtclosure}%
\tdefined{fecho!transitivo}%
\tdefined{fecho!reflexivo-transitivo}%
\sdefined {\tclosure {\sholed R}} {o fecho transitivo da $R$}%
\sdefined {\tclo {\sholed R}} {o fecho transitivo da $R$}%
\sdefined {\rtclosure {\sholed R}} {o fecho reflexivo-transitivo da $R$}%
\sdefined {\rtclo {\sholed R}} {o fecho reflexivo-transitivo da $R$}%
Seja $R$ relação num conjunto $A$.
Definimos as relações $\tclosure R$ e $\rtclosure R$ pelas
$$
\xalignat2
x \tclosure R y &\defiff x \rel {R^n} y \ \ \text{para algum $n\in\nats_{>0}$}.
&&\text{(\dterm{fecho transitivo} da $R$)}\\
x \rtclosure R y &\defiff x \rel {R^n} y \ \ \text{para algum $n\in\nats$}
&&\text{(\dterm{fecho reflexivo-transitivo} da $R$)}\\
\endxalignat
$$
Chamamos a $\tclosure R$ o \dterm{fecho transitivo} da $R$,
e a $\rtclosure R$ o \dterm{fecho reflexivo-transitivo} da $R$.
Também usamos as notações $\tclo R$ para o $\tclosure R$
e $\rtclo R$ para o $\rtclosure R$.
%%}}}

%%{{{ x: find_reflexive_transitive_closure_of_pgoesto 
\exercise.
\label{find_reflexive_transitive_closure_of_pgoesto}%
Definimos no $\nats$ a relação binária $\leadsto$ pela:
$$
a\leadsto b \defiff \text{para algum primo $p$, $ap = b$}.
$$
Qual é o seu fecho reflexivo-transitivo?

\endexercise
%%}}}

\blah.
Deixamos as definições de outros fechos para os problemas.

%%{{{ x: isPred 
\exercise.
\label{isPred}%
Considere a relação $\to$ no $\nats$, definida pela:
$$
x\to y \defiff x + 1 = y.
$$
Descreva as relações seguintes:
\item{$\transcl{\to}$}: seu fecho transitivo;
\item{$\rtranscl{\to}$}: seu fecho reflexivo-transitivo;
\item{$\rtranscl{\leftrightarrow}$}: seu fecho reflexivo-transitivo-simétrico.
\endgraf\noindent

\endexercise
%%}}}

%%{{{ x: isPred_in_reals 
\exercise.
\label{isPred_in_reals}%
Considere a relação $\to$ definida pela mesma equação como
no~\ref{isPred}, mas essa vez no conjunto $\reals$.
Descreva os mesmos fechos.

\endexercise
%%}}}

%%{{{ remark: and_if_we_never_reach_closure 
\remark E se nunca chegar?.
\label{and_if_we_never_reach_closure}%
Esse processo descrito no~\ref{Closure_informal_bottom_up} pode ser
que nunca termina, ou seja esse <<até finalmente chegar>> que escrevi
lá pode ser que nunca chega mesmo numa relação com a propriedade
desejada.  Por exemplo, considere a $\to$ do~\ref{isPred}.
Se pensar que começamos com ela no dia $1$ e que cada dia que passa
adicionamos todas as cetinhas atualmente sendo testemunhas de
falta de transitividade, em qual dia vamos chegar numa relação
transitiva?
\emph{Nunca!}
\emph{E isso seria verdade para um imortal também!}
Mas a idéia descrita no~\refn{Closure_informal_bottom_up} funciona
mesmo assim; é só esquecer essa frase de <<finalmente chegar>>
e entender que pode ser que nunca chegamos numa relação completa,
mas mesmo assim, o processo determina uma relação sim:
para saber se uma setinha $(x,y)$ está no fecho ou não, é só
perguntar se ela vai ``entrar'' um belo dia ou não.
%%}}}

\endsection
%%}}}

%%{{{ Bottom_up_top_down_closures 
\section Bottom-up \vs top-down.
\label{Bottom_up_top_down_closures}

\blah.
Vamos fingir para essa discussão que relações são mesmo
os conjuntos das suas setinhas (ou seja, seus gráficos)
pois vai facilitar a fala informal e uma notação conjuntista
que vou usar.  Espero que tu já fez
o~\ref{repeat_after_me_relations_are_not_sets}, e logo
tu entenderás bem a discussão seguinte tanto no nível informal
quanto nos detalhes ``verdadeiros'' por trás.  Vamo lá!

\TODO Adicionar desenhos.

%%{{{ top_down_closure 
\note Top-down.
\label{top_down_closure}%
Imagine que para algum motivo gostamos muito duma propriedade de
relações da forma
\standout
<<se \emph{algo}, então tem que ter essas certas setinhas>>.
\endstandout
(Pense em transitividade como exemplo ``padrão'' aqui.)
Vamos chamar as relações que tem nossa propriedade de \dterm{legais}.
Começamos com um conjunto $A$ uma relação nele $R$ bugada,
possivelmente ilegal.
(Isso quis dizer que não tem a propriedade escolhida.)
Procuramos \emph{a} relação $\overline R$ para chamar
de fecho ``legal'' da $R$; esse fecho deve satisfazer:
\beginil
\item{(L1)} $\overline R \supset R$;
\item{(L2)} $\overline R$ é legal;
\endil
e deve ser ``a melhor'' entre todas as relações $L$ que
satisfazem ambas essas condições.
Mas o que significa \emph{melhor}, e o que nos faz acreditar
que existe \emph{a} melhor?
Aqui melhor quis dizer que a $\overline R$ deve ser \emph{fiel}
na $R$, no sentido de não conter setas desnecessárias, setas
não fornecidas/necessidadas por causa da relação original $R$.
Como vamos descobrir, tal $\overline R$ existe mesmo, e vamos
definí-la numa maneira extremamente elegante e legal!
\endgraf
A primeira coisa importante para perceber é que
\emph{já sabemos que pelo menos uma relação satisfaz ambas as
condições (L1)--(L2) acima:} a relação cheia, trivial $\True$
do $A$.  Vamo chamá-la de $G$---pense ``Grande''.
Com certeza $G \supset R$, pois como poderia não ser?
$G$ é a relação cheia, ela tem todas as setinhas, então
com certeza as setinhas da $R$ também.
Pelo mesmo motivo e pela natureza da própria propriedade
temos certeza que $G$ também goza da (L2): ela é legal.
\endgraf
Bem, temos uma candidata; mas estamos procurando a melhor,
pois essa pode ter \dterm{lixo}.  Procuramos uma maneira
de jogar fora todo o lixo da $G$.
\endgraf
Uma idéia ruim para conseguir isso seria seguinte:
pega uma setinha $\alpha$ do $G\setminus R$ e veja se removendo
essa $\alpha$, tu quebras a ``legaldade''.
Qual o problema com essa abordagem?
Bem: vai que tu pegou uma setinha e que observou
que ela não pode ser jogada fora, pois duas outras setinhas
estão a obrigando ficar mesmo.
Mas, por que confiar nessas outras setinhas?
Talvez elas mesmas também fazem parte do lixo, e deveriam ser jogadas
foras também.  Mas então, como escolher onde começar a investigação?
Hah!  Nem vamos escolher nenhum canto para começar, pois nem vamos
começar investigar nada disso!  Vamos usar uma maneira bem simples
e jogar todo o lixo fora num instante só!
\endgraf
Vamos definir a colecção de todos os candidatos:
$$
\scr L_R \defeq
\setst {L : \reltype{A,A}} {L \supset R \mland \text{$L$ é legal}}.
$$
Primeiramente observe que sabemos que essa colecção não é vazia,
pois se fosse a gente teria um problema grande---tu vai entender logo qual.
Realmente, a $G$ é uma das candidatas, então $G \in \scr L_R$ e logo
$\scr L_R \neq \emptyset$.
Agora observe que cada candidato $L \in \scr L_R$ satisfaz
$$
G \supset L \supset R.
$$
Ambas são imediates pela definição do $\scr L_R$.
Tem então dois casos extremos (onde $L$ é uma das $G,R$) mas no caso
geral $L$ fica estritamente entre as relações $G$ e $R$.
Estamos finalmente prontos para a definição linda que prometi,
que vai acabar com todo o lixo:
\endgraf
$$
\overline R \defeq \Inter \scr L_R.
$$
Afirmo que:
\beginil
\item{(1)} $\overline R \supset R$;
\item{(2)} $\overline R$ é legal;
\item{(3)} $\overline R$ é a melhor: não tem lixo nenhum.
\endil
\endgraf
Antes de demonstrar esses pontos, primeiramente quero te preocupar
com uma outra perguta:
%%}}}

%%{{{ Q: How do you know that the arrow you deleted is not needed? 
\question.
Alguém poderia reclamar que certas das setinhas que foram jogadas
fora nesse processo, por exemplo essa aqui abaixo, foram injustamente
tiradas, e talvez eram essenciais, ou seja, necessárias mesmo para
a legaldade da relação.  O que responderias?  Como podemos convencer
essa pessoa que a setinha não foi realmente necessária?
%%}}}
\spoiler.

%%{{{ A 
\note Resposta.
Observe que essa setinha pertence a uma das candidatas do $\scr L_R$,
mas tem outras candidatas que não têm essa setinha nelas e mesmo assim
conseguem ser legais!  Ou seja, com certeza essa setinha não pode ser
necessária mesmo para a legaldade da relação que estamos procurando!
%%}}}

%%{{{ What's missing? 
\note O que falta?.
Basta demonstrar as (1)--(3) agora.
A primeira \emph{deve ser óbvia} para o leitor que já passou pelo~\ref{Sets}
(até se ele pulou---foi sem querer né?---o~\ref{Inter_of_supsets_supset},
que é exatamente isso).
As outras duas, tu demonstrarás agora:
%%}}}

%%{{{ x: top_down_closure_prove_2 
\exercise.
\label{top_down_closure_prove_2}%
Demonstre a (2) do~\ref{top_down_closure}

\endexercise
%%}}}

%%{{{ x: top_down_closure_prove_3 
\exercise.
\label{top_down_closure_prove_3}%
Demonstre a (3) do~\ref{top_down_closure}

\endexercise
%%}}}

%%{{{ bottom_up_closure 
\note Bottom-up.
%%}}}

\TODO Descrever como imortal construtor por dia.

%%{{{ Always coincide? 
\note Sempre concordam?.
Tem situações onde a definição bottom-up e definição top-down discordam!
Isso pode acontecer, por exemplo, quando o ``imortal'' construindo na
maneira bottom-up necessitaria uma infinidade
\emph{mais longa que a largura dos naturais}---e se essa frase
não fez nenhum sentido agora, tranqüilo, não era pra fazer:
volte a relê-la depois de ter estudado \emph{aritmética ordinal}
no~\ref{Ordinal_arithmetic}.
%%}}}

\endsection
%%}}}

%%{{{ Order relations 
\section Relações de ordem.
\label{Order_relations}%

%%{{{ df: order_relation 
\definition Ordem.
\label{order_relation}%
Seja $R$ uma relação binária num conjunto $A$.
Chamamos a $R$ \dterm{ordem parcial} sse ela é reflexiva, transitiva, e antissimétrica.
Se ela também é total, a chamamos de \dterm{ordem total}.
%%}}}

%%{{{ beware: total-partial default, relations vs functions 
\beware.
Quando usamos apenas o termo \emph{ordem}, entendemos como \emph{ordem parcial}.
Observe que esta convenção é a oposta que seguimos nas funções, onde um pleno
\emph{função} quis dizer \emph{função total}.
%%}}}

%%{{{ eg: subset and supset are orders 
\example.
Dado qualquer conjunto $X$, seus subconjuntos
são parcialmente ordenados tanto por $\subset$
quanto por $\supset$.
\endexample
%%}}}

%%{{{ eg: common orders are orders 
\example.
As $\leq$ e $\geq$ comuns são ordens totais nos $\nats,\ints,\rats,\reals$.
\endexample
%%}}}

%%{{{ divides_is_not_an_order_on_ints 
\exercise.
\label{divides_is_not_an_order_on_ints}%
A relação $\divides$ nos inteiros é uma relação de ordem?

\hint
O que podemos concluir se $a\divides b$ e $b\divides a$?

\endexercise
%%}}}

%%{{{ divides_is_a_partial_order_on_nats 
\example.
A relação $\divides$ no $\nats$ é uma ordem parcial.
(Provaste isso no~\ref{divides_is_almost_a_partial_order}.)
\endexample
%%}}}

%%{{{ df: strict_order 
\definition Ordem estrita.
\label{strict_order}%
\tdefined{ordem}[estrita]%
Seja $R$ uma relação binária num conjunto $A$.
Chamamos a $R$ \dterm{ordem estrita} sse ela é irreflexiva, transitiva, e assimétrica.
Se ela também é tricotômica, chamamos-la \dterm{ordem estrita total}.
%%}}}

%%{{{ remark: default adjective 
\remark Adjectivo implícito.
\tdefined{ordem}[fraca]%
Quando queremos enfatizar que uma relação é uma ordem e não uma ordem estrita,
usamos o termo \dterm{fraca}.  Similarmente com as funções (totais vs.~parciais),
Dependendo do contexto o \emph{adjectivo implícito} pode mudar.
Quando focamos em ordens estritas, ``ordem'' vira sinônimo de ``ordem estrita''
e precisamos o adjectivo ``fraca'' para referir a uma ordem (fraca).
%%}}}

%%{{{ x: weak_fromto_strong_orders 
\exercise De fraca para estrita; ida e volta.
\label{weak_fromto_strong_orders}%
(1)
Seja $\leq$ ordem num conjunto $A$.
Defina a relação $<$ no $A$ pela:
$$
x < y \defiff x \leq y \mland x \neq y.
$$
Prove que $<$ é uma ordem estrita.
\endgraf\noindent
(2)
Seja $<$ ordem estrita num conjunto $A$, e
defina a relação $\leq$ no $A$ pela:
$$
x \leq y \defiff x < y \mlor x = y.
$$
Prove que $\leq$ é uma ordem.

\endexercise
%%}}}

%%{{{ df: preorder_relation 
\definition Preordem.
\label{preorder_relation}%
\tdefined{preordem}%
\iisee{quasiordem}{preordem}%
Uma relação binária $R$ num conjunto $A$ é chamada \dterm{preordem} (ou \dterm{quasiordem}) sse ela é reflexiva e transitiva.
%%}}}

%%{{{ eg: divides_is_a_preorder_on_ints 
\example.
\label{divides_is_a_preorder_on_ints}%
Como provamos no~\ref{divides_is_almost_a_partial_order},
a relação $\divides$ nos inteiros é uma preordem.
\endexample
%%}}}

\blah.
No~\ref{why_called_preorder} tu vai justificar o nome ``preordem'',
mostrando que cada preordem $R$ fornece uma ordem $R'$.

\blah.
Paramos \emph{por enquanto} o estudo de relações de ordem;
pois voltaremos a estudá-las depois (capítulos~\refn{Posets},
\refn{Wellorderings_and_transfinite_induction},
\refn{Ordinal_arithmetic}, e~\refn{Denotational_semantics}).

\endsection
%%}}}

%%{{{ Equivalence relations 
\section Relações de equivalência.
\label{Equivalence_relations}%

%%{{{ idea_of_equivalence 
\note Equivalência.
\label{idea_of_equivalence}%
Considere um conjunto $A$, onde queremos ``identificar'' certos elementos deles,
talvez porque ligamos apenas sobre uma propriedade, e queremos ignorar os
detalhes irrelevantes que nos obrigariam distinguir uns deles.
Por exemplo, se $A$ é um conjunto de pessoas, podemos focar apenas na
``nacionalidade''.  Esquecendo todos os outros detalhes então, vamos
considerar todos os copatriotas como se fossem ``iguais'':
o termo certo é \dterm{equivalentes}.
Outra propriedade poderia ter sido o ano que cada pessoa nasceu,
ou o primeiro nome, ou até quem é a mãe de cada pessoa.
Queremos identificar as propriedades que uma relação desse tipo tem que ter:
\item{(i)} Reflexividade: não importa qual foi o critério que escolhemos
para ``equivaler'' os objetos, cada objeto com certeza vai ``concordar''
com ele mesmo nesse critério.
\item{(ii)} Transitividade:
se $a$ e $b$ concordam no assunto escolhido, e $b$ e $c$ também,
com certeza $a$ e $c$ devem concordar também.
\item{(iii)} Simetría: pela natureza da nossa intuição é claro que
para decidir se dois elementos serão equivalentes ou não, não precisamos
considerá-los numa ordem específica.
\endgraf
\noindent Chegamos assim na definição seguinte:
%%}}}

%%{{{ df: equivalence_relation 
\definition.
\label{equivalence_relation}%
\tdefined{relação!de equivalência}%
Seja $A$ conjunto e $\sim$ uma relação binária no $A$.
Chamamos $\sim$ uma \dterm{relação de equivalência} sse ela é
reflexiva, simétrica, e transitiva.
Definimos também o
$$
\eqrelspace A \defeq \setstt {R \in \relspace{A,A}} {$R$ é uma relação de equivalência}.
$$
%%}}}

%%{{{ eg: eqrel_eg_eq 
\example.
\label{eqrel_eg_eq}%
A $=$ é uma relação de equivalência.
\endexample
%%}}}

%%{{{ eg: eqrel_eg_parity 
\example.
\label{eqrel_eg_parity}%
A relação $\sim_2$ que relaciona exatamente os inteiros com a mesma paridade
$$
x \sim_2 y \defiff \text{ambos os $x,y$ são pares ou ambos os $x,y$ são ímpares}.
$$
Essa relação de equivalência é um caso especial da próxima.
\endexample
%%}}}

%%{{{ x: congruence_mod_m_is_an_eqrel_again 
\exercise.
\label{congruence_mod_m_is_an_eqrel_again}%
Seja $m\in\nats$.
Prove que a relação binária nos inteiros definida pela
$$
a \congmod m b \defiff a \cong b \pmod m
$$
é uma relação de equivalência.

\solution
Esqueceu o~\ref{congruence_mod_m_is_an_eqrel}?

\endexercise
%%}}}

%%{{{ eg: eqrel_eg_countries 
\example.
\label{eqrel_eg_countries}%
No conjunto $\cal P$ de pessoas, a relação
$$
x \sim y \defiff \text{$x$ e $y$ nasceram no mesmo país}
$$
é uma relação de equivalência.
\endexample
%%}}}

%%{{{ eg: eqrel_eg_children 
\example.
\label{eqrel_eg_children}%
No conjunto $\cal P$ de pessoas, a relação
$$
x \sim y \defiff \text{$x$ e $y$ têm a mesma quantidade de filhos}
$$
é uma relação de equivalência.
\endexample
%%}}}

%%{{{ eg: eqrel_eg_teams 
\example.
\label{eqrel_eg_teams}%
No conjunto $\cal B$ de jogadores profissionais de basquete,
a relação
$$
x \sim y \defiff \text{$x$ e $y$ jogam no mesmo clube}
$$
é uma relação de equivalência.
\endexample
%%}}}

%%{{{ noneg: eqrel_noneg_food
\nonexample.
\label{eqrel_noneg_food}%
Num conjunto $\cal P$ de pessoas, a relação
$$
x \sim y \defiff \text{existe comida que $x$ e $y$ ambos comeram hoje}
$$
não é sempre uma relação de equivalência.
\endnonexample
%%}}}

%%{{{ x: why not? 
\exercise.
Por que não?

\hint
Não é necessariamente nem reflexiva nem transitiva.
Invente um contraexemplo para cada propriedade.

\endexercise
%%}}}

%%{{{ eg: equivalent_relations_on_euclidean_plane 
\example.
\label{equivalent_relations_on_euclidean_plane}%
No $\reals^2$ considere as relações:
$$
\align
\tup{x,y} \sim_1 \tup{x',y'}
&\iff x = x'\\
\tup{x,y} \sim_2 \tup{x',y'}
&\iff y = y'\\
\tup{x,y} \sim_{\textrm N} \tup{x',y'}
&\iff \norm{ \tup{x,y} } = \norm{ \tup{x',y'} }
\endalign
$$
Facilmente todas são relações de equivalência.
\endexample
%%}}}

%%{{{ eg: equivalent_relations_on_euclidean_space 
\example.
\label{equivalent_relations_on_euclidean_space}%
No $\reals^3$ considere as relações:
$$
\align
\tup{x,y,z} \sim_3 \tup{x',y',z'}
&\iff z = z'\\
\tup{x,y,z} \sim_{1,2} \tup{x',y',z'}
&\iff x = x' \mland y = y' \\
\tup{x,y,z} \sim_{\textrm N} \tup{x',y',z'}
&\iff \norm{ \tup{x,y,z} } = \norm{ \tup{x',y',z'} }
\endalign
$$
Facilmente todas são relações de equivalência.
\endexample
%%}}}

%%{{{ x: cannot replace and with or 
\exercise.
Mudamos o ``e'' para ``ou'' na segunda relação
do~\ref{equivalent_relations_on_euclidean_space}:
$$
\tup{x,y,z} \sim \tup{x',y',z'} \iff x = x' \mlor y = y'
$$
A $\sim$ é uma relação de equivalência?

\hint
Ache um contraexemplo que refuta sua transitividade.

\solution
Não, pois não é transitiva.
Tome os
$\tup{0,0,0}$,
$\tup{0,1,0}$, e
$\tup{2,1,0}$.
Observe que
$$
\tup{0,0,0}
\sim
\tup{0,1,0}
\mland
\tup{0,1,0}
\sim
\tup{2,1,0}
$$
mas $\tup{0,0,0} \not\sim \tup{2,1,0}$.

\endexercise
%%}}}

%%{{{ x: guaranteed_eqrels 
\exercise.
\label{guaranteed_eqrels}%
Seja $A$ um conjunto qualquer.
Quais relações de equivalência podes já definir nele,
sem saber absolutamente nada sobre seus elementos?

\solution
A identidade $\eqof A$, a trivial $\True$, e a vazia $\False$.

\endexercise
%%}}}

%%{{{ x: how_many_equivalence_relations_on_3 
\exercise.
\label{how_many_equivalence_relations_on_3}%
Seja $A$ conjunto com $\card A = 3$.
Quantas relações de equivalência podemos definir no $A$?

\hint
Deixe para responder junto com o~\ref{how_many_partitions_on_3}.

\solution
Encontramos a resposta dessa pergunta no~\ref{how_many_partitions_on_3}.

\endexercise
%%}}}

%%{{{ x: equivalent_properties_to_eqrel 
\exercise.
\label{equivalent_properties_to_eqrel}%
Seja $R$ uma relação binária num conjunto $A$.
O.s.s.e.:
\item{(i)}   $R$ é uma relação de equivalência;
\item{(ii)}  $R$ é reflexiva e circular;
\item{(iii)} $R$ é reflexiva e left-euclideana;
\item{(iv)}  $R$ é reflexiva e right-euclideana.

\endexercise
%%}}}

%%{{{ x: distance_like_not_transitive 
\exercise.
\label{distance_like_not_transitive}%
Seja real $\epsilon\in(0,1)$, e defina a relação $\approx_\epsilon$:
$$
x \approx_\epsilon y \defiff (x-y)^2 < \epsilon.
$$
A $\approx_\epsilon$ é uma relação de equivalência?

\hint
Primeiramente resolve o mesmo problema mas para a relação:
$$
x \sim_\epsilon y \defiff |x-y| < \epsilon
$$
onde $\epsilon > 0$.

\hint
Reflexividade e simetria das $\sim_\epsilon$ e $\approx_\epsilon$ são imediatas.
Sobre a transitividade, um desenho na linha real ajudaria.

\hint
Como contraexemplo, tome os reais $0$, $\epsilon/2$, e $\epsilon$ e
observe que $0 \sim_\epsilon \epsilon/2$ e $\epsilon/2 \sim_\epsilon \epsilon$
mas mesmo assim não temos $0\sim_\epsilon \epsilon$.

\hint
Como podes usar a não-transitividade da $\sim_\epsilon$
para deduzir a não-transitividade da $\approx_\epsilon$?

\hint
Para todo $\alpha\in\reals_{\geq 0}$ temos:
$$
\cdots
\iff
\sqrt{\alpha}\in(0,1)
\iff
\alpha\in(0,1)
\iff
\alpha^2\in(0,1)
\iff
\cdots
$$

\solution
Não é.  Uma resolução já foi rescunhada nas dicas.
Para um contraexemplo direto, pode tomar os reais
$0$, $\sqrt \epsilon / 2$, e $\sqrt \epsilon$.
Observe que $0 \approx_\epsilon \sqrt \epsilon / 2$
e $\sqrt \epsilon / 2 \approx_\epsilon \sqrt \epsilon$
mas não temos $0 \approx_\epsilon \sqrt \epsilon$.

\endexercise
%%}}}

%%{{{ df: equivalent_class 
\definition.
\label{equivalent_class}%
\tdefined{classe de equivalência}%
\sdefined {\eqclass {\sholed a} {\sholed R}} {a classe de equivalência do $a$ através da $R$}%
\sdefined {\eqclassimp {\sholed a}} {a classe de equivalência do $a$ (relação implícita pelo contexto)}%
Seja $A$ um conjunto e $\sim$ uma relação de equivalência no $A$.
Para cada $a\in A$, definimos a \dterm{classe de equivalência do} $a$
como o conjunto de todos os membros de $A$ que $\sim$-relacionam com o $a$.
Formalmente definimos
$$
\eqclass a {\sim} \defeq \set {x\in A \st x\sim a}.
$$
Às vezes aparece também a notação $\eqclassalt a \sim$.
Quando a relação de equivalência é implicita pelo contexto
denotamos a $\eqclass a \sim$ apenas por $\eqclassimp a$.
%%}}}

%%{{{ x: type_of_eqclass_hole 
\exercise.
\label{type_of_eqclass_hole}%
Sejam $A$ conjunto, $a\in A$, e $\sim$ relação de equivalência no $A$.
Considere as funções seguintes definidas com buracos:
$$
\xalignat3
\eqclass {\dhole} {\sim}   &: \ \askdots &
\eqclass {a} {\dhole}      &: \ \askdots &
\eqclass {\dhole} {\dhole} &: \ \askdots
\endxalignat
$$
Escreva tipos válidos para essas funções.

\solution
Escrevemos os tipos:
$$
\align
\eqclass {\dhole} {\sim}   &: A \to \pset A \\
\eqclass {a} {\dhole}      &: E \to \pset A \\
\eqclass {\dhole} {\dhole} &: \paren{A \cross \eqreltype A} \to \pset A.
\endalign
$$

\endexercise
%%}}}

%%{{{ x: equivalent_statements_to_x_equiv_y 
\exercise.
\label{equivalent_statements_to_x_equiv_y}%
Sejam $\sim$ uma relação de equivalência num conjunto $X$, e $a,b\in X$.
Mostre que as afirmações seguintes são equivalentes:
\item{(i)} $a\sim b$;
\item{(ii)} $\eqclassimp a = \eqclassimp b$;
\item{(iii)} $\eqclassimp a \inter \eqclassimp b \neq \emptyset$.

\solution
\proofpart{Vamos demonstrar primeiro a {\rm ((i)\tiff(iii))}.}
\crtabproofpart{\lrdir.}
Suponha que $a \sim b$.
Precisamos achar um elemento que pertence nos dois conjuntos
$\eqclassimp a$ e $\eqclassimp b$.
Tome o próprio $a$.
Temos $a\in \eqclassimp a$ pois $a \sim a$ (pela reflexividade da $\sim$).
Também temos $a \in \eqclassimp b$, pois $a \sim b$ (hipótese).
Logo $a \in \eqclassimp a \inter \eqclassimp b\neq\emptyset$.
\crtabproofpart{\rldir.}
Suponha que $\eqclassimp a\inter\eqclassimp b \neq \emptyset$
e tome $w \in \eqclassimp a\inter\eqclassimp b$.
Logo $w \in \eqclassimp a$ e $w \in \eqclassimp b$,
ou seja $w \sim a$ e $w \sim b$ pela definição de classe de equivalência.
Pela simetría da $\sim$ temos $a \sim w$.
Agora como $a\sim w$ e $w \sim b$, pela transitividade da $\sim$ ganhamos
o desejado $a \sim b$.
\crproofpart{Agora vamos demonstrar a {\rm ((i)\tiff(ii))}.}
\crtabproofpart{\lrdir.}
Suponha que $a \sim b$.
Tome $x\in \eqclassimp a$.
Logo $x \sim a$.
Mas $a \sim b$ e logo pela transitividade da $\sim$ temos $x \sim b$,
e logo $x \in \eqclassimp b$.
\crtabproofpart{\rldir.}
Suponha que $\eqclassimp a = \eqclassimp b$.
Pela reflexividade da $\sim$, sabemos que $a\in\eqclassimp a$.
Logo $a\in\eqclassimp b$, e logo $a\sim b$ pela definição de $\eqclassimp b$.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Problems intermission 
\problems Intervalo de problemas.

%%{{{ prob: preorders_are_idempotent 
\problem.
\label{preorders_are_idempotent}%
Seja $R$ uma preordem num conjunto $A$.
Prove que $R$ é \dterm{idempotente}, ou seja, $R = R \rcom R$.

\solution
\def\R{\rel R}%
\def\RR{\rel {(R \rcom R)}}%
Vamos provar as duas direções separadamente.
\crproofpart{$x \R y \implies x \RR y$:}
Suponha $x \R y$.
Como $\R$ é reflexiva, logo $x \R x$.
Pelas $x \R x$ e $x \R y$ concluimos que $x \RR y$.
\crproofpart{$x \RR y \implies x \R y$:}
Suponha $x \RR y$.
Logo $x \R w$ e $w \R y$ para algum $w \in A$ (pela def.~de $\rcom$),
e logo pela transitividade da $\R$ temos $x \R y$.

\endproblem
%%}}}

%%{{{ prob: when_is_rop_irreflexive 
\problem.
\label{when_is_rop_irreflexive}%
Seja $S$ uma relação binária num conjunto $A$ tal que
$$
\text{$\relp{S \rcom {\rop S}}$ é irreflexiva}.
$$
Qual é o gráfico da $S$?
Prove tua resposta.

\hint
Supondo que $x \rel S y$, o que tu consegues concluir?

\solution
$\graph(S) = \emptyset$.
\endgraf
Pois, supondo que tem membros, tome $(x,y) \in \graph(S)$, e agora:
$x \rel S y$ e logo $y \rop S x$ (pela def.~de $\rop S$).
Logo $x \relp{S \rcom {\rop S}} x$, que contradiza
a irreflexividade da $S \rcom {\rop S}$.

\endproblem
%%}}}

%%{{{ prob: rcom_does_not_respect_transitivity 
\problem.
\label{rcom_does_not_respect_transitivity}%
Sejam $R,S$ relações binárias e transitivas no $A$.
Podemos concluir que $R \rcom S$ também é transitiva?
Se sim, demonstre; se não, mostre um contraexemplo.

\hint
Não.  Para achar um contraexemplo desenha as
setinhas das relações envolvidas para construir
os desejados $x,y,z$.

\endproblem
%%}}}

%%{{{ prob: rop_iter_R_eq_iter_rop_R 
\problem.
\label{rop_iter_R_eq_iter_rop_R}%
Seja $R:\reltype{X,X}$.
Demonstre que para todo $n\in\nats$,
$$
\ropp{R^n} = \paren{\rop R}^n.
$$

\hint
Indução.

\solution
Por indução.
\crproofpart{Base.}
Calculamos:
\compute
\ropp{R^0}
&= \ropp{\eqof X}     \by {def.~$R^0$}
&= (\eqof X)          \by {pelo~\ref{rop_of_symmetric}}
&= \paren{\rop R}^0.  \by {def.~$\paren{\rop R}^0$}
\endcompute
\crproofpart{Passo indutivo.}
Seja $k\in\nats$ tal que $\ropp{R^k} = \paren{\rop R}^k$\fact{HI}.
Calculamos:
\compute
\ropp{R^{k+1}}
&=\ropp{R R^k}              \by {def.~$R^{k+1}$}
&=\ropp{R^k R}              \by {Lemma}
&=\rop R \ropp{R^k}         \by {\ref{rop_of_rcompose}}
&=\rop R \paren{\rop R}^k   \by {HI}
&=\paren{\rop R}^{k+1}      \by {def.~$R^{k+1}$}
\endcompute
Onde devemos demonstrar o Lemma:
{\proclaimstyle
para todo $t\in\nats$, $R^t R = R R^t$.}
\crproofpart{Demonstração do Lemma.}
Por indução.
\crproofpart{Base: $R^0 R \askeq R R^0$.}
Imediato pois $R^0 = (\eqof X)$ e $\eqof X$ é uma $\rcom$-identidade (\ref{id_of_rcom}).
\crproofpart{Passo indutivo.}
Seja $w \in \nats$ tal que $R^w R = R R^w$\fact{HI}.
Calculamos:
\compute
R^{w+1} R
&= (R^w R) R  \by {def.~$R^{w+1}$}
&= (R R^w) R  \by {HI}
&= R (R^w R)  \by {assoc.~$\rcom$ (\refn{associativity_of_rcom})}
&= R (R R^w)  \by {HI}
&= R R^{w+1}. \by {def.~$R^{w+1}$}
\endcompute

\endproblem
%%}}}

%%{{{ prob: condorcet_paradox 
\problem Condorcet.
\label{condorcet_paradox}%
\Condorcet[parádoxo]%
Seja $P\neq\emptyset$ um conjunto de pessoas e
$C\neq\emptyset$ um conjunto de candidatos.
Seja $\gtrdot$ a relação binária no $C$ definida pela
$$
x \gtrdot y \defiff \text{a maioria da população do $P$ prefere $x$ do que $y$}.
$$
Podemos concluir que $\gtrdot$ é transitiva?
Responde ``sim'' e prove; ou ``não'' e mostre um contraexemplo.

\hint
Já jogou ``pedra--papel--tesoura''?

\solution
Não.  Sejam $P = \set{p,q,r}$ e $C = \set{a,b,c}$.
Considere que as pessoas do $P$ em ordem de preferência de melhor para pior têm:
$$
\align
    p:\ & a, b, c \\
    q:\ & c, a, b \\
    r:\ & b, c, a.
\endalign
$$
Assim temos:
$$
\alignat2
a &\gtrdot b, \by {pois os $p,q$ preferem $a$ que $b$}
b &\gtrdot c, \by {pois os $p,r$ preferem $b$ que $c$}
\endalignat
$$
mas $a \smartnot\gtrdot c$ pois apenas o $p$ prefere $a$ que $c$.
De fato, $c \gtrdot a$, pois os $q,r$ preferem $c$ que $a$.

\endproblem
%%}}}

%%{{{ prob: dom_trans_cod_not_trans 
\problem.
\label{dom_trans_cod_not_trans}%
Sejam $A \toby f B$ e $\leadsto$ uma relação transitiva no $A$.
Definimos a relação $R$ no $B$ pela
$$
b \rel R b'
\defiff
\text{existem $a, a' \in A$ tais que $f(a) = b$, $f(a') = b'$, e $a \leadsto a'$}.
$$
Podemos concluir que $R$ também é transitiva?
Se sim, demonstre; se não, mostre um contraexemplo.

\hint
Não.

\hint
A $f$ não é necessariamente injetora.

\solution
Não, e vamos ver um contraexemplo.
Considere:
$$
\align
A &= \set{1,2,3,4} \\
B &= \set{5,6,7}
\endalign
$$
e a $\leadsto$ relacionando apenas os:
$$
\align
1 &\leadsto 2 \\
3 &\leadsto 4.
\endalign
$$
Defina a $f:A\to B$ pelas
$$
\align
1 &\mapstoby f 5 \\
2 &\mapstoby f 6 \\
3 &\mapstoby f 6 \\
4 &\mapstoby f 7.
\endalign
$$
Primeiramente observe que realmente $\leadsto$ é transitiva.
Vamos verificar que: $5 \rel R 6$ e $6 \rel R 7$ mas mesmo assim
$5 \not\rel R 7$.
Os testemunhos de $5 \rel R 6$ são os $1$ e $2$; e
os testemunhos de $6 \rel R 7$ são os $3$ e $4$.
Mas os únicos candidados para testemunhos de $5 \rel R 7$
são os $1$ e $4$, e $1 \not\leadsto 4$; e logo $5 \not\rel R 7$.

\endproblem
%%}}}

%%{{{ prob: dom_trans_cod_trans_if_inj 
\problem.
\label{dom_trans_cod_trans_if_inj}%
O que muda no~\ref{dom_trans_cod_not_trans} se
adicionar a hipótese que $f$ é injetora?
Prove tua afirmação.

\endproblem
%%}}}

%%{{{ prob: explain_succ_rel 
\problem.
\label{explain_succ_rel}%
Seja a relação $\to$ no $\nats$ definida pela
$$
a \to b \defiff a + 1 = b.
$$
Dê uma definição simples da relação $\to^n$ para quem não sabe
nem de iterações nem de composições de relações (e sequer quer aprender essas noções).
Prove tua afirmação, que a relação $\to^n$ é igual à relação que tu definiu.

\hint
Seja $n\in\nats$.  Temos:
$$
a \rel{\to^n} b \iff a + n = b.
$$
Agora prove que isso é válido para todo $a,b,n\in\nats$.

\solution
Seja $n\in\nats$.  Temos:
$$
a \rel{\to^n} b \iff a + n = b.
$$
Sejam $a,b\in\nats$.
Vou provar por indução que para todo $n\in\nats$,
$$
a \ton n b  \iff  a + n = b.
$$
\proofpart{Base.}
Temos
\compute
a \ton 0 b
&\iff a = b \by {pela def.~$\ton 0$}
&\iff a + 0 = b.
\intertext{
\proofpart{Passo Indutivo.}
Seja $k\in\nats$ tal que
}
a \ton k b &\ifflabel {HI} a + k = b.
\intertext{Calculamos:}
a \ton {k+1} b
&\iff a \rel{(\ton k\rcom\to)} b              \by {def.~$\ton{k+1}$}
&\iff \lexists w {a \ton k w \mland w \to b}  \by {def.~$\rcom$}
&\iff \lexists w {a + k = w \mland w + 1 = b} \by {HI; def.~de~$\to$}
&\iff {(a + k) + 1 = b} \\
&\iff {a + (k + 1) = b}.
\endcompute

\endproblem
%%}}}

%%{{{ prob: agree_on_at_least_half_relation 
\problem.
Sejam conjunto $A$ com $\card A>2$, e $n$ inteiro par positivo.
No $A^n$ defina:
$$
a \sim b
\defiff
\card{ \setst {i\in\finord n} {a_i = b_i} } \geq n/2,
$$
onde
$a \eqass \tup{ a_0, \dotsc, a_{n-1}}$
e
$b \eqass \tup{ b_0, \dotsc, b_{n-1}}$.
A $\sim$ é uma relação de equivalência?

\solution
Não é.
Sejam $s,t,u\in A$ distintos dois-a-dois.
Tome
$$
\align
a &\leteq \tup{ s,s,\dots,s,t,t,\dotsc,t }\\
b &\leteq \tup{ s,s,\dots,s,u,u,\dotsc,u }\\
c &\leteq \tup{ t,t,\dots,t,u,u,\dotsc,u }
\endalign
$$
como contraexemplo, pois temos
$a \sim b$ e $b \sim c$ mas $a\not\sim c$.

\endproblem
%%}}}

%%{{{ prob: simh_simv_apph_appv 
\problem.
\label{simh_simv_apph_appv}%
\def\simh{\mathrel{\sim}}%
\def\simv{\mathrel{\wr}}%
\def\apph{\mathrel{\approx}}%
\def\appv{\mathrel{\wr\mkern-1mu\wr}}%
Considere as relações seguintes no $(\ints\to\ints)$:
$$
\align
f \simh g &\defiff \pexists {u\in\ints} \lforall {x \in\ints} {f(x) = g(x+u) } \\
f \apph g &\defiff \pexists {u\in\nats} \lforall {x \in\ints} {f(x) = g(x+u) } \\
f \simv g &\defiff \pexists {u\in\ints} \lforall {x \in\ints} {f(x) = g(x)+u } \\
f \appv g &\defiff \pexists {u\in\nats} \lforall {x \in\ints} {f(x) = g(x)+u }.
\endalign
$$
Para cada uma dessas relações, decida se é:
(ir)reflexiva; transitiva; (a(nti)s)simétrica.

\hint
Primeiramente tente entender (visualizar) essas relações.

\solution
{%
\def\simh{\mathrel{\sim}}%
\def\simv{\mathrel{\wr}}%
\def\apph{\mathrel{\approx}}%
\def\appv{\mathrel{\wr\mkern-1mu\wr}}%
Primeiramente tentamos entender essas relações bem informalmente.
As $\simh$ e $\apph$ envolvem um movimento horizontal,
e as $\simv$ e $\appv$ um movimento vertical.
Especificamente $f \simh g$ [$f \simv g$]
sse $f$ e $g$ são a mesma função depois de um ``shift'' horizontal
[vertical] para qualquer direção.
As $\apph$ e $\appv$ são parecidas so que $f \apph g$
[$f \appv g$] sse a $f$ ``coincide'' com a $g$ depois de um
``shift'' da $f$ para a direita [para baixo] $0$ ou mais ``posições''.
\endgraf\medskip
\crtabproofpart{Reflexividade.}
Todas são reflexivas, algo que mostramos tomando $u \asseq 0$.
Vamos ver em detalhe apenas para a $\simh$.
\crproofpart{Reflexividade da $\apph$.}
\endgraf\noindent
    Seja $f : \ints\to\ints$.
    Temos para todo $x\in \ints$, $f(x) = f(x + 0)$, e como $0\in\nats$,
    logo $f\apph f$.
\endgraf\medskip
\crtabproofpart{Transitividade.}
Todas são transitivas, e parecida em todas:
usando nossas hipoteses ganhamos dois números $i,j$ e o número que procuramos
acaba sendo o $i + j$.
Vamos ver em detalhe apenas para a $\appv$:
\crproofpart{Transitividade da $\appv$.}
\endgraf\noindent
    Sejam $f,g,h: \ints\to\ints$ tais que $f\simh g$ e $g\simh h$.
    Sejam então $i,j\in\ints$ tais que:
    $$
    \align
    \text{para todo $x\in \ints$, }&f(x) = g(x+i) \tag{1} \\
    \text{para todo $x\in \ints$, }&g(x) = h(x+j).\tag{2}
    \endalign
    $$
    Seja $z\in\ints$ e calcule:
    \compute
    f(z)
    &= g(z+i)       \by {pela (1) com $x \asseq z$}
    &= h((z+i)+j)   \by {pela (2) com $x \asseq z+i$}
    &= h(z+(i+j)).
    \endcompute
    Ou seja, o inteiro $i+j$ mostra que $f\simh h$.
Já provamos então que todas essas relações são preordens!
Vamos pesquisar sobre as outras propriedades agora.
\endgraf\medskip
\crtabproofpart{(A(nti)s)simetria.}
As $\simh$ e $\simv$ são simétricas, algo que mostramos para as
duas no mesmo jeito: nossa hipótese fornece um $i\in\ints$
que satisfaz algo, e o inteiro que procuramos acaba sendo o $-i$.
As $\appv$ é antissimétrica, mas a $\apph$ não satisfaz nenhuma
dessas propriedades.
Vamos provar a simetria da $\simh$, a antisimmetria da $\appv$,
e refutar a simetria e a antissimetria da $\apph$.
\crproofpart{Simetria da $\simh$.}
\endgraf\noindent
    Sejam $f,g : \ints\to\ints$ tais que $f\simh g$.
    Então seja $i\in\ints$ tal que
    para todo $x\in \ints$, $f(x) = g(x+i)$\fact1.
    Observe que para todo $x\in\ints$, temos:
    \compute
    g(x)
    &= g(x+(i-i)) \\
    &= g((x-i)+i) \\
    &= f(x-i).    \by {pela~\byfact1~com $x\asseq x-i$}
    \endcompute
    Ou seja, o $-i\in\ints$ mostra que $g\simh f$.
\crproofpart{Antisimmetria da $\appv$.}
\endgraf\noindent
    Sejam $f,g : \ints\to\ints$ tais que $f\appv g$ e $g\appv f$.
    Sejam então $i,j\in\nats$ tais que para todo $x\in \ints$
    $f(x) = g(x)+i$ e $g(x) = f(x)+j$.
    Seja $x\in\ints$ e calcule:
    $$
    f(x) = g(x)+i = f(x) + j + i.
    $$
    Logo $i+j = 0$, e sendo ambos naturais, temos $i=j=0$.
    Ou seja, para todo $x\in\ints$, $f(x) = g(x)$, e logo $f=g$.
\crtabproofpart{A $\appv$ não é nem relação de equivalência nem de ordem.}
\crproofpart{Refutação da simetria da $\apph$.}
    \endgraf\noindent
    Como contraexemplo tome as funções $f,g : \ints\to\ints$
    definidas pelas:
    $$
    \xalignat2
    f(0) &= 1                   & g(1) &= 1 \\
    f(x) &= 0 \quad (x \neq 0)  & g(x) &= 0 \quad (x \neq 1)
    \endxalignat
    $$
    Observe que realmente $f \apph g$ pois temos
    que para todo $x \in \ints$, $f(x) = g(x+1)$.
    Mas $g\not\apph f$.  Suponha que tem $u\in\nats$
    tal que para todo $x\in\ints$, $g(x) = f(x + u)$.
    Basta ou achar um absurdo.
    Pela nossa hipótese, $g(1) = f(1 + u)$.
    Mas $g(1) = 1$, ou seja $f(1+u) = 1$.
    Pela definição da $f$ então $u+1 = 0$,
    Absurdo, pois o $0$ não é sucessor de nenhum natural.
\crproofpart{Refutação da antissimetria da $\apph$.}
    \endgraf\noindent
    Como contraexemplo tome as funções $f,g : \ints\to\ints$
    definidas pelas:
    $$
    \xalignat2
    f(x) &=
    \knuthcases{
    0, & se $x$ é par; \cr
    1, & se $x$ é ímpar;
    }
    &
    g(x) &=
    \knuthcases{
    1, & se $x$ é par; \cr
    0, & se $x$ é ímpar;
    }
    \endxalignat
    $$
    Observe que realmente $f \apph g$ (tome $u \asseq 1$)
    e $g \apph f$ (tome $u \asseq 1$ de novo).
    Mesmo assim, $f\neq g$.
    Logo $\apph$ não é uma relação antisimmétrica.
\endgraf\medskip
Concluimos então que:
as $\simh$ e $\simv$ são relações de equivalência,
a $\appv$ é uma relação de ordem,
e a $\apph$ apenas uma preordem.
}

\endproblem
%%}}}

%%{{{ prob: simz_sime_simo_simi 
\problem.
\label{simz_sime_simo_simi}%
\def\simz{\rel{\stackrel{{}_{\mathrmsmall z}}=}}%
\def\sime{\rel{\stackrel{{}_{\mathrmsmall e}}=}}%
\def\simo{\rel{\stackrel{{}_{\mathrmsmall o}}=}}%
\def\simi{\rel{\stackrel{\infty}=}}%
Defina as relações seguintes no $(\nats\to\nats)$ assim:
$$
\align
f\simz g&\defiff f(0)    = g(0) \\
f\sime g&\defiff f(2n)   = g(2n)  \ \text{para todo $n\in\nats$} \\
f\simo g&\defiff f(2k+1) = g(2k+1)\ \text{para todo $k\in\nats$} \\
f\simi g&\defiff f(n)    = g(n)   \ \text{para uma infinidade de $n\in\nats$.}
\endalign
$$
\beginil
\item{(i)}
Para cada uma da $\simz,\sime,\simo,\simi$, decida se é uma relação de
equivalência ou não.
\item{(ii)}
Prove ou refute a afirmação seguinte:
\emph{a relação $(\sime\rcom\simo)$ é a relação trivial $\mathsf{True}$.}
\endil

\hint
{%
\def\simi{\rel{\stackrel{\infty}=}}%
Ache um contraexemplo para a $\simi$.  As outras, são.
}

\solution
{%
\def\simz{\rel{\stackrel{{}_{\mathrmsmall z}}=}}%
\def\sime{\rel{\stackrel{{}_{\mathrmsmall e}}=}}%
\def\simo{\rel{\stackrel{{}_{\mathrmsmall o}}=}}%
\def\simi{\rel{\stackrel{\infty}=}}%
(i)
A $\simi$ não é.  Considere o seguinte contraexemplo.
Sejam as $\alpha, \beta, \gamma : \nats\to\nats$ (como seqüências):
$$
\align
\alpha &= \tup{0,1,0,1,0,1,\dotsc} \\
\beta  &= \tup{0,2,0,2,0,2,\dotsc} \\
\gamma &= \tup{1,2,1,2,1,2,\dotsc}.
\endalign
$$
Trivialmente, $\alpha\simi\beta$ e $\beta\simi\gamma$ mas $\alpha\not\simi\gamma$.
\endgraf\noindent
(ii)
Correto.
Sejam $f, g \in (\nats\to\nats)$.
Vamos mostrar que $f \relp{\sime\rcom\simo} g$.
Pela definição da $\rcom$ temos:
$$
f \relp{\sime\rcom\simo} g
\iff \text{existe $h \in (\nats\to\nats)$ tal que $f \sime h$ e $h\simo g$}.
$$
A função $h : \nats\to\nats$ definida pela
$$
h(n) = \knuthcases{
f(n), &se $n$ par \cr
g(n), &se $n$ ímpar
}
$$
satisfaz as $f \sime h\simo g$ pela sua construção.
Logo, $f \relp{\sime\rcom\simo} g$.
}

\endproblem
%%}}}

%%{{{ prob: cofinite_cameo_appearance 
\problem.
\label{cofinite_cameo_appearance}%
No conjunto $(\reals\to\reals)$ definimos:
$$
\align
f \approx g &\defiff \text{o conjunto $\setst {x \in \reals} {f(x) = g(x)}$ é infinito};\\
f \sim    g &\defiff \text{o conjunto $\setst {x \in \reals} {f(x) \neq g(x)}$ é finito}.
\endalign
$$
Demonstre que:
\item{(i)} uma delas é relação de equivalência;
\item{(ii)} a outra não é.

\hint
Se um subconjunto $X\subset\reals$ é infinito, isso não quis dizer
que $\reals\setminus X$ é finito!

\hint
A $\sim$ é a relação de equivalência.
Demonstre.

\hint
A $\approx$ não é transitiva.
Refute!

\solution%%{{{
A $\sim$ é uma relação de equivalência:
\crproofpart{Reflexiva.}
Seja $f : \reals\to\reals$.
Calculamos:
$$
\setst {x \in \reals} {f(x) \neq f(x)} = \emptyset,
$$
que, sendo finito, mostra que $f\sim f$.
\crproofpart{Simétrica.}
Trivial, pois para quaisquer $f,g : \reals\to\reals$ temos
$$
\setst {x \in \reals} {f(x) \neq g(x)}
=
\setst {x \in \reals} {g(x) \neq f(x)}
$$
e logo um é finito sse o outro é finito.
\crproofpart{Transitiva.}
Sejam $f,g,h:\reals\to\reals$ tais que $f\sim g$ e $g\sim h$.
Logo:
$$
\align
A &\defeq \text{$\setst {x \in \reals} {f(x) \neq g(x)}$ finíto} \tag{1} \\
B &\defeq \text{$\setst {x \in \reals} {g(x) \neq h(x)}$ finíto} \tag{2}.
\endalign
$$
Seja $w \in \reals$.
Vamos provar que
$$
w \notin A \union B \implies f(w) = h(w).
$$
Calculamos:
\compute
f(w) &= g(w)    \by {pois $w \notin A$}
     &= h(w).   \by {pois $w \notin B$}
\endcompute
Contrapositivamente,
$$
f(w) \neq h(w) \implies w \in A \union B.
$$
Mas $A\union B$ é finito,
(sendo uma união finita de conjuntos finitos)
e mostramos que
$$
\setst {x \in \reals} {f(x) \neq h(x)} \subset A\union B
$$
e logo também finito, ou seja, $f\sim h$.
\crproofpart{A $\approx$ não é uma relação de equivalência.}
Vamos refutar a sua transitividade.
Como contraexemplo, tome as $f,g,h : \reals\to\reals$ definidas pelas:
$$
\alignat3
    f(x) &= 1 &
    g(x) &= \cos(x) &
    h(x) &= -1.
\endalignat
$$
Observe que $f \approx g$ pois concordam nos pontos $2k\pi$ para todo $k\in\ints$.
Também $g \approx h$ pois concordam nos pontos $(2k+1)\pi$ para todo $k\in\ints$.
Mesmo assim, $f \not\approx h$ pois não concordam em ponto nenhum.
%%}}}

\endproblem
%%}}}

%%{{{ prob: efle_vs_fele_and_eflt_vs_felt 
\problem.
\label{efle_vs_fele_and_eflt_vs_felt}%
\def\efle{\rel{\buildrel{{}_{\exists\forall}} \over \leq}}%
\def\fele{\rel{\buildrel{{}_{\forall\exists}} \over \leq}}%
\def\eflt{\rel{\buildrel{{}_{\exists\forall}} \over <}}%
\def\felt{\rel{\buildrel{{}_{\forall\exists}} \over <}}%
Defina no $(\reals\to\reals)$ as relações seguintes:
$$
\align
f \efle g &\defiff \pexists {n\in\nats} \lforall {x \geq n} { f(x) \leq g(x) } \\
f \fele g &\defiff \pforall {n\in\nats} \lexists {x \geq n} { f(x) \leq g(x) } \\
f \eflt g &\defiff \pexists {n\in\nats} \lforall {x \geq n} { f(x) < g(x) } \\
f \felt g &\defiff \pforall {n\in\nats} \lexists {x \geq n} { f(x) < g(x) }
\endalign
$$
Para cada uma das relações acima, decida se ela tem ou não cada uma
das propriedades de uma ordem total, e de uma ordem estrita.

\endproblem
%%}}}

%%{{{ prob: implementing_functions_as_relations_and_vice_versa 
\problem implementando funções como relações e vice versa.
\label{implementing_functions_as_relations_and_vice_versa}%
Já encontramos a idéia de \emph{implementação} de algum
conceito matemático no~\ref{Functions}
(\refn{Implementations_seq_fam}, \refn{implement_partial_functions},
\refn{implement_nondeterministic_functions}).
Como tu definiria funções como relações, e como relações como funções?
Dê apenas um esboço da tua idéia, sem entrar em muitos detalhes.

\solution
Seguem umas idéias.
\crproofpart{Função como relação.}
Sejam $A,B$ conjuntos.
Uma relação $f$ de $A$ para $B$
tal que $f$ é \emph{left-total} e \emph{right-unique}
(veja o glossário~\refn{relations_glossary})
é chamada uma \dterm{função de $A$ para $B$}.
Escrevemos $f(x) = y$ em vez de $f(x,y)$ ou de $x \rel f y$
e para todo $a\in A$ denotamos com $f(a)$ o único $b\in B$
tal que $a \rel f b$.
\crproofpart{Relação binária como função.}
Sejam $A,B$ conjuntos.
Uma função $R : A \to \pset B$ é chamada uma \dterm{relação de $A$ para $B$}.
Escrevemos $a \rel R b$ quando $b \in R(a)$,
e $a \not\rel R b$ quando $b \notin R(a)$.
\crproofpart{Relação geral como função.}
Seja $W$ conjunto.
Uma função $R : W \to \bools$ é chamada uma \dterm{relação no $W$}.
Escrevemos $R(w)$ como afirmação, quando $R(w) = \True$, e $\lnot R(w)$
ou ``não $R(w)$'' quando $R(w) = \False$.

\endproblem
%%}}}

\endproblems
%%}}}

%%{{{ Partitions 
\section Partições.
\label{Partitions}%

%%{{{ idea_of_partition 
\note Partição.
\label{idea_of_partition}%
Voltamos de novo para nosso conjunto $A$ do~\refn{idea_of_equivalence},
mas essa vez sem uma predeterminada propriedade para focar.
Essa vez vamos dividir os elementos do $A$ em \dterm{classes},
tais que cada membro do $A$ pertencerá a \emph{exatamente uma delas},
e cada uma delas terá pelo menos um membro do $A$.
E nem vamos justificar essa separação, explicando o como ou o porquê.
Esse tipo de colecção de classes vamos definir agora:
%%}}}

%%{{{ df: partition 
\definition.
\label{partition}%
\tdefined{partição}%
Seja $A$ conjunto e $\scr A \subset \pset A$ uma família de subconjuntos de $A$.
$\scr A$ é uma \dterm{partição} de $A$, sse:
\beginil
\item{(P1)} $\Union \scr A = A$;
\item{(P2)} os membros de $\scr A$ são disjuntos dois-a-dois;
\item{(P3)} $\emptyset \notin \scr A$.
\endil
Chamamos de \dterm{classes} os membros da $\scr A$.
%%}}}

%%{{{ x: partitions_of_seven 
\exercise.
\label{partitions_of_seven}%
Seja $A=\set{0,1,2,3,4,5,6}$.
Quais das colecções seguintes são partições do $A$?:
$$
\xalignat 2
\scr A_1 &= \big\{ \set{0,1,3}, \set 2, \set{4,5}, \set 6 \big\}                &\scr A_5 &= \big\{ \set{0,1,2}, \set{2,3,4}, \set{4,5,6} \big\} \\
\scr A_2 &= \big\{ \set{0,1,2,3}, \emptyset, \set{4,5,6} \big\}                 &\scr A_6 &= \big\{ \set{1,2}, \set{0,3}, \set 5, \set 6 \big\}  \\
\scr A_3 &= \big\{ \set{0,1,2,3,4,5,6} \big\}                                   &\scr A_7 &= \big\{ \set{0,1,2}, \set 3, \set{4,5,6,7} \big\}    \\
\scr A_4 &= \big\{ \set 0, \set 1, \set 2, \set 3, \set 4, \set 5, \set 6 \big\}&\scr A_8 &= \big\{ \set 0, \set{1,2}, \set{6,5,4,3} \big\}
\endxalignat
$$

\hint
Quatro delas são, as outras não.

\solution
As $\scr A_1, \scr A_3, \scr A_4, \scr A_8$ são.
As outras não:
\beginul
\li a $\scr A_2$ não é: $\emptyset$ é seu membro;
\li a $\scr A_5$ não é: o $2$ que pertence a dois membros dela;
\li a $\scr A_6$ não é: $4 \in A$ mas não pertence a nenhum membro dela;
\li a $\scr A_7$ não é: $7 \notin A$ mas $7 \in \Union \scr A_7$.
\endul


\endexercise
%%}}}

%%{{{ x: union_scr_A_subset_already_known 
\exercise.
\label{union_scr_A_subset_already_known}%
Podemos trocar o~(P1) da~\ref{partition} por
$$
\text{(P1$'$)}\quad\Union \scr A \supset A \ ?
$$

\hint
Será que já sabemos a outra ``direção'' da igualdade?

\solution
Sim!
Pois como $\scr A$ é uma família de subconjuntos de $A$,
já sabemos que $\Union \scr A \subset A$.
Logo, afirmar $\Union \scr A = A$ ou afirmar $\Union \scr A \supset A$
nesse caso é a mesma coisa.
Escolhemos o (P1) pois fica mais natural (e porque se retirar a hipótese
que $\scr A \subset \pset A$, o (P1) vira necessário).

\endexercise
%%}}}

%%{{{ x: pairwise_necessary_for_partition 
\exercise.
\label{pairwise_necessary_for_partition}%
Podemos trocar o~(P2) da~\ref{partition} por
$$
\text{(P2$'$)}\quad\Inter \scr A = \emptyset\  ?
$$

\hint
Não: nossa definição vai permitir mais colecções ser chamadas ``partição'' do que deveriam.

\hint
Uma das colecções não-partições do~\ref{partitions_of_seven} vai
acabar sendo partição.

\solution
A $\scr A_5\subset\powerset A$ do~\ref{partitions_of_seven} satisfaz as
$$
\Union \scr A_5 = A,
\qqqquad
\Inter \scr A_5 = \emptyset,
$$
mas não é uma partição: o $2\in A$ por exemplo, pertenceria em duas classes
diferentes, algo contra da nossa idéia de ``partição''.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Quotient set 
\section Conjunto quociente.
\label{Quotient_set}%

\blah.
Os dois conceitos de ``relação de equivalência'' e ``partição'',
parecem diferentes mas realmente são apenas duas formas diferentes de
expressar a mesma idéia.
Cada relação de equivalência determina uma partição;
e vice-versa: cada partição determina uma relação de equivalência.
Bora provar isso!

%%{{{ x: wrong_partition_of_eqrel_def 
\exercise Cuidado!.
\label{wrong_partition_of_eqrel_def}%
Tentando investigar isso, começando com uma relação de equivalência $R$,
um aluno tentou definir a partição correspondente $\scr A_R$ assim:
$$
\align
C \in \scr A_R
\defiff
&C \subset A \\
&\mland  C \neq \emptyset \\
&\mland  \lforall {c,d \in C} {c \rel R d}.
\endalign
$$
Qual o erro na definição do aluno?
O que faltou escreverer para virar uma definição correta?

\hint
Considere o conjunto $A$ com a relação de equivalência $R$ como no diagrama
interno seguinte:
$$
\tikzpicture
\tikzi eqrel2partitionbase;
\draw (elem-1) -- (elem-2) -- (elem-3) -- (elem-4);
\draw (elem-5) -- (elem-6);
\endtikzpicture
$$
Lembra-se que como já declaramos a~$R$ de ser uma relação de
equivalência, não precisamos botar todas as setinhas, apenas as necessárias
para ``gerar'' a~$R$
(veja~\ref{conventions_for_internal_diagrams_of_rel}).
Agora, seguindo fielmente sua definição, qual é o conjunto $\scr A_{R}$?

\hint
\emph{Não} é o conjunto dos seguintes subconjuntos de $A$:
$$
\tikzpicture
\tikzi eqrel2partitionbase;
\tikzi eqrel2partitiondesired;
\endtikzpicture
$$
Ache um $C\subset A$ tal que $C \in \scr A_{R}$ mas \emph{não deveria}.

\hint
A definição do aluno garanta que todos os elementos numa classe realmente
relacionam entre si através da $R$;
mas não garanta que cada classe $C$ é feita por \emph{todos} os elementos
de~$A$ que relacionam com os membros da $C$ mesmo.
Por exemplo, ela \emph{corretamente exclue} conjuntos como $\set{2,5}$;
mas ela \emph{incorretamente inclue} conjuntos como o $\set{2,3}$.
$$
\tikzpicture
\draw [rounded corners=3mm, fill=blue!20] (-1.6,0.4)--(-1.6,1.4)--(-0.3,1.4)--(-0.3,0.4)--cycle;
\tikzi eqrel2partitiondesired;
\tikzi eqrel2partitionbase;
\endtikzpicture
\qqqquad
\tikzpicture
\draw [rounded corners=2mm, fill=red!20] (-1.5,1.4)--(-1.5,-1.0)--(-0.9,-1.0)--(-0.9,1.4)--cycle;
\tikzi eqrel2partitiondesired;
\tikzi eqrel2partitionbase;
\endtikzpicture
$$

\solution
Seguindo as dicas, faltou escrever a ultima linha:
$$
\align
C \in \scr A_{R}
\defiff
&C \subset A\\
&\mland  C \neq \emptyset\\
&\mland  \lforall {c,d \in C} {c \rel R d}\\
&\mland  \pforall {a \in A} \lforall {c \in C} {a \rel R c \implies a \in C}.
\endalign
$$

\endexercise
%%}}}

%%{{{ x: from_eqrel_to_partition 
\exercise De equivalência para partição.
\label{from_eqrel_to_partition}%
Seja $\sim$ relação de equivalência num conjunto $A$.
Escreva formalmente como definir uma partição
$\scr A_{\sim}$ do $A$ em que suas classes são feitas
por todos os $\sim$-relacionados.
Prove que realmente é uma partição.

\hint
Mande os membros de $A$ se separar:
<<se juntem todos os relacionados entre si!>>.

\solution
\proofpart{Definir uma família de subconjuntos de $A$.}
Definimos $\scr A_{\sim}$ para ser a família de todas as
classes de equivalência através da $\sim$.  Formalmente:
$$
\scr A_{\sim}
\defeq
\setst {\eqclassimp a} {a \in A}.
$$
\proofpart{Provar que a família $\scr A_{\sim}$ é uma partição.}
Primeiramente observe que cada membro de $\scr A_{\sim}$
é um subconjunto de $A$.
Agora basta verificar as (P1)--(P3) da~\ref{partition}.
\crproofpart{(P1) Mostrar que $A \subset \Union \paren{\scr A_{\sim}}$.}
Tome $a\in A$.
Como $a \sim a$ (reflexividade), então $a \in \eqclassimp a$.
Agora como $\eqclassimp a \in \scr A_{\sim}$,
temos que $a \in \Union \paren{\scr A_{\sim}}$.
\crproofpart{(P2) Os membros de $\scr A_{\sim}$ são disjuntos dois-a-dois.}
Sejam $C,D \in \scr A_{\sim}$.
Logo sejam $c,d \in A$ tais que $C = \eqclassimp c$ e $D = \eqclassimp d$.
Precisamos provar \emph{qualquer uma} das duas implicações (são contrapositivas):
$$
\align
C\neq D                 &\implies C\inter D = \emptyset; \\
C\inter D\neq\emptyset  &\implies C = D.
\endalign
$$
Vamos provar a segunda.
Suponha $C\inter D \neq \emptyset$ e seja logo $w\in C\inter D$.
Ou seja, $w\in C$ e $w \in D$, e logo $w \sim c$ e $w \sim d$.
Queremos provar que $C = D$.
{\lrdirset.}
Tome $x \in C = \eqclassimp c$.
Temos:
$$
x \sim c \sim w \sim d
$$
(simetria e transitividade da $\sim$)
e logo $x \in \eqclassimp d = D$ e $C\subset D$.
A {\rldirset} é similar.
\crproofpart{(P3) $\emptyset \notin \scr A_{\sim}$.}
Basta provar que para cada $a\in A$, $\eqclassimp a \neq \emptyset$.
Isso é uma conseqüência da reflexividade da $\sim$, pois
para todo $a\in A$, $a \in \eqclassimp a$.
\endgraf
Se escolher a primeira implicação na parte de (P2), a gente continua assim:
Suponha $C\neq D$ e logo sem perda de generalidade, tome $c_0 \in C\setminus D$.
Logo $c_0 \sim c$ e $c_0 \not\sim d$.
Isso já mostra que não pode ter nenhum elemento $w \in C\inter D$, pois
nesse caso usando a simetria e transitividade da $\sim$ teriamos
$c_0 \sim c \sim w \sim d$ que obrigaria $c_0 \sim d$;
impossível.

\endexercise
%%}}}

%%{{{ x: why_all_of_eqrel_properties_are_needed 
\exercise.
\label{why_all_of_eqrel_properties_are_needed}%
Explique onde precisou cada uma das propriedades da~\ref{equivalence_relation}
(reflexividade, transitividade, simetria)
na tua resolução do~\ref{from_eqrel_to_partition}.

\solution
Veja a resolução do~\ref{from_eqrel_to_partition}.

\endexercise
%%}}}

\blah.
A partição definida no~\ref{from_eqrel_to_partition} é muito importante
e merece seu próprio nome e sua própria notação.  Definimos agora.

%%{{{ df: quoset 
\definition.
\label{quoset}%
\tdefined{conjunto}[quociente]%
\sdefined {\quoset {\sholed A} {\sholed R}} {o conjunto quociente do $A$ por $R$}%
\iisee{quociente!conjunto}{conjunto quociente}%
Seja $A$ um conjunto e $\sim$ uma relação de equivalência no $A$.
Definimos o \dterm{conjunto quociente} de $A$ por $\sim$ para ser a colecção
de todas as classes de equivalência através da $\sim$.
Formalmente:
$$
\quoset A {\sim} \defeq \setst {\eqclass a {\sim}} {a \in A}.
$$
%%}}}

%%{{{ x: type_of_holed_quoset 
\exercise.
\label{type_of_holed_quoset}%
Sejam $A$ conjunto e $\sim$ relação de equivalência no $A$.
Considere a função seguinte definida com buraco:
$$
\quoset A \dhole : \ \askdots
$$
Escreva um tipo válido para essa função.

\solution
$\quoset A \dhole : \eqreltype A \to \pset\pset A$.

\endexercise
%%}}}

%%{{{ seeing_the_quotient_set 
\note Enxergando o conjunto quociente.
\label{seeing_the_quotient_set}%
Tendo um conjunto $A$ e uma relação de equivalência $\sim$,
no conjunto quociente $\quoset A \sim$ a relação de equivalência
$\sim$ se vira igualdade $=$ mesmo.
Numa maneira, $\quoset A \sim$ é o mundo que chegamos se nossa $\sim$
virar para ser a nossa $=$.  O mundo onde não conseguimos enxergar
diferenças entre objetos $\sim$-relaçionados.
Para dar um exemplo, considere o conjunto dos inteiros $\ints$,
e a relação de equivalência $\sim$ definida pela
$$
x \sim y \defiff x \cong y \pmod 2,
$$
ou seja, $\sim$ relaciona os inteiros com a mesma \dterm{paridade}
(\ref{eqrel_eg_parity}).
Vamos olhar para nosso conjunto:
$$
\set {\dots, -3, -2, -1, 0, 1, 2, 3, \dots}
$$
Quantos elementos ele tem?
Uma infinidade, correto?
Sim, pois todos os
$$
\dots, -3, -2, -1, 0, 1, 2, 3, \dots
$$
são distintos dois-a-dois.
Vamos lembrar uma propriedade fundamental de conjuntos:
quantos elementos tem o
$$
\set {7, 7, 7, 5, 0, 8, 8}?
$$
Temos escrito $7$ termos para ser exatamente os membros
desse conjunto, mas quantos elementos ele tem mesmo?
$4$, pois num conjunto não existe a noção de
\emph{quantas vezes} um membro pertence a ele;
só a noção de pertencer.
E isso é uma conseqüência imediata da definição de igualdade
de conjuntos.  Lembre se:
$$
A = B \defiff \lforall x {x\in A \iff x \in B}
$$
e logo
$$
\set {7, 7, 7, 5, 0, 8, 8} = \set {0, 8, 7, 5}
$$
pois realmente para todo $x$,
$$
x \in \set {7, 7, 7, 5, 0, 8, 8}
\iff
x \in \set {0, 8, 7, 5}
$$
e, sendo iguais não pode ser que eles tem cardinalidades diferentes!
Voltando para o conjunto de inteiros
$$
\set {\dots, -3, -2, -1, 0, 1, 2, 3, \dots}
$$
agora imagina que perguntamos sobre sua cardinalidade uma pessoa
$\sim$-cega.  O que quis dizer $\sim$-cega?  Ela não consegue
enxergar como distintos objetos relacionados pela $\sim$.
O que ela vai responder em nossa pergunta?
<<2>>.
Pois, para essa pessoa os
$$
\dots, -4, -2, 0, 2, 4, \dots
$$
são todos indistingüíveis, e a mesma coisa sobre os
$$
\dots, -5, -3, -1, 1, 3, 5, \dots
$$
O conjunto quociente $\quoset \ints \sim$ então,
é o conjunto que ela enxerga.
Só tem um probleminha agora:
\emph{quais} são esses dois membros do conjunto que ela enxerga?
A resposta correta aqui pode aparecer chocante mas é a seguinte:
\standout
\emph{Não importa!}
\endstandout
Uma escolha natural seria escolher como membros do $\quoset \ints \sim$
os dois conjuntos:
$$
\set{\dots, -4, -2, 0, 2, 4, \dots}
\qqtext{e}
\set{\dots, -5, -3, -1, 1, 3, 5, \dots}
$$
chegando assim no
$$
\quoset\ints\sim
= \set {
\set{\dots, -4, -2, 0, 2, 4, \dots},
\set{\dots, -5, -3, -1, 1, 3, 5, \dots}
}.
$$
De fato, pela \ref{quoset} do conjunto quociente, $\quoset\ints\sim$
realmente \emph{é} esse conjunto.  E isso faz sentido,
pois uma definição de $\quoset A R$ precisa determinar completamente
um objeto.
Mas uma outra escolha poderia ser, por exemplo, o conjunto
$$
\set{0, 1}
$$
ou qualquer conjunto feito escolhendo outros ``rótulos'' para cada
classe de equivalência:
$$
\set{{\mathbf 0}, {\mathbf 1}}, \quad
\set{\mathrm{even}, \mathrm{odd}}, \quad
\set{\mathrm{E}, \mathrm{O}}, \quad
\set{\emptyset, \set{\emptyset}}, \quad\dotsc
$$
Basta só ter exatamente dois membros.
Toda esse conversa chega no teorema e na definição seguintes:
%%}}}

%%{{{ thm: only_theorem_about_relations 
\theorem.
\label{only_theorem_about_relations}%
Seja $A$ conjunto e $\sim$ uma relação binária nele.
A $\sim$ é uma relação de equivalência se e somente se
existe conjunto $Q$ e surjecção
$$
\pi : A \surto Q
\taglabel{QS1}{quoset_determining_surjection_1}
$$
tal que $(\sim) = (\frel \pi)$ (\ref{kernel_coimage}), ou seja, tal que
$$
x \sim y \iff \pi(x) = \pi(y).
\taglabel{QS2}{quoset_determining_surjection_2}
$$
\sketch.
\proofpart{\lrdir.}
O conjunto $Q$ é o $\quoset A \sim$ e a surjecção $\pi$
é a ``projecção canônica'' $\eqclass \dhole \sim$.
\crproofpart{\rldir.}
Demonstrado no~\ref{frel_is_an_eqrel}.
\qes
%%}}}

%%{{{ df: general_quotient_and_determining_surjection 
\definition.
\label{general_quotient_and_determining_surjection}%
No contexto do~\ref{only_theorem_about_relations},
quando temos $\pi$ e $Q$ que satisfazem
as~\tagref{quoset_determining_surjection_1}
e~\tagref{quoset_determining_surjection_1},
dizemos que $Q$ é um \dterm{quociente} de $A$ por $\sim$,
e que $\pi$ é uma \dterm{surjecção determinante} da $\sim$.
%%}}}

%%{{{ remark: choose_your_quotient_wisely 
\remark.
\label{choose_your_quotient_wisely}%
A demonstração do~\ref{only_theorem_about_relations} fornece
o quociente $\quoset A \sim$ e a surjecção determinante
$\lam x {\eqclass x \sim}$
(ou, com buracos, $\eqclass {\dhole} {\sim}$)
que mapeia cada membro de $A$ a sua classe de equivalência.
Vamos dizer que esse será o ``conjunto quociente oficial'',
e a ``surjecção determinante oficial''.
Mas dependendo do uso, pode ser que para uns
casos é melhor utilizar outro quociente
e outra surjecção determinante.
E até pior---ou, na verdade, melhor---pessoas
diferentes podem escolher quocientes diferentes
como \emph{mais iluminantes}.
Vamos ver uns exemplos.
Em cada um, vamos ver o oficial, e comparar com uma
alternativa melhor.
Vamos usar a notação
$$
\quoset A \sim \pseudoeq Q
$$
para afirmar que $Q$ é \emph{um} quociente que possivelmente
parece mais iluminante do que o oficial.
%%}}}

%%{{{ eg: quoset_eg_countries 
\example.
\label{quoset_eg_countries}%
Na relação do~\ref{eqrel_eg_countries}
$$
x \sim y \defiff \text{$x$ e $y$ nasceram no mesmo país}
$$
o conjunto quociente oficial é feito por conjuntos
de pessoas copatriotas.  Uma escolha melhor seria
usar os próprios paises como quociente, e a
$$
\pi(x) = \text{o país em que $x$ nasceu}.
$$
Para ser sobrejetora mesmo, no quociente não vamos
incluir paises em quais nenhuma pessoa do $\cal P$ nasceu.
Seja $\cal C$ esse conjunto de paises $c$ onde pelo menos
uma pessoa $p\in \cal P$ nasceu.
Então temos
$$
\quoset {\cal P} {\sim} \pseudoeq \cal C.
$$
Num certo sentido, \emph{dividindo esse conjunto de pessoas
$\cal P$ por a relação $\sim$}, chegamos no conjunto de
paises $\cal C$.
\endexample
%%}}}

%%{{{ x: quoset_children 
\exercise.
\label{quoset_children}%
Na relação do~\ref{eqrel_eg_children}
$$
x \sim y \defiff \text{$x$ e $y$ têm a mesma quantidade de filhos}
$$
qual é o conjunto quociente (oficial)?
Qual tu escolharia como melhor?

\endexercise
%%}}}

%%{{{ x: quoset_teams 
\exercise.
\label{quoset_teams}%
\ref{eqrel_eg_teams}
Na relação do~\ref{eqrel_eg_teams}
$$
x \sim y \defiff \text{$x$ e $y$ jogam no mesmo clube}
$$
qual é o conjunto quociente (oficial)?
Qual tu escolharia como melhor?

\endexercise
%%}}}

%%{{{ eg: some_eqclasses_geometrically_and_algebrically 
\example.
\label{some_eqclasses_geometrically_and_algebrically}%
Vamos descrever geometricamente as classes de equivalência das
relações do~\ref{equivalent_relations_on_euclidean_plane} no $\reals^2$,
ou seja, determinar os conjuntos quocientes correspondentes.
Lembramos as relações:
$$
\align
\tup{x,y} \sim_1 \tup{x',y'}
&\iff x = x'\\
\tup{x,y} \sim_2 \tup{x',y'}
&\iff y = y'\\
\tup{x,y} \sim_{\textrm N} \tup{x',y'}
&\iff \norm{ \tup{x,y} } = \norm{ \tup{x',y'} }
\endalign
$$
Em cada classe de equivalência da $\sim_1$ então, estão todos os
pares que concordam na sua primeira coordenada.  Ou seja,
cada classe é uma retas vertical, e o conjunto quociente é
colecção de todas essas linhas.  Olhando ainda mais de longe,
podemos ``identificar'' cada reta com seu representante canônico
que fica no eixo-$x$, ou seja, podemos dizer que
$$
\quoset {\reals^2} {\sim_1} \pseudoeq \reals.
$$
A situação é similar para a $\sim_2$, so que essa vez são todas
as retas horizontais, mas olhando novamente de longe,
identificamos cada reta com seu representante canônico
que agora fica no eixo-$y$, ou seja, novamente temos
$$
\quoset {\reals^2} {\sim_2} \pseudoeq \reals.
$$
Sobe a $\sim_{\textrm N}$, a classes do seu
conjunto quociente são todos os cíclos com centro a origem $(0,0)$,
incluindo o ``ciclo-trivial'' com raio $0$, que acaba sendo apenas
o ponto $(0,0)$ mesmo.
Essa vez, identificando cada cíclo com seu raio, chegamos na
$$
\quoset {\reals^2} {\sim_{\textrm N}} \pseudoeq \reals_{\geq 0}.
$$
Por enquanto, entendemos todas essas $\pseudoeq$ apenas como
um ``modo de falar''.
Cuidado pois nenhuma delas é uma verdadeira $=$!
Os dois lados dessas ``igualdades'' são conjuntos cujos membros
nem são objetos do mesmo tipo!
No lado esquerdo pertencem \emph{conjuntos de pares de números reais},
no lado direito pertencem \emph{números reais}.
\endexample
%%}}}

%%{{{ x: more_eqclasses_geometrically_and_algebrically 
\exercise.
\label{more_eqclasses_geometrically_and_algebrically}%
Descreva geometricamente e algebricamente os conjuntos quocientes
das relações de equivalência
do~\ref{equivalent_relations_on_euclidean_space}.

\hint
Entendeu o~\ref{some_eqclasses_geometrically_and_algebrically}?

\solution
O $\quoset {\reals^3} {\sim_3}$ parece lasanha:
é composto por todos os planos horizontais.
O $\quoset {\reals^3} {\sim_{1,2}}$ é composto pelas todas as retas
verticais (perpendiculares no $xy$-plano).
O $\quoset {\reals^3} {\sim_{\textrm N}}$ é composto pelas todas as
sferas com centro na origem.
Informalmente temos as ``equações'' seguintes:
$$
\xalignat3
\quoset {\reals^3} {\sim_3}             & \pseudoeq \reals &
\quoset {\reals^3} {\sim_{1,2}}         & \pseudoeq {\reals^2} &
\quoset {\reals^3} {\sim_{\textrm N}}   & \pseudoeq \reals_{\geq 0}.
\endxalignat
$$
Na primeira identificamos cada plano com sua altura;
na segunda cada reta com sua sombra no $xy$-plano;
na terceira casa sfera com seu raio.

\endexercise
%%}}}

%%{{{ x: quoset_of_congruence_mod_m 
\exercise.
\label{quoset_of_congruence_mod_m}%
Seja $m\in\nats_{>1}$.
Já provou no~\ref{congruence_mod_m_is_an_eqrel_again} que a relação de
congruência módulo $m$ é uma relação de equivalência.
Vamos denotá-la \sq{$\congmod m$}.
Então: qual é o seu conjunto quociente?
Também: seguindo a idéia do~\ref{some_eqclasses_geometrically_and_algebrically},
com que tu ``identificaria'' o $\quoset \ints {\congmod m}$?

\endexercise
%%}}}

%%{{{ x: cong_0_and_cong_1 
\exercise.
Continuando: quais são as relações $\congmod 0$ e $\congmod 1$?

\hint
Uma é a igualdade e outra é a trivial $\True$.
Qual é qual?  Demonstre.

\solution
Temos:
$$
\align
a \congmod 0 b &\iff 0 \divides a - b \iff a - b = 0 \iff a = b \\
a \congmod 1 b &\iff 1 \divides a - b \iff \True.
\endalign
$$
Ou seja:  $(\congmod 0) = (\eqof \ints)$ e $(\congmod 1) = (\True)$.

\endexercise
%%}}}

%%{{{ x: isPred_quoset 
\exercise.
\label{isPred_quoset}%
Descreva o conjunto quociente
$\quoset{\nats}{\rtranscl{\leftrightarrow}}$ do~\ref{isPred}.

\endexercise
%%}}}

\blah.
Já vimos que cada relação de equivalência determina uma partição:
seu conjunto quociente.
Mas parece que a partição é um conceito mais geral, pois nos permite
``separar em classes'' um conjunto numa forma que não é obrigada seguir
nenhuma lógica ou regra: sem nenhuma relação de equivalência
``por trás''.
Ou seja: \emph{talvez tem partições que não são conjuntos quocientes de
nenhuma relação de equivalência.}
Mas essa intuição razoável é enganosa!
Vamos investigar agora o caminho de volta: mostrar que cada
partição $\scr A$ também determina uma relação de equivalência
$\sim_{\scr A}$, e sim, a partição $\scr A$ é um conjunto quociente:
o $\quoset A {\sim_{\scr A}}$!

%%{{{ x: from_partition_to_eqrel 
\exercise de partição para equivalência.
\label{from_partition_to_eqrel}%
Seja $A$ conjunto e $\scr A$ partição dele.
Escreva claramente como definir uma relação de equivalência $\sim_{\scr A}$
no $A$ tal que $\quoset A {\sim_{\scr A}} = \scr A$.

\hint
Defina a relação tal que dois objetos são relacionados sse eles pertencem
no mesmo membro da família $\scr A$.

\hint
Definimos a $\sim_{\scr A}$ pela
$$
x \sim_{\scr A} y
\defiff
\lexists {C \in \scr A} {x,y \in C}.
$$
Prove que $\sim_{\scr A}$ é uma relação de equivalência.

\solution
Definimos a $\sim_{\scr A}$ pela
$$
x \sim_{\scr A} y
\defiff
\lexists {C \in \scr A} {x,y \in C}.
$$
\crtabproofpart{A relação $\sim_{\scr A}$ é uma relação de equivalência.}
\crproofpart{Reflexiva.}
Tome $a \in A$.
Precisamos mostrar que existe $C \in \scr A$ tal que $a \in C$.
Mas, como $\scr A$ é uma partição \byfact{P1}, temos que $\Union \scr A = A$.
Seja então $C$ tal que $a \in C \in \scr A$.  Logo $a \sim_{\scr A} a$.
\crproofpart{Simétrica.}
Trivial pois $x,y \in C \iff y,x \in C$.
\crproofpart{Transitiva.}
Suponha $x \sim_{\scr A} y$ e $y \sim_{\scr A} z$.
Logo sejam $C,D \in \scr A$ tais que $x,y \in C$ e $y,z \in D$.
Agora, como $y \in C\inter D$ e $\scr A$ é uma partição \byfact{P2},
temos $C = D$.  Ou seja, $x,z \in C \in \scr A$ e logo $x \sim_{\scr A} z$.
\crtabproofpart{O conjunto quociente $\quoset A {\sim_{\scr A}}$ é a partição $\scr A$.}
\crproofpart{\lrdirset.}
Tome $C \in \quoset A {\sim_{\scr A}}$.
Seja $c \in A$ tal que $C = \eqclassimp c$.
Como $c \in \Union \scr A$ ($\scr A$ partição \byfact{P1}),
seja $C'$ o único ($\scr A$ partição \byfact{P2}) membro da $\scr A$ tal que $c \in C'$.
Basta mostrar que $C = C'$.
Tome $x \in C = \eqclassimp c$.
logo $x \sim_{\scr A} c$, e logo existe $D' \in \scr A$ tal que $x,c \in D'$.
Mas pela escolha do $C'$, temos $D' = C'$, e logo $x \in C'$ e $C \subset C'$.
Conversamente, tome $x' \in C'$.
Logo $x',c \in C'$, logo $x'\sim_{\scr A} c$, e logo $x' \in \eqclassimp c = C$.
Ou seja, $C' \subset C$.
\crproofpart{\rldirset.}
Tome $C' \in \scr A$.
Como $C' \neq \emptyset$ (pois $\scr A$ é partição~\byfact{P3}),
seja $c' \in C'$.
Basta provar que $\eqclassimp {c'} = C'$.
Tome $x \in \eqclassimp {c'}$.
Logo $x \sim_{\scr A} c'$, e logo seja $D' \in \scr A$ tal que $x,c' \in D'$.
Mas, como $c' \in C'\inter D'$, concluimos que $C'=D'$ (pela~\byfact{P2}).
Ou seja, $x \in C'$.
Conversamente, tome $x' \in C'$.
Como $c'\in C'$, logo $x' \sim_{\scr A} c'$ pela definição da $\sim_{\scr A}$,
ou seja $x'\in\eqclassimp {c'}$.

\endexercise
%%}}}

%%{{{ x: why_all_of_partition_properties_are_needed 
\exercise.
\label{why_all_of_partition_properties_are_needed}%
Explique onde precisou cada uma das condições (P1)--(P3) da~\ref{partition}
na tua resolução do~\ref{from_partition_to_eqrel}.

\solution
Veja a resolução do~\ref{from_partition_to_eqrel}.

\endexercise
%%}}}

%%{{{ df: induced_equivalence_relation_and_partition 
\definition.
\label{induced_equivalence_relation_and_partition}%
\tdefined{relação}[induzida]%
\tdefined{partição}[induzida]%
Chamamos a $\sim_{\scr A}$ a \dterm{relação de equivalência induzida pela $\scr A$}.
Similarmente chamamos o conjunto quociente $\quoset A {\sim}$
a \dterm{partição induzida pela $\sim$}.
%%}}}

%%{{{ x: how_many_partitions_on_3 
\exercise.
\label{how_many_partitions_on_3}%
Seja $A$ conjunto finito com $\card A = 3$.
Quantas partições de $A$ existem?
Por que isso resolve o~\ref{how_many_equivalence_relations_on_3}?

\endexercise
%%}}}

%%{{{ Summary 
\note Resumo.
\label{eqrel_quoset_partition_summary}%
\DefFun quotient
\DefFun eqrelize
\DefOp EqRel
\DefOp Part
O coração dessa secção fica nos exercícios~\refn{from_eqrel_to_partition}
e~\refn{from_partition_to_eqrel}.  Vamos resumir o que tá acontecendo.
Para qualquer conjunto $A$ definimos os conjuntos $\EqRel(A)$
de todas as suas relações de equivalência e $\Part(A)$ de
todas as suas partições:
$$
\align
\EqRel(A) &\defeq \setstt {{\sim}} {$\sim$ é uma relação de equivalência no $A$} \\
\Part(A)  &\defeq \setstt {{\scr A}} {$\scr A$ é uma partição do $A$}.
\endalign
$$
Dado conjunto $A$ encontramos como definir \emph{funções}
$$
\cdopt{sep=2cm}
\EqRel(A) \ar[r, shift left, "\quotient"] \|
\Part(A)  \ar[l, shift left, "\eqrelize"]
\endcd
$$
que ``traduzem'' qualquer relação de equivalência para sua partição induzida
e qualquer partição para sua relação de equivalência induzida.
São definidas pelas:
$$
\xalignat2
\quotient(\sim) &\defeq \quoset A {\sim} &
x \relp{\eqrelize(\scr A)} y &\defiff \lexists {C\in \scr A} {x,y \in C}.
\endxalignat
$$
Essas traduções são fieis, no sentido de:
$$
\xalignat2
\quotient \of \eqrelize &= \idof {\Part(A)} &
\eqrelize \of \quotient &= \idof {\EqRel(A)}.
\endxalignat
$$
De fato, ambas são bijecções, e cada uma é a inversa da outra.
Com as primeiras notações que usamos e também com palavras, temos:
$$
\xalignat2
{\sim_{\scr A_{\sim}}}   &= {\sim}    && \text{<<a relação induzida pela partição induzida pela $\sim$ é a própria $\sim$>>}; \\
{\scr A_{\sim_{\scr A}}} &= {\scr A}  && \text{<<a partição induzida pela relação induzida pela $\scr A$ é a própria $\scr A$>>}.
\endxalignat
$$
Não se preocupe se o conceito do \emph{conjunto quociente} ainda parece meio
distante ou abstrato demais.  Ataque os problemas e os exercícios, e confie
que estudando teoria dos grupos (\ref{Group_theory}) isso vai mudar!
%%}}}

%%{{{ two_sides_of_the_same_coin_eqrel_partition 
\note Dois lados da mesma moeda.
\label{two_sides_of_the_same_coin_eqrel_partition}%
Vimos aqui que ``partição'' e ``classe de equivalência'' são
\emph{dois lados da mesma moeda}.  Considere um conjunto $A$.
\beginol
\li Quando precisamos \emph{definir uma relação de equivalência} no $A$,
podemos \emph{definir uma partição} $\scr A$ de $A$ e usar a $\sim_{\scr A}$.
\li Conversamente, quando precisamos \emph{definir uma partição} no $A$,
podemos \emph{definir uma relação de equivalência} $\sim$ no $A$
e usar a $\quoset A {\sim}$.
\li
Alem disso, quando temos uma relação $\sim$ no $A$ e precisamos
\emph{provar que ela é uma relação de equivalência},
podemos definir uma família $\scr A$ de subconjuntos de $A$,
\emph{provar que ela é uma partição}, e mostrar que:
$$
x \sim y \iff \lexists {C\in\scr A} {x,y \in C}.
$$
\li
Finalmente, quando temos uma família $\scr A$ de subconjuntos de $A$
e precisamos \emph{provar que ela é uma partição}, podemos definir
a relação $\sim_{\scr A}$ pela
$$
x \sim_{\scr A} y \iff \lexists {C\in\scr A} {x,y \in C}
$$
e \emph{provar que ela é uma relação de equivalência}.
\endol
Não esqueça essas dicas!
%%}}}

%%{{{ df: kernel_coimage 
\definition.
\label{kernel_coimage}%
\tdefined{kernel}%
\tdefined{coimagem}%
\sdefined {\ker {\sholed f}} {o kernel da $f$}%
\sdefined {\coim {\sholed f}} {a coimagem da $f$}%
Seja $f : X \to Y$ e defina a relação binária $\frel f$ no $X$ pela
$$
x_1 \frel f x_2 \defiff f(x_1)=f(x_2).
$$
Chamamos a $\frel f$ o \dterm{kernel} da $f$, e seu conjunto quociente
a \dterm{coimagem} da $f$.
Usamos também os símbolos $\ker f$ e $\coim f$ respectivamente.
%%}}}

%%{{{ x: frel_is_an_eqrel 
\exercise.
\label{frel_is_an_eqrel}%
Com os dados da~\ref{kernel_coimage} mostre que $\frel f$
é uma relação de equivalência e descreva os elementos da coimagem.
O que podemos dizer se $f$ é injetora?
Se ela é sobrejetora?

\solution
\proofpart{$\frel f$ é uma relação de equivalência.}
Cada uma das três propriedades é uma conseqüência direta da
propriedade correspondende da igualdade.  Em detalhe:
\crproofpart{Reflexiva.}
Seja $x\in X$.
Temos $x \frel f x$ pois $f(x) = f(x)$ (reflexividade da $=$).
\crproofpart{Transitiva.}
Sejam $a,b,c \in X$ tais que $a \frel f b$ e $b \frel f c$.
Logo $f(a) = f(b)$ e $f(b) = f(c)$.
Logo $f(a) = f(c)$ (transitividade da $=$), ou seja, $a \frel f c$.
\crproofpart{Simétrica.}
Sejam $a, b \in X$ tais que $a \frel f b$, e logo $f(a) = f(b)$
e logo $f(b) = f(a)$ (simetria da $=$), ou seja, $b \frel f a$.
\crtabproofpart{Descrição do conjunto quociente.}
O conjunto quociente ``é'' a imagem $\ima f$.
Caso que $f$ é injetora a relação acaba sendo a igualdade e logo
o ocnjunto quociente acaba sendo o próprio $\dom f$.
Caso que $f$ é sobrejetora nada demais muda,
só que agora $\ima f = \cod f$.

\endexercise
%%}}}

%%{{{ x: gen_frel_is_an_eqrel 
\exercise.
\label{gen_frel_is_an_eqrel}%
Seja $f : A \to B$ e seja $\sim_B$ uma relação de equivalência no $B$.
Defina a $\frel {f,\sim_B}$ no $A$ pela
$$
x_1 \frel {f,\sim_B} x_2 \defiff f(x_1) \sim_B f(x_2).
$$
A $\frel {f,\sim_B}$ é uma relação de equivalência?

\solution
A $\frel {f,\sim_B}$ é uma relação de equivalência sim.
Isso já foi demonstrado, pois a resolução do~\ref{frel_is_an_eqrel}
usou apenas o fato que a igualdade é uma relação de equivalência.

\endexercise
%%}}}

%%{{{ x: immediate applications 
\exercise.
Mostre que todas as relações dos
exemplos~\refn{equivalent_relations_on_euclidean_plane}
e~\refn{equivalent_relations_on_euclidean_space}
são casos especiais do~\ref{frel_is_an_eqrel}
(e logo são relações de equivalência ``gratuitamente'').

\hint
Para cada uma delas, precisa definir completamente a
$f : A \to B$ (esclarecendo também quais são os $A,B$).

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Recursive definitions 
\section Relações recursivas.

\blah.
Aqui são exemplos familiares para definir recursivamente relações.

%%{{{ eg: even_and_odd_rels_recursion 
\example.
No $\nats$ definimos:
$$
\xalignat2
\Even(0).      &                       &\lnot\Odd(0).&\\
\Even(n+1)     &\defiff \lnot \Even(n) &\Odd(n+1)&\defiff \lnot \Odd(n)
\intertext{Ou, alternativamente, usando duas bases:}
\Even(0).      &                       &\lnot\Odd(0).&\\
\lnot\Even(1). &                       &\phantom\lnot\Odd(1).&\\
\Even(n+2)     &\defiff \Even(n)       &\Odd(n+2)&\defiff \Odd(n)
\endxalignat
$$
\endexample
%%}}}

%%{{{ eg: even_and_odd_rels_mutual_recursion 
\example Recursão mutual.
$$
\xalignat2
\Even(0).  &                  &\lnot\Odd(0).&\\
\Even(n+1) &\defiff \Odd(n)   &\Odd(n+1)&\defiff \Even(n)
\endxalignat
$$
\endexample
%%}}}

\blah.
Num paradigma de programação, na \emph{programação lógica},
programamos definindo relações nesse jeito.
Deixamos então esse assunto para o~\ref{Logic_programming}.

\endsection
%%}}}

%%{{{ Higher-order relations 
\section Relações de ordem superior.

\blah.
Talvez você já se perguntou o que acontece se numa frase como a
$$
\mtrel{João ama Maria}
$$
em vez de substrituir os objetos ``João'' e ``Maria'' com buracos,
substituir o próprio verbo ``amar'':
$$
\mtrel{João {\thole} Maria}.
$$
Chegamos assim no conceito de relações de ordem superior.
Não vale a pena investigar (ainda) esse conceito pois necessita
mais umas ferramentas (e pouco mais maduridade).
Voltamos depois de estudar programação lógica (\ref{Logic_programming})
e lógicas de ordem superior (\ref{Mathematical_logic}).

\endsection
%%}}}

%%{{{ Categories_and_relations 
\section Pouco de cats---categorias e relações.
\label{Categories_and_relations}%

\TODO Escrever.

\endsection
%%}}}

%%{{{ Problems 
\problems.

%%{{{ prob: rats_via_eqrel_no_ints 
\problem.
\label{from_ints_to_rats_via_eqrel}%
Defina no $\ints\times\ints_{\neq0}$ a relação
$$
\tup{a,b} \approx \tup{c,d}
\defiff
ad = bc
$$
Mostre que $\approx$ é uma relação de equivalência
e descreva suas classes de equivalência:
$\quoset {\ints\times\ints_{\neq0}} {\approx} \pseudoeq ?$

\endproblem
%%}}}

%%{{{ prob: like_vitali_rel 
\problem.
\label{like_vitali_rel}%
Defina no $\rats$ a relação
$$
r \sim s \defiff r-s\in\ints.
$$
Prove que $\sim$ é uma relação de equivalência e descreva as
classes do $\quoset {\rats} {\sim}$.

\endproblem
%%}}}

%%{{{ prob: vitali_rel 
\problem.
\label{vitali_rel}%
Defina no $\reals$ a relação
$$
x \sim y \defiff x-y\in\rats.
$$
Prove que $\sim$ é uma relação de equivalência e descreva as classes
do $\quoset {\reals} {\sim}$.

\endproblem
%%}}}

%%{{{ prob: epimono_factorization_teaser_now_easy 
\problem Agora é fácil.
\label{epimono_factorization_teaser_now_easy}%
Resolvemos o~\ref{epimono_factorization_teaser}.
Seja $f : A\to B$ uma função qualquer, e considere a $\frel f$
da~\ref{kernel_coimage}.
Então $f$ pode ser ``decomposta'' assim:
$$
\cdopt{sep=1.5cm}
A   \ar[r,two heads, ""]\ar[rrr, bend left, "f"] \|
\quoset A {\frel f} \ar[r,two heads,tail, "\tilde f"'] \|
\ima f              \ar[r,hook, ""] \|
B
\endcd
$$
onde a primeira função é a ``projecção'' $\eqclassimp {\dhole}$,
a terceira é a inclusão $\ima f \subset B$, e a bijecção no meio
é a função definida pela
$$
\tilde f(\eqclassimp a) = f(a),
$$
que garanta a comutatividade do diagrama acima.
Mesmo assim, falta provar umas coisas.
Ache o que, e prove.

\hint
Precisas mostrar que:
(1) a $\tilde f$ é bem-definida;
(2) a $\tilde f$ é uma bijecção.

\hint
(1)
Para mostrar que $\tilde f$ é bem-definida, precisa mostrar que
a escolha do representante da classe não afeta o valor da função.
Ou seja, tome $a, a'\in A$ e mostre que:
$$
\eqclass a = \eqclass {a'} \implies f(a) = f(a').
$$
(2)
A bijectividade da $\tilde f$ não precisa de dicas!

\endproblem
%%}}}

%%{{{ word_on_the_street_for_order_of_limit_depending_quantifiers 
\note Com palavras da rua.
\label{word_on_the_street_for_order_of_limit_depending_quantifiers}%
Já encontramos várias vezes situações onde a troca dos $\forall\exists$
para $\exists\forall$ mudou completamente o significado
(o~\ref{mother_of_all} é o mais ilustrativo).
Vamos focar agora no caso onde o universo é o $\nats$, o primeiro
quantificador quantifica o $n$ sobre todo o $\nats$, mas o segundo
quantifica todos os naturais \emph{começando com esse $n$}.
Tu já fez o~\ref{set_liminf_limsup_problem_heart_level}, certo?
Seria bom achar aqui mais uma maneira de entender essa situação,
explicando os dois significados \emph{com palavras de rua}.
A situação aqui é parecida:
$$
\gather
\pexists {n\in\nats} \lforall {x \geq n} { \text{algo} }\phantom.\\
\pforall {n\in\nats} \lexists {x \geq n} { \text{algo} }.
\endgather
$$
Supondo que esse ``algo'' tá dizendo que <<$x$ é legal>>,
as afirmações acima com palavras de rua ficam assim:
$$
\align
\pexists {n\in\nats} \lforall {x \geq n} { \text{$x$ é legal} }
&\quad\text{<<A partir dum ponto, todos são legais.>>} \\
\pforall {n\in\nats} \lexists {x \geq n} { \text{$x$ é legal} }
&\quad\text{<<Sempre vai ter legais.>>}
\endalign
$$
Assim, ambas nos permitem concluir que tem uma infinidade de legais.
Mas quantos \emph{ilegais} tem?  A primeira nos permite concluir
que tem apenas uma quantidade finita de ilegais, pois, escolhendo
tal $n_0\in\nats$ cuja existência é afirmada sabemos que todas
as possíveis excessões (os ``possivelmente ilegais'') estão
entre eles: $0,1,\dotsc,n_0-1$.
Note que isso não quis dizer que todos eles são ilegais.
No outro lado, a segunda, não nos permite concluir isso.
O fato que ``sempre vai ter legais'', não exclue a possibilidade
de ``sempre vai ter ilegais'' também!
Por exemplo, sempre vai ter números pares, mas sempre vai ter números
ímpares também, né?
Os problemas seguintes brincam com essas idéias.
%%}}}

%%{{{ prob: efeq_vs_feeq 
\problem.
\label{efeq_vs_feeq}%
\def\efeq{\rel{\buildrel{{}_{\exists\forall}} \over =}}%
\def\feeq{\rel{\buildrel{{}_{\forall\exists}} \over =}}%
Defina no $(\nats\to\nats)$ as relações seguintes:
$$
\align
f \efeq g &\defiff \pexists {n\in\nats} \lforall {x \geq n} { f(x) = g(x) }\\
f \feeq g &\defiff \pforall {n\in\nats} \lexists {x \geq n} { f(x) = g(x) }
\endalign
$$
Para cada uma das relações acima, decida se ela é relação de equivalência (demonstre ou refute).
Se é, descreva seu conjunto quociente.

\endproblem
%%}}}

%%{{{ why_called_preorder 
\problem Por que preordem?.
\label{why_called_preorder}%
Justifique o nome ``preordem'': mostre como começando com uma preordem
$R$ num conjunto $A$, podemos construir uma relação $R'$ consultando a $R$.
Pode provar essa afirmação em vários jeitos, mas o objectivo é achar
a ordem $R'$ mais natural e a mais \emph{justa}, seguindo a preordem $R$.

\hint
A ordem $R'$ não vai ser uma ordem no $A$, pois não podemos
decidir como ``resolver conflitos'' do tipo $R(a,b)$ e $R(b,a)$.
Não podemos arbitrariamente escolher um dos $a,b$ como ``menor'',
botando assim por exemplo $R'(a,b)$ e $\lnot R'(b,a)$.
Isso não seria justo!
Então, em qual conjunto $A'$ faz sentido definir nossa ordem $R'$?

\endproblem
%%}}}

%%{{{ prob: how_many_partitions 
\problem Números Bell.
\label{how_many_partitions}%
Seja $A$ conjunto finito.
Quantas partições de $A$ existem?

\hint
Conte ``manualmente'' os casos com $\card A = 0, 1, 2, 3$.

\hint
(Os números que tu achou na dica anterior devem ser: $1$, $1$, $2$, e $5$, respectivamente.)
Chame $B_n$ o número de partições dum conjunto finito com $n$ elementos.
Use recursão para definir o $B_n$.

\hint
Já temos umas bases desde a dica anterior:
$$
\align
B_0 &= 1\\
B_1 &= 1\\
B_2 &= 2\\
B_3 &= 5
\intertext{Para a equação recursiva,}
B_{n+1} &= \dots
\endalign
$$
lembra-se que podes considerar conhecidos \emph{todos} os números
$B_k$ para $k \leq n$.

\hint
Sejam $a_0,\dots,a_n$ os $n+1$ elementos de $A$
e considere uma partição arbitrária $\scr A$ dele.
Sendo partição, existe exatamente um conjunto-classe $A_0$ no $\scr A$
tal que $a_0\in A_0$.
Influenciados por a notação de classes de equivalência, denotamos
o $A_0$ por $\eqclassimp {a_0}$.
Tirando esse conjunto da partição $\scr A$ chegamos no
$$
\scr A \setminus \set {\eqclassimp {a_0}}
$$
que é (certo?)\ uma partição do conjunto
$$
\Union\paren{\scr A \setminus \set {\eqclassimp {a_0}}}.
$$
Seja $k$ o número de elementos desse conjunto.
Quais são os possíveis valores desse $k$?

\hint
Vamos melhorar nossa notação para nos ajudar raciocinar.
O conjunto 
$$
\Union\paren{\scr A \setminus \set {\eqclassimp {a_0}}}.
$$
da dica anterior, depende de quê?
Como a gente fixou uma enumeração dos elementos do $A$,
ele depende apenas na partição $\scr A$.
Introduzimos então a notação
$$
R_{\scr A} \asseq
\Union\paren{\scr A \setminus \set {\eqclassimp {a_0}}}.
$$
E denotamos o $k$ da dica anterior com
$k_{\scr A} \asseq \card {R_{\scr A}}$.
O $k_{\scr A}$ da dica anterior pode ter qualquer um dos valores
$k_{\scr A}=0,\dotsc,n$.
E agora?

\hint
Agora separe todas as partições $\scr A$ de $A$ em grupos dependendo
no valor de $k_{\scr A}$, ache o tamanho de cada grupo separadamente,
e use o princípio da adição para achar a resposta final.

\hint
Todas as partições do $A$ são separadas assim em:
\beginil
\item{--} as partições $\scr A$ de $A$ tais que $k_{\scr A} = 0$;
\item{--} as partições $\scr A$ de $A$ tais que $k_{\scr A} = 1$;
\item{$\eqvdots$}
\item{--} as partições $\scr A$ de $A$ tais que $k_{\scr A} = n$.
\endil
Seja
$N_i$
o número das partições $\scr A$ de $A$ tais que $k_{\scr A} = i$.
Graças ao princípio da adição, procura-se o somatório $\Sum_{i=0}^n N_i$.
Ache o valor do arbitrário $N_i$.

\hint
De quantas maneiras pode acontecer que o
$$
R_{\scr A} = \Union\paren{\scr A \setminus \set {\eqclassimp {a_0}}}
$$
tem $i$ elementos?

\hint
Sabemos que o $a_0$ não pode ser um deles,
então precisamos escolher $i$ elementos dos $n$ seguintes: $a_1, \dotsc, a_n$.
Ou seja, de $\comb n i$ maneiras.
Cada escolha $A_i$ corresponde numa colecção de partições:
$$
\Big\{
\eqclassimp {a_0}\ 
,
\underbrace{\quad\dots\quad}_{\hbox{partição do $A_i$}}
\Big\}
$$

\hint
Sabemos a quantidade de partições de qualquer conjunto de tamanho $i$
com $i\leq n$: são $B_i$.

\solution
Seguindo todas as dicas, basta definir:
$$
\align
B_0 &= 1\\
B_{n+1}
&= \Sum_{i=0}^n N_i
= \Sum_{i=0}^n \comb n i B_i
\endalign
$$
\tdefined{Bell numbers}
Essa seqüência de números é conhecida como números~\Bell[números]{}Bell.

\endproblem
%%}}}

%%{{{ prob: same_limits_eqrel 
\problem.
\label{same_limits_eqrel}%
No $(\nats\to\reals)$ defina a relação
$$
a\sim b
\defiff
\lim\nolimits_n a_n = \lim\nolimits_n b_n
\mlor
\text{nenhum dos dois limites é definido.}
$$
descreva o $\quoset {(\nats\to\reals)} {\sim}$.

\endproblem
%%}}}

%%{{{ prob: smiles_and_frowns 
\problem.
\label{smiles_and_frowns}%
No conjunto $\reals$ defina as relações:
$$
\align
x \smile y
    &\defiff x \leq y
             \mland
             \lnot \lexists {n \in \ints} {x \leq n \leq y} \\
x \frown y
    &\defiff x \leq y
             \mland
             \lnot \lexists {n \in \ints} {x < n < y}
\endalign
$$
Sejam $\Smile$ o fecho reflexivo-simétrico da $\smile$,
e $\Frown$ o fecho simétrico da $\frown$.
\endgraf
(i) Prove que $\Smile$ é uma relação de equivalência;
(ii) Prove ou refute a afirmação: \emph{$\Frown$ é uma relação de equivalência}.

\hint
Sobre a (i): veja o~\ref{two_sides_of_the_same_coin_eqrel_partition}.
Sobre a (ii): a afirmação é falsa; refute!

\hint
Sobre a (i):
Defina a partição de $\reals$
$$
\scr C \defeq
\mubraceleg {\setst {(n,n+1)} {n\in\ints}} {\cal I}
\union
\mubraceleg {\setst {\set{n}} {n \in\ints}} {\cal S}.
$$
Basta provar que $\scr C = \quoset \reals {\Smile}$.
\endgraf\noindent
Sobre a (ii):
mostre com um contraexemplo que $\Frown$ não é transitiva.

\solution
(i)
Defina a partição de $\reals$
$$
\scr C \defeq
\munderbrace {\set{ (n,n+1) \st n\in\ints}} {\dsize \cal I}
\union
\munderbrace {\set{ \set{n} \st n \in\ints}} {\dsize \cal S}.
$$
Basta provar que
$
\scr C = \quoset \reals {\Smile}
$,
ou seja:
$$
    x\Smile y \iff \lexists {C\in \scr C} {x\in C \mland y\in C}.
$$
{\rldir}.
Trivial nos dois casos $C\in\cal I$ e $C\in\cal S$.
\endgraf\noindent
{\lrdir}.
Pela hipótese, $x=y$ ou $x\smile y$ ou $y\smile x$.
Separamos então em casos:
\endgraf\noindent
\case{Caso $x=y$:}
Caso $x\in\ints$ tome $C=\set x\in\cal S$.
Caso $x\notin\ints$ tome $C=(\floor x, \floor x + 1)\in\cal I$.
\endgraf\noindent
\case{Caso $x\smile y$:}
Nesse caso $[x,y] \inter \ints = \emptyset$.
Facilmente, $\floor x < x \leq y < \floor x + 1$.
Tome novamente $C=(\floor x, \floor x + 1)\in\cal I$.
\endgraf\noindent
\case{Caso $y\smile x$:}
Similar.
\endgraf
(ii) Não é, pois não é transitiva.
Observe que $0 \Frown 1$, pois não existe inteiro no $(0,1)$,
e similarmente $1 \Frown 2$.
Mas $0 \not\Frown 2$, pois $1$ é inteiro e $1\in(0,2)$.

\endproblem
%%}}}

%%{{{ prob: cyclic_and_euclidean_closures 
\problem Fecho cíclico, fechos euclideanos.
\label{cyclic_and_euclidean_closures}%
\tdefined{fecho!cíclico}%
\tdefined{fecho!left-euclideano}%
\tdefined{fecho!right-euclideano}%
\sdefined {\cclo {\sholed R}} {o fecho cíclico da $R$}%
\sdefined {\reclo {\sholed R}} {o fecho right-euclideano da $R$}%
\sdefined {\leclo {\sholed R}} {o fecho left-euclideano da $R$}%
Seja $R$ uma relação num conjunto $A$.
Defina seus fechos: cíclico~($\cclo R$), left-euclideano~($\leclo R$), right-euclideano~($\reclo R$).

\endproblem
%%}}}

%%{{{ prob: tclosure_recursive_def 
\problem.
Seja $R$ relação binária num conjunto $A$.
Dê uma definição recursiva do fecho transitivo $\tclosure R$.

\solution
Definimos:
$$
x \tclosure R y
\defiff
x \rel R y \mlor \lexists {w \in A} {x \rel R w \mland w \tclosure R y}.
$$
Pense para visualizar como isso ``funciona''.

\endproblem
%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

O \cite[Cap.~4]{velleman} defina e trata relações
diretamente como conjuntos, algo que não fazemos nesse texto.
De novo: muitos livros seguem essa abordagem, então o leitor é conselhado
tomar o cuidado necessário enquanto estudando esses assuntos.
Nos vamos \emph{implementar} e tratar relações como conjuntos apenas
no~\ref{Axiomatic_set_theory}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Logic_programming 
\chapter Programação lógica.
\label{Logic_programming}%

%%{{{ Problems 
\problems.

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite{lpbook},
\cite{artofprolog},
\cite{holpbook}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Structured sets 
\chapter Conjuntos estruturados.
\label{Structured_sets}%

\TODO Elaborar.

%%{{{ Concept, notation, equality 
\section Conceito, notação, igualdade.
Já encontramos a idéia de estrutura (interna) dum
conjunto~(foi no~\ref{blackbox_set}).

%%{{{ notational_abuse_structured_sets 
\note Abuso notacional.
\label{notational_abuse_structured_sets}%
Suponha $\ssetfont A = \sset A {\dotsc}$ é algum conjunto estruturado.
Tecnicamente falando, escrever ``$a\in \ssetfont A$'' seria errado.
Mesmo assim escrevemos sim $a\in \ssetfont A$ em vez de $a\in A$,
similarmente falamos sobre ``os elementos de~$\ssetfont A$''
quando na verdade estamos se referendo aos elementos de~$A$,
etc.
Em geral, quando aparece um conjunto estruturado~$\ssetfont A$ num contexto
onde deveria aparecer algum conjunto, identificamos o~$\ssetfont A$
com seu \dterm{carrier set}~$A$.
Às vezes usamos até o mesmo símbolo na sua definição, escrevendo
$A = \sset A {\dotsc}$.
%%}}}

\endsection
%%}}}

%%{{{ Structured sets with constants 
\section Conjuntos estruturados com constantes.

\endsection
%%}}}

%%{{{ Structured sets with operations 
\section Conjuntos estruturados com operações.

%%{{{ df: closed_associative_identity_inverse 
\definition.
\label{closed_associative_identity_inverse}%
Sejam conjunto $A$,
uma operação binária $\ast$ no $A$,
e um $g \in A$.
Dizemos que:
$$
\align
\text{$A$ é $\ast$-fechado}                     &\defiff \lforall {a,b \in A}   {a \ast b \in A}\\
\text{$\ast$ é associativa}                     &\defiff \lforall {a,b,c \in A} {(a \ast b) \ast c = a \ast (b \ast c)}\\
\text{$\ast$ é comutativa}                      &\defiff \lforall {a,b \in A}   {a \ast b = b \ast a}\\
\text{$u$ é uma $\ast$-identidade esquerda}     &\defiff \lforall {a \in A}     {u \ast a = a}\\
\text{$u$ é uma $\ast$-identidade direita}      &\defiff \lforall {a \in A}     {a \ast u = a}\\
\text{$u$ é uma $\ast$-identidade}              &\defiff \lforall {a \in A}     {u \ast a = a = a \ast u}\\
\text{$y$ é um $\ast$-inverso esquerdo de $g$}  &\defiff \text{$y \ast g = e$, \ onde $e$ é uma $\ast$-identidade}\\
\text{$y$ é um $\ast$-inverso direito de $g$}   &\defiff \text{$g \ast y = e$, \ onde $e$ é uma $\ast$-identidade}\\
\text{$y$ é um $\ast$-inverso de $g$}           &\defiff \text{$y \ast g = e = g \ast y$, \ onde $e$ é uma $\ast$-identidade}
\endalign
$$
onde não escrevemos os ``$\ast$-'' quando são implícitos pelo contexto.
%%}}}

%%{{{ operating_on_an_empty_list_of_objects 
\note Operando numa lista vazia de objetos.
\label{operating_on_an_empty_list_of_objects}%
Suponha que para algum $k\in\nats$ temos uns objetos
$$
a_0,a_1,\dotsc,a_{k-1}
$$
definidos.  Ou seja, temos $k$ objetos.
O que seria o resultado operando eles entre si?
Isso é algo que denotamos por
$$
a_0 \ast a_1 \ast \dotsb \ast a_{k-1}
\qqqqtext{ou}
a_0 a_1 \dotsb a_{k-1}.
$$
Como \emph{a operação associativa}, essa expressão faz sentido,
assim sem parênteses, para qualquer $k>0$.
E, se \emph{a operação tem identidade}, então ela é definida até
para o caso extremo de $k=0$.
Se $k=0$ temos uma lista de $0$ membros para operar.
E realmente definimos esse resultado para ser a identidade da operação.
%%}}}

\endsection
%%}}}

%%{{{ Structured sets with relations 
\section Conjuntos estruturados com relações.

%%{{{ df: rel_fechado 
\definition.
\label{rel_fechado}%
Seja $R$ uma relação num conjunto $A$ e $X \subset A$.
Chamamos o $X$ de \dterm{$R$-fechado}
sse para todo $x \in X$, e todo $a \in A$
com $x \rel R a$, temos $a \in X$ também.
%%}}}

\endsection
%%}}}

%%{{{ Problems 
\problems.

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Group theory 
\chapter Teoria dos grupos.
\label{Group_theory}%

%%{{{ chapintro: work on proof sketches 
\chapintro
Nesse capítulo vamos ver os ``baby steps'' da teoria dos grupos.
Os grupos têm uma quantidade de leis perfeita que fornecem
uma estrutura ideal para começar nosso estudo de \dterm{algebra abstrata}.
Depois estudamos mais teorias de outras estruturas algébricas.
%%}}}

%%{{{ History 
\history.

A teoria dos grupos é principalmente atribuida no trabalho do gigante
\Galois{}Galois.  Ele morreu muito jovem (20 anos) baleado num duel.
Sua biografia sendo bastante romântica e aventurosa,
naturalmente atrai muita atenção, muitas lendas, umas exageradas, outras não.
Mas seu trabalho matemático não precisa nenhum toque de exagero.
Ele introduziu o conceito de grupo e começou estudar sua teoria.
Ele conseguiu perceber, construir, e abstrair numa maneira tão profunda e
original que o resto da humanidade demorou para entender e apreciar.
O que chamamos hoje de \dterm{teoria dos grupos} e de \dterm{teoria de Galois}
nasceram na cabeça desse menino francês, e os \dterm{corpos finitos} também!
A teoria de Galois conecta as duas teorias, de grupos e de corpos.

\Abel{}Abel, um matemático norueguês que morou na mesma época
(e também morreu jovem: 26 anos) estudou uns assuntos parecidos,
e hoje em dia chamamos uma classe de grupos de
\dterm{abelianos} como homenagem a ele.
Uma das coisas que Abel conseguiu provar foi que não existe uma única fórmula
para ``matar'' todas as equações de quinto grau.  Esse teorema é conhecido como
Abel--Ruffini: \Ruffini{}Ruffini atacou o problema com uma prova complicada
que, mesmo que \Cauchy{}Cauchy a aceitou como convincente, ela realmente tava
incompleta; foi Abel matou o problema no \yearof{1826} numa maneira completa e concisa.
Mas o teorema de Abel deixa a possibilidade de existir, por exemplo,
uma família de fórmulas, ou até uma fórmula diferente para resolver cada
polinómio de quinto grau separadamente.

É a teoria de Galois que ilumina mesmo a situação: graças à ela sabemos
que tem polinómios que não são resolutíveis por nenhuma fórmula.
E bem mais que isso.

Três problemas abertos na epoca desde os gregos antigos eram as
construções de régua e compaço seguintes:
(1) trissecção do ângulo;
(2) quadratura do cíclo;
(3) duplicação do cubo.
No (1) são dadas duas linhas que interesetam num ponto único,
formando assim um ángulo.
O problema pede construir duas linhas que dividem esse ângulo
em 3 ángulos iguais.
No (2) é dado um cíclo e seu ráio e o objectivo é construir
um quadrado com a mesma área.
No (3) é dado um cubo e queremos construir um cubo com
volume duplo.%
\footnote{%
Na verdade, é dada a \emph{aresta} dum cubo com volume $V$,
é o problema é construir a aresta dum cubo com volume $2V$.
Ou seja, chamando o tamanho da aresta dada $1$,
construir segmento com tamanho $\cbrt 2$.
}

\Wantzel{}Wantzel no \yearof{1837} provou a \emph{impossibilidade} desses
três problemas.  Para os (1) e (2), sua demonstração dependeu
do fato que $\pi$ é \dterm{transcendental}.
Na época a transcendentalidade do $\pi$ era apenas uma conjectura,
proposta por \Lambert{}Lambert no \yearof{1768} (no mesmo artigo onde
\emph{demonstrou} a sua irracionalidade).
A conjectura vira teorema bem depois, no ano \yearof{1882},
por \vonLindemann{}von~Lindemann.
Mesmo que esse trabalho de Wantzel é depois da morte de
Galois, ele não aproveitou a teoria de Galois pois
ela demorou bastante para ser publicada (\yearof{1846}), e ainda mais
para ser entendida e aproveitada!

Novamente, é a teoria de Galois que ilumina a situação:
ela oferece as ferramentas para demonstrar com elegância e clareza todos esses
teoremas difíceis!

\endhistory
%%}}}

%%{{{ Permutations 
\section Permutações.

%%{{{ Introduce \sym 3 
\note.
\ii{permutação}%
Vamos começar considerando o conjunto $\sym n$ de todas as permutações
dum conjunto com $n$ elementos.  Tomamos o $\set{1,2,\dotsc,n}$ como
nosso conjunto mas sua escolha é inessencial.
Logo, temos por exemplo
$$
\sym 3 \defeq (\set{1,2,3}\bijto\set{1,2,3}).
$$
Quantos elementos o $\sym 3$ tem?
Lembramos%
\footnote{Se não lembramos, veja a~\ref{total_permutations} e a~\refn{Permutations_and_combinations} em geral.  Depois disso, lembramos!}
que são
$$
\card{\sym 3} = \totperm 3 = 3! = 3\ntimes 2\ntimes 1 = 6.
$$
Nosso primeiro objectivo é achar todos esses $6$ membros de $\sym 3$.
\endgraf
Primeiramente, a identidade $\idof {\set{1,2,3}} \in \sym 3$ pois é bijetora.
Para continuar, introduzimos aqui uma notação bem práctica para
trabalhar com permutações:
%%}}}

%%{{{ Notation 
\note Notação.
\label{notation_with_cycles}%
Denotamos a bijecção $f \in \sym n$ assim:
$$
f = \permf{
1    & 2    & \dotsb & n\\
f(1) & f(2) & \dotsb & f(n)
}
$$
Por exemplo, a identidade de $\sym 3$,
e a permutação $\phi$ que troca apenas o primeiro com o segundo elemento
são denotadas assim:
$$
\xalignat2
\id
&= \permf{
1 & 2 & 3\\
1 & 2 & 3
}
&
\phi
&\asseq \permf{
1 & 2 & 3\\
2 & 1 & 3
}
\endxalignat
$$
Considere agora uma permutação do $\sym 8$ e uma do $\sym {12}$ por exemplo as
$$
\align
\permf{
1 & 2 & 3 & 4 & 5 & 6 & 7 & 8\\
2 & 3 & 1 & 4 & 6 & 5 & 7 & 8
}
\quad&\text{e}\quad
\permf{
1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12\\
2 & 3 & 1 & 4 & 5 & 10 & 6 & 11 & 9 & 12 & 8 & 7
}.
\intertext{Podemos quebrá-las em ``ciclos'' escrevendo}
\permc{1 & 2 & 3}
\permc{5 & 6}
\quad&\text{e}\quad
\permc{1 & 2 & 3}
\permc{6 & 10 & 12 & 7}
\permc{8 & 11}
\endalign
$$
respectivamente.
Entendemos o ciclo $\permc{1 & 2 & 3}$ como
$1 \mapsto 2 \mapsto 3 \mapsto 1$:
$$
(
\cdopt{sep=.666cm}
1 \ar[r,maps to] \| 2 \ar[r,maps to] \| 3 \ar[ll,maps to,bend left=36]
\endcd
)
$$
Observe que, por exemplo,
$$
\permc{1 & 3 & 2} = \permc{3 & 2 & 1} = \permc{2 & 1 & 3}
=
\gathered
\tikzpicture
\node (a) at ( 0,.866) {$1$};
\node (b) at (-.5,0)   {$2$};
\node (c) at ( .5,0)   {$3$};
\draw[|->] (a) to [bend left=30] (c);
\draw[|->] (c) to [bend left=30] (b);
\draw[|->] (b) to [bend left=30] (a);
\endtikzpicture
\endgathered
$$
mas mesmo assim preferimos botar o menor número na primeira posição na escrita;
optariamos para o $\permc{1 & 3 & 2}$ nesse caso.
%%}}}

%%{{{ x: verify cycle notation 
\exercise.
Verifique que as duas permutações que escrevemos usando ciclos
realmente correspondem nas permutações anteriores.

\endexercise
%%}}}

%%{{{ beware: beware_notation_with_cycles 
\beware.
\label{beware_notation_with_cycles}%
Para usar a notação com ciclos para denotar os membros de algum
$\sym n$, precisamos esclarecer o $n$---algo que não é necessário
com a notação completa, onde esta informação é dedutível pela
sua forma.  Por exemplo as duas permutações
$$
\underbrace{
\permf{
1 & 2 & 3 & 4 & 5\\
2 & 1 & 3 & 5 & 4
}}_{\permc{1 & 2}\permc{4 & 5}}
\qtext{e}
\underbrace{
\permf{
1 & 2 & 3 & 4 & 5 & 6 & 7\\
2 & 1 & 3 & 5 & 4 & 6 & 7
}}_{\permc{1 & 2}\permc{4 & 5}}
$$
compartilham a mesma forma usando a notação com ciclos!
Olhando para as formas acima, sabemos que a primeira
é uma permutação do $\sym 5$, e a segunda do $\sym 7$.
\endgraf
Mais um defeito dessa notação é que não temos como denotar
a identidade numa forma consistente: podemos concordar
denotá-la pelo $\permc {1}$ ou $\permc{}$, mas na práctica
optamos para o $\id$ mesmo.
%%}}}

%%{{{ The members of \sym 3 
\note Os membros de $\sym 3$.
Já achamos $2$ dos $6$ elementos de $\sym 3$:
$$
\xalignat2
\id
&=\permf{
1 & 2 & 3\\
1 & 2 & 3
}
&
\phi
&\leteq\permf{
1 & 2 & 3\\
2 & 1 & 3
}
=\permc{1 & 2}
\endxalignat
$$
Sabendo
que a composição de bijecções é bijecção (\ref{fcom_respects_jections}),
tentamos a
$$
\phi^2 = \phi\com\phi
=\permf{
1 & 2 & 3\\
2 & 1 & 3
}\com\permf{
1 & 2 & 3\\
2 & 1 & 3
}
=\permf{
1 & 2 & 3\\
1 & 2 & 3
}
=\id
$$
e voltamos para a própria $\id$!
Uma outra permutação no $\sym 3$ é a
$$
\psi\leteq\permf{
1 & 2 & 3\\
2 & 3 & 1
}
=\permc{1 & 2 & 3}.
$$
Vamos agora ver quais diferentes permutações ganhamos combinando essas:
$$
\align
\psi^2
= \psi\com\psi
&=\permf{
1 & 2 & 3\\
2 & 3 & 1
}\com\permf{
1 & 2 & 3\\
2 & 3 & 1
}
=\permf{
1 & 2 & 3\\
3 & 1 & 2
}
=\permc{1 & 3 & 2}
\\
\phi\com\psi
&=\permf{
1 & 2 & 3\\
2 & 1 & 3
}\com\permf{
1 & 2 & 3\\
2 & 3 & 1
}
=\permf{
1 & 2 & 3\\
1 & 3 & 2
}
=\permc{2 & 3}\\
\psi\com\phi
&=\permf{
1 & 2 & 3\\
2 & 3 & 1
}\com\permf{
1 & 2 & 3\\
2 & 1 & 3
}
=\permf{
1 & 2 & 3\\
3 & 2 & 1
}
=\permc{1 & 3}
\endalign
$$
E achamos $6$ membros distintos do $\sym 3$.%
\footnote{Por que são distintos?
Veja~\ref{why_phipsi_neq_psiphi} por exemplo.}
Mas $\card{\sym 3} = 6$, e logo achamos \emph{todos} os membros de
$\sym 3 = \set{\id, \phi, \psi, \psi^2, \phi\psi,\psi\phi}$:
$$
\xalignat3
\id  &= \permc {1}         &\psi         &= \permc {1 & 2 & 3}  & \phi\com\psi &= \permc {2 & 3}\\
\phi &= \permc {1 & 2}     &\psi^2       &= \permc {1 & 3 & 2}  & \psi\com\phi &= \permc {1 & 3}.
\endxalignat
$$
%%}}}

%%{{{ remark: is_it_needed_to_compute_last_value_of_perm 
\remark.
\label{is_it_needed_to_compute_last_value_of_perm}%
Preciso mesmo calcular os últimos números das permutações?
Vamos voltar no momento que estamos calculando o $\phi\fcom\psi$;
acabamos de calcular as imagens de $1$ e $2$:
$$
\cdopt{column sep=4mm}
 1 \ar[d,maps to,"\psi"'] \| 2 \ar[d,maps to] \| 3 \\
 2 \ar[d,maps to,"\phi"'] \| 3 \ar[d,maps to] \| \\
 \alertB1                 \| \alertB3         \| \alertR?
\endcd
$$
Estamos então aqui:
$$
\phi\fcom\psi
=\permf{
1 & 2 & 3\\
\alertB1 & \alertB3 & \alertR?
}
$$
Agora podemos continuar no mesmo jeito, para calcular a imagem de $3$:
$$
\cdopt{column sep=4mm}
 1 \ar[d,maps to,"\psi"'] \| 2 \ar[d,maps to] \| 3 \ar[d,maps to] \\
 2 \ar[d,maps to,"\phi"'] \| 3 \ar[d,maps to] \| 1 \ar[d,maps to] \\
 1                        \| 3                \| 2
\endcd
$$
e assim chegar no
$$
\phi\fcom\psi
=\permf{
1 & 2 & 3\\
1 & 3 & 2
}
$$
Mas, $\phi\fcom\psi$ é uma bijecção (pois $\phi,\psi$ são,
e~\ref{fcom_respects_jections}), e logo podemos concluir desde o penúltimo
passo que $(\phi\fcom\psi)(3) = 2$.
Mesmo assim, sendo humanos, faz sentido achar esse último valor
\emph{com as duas maneiras}.
Assim, caso que elas chegam em resultados diferentes, teriamos um aviso sobre
um erro nos nossos cálculos anteriores!
%%}}}

%%{{{ x: inj_or_surj_needed_to_compute_last_value_of_perm 
\exercise.
\label{inj_or_surj_needed_to_compute_last_value_of_perm}%
Qual das duas propriedades de bijecção estamos usando
na~\ref{is_it_needed_to_compute_last_value_of_perm} para
concluir que $(\phi\psi)\fa 3 = 2$ sem calculá-lo
explicitamente?

\solution
Qualquer uma das duas seria suficiente nesse caso!

\endexercise
%%}}}

%%{{{ x: calculate psi 
\exercise.
Calcule a $\psi\com\psi^2$ e justifique que ela é igual à $\psi^2\com\psi$.

\solution
Calculamos:
$$
\align
1 &\mapstoby {\psi^2} 3 \mapstoby \psi 1\\
2 &\mapstoby {\psi^2} 1 \mapstoby \psi 2\\
3 &\mapstoby {\psi^2} 2 \mapstoby \psi 3
\endalign
$$
ou seja, $\psi\com\psi^2 = \id$.
A igualdade é imediata pela associatividade da $\fcom$.
(E ambas são iguais à $\psi^3$.)

\endexercise
%%}}}

%%{{{ x: calculate phi psi^2 and psi^2 phi 
\exercise.
Calcule as $\phi\com\psi^2$ e $\psi^2\com\phi$.

\endexercise
%%}}}

%%{{{ note: abstracting_the_notion_of_group 
\note Abstraindo.
\label{abstracting_the_notion_of_group}%
Temos um conjunto cujos elementos podemos ``combinar'' através duma operação binária.
As seguintes propriedades são satisfeitas nesse caso:
\beginil
\item{(G0)}
O conjunto é fechado sobre a operação.%
\footnote{Aplicando a operação em quaisquer membros do nosso conjunto,
o resultado pertence ao conjunto.}
\item{(G1)}
A operação é associatíva.
\item{(G2)}
A operação tem identidade no conjunto.
\item{(G3)}
Cada elemento do conjunto possui inverso no conjunto.
\endil
\endgraf
Conjuntos onde é definida uma operação que satisfaz essas propriedades
aparecem com freqüência, e vamos ver que são suficientes para construir
uma teoria rica baseada neles.
%%}}}

\endsection
%%}}}

%%{{{ What is a group? 
\section O que é um grupo?.

\blah.
Seguindo a abstracção do~\refn{abstracting_the_notion_of_group},
chegamos numa primeira definição:

%%{{{ df: group_def_wordy 
\definition Grupo.
\label{group_def_wordy}%
\tdefined{grupo}%
Um conjunto $G$ com uma operação binária $\ast$ é um \dterm{grupo}
sse:
o $G$ é $\ast$-\emph{fechado};
a $\ast$ é \emph{associativa};
a $\ast$ tem \emph{identidade} no $G$;
cada elemento de $G$ possui $\ast$-\emph{inverso}.
%%}}}

\blah.
Lembrando a~\ref{closed_associative_identity_inverse},
tentamos esclarecer pouco essa definição:

%%{{{ pseudodf: group_def_2_classic 
\pseudodefinition Grupo.
\label{group_def_2_classic}%
\tdefined{grupo}%
Um conjunto $G$ com uma operação binária $\ast$ no $G$ é um \dterm{grupo}
sse as leis seguintes
$$
\gather
a,b \in G \implies a\ast b \in G                                             \tag{G0} \\
a\ast(b\ast c) = (a\ast b)\ast c                                             \tag{G1} \\
\text{existe $e\in G$ tal que para todo $a\in G$, $e\ast a = a = a\ast e$}   \tag{G2} \\
\text{para todo $a\in G$, existe $y\in G$, tal que $y\ast a = e = a \ast y$} \tag{G3}
\endgather
$$
são satisfeitas.
\mistake
%%}}}

%%{{{ Laws vs. axioms 
\note Leis vs.~axiomas.
\label{laws_vs_axioms}%
\tdefined{lei}%
\tdefined{leis de grupo}%
\ii{axioma!vs.~lei}%
As (G0)--(G3) são conhecidas como \dterm{as leis de grupos},
ou \dterm{os axiomas de grupos}.
Tentarei evitar---mas não sempre!---usar a palavra \emph{axioma}
com esse sentido, optando para a palavra \emph{lei} mesmo,
pois chamamos de ``axioma'' algo que aceitamos como verdade em
nosso univérso (mais sobre isso no~\ref{Axiomatic_set_theory}),
mas nesse caso não estamos afirmando a veracidade das (G0)--(G3).
Faz apenas parte do que significa ``ser grupo''.
Se um conjunto estruturado satisfaz todas as leis,
bem, ele ganha o direito de ser chamado um ``grupo''.
Se não, beleza, ele não é um grupo.
%%}}}

%%{{{ notational_abuse_groups 
\note Abuso notacional.
\label{notational_abuse_groups}%
Lembra-se o abuso notacional que introduzímos
no~\refn{notational_abuse_structured_sets}:
usamos $a,b\in\ssetfont G$, $G=\sset G {\bullet}$, etc.
%%}}}

%%{{{ Multiplicative and additive groups 
\note Grupos multiplicativos e aditivos.
\tdefined{grupo}[aditivo]%
\tdefined{grupo}[multiplicativo]%
Dependendo da situação, podemos adoptar um ``jeito multiplicativo''
para a notação dum grupo, ou um ``jeito additivo''---ou ficar
realmente com um jeito neutro.
Num \dterm{grupo multiplicativo} usamos $\cdot$ para denotar a operação do grupo,
aproveitamos a convenção de omitir o símbolo totalmente, usando apenas
juxtaposição: $a(bc)$ significa $a\cdot(b\cdot c)$ por exemplo.
A identidade parecerá com $e$ ou $1$, e $a^{-1}$ será o inverso de~$a$.
Num \dterm{grupo aditivo} usamos $+$ para denotar a operação do grupo,
a identidade parecerá com $e$ ou $0$; e $-a$ será o inverso de~$a$.
Naturalmente usamos $\ast$, $\bullet$, etc.~para denotar operação
de grupo, $e$ para sua identidade, e $a^{-1}$ para denotar o inverso de~$a$.
É importante entender que os termos ``grupo multiplicativo'' e ``grupo aditivo''
usados assim não carregam nenhum significado matemático mesmo: apenas mostram
uma preferência notacional.
Mas quando um conjunto já tem adição e/ou multiplicação definida
(como por exemplo os reais), então usamos frases como
``o grupo aditivo dos reais'' para referir ao $\sset \reals +$,
e até ``o grupo multiplicativo dos reais'' para referir ao
$\sset {\reals_{\neq0}} \ntimes$, considerando óbvio o ``sem o zero'',
pois \emph{com} o zero nem é grupo (\ref{numeric_noneg_of_groups_are_really_noneg}).
%%}}}

\blah.
Para entender melhor as quatro leis de grupo, as escrevemos novamente,
essa vez sem deixar nenhum quantificador como implícito,
e começando com um \emph{conjunto estruturado} com uma operação binária:

%%{{{ pseudodf: group_def_2 
\pseudodefinition Grupo (2).
\label{group_def_2}%
Um conjunto estruturado $\ssetfont G = \sset G {\ast}$ é um \dterm{grupo} sse
$$
\alignat2
\pforall {a,b\in G}                 &\bracket{a\ast b \in G}                   &\tag{G0} \\
\pforall {a,b,c\in G}               &\bracket{a\ast(b\ast c) = (a\ast b)\ast c}&\tag{G1} \\
\pexists {e\in G} \pforall {a \in G}&\bracket{e\ast a = a = a\ast e}           &\tag{G2} \\
\pforall {a\in G} \pexists {y\in G} &\bracket{y\ast a = e = a \ast y}          &\tag{G3} 
\endalignat
$$
Chamamos o elemento garantido pela~(G2) a \dterm{identidade} do grupo,
chamamos o~$y$ da~(G3) o \dterm{inverso} de~$a$.
\mistake
%%}}}

%%{{{ x: check_group_def_classic_and_group_def_2 
\exercise.
\label{check_group_def_classic_and_group_def_2}%
Tá tudo certo com as definições~\refn{group_def_2_classic}
e~\refn{group_def_2}?

\hint
Quem é esse $e$ que aparece no (G3)?

\hint
Como assim \emph{o} inverso?

\endexercise
%%}}}

%%{{{ Galois, Abel, Cayley.
\note Galois, Abel, Cayley.
Como vimos, na mesma época o \Galois{}Galois e o \Abel{}Abel chegaram na
idéia abstrata de grupo.  Galois mesmo escolheu a palavra ``group'' para
esse conceito.
A definição ``moderna'' de grupo como conjunto com operação que satisfaz
as leis~(G0)--(G3) é de~\Cayley{}Cayley.
Como Abel focou em grupos cuja operação é comutativa, chamamos esses
grupos de abelianos:
%%}}}

%%{{{ df: abelian group 
\definition Grupo abeliano.
\label{abelian_group}%
\tdefined{grupo!abeliano}%
Um grupo é \dterm{abeliano}
(também: \dterm{comutativo})
sse sua operação é comutativa:
$$
\alignat2
\pforall {a,b\in G}    &\bracket{a\ast b = b\ast a}.   &\tag{GA}
\endalignat
$$
%%}}}

%%{{{ note: groups_and_abelian_groups_schematically 
\note.
\label{groups_and_abelian_groups_schematically}%
Esquematicamente:
$$
\gathered
\text{(fechado)}\\
\text{(associatividade)}\\
\text{(identidade)}\\
\text{(inversos)}\\
\text{(comutatividade)}
\endgathered
\gathered
\rightbrace{
\gathered
\vphantom0\\
\vphantom1\\
\vphantom2\\
\vphantom3
\endgathered
}
\text{grupo}\\
\vphantom4\\
\endgathered
\gathered
\rightbrace{
\gathered
\vphantom0\\
\vphantom1\\
\vphantom2\\
\vphantom3\\
\vphantom4
\endgathered
}
\text{grupo abeliano}
\endgathered
$$
%%}}}

%%{{{ eg: S3_is_a_non_abelian_group 
\example.
\label{S3_is_a_non_abelian_group}%
Verifique que $\sym 3$ é um grupo.
Ele é abeliano?

\solution
Precisamos verificar as leis de grupo.
\endgraf\noindent
{(G0).}
Para provar que $\sym 3$ é fechado pela $\fcom$, precisamos verificar
que para todo $a,b\in \sym 3$, $a \fcom b \in \sym 3$.
Pela definição do $\sym 3$, isso segue pelo~\ref{fcom_respects_jections}~(3).
\endgraf\noindent
{(G1).}
Já provamos a associatividade da $\fcom$ na~\ref{fcom_associativity_law}.
\endgraf\noindent
{(G2).}
Facilmente verificamos que a $\idof {\set{1,2,3}}$ é a identidade do
$\sset {\sym 3} {\fcom}$, pela sua definição.
\endgraf\noindent
{(G3).}
Cada bijecção tem uma função-inversa, que satisfaz as equações dessa lei
pela definição de função-inversa.
(Veja~\ref{finverse} e~\ref{finv_is_bij}.)
\endgraf\noindent
{(GA).}
Basta mostrar pelo menos um contraexemplo, ou seja, duas permutações
$a,b$ do $\sym 3$ tais que $a\fcom b \neq b\fcom a$.
Agora preciso saber o que significa igualdade entre \emph{funções}
(\ref{f_eq_g}).
Escolho os $\phi,\psi$.
Já calculamos as $\phi\fcom\psi$ e $\psi\fcom\phi$ e são diferentes.
\endgraf
Logo, $\sym 3$ é um grupo não abeliano.
\endexample
%%}}}

%%{{{ x: why_phipsi_neq_psiphi 
\exercise.
\label{why_phipsi_neq_psiphi}%
E por que $\phi\fcom\psi \neq \psi\fcom\phi$?

\solution
Pois elas discordam em pelo menos um valor: tome o $1$.
Agora
$$
(\phi\fcom\psi)(1)
= \phi(\psi(1))
= \phi(2)
= 1
\neq
3
= \psi(2)
= \psi(\phi(1))
= (\psi\fcom\phi)(1).
$$
Logo $\phi\fcom\psi \neq \psi\fcom\phi$.

\endexercise
%%}}}

%%{{{ And why 1 neq 3? 
\note E por que $1\neq 3$?.
Na resolução do~\ref{why_phipsi_neq_psiphi} nosso argumento reduziu
o que queriamos provar à afirmação $1 \neq 3$.
\emph{E por que $1 \neq 3$?}
Bem, precisamos saber o que significa igualdade no $\nats$!
Mas podemos já considerar o $1 \neq 3$ como um fato conhecido sobre os números
naturais.  Depois, no~\ref{Axiomatic_set_theory}, vamos \emph{fundamentar}
o~$\nats$ na teoria de conjuntos, e logo vamos ter como realmente provar essa
afirmação para nosso $\nats$, por exemplo.
%%}}}

%%{{{ x: find_all_inverses_on_S3 
\exercise.
\label{find_all_inverses_on_S3}%
Ache o inverso de cada elemento de $\sym 3$.%
\footnote{%
Se tu já fez isso para resolver o~\ref{S3_is_a_non_abelian_group},
não foi necessário.  Por quê?
Veja a resolução do~\refn{S3_is_a_non_abelian_group} mesmo.
}

\endexercise
%%}}}

\blah.
Agora vamos dar mais uma definição de grupo, essa vez usando um conjunto
estruturado de tipo diferente: alem de ter uma operação binária,
tem uma constante também:

%%{{{ df: group_def_20 
\definition Grupo (2,0).
\label{group_def_20}%
\tdefined{grupo}%
Um conjunto estruturado $\ssetfont G = \sset G {\ast, e}$ é um grupo sse
$$
\alignat2
\pforall {a,b\in G}                 &\bracket{a\ast b \in G}                   &\tag{G0} \\
\pforall {a,b,c\in G}               &\bracket{a\ast(b\ast c) = (a\ast b)\ast c}&\tag{G1} \\
\pforall {a \in G}                  &\bracket{e\ast a = a = a\ast e}           &\tag{G2} \\
\pforall {a\in G} \pexists {y\in G} &\bracket{y\ast a = e = a \ast y}          &\tag{G3}
\endalignat
$$
%%}}}

%%{{{ x: check_group_def_20 
\exercise.
\label{check_group_def_20}%
Tá tudo certo com a~\ref{group_def_20}?

\solution
Sim!
Veja também a~\ref{a_vs_the_identity_of_a_group}.

\endexercise
%%}}}

%%{{{ remark: a_vs_the_identity_of_a_group 
\remark.
\label{a_vs_the_identity_of_a_group}%
O $e$ que aparece na~(G3) não é ``\emph{a} identidade do $\cal G$''.
É sim \emph{a} constante que aparece na estrutura do $\sset G {\ast,e}$,
que---graças à~(G2)---é \emph{uma} identidade do $\cal G$.
No~\ref{uniqueness_of_identity_in_group} vamos provar que cada grupo tem identidade única,
e a partir dessa prova, vamos ganhar o direito de usar o artigo definido ``a''.
%%}}}

%%{{{ Q: can you define group (2,1,0)? 
\question.
Já encontramos definições de grupo como conjunto estruturado com assinaturas
de aridades $(2)$ e $(2,0)$.
Como definarias com assinatura de aridades $(2,1,0)$?
%%}}}
\spoiler.

%%{{{ df: group_def_210 
\definition Grupo (2,1,0).
\label{group_def_210}%
Um conjunto estruturado $\ssetfont G = \sset G {\ast, {}^{-1}, e}$
onde $\ast$ é uma operação binária, ${}^{-1}$ unária, e $e$ uma constante
é um \dterm{grupo} sse:
\beginil
\item{(G0)} $G$ é $\ast$-fechado;
\item{(G1)} $\ast$ é associativa;
\item{(G2)} $e$ é uma $\ast$-identidade;
\item{(G3)} para todo $a \in G$, $\ginv a$ é um $\ast$-inverso do $a$.
\endil
Formulamente:
$$
\alignat2
\pforall {a,b \in G}   &\bracket{a\ast b \in G}                    &\tag{G0} \\
\pforall {a,b,c \in G} &\bracket{a\ast(b\ast c) = (a\ast b)\ast c} &\tag{G1} \\
\pforall {a \in G}     &\bracket{e\ast a = a = a\ast e}            &\tag{G2} \\
\pforall {a \in G}     &\bracket{a^{-1}\ast a = e = a \ast a^{-1}} &\tag{G3} 
\endalignat
$$
%%}}}

%%{{{ df: order of group 
\definition Ordem de grupo.
\label{order_of_group}%
\tdefined{ordem!de grupo}%
\sdefined {\gord {\sholed G}} {a ordem do grupo $G$}%
O número de elementos de um grupo $G$ é sua \dterm{ordem}.
Denotamos a ordem de $G$ com:
$\gord G$, $\tord G$, ou até $\bord G$ quando não existe ambigüidade.
Se o carrier set do grupo é infinito, escrevemos
$\gord G = \infty$.
%%}}}

%%{{{ x: group_of_any_finite_order 
\exercise.
\label{group_of_any_finite_order}%
Já conhecemos um grupo finito bem, o $\sym 3$,
com $\gord {\sym 3} = 6$.
No~\ref{Sn_is_a_group} provarás que para todo $n\in\nats$,
o $\sym n$ é um grupo.
Seja $m\in\nats$.
Tem como achar um grupo com ordem $m$?
Observe que como sabemos que $\gord {\sym n} = n!$, podemos já achar
um grupo com ordem $m$ para qualquer $m$ que fosse um fatorial.
Por exemplo, se $m=120$ já temos o grupo $\sym 5$,
pois $\gord {\sym 5} = 5! = 120$.
Mas para um $m$ arbitrário, existe grupo de ordem $m$?

\hint
\ref{Number_theory_congruences}.

\endexercise
%%}}}

%%{{{ remark: G0_is_redundant 
\remark Uma lei que não é lei.
Talvez resolvendo os exercícios~\refn{check_group_def_classic_and_group_def_2}
e~\refn{check_group_def_20},
tu já percebeste algo redundante na~\ref{group_def_2}:
\emph{pra que essa (G0)?}
O $\sset G \ast$ é um conjunto estruturado cuja estrutura tem uma
\emph{operação binária}, ou seja uma \emph{função}
$$
\ast : G \cross G \to G.
$$
Logo, a (G0) não tem absolutamente nada pra oferecer:
\emph{necessariamente}
$$
\lforall {a,b \in G} {a \ast b \in G}
$$
pois $\ast : G \cross G \to G$.
Observe que se relaxar a definição de conjunto estruturado
para permitir operações \emph{parciais} (\ref{partial_function})
o (G0) vira lei necessária mesmo e afirma simplesmente
que $\ast$ é total.
Mas nosso padrão de operação foi operação total mesmo,
e, nesse sentido, \emph{as leis de grupo} são as (G1)--(G3).%
\footnote{%
E por isso denotei a primeira com \sq{0}, não foi questão
de começar a conta com o primeiro Nat.
}
\emph{Mesmo assim}, é comum encontrar a (G0) como axioma
de grupo, e se tirá-la não ganhamos nada mesmo.
Suponha que tu trabalhas com a (G0) como lei que faz parte
da tua definição de grupo; e teu amigo trabalha apenas com
as (G1)--(G3).
Inicialmente parece que teu amigo vai ter menos trabalho
pra fazer quando precisar demonstrar que um $\sset G \ast$
é um grupo.
Mas não é assim: a definição começa com um
\emph{conjunto estruturado} cuja estrutura inclui a operação
binária $\ast$.
Ou seja, para demonstrar que $\sset G \ast$ é um grupo
ele vai precisar demonstrar que $\ast$ realmente é uma operação
$$
\ast : G \cross G \to G
$$
ou seja, (G0), ou seja, ele não vai ter menos trabalho;
se preocupe não!
%%}}}

\endsection
%%}}}

%%{{{ Examples and nonexamples 
\section Exemplos e nãœxemplos.

%%{{{ eg: with numbers 
\example Com números.
Todos os seguintes conjuntos estruturados são grupos:
\beginol
\li$\sset A {+,0}$, onde $A \asseq \ints, \rats, \reals, \complex$;
\li$\sset B {\ntimes,1}$, onde $B \asseq \rats_{\neq0}, \reals_{\neq0}$;
\li$\sset C {\ntimes,1}$, onde $C \asseq \set{1,-1}, \set{1,i,-1,-i} \subset\complex$.
\endol
\endexample
%%}}}

%%{{{ noneg: with numbers 
\nonexample Com números.
E \emph{nenhum} dos seguintes é um grupo:
$\sset \nats {+}$;
$\sset \reals {\ntimes,1}$;
$\sset {\ints_{\neq 0}} {\ntimes,1}$;
$\sset \reals {+,1}$.
\endnonexample
%%}}}

%%{{{ x: why? : numeric_noneg_of_groups_are_really_noneg 
\exercise.
\label{numeric_noneg_of_groups_are_really_noneg}
Por quê?

\endexercise
%%}}}

%%{{{ noneg: strings_with_concat_is_not_a_group 
\nonexample Strings.
\label{strings_with_concat_is_not_a_group}%
Sejam $\Sigma\neq\emptyset$ um alfabeto finíto,
e $S$ o conjunto de todos os strings finitos formados por símbolos do $\Sigma$.
O $\sset S +$ onde $+$ é a \emph{concatenação} de strings \emph{não} é um grupo.
\endnonexample
%%}}}

%%{{{ x: verify_all_group_laws_for_strings 
\exercise.
\label{verify_all_group_laws_for_strings}%
Para cada uma das leis~(G0)--(GA), decida se é
satisfeita pelo $\sset S +$ do~\ref{strings_with_concat_is_not_a_group}.
Se é, prove; se não é, refute!

\endexercise
%%}}}

%%{{{ x: shared_carrierset_group_notgroup 
\exercise.
\label{shared_carrierset_group_notgroup}%
Sejam $B = \setst {2^m} {m \in \ints}$ e $B_0 = B \union \set{0}$.
Considere os conjuntos estruturados
$$
\xalignat4
&\sset B {+}
&&\sset B {\ntimes}
&&\sset {B_0} {+}
&&\sset {B_0} {\ntimes}.
\endxalignat
$$
Para cada um deles decida se satisfaz cada uma das leis (G0)--(GA).

\endexercise
%%}}}

%%{{{ x: more number-based groups 
\exercise.
Mostre mais grupos formados de números dos
$\nats$, $\ints$, $\rats$, $\reals$, $\complex$,
e uma operação não-padrão da sua escolha.

\endexercise
%%}}}

%%{{{ eg: matrix_group_examples 
\example Matrizes.
\label{matrix_group_examples}%
Considere os conjuntos seguintes:
$$
\xalignat2
A &= \setst{ \matrixp{a & b\\c & d}\in\reals^{2\times2}} {a,b,c,d \in \reals } &
M &= \setst{ \matrixp{a & b\\c & d}\in\reals^{2\times2}} {ad - bc \neq 0 }.
\endxalignat
$$
O $A$ com a adição de matrízes vira um grupo $\sset A +$,
mas com a multiplicação não: não todos os seus membros tem inverso.
No outro lado, graças à condição no filtro na definição do conjunto $M$,
todos os seus membros são matrízes invertíveis,
e $\sset M {\cdot}$ realmente é um grupo.
\endexample
%%}}}

%%{{{ x: (M;+) is not a group 
\exercise matrizes.
O $\sset M +$ é?

\hint
Não: tem como adicionar dois matrizes invertíveis e resultar
numa matriz que não é.

\solution
Não é, pois quebra a (G0):
$$
\munderbrace {\matrixp{1 & 0\\0 & 1}} {\in \sset M +} +
\munderbrace {\matrixp{0 & 1\\1 & 0}} {\in \sset M +} =
\munderbrace {\matrixp{1 & 1\\1 & 1}} {\notin \sset M +}.
$$

\endexercise
%%}}}

%%{{{ eg: modular_addition_group_eg 
\example Adição modular.
\label{modular_addition_group_eg}%
O $\finord n \defeq \set{0,\dotsc,n-1}$ com a operação $+_n$
da adição módulo $n$.
Qual é o inverso de um elemento $a$ nesse caso?
É o $n-a$, pois $a +_n (n-a) = 0 = (n-a) +_n a$.

\endexample
%%}}}

%%{{{ df: modular addition group 
\definition.
\sdefined {\ints_{\sholed n}} {o grupo aditivo dos inteiros módulo}%
Denotamos o grupo do~\ref{modular_addition_group_eg} por $\ints_n$.
%%}}}

%%{{{ noneg: modular_multiplication_group_noneg
\nonexample Multiplicação modular.
\label{modular_arithmetic_group_eg}%
O $\finord n \defeq \set{0,\dotsc,n-1}$ com a operação $\ntimes_n$
da multiplicação módulo $n$, não é um grupo, pois o $0$ não tem inverso.
E se jogar fora o problemático $0$?  Talvez vira um grupo.
Mas não: o $\sset {\set{1,\dotsc,5}} {\ntimes_6}$ também não é um grupo,
pois não é fechado: $2 \ntimes_6 3 = 0$.
\endnonexample
%%}}}

%%{{{ df: symmetric_group 
\definition.
\label{symmetric_group}%
\tdefined {grupo}[simétrico]%
\sdefined {\sym {\sholed n}} {o grupo simétrico $\sym n$}%
Usamos $\sym n$ para denotar o conjunto de todas as permutações
dum conjunto de tamanho $n\in\nats$.
Para definir mesmo o $\sym n$ escolhemos o conjunto canônico:
$$
\sym n \pseudodefeq (\set{1,\dotsc,n}\bijto\set{1,\dotsc,n}).
$$
Para qualquer $n\in\nats$, chamamos o $\sset {\sym n} {\fcom}$
o \dterm{grupo simétrico} de tamanho $n$.
%%}}}

%%{{{ x: Sn_is_a_group 
\exercise.
\label{Sn_is_a_group}%
Justifique a~\ref{symmetric_group}: prove que o grupo simétrico $\sym n$
realmente é um grupo.
Ele é abeliano?

\endexercise
%%}}}

%%{{{ x: pset_with_setops_group 
\exercise Conjuntos.
\label{pset_with_setops_group}%
Seja $A$ conjunto.
Com quais das operações $\union$, $\inter$, $\symdiff$, e $\setminus$,
o $\pset A$ é um grupo?

\endexercise
%%}}}

%%{{{ x: real_functions_pointwise_plus_group 
\exercise Funções reais: adição pointwise.
\label{real_functions_pointwise_plus_group}%
O $(\reals \to \reals)$ com operação a pointwise $+$, é um grupo?%
\footnote{Qual operação é a pointwise $+$?  Veja a~\ref{pointwise_operation}.}
Ele é abeliano?

\endexercise
%%}}}

%%{{{ x: real_functions_pointwise_times_nongroup 
\exercise Funções reais: multiplicação pointwise.
\label{real_functions_pointwise_times_nongroup}%
O $(\reals \to \reals) \setminus \set{ \lam x 0 }$ com operação a
pointwise~$\ntimes$, é um grupo?
Ele é abeliano?

\endexercise
%%}}}

\blah.
Lembre que já usamos $\times$ entre \emph{conjuntos} $A,B$ para formar seu
produto cartesiano $A \times B$; e também entre \emph{funções} $f : A \to B$,
$g : C \to D$ para formar seu produto
$f \times g : (A\times C) \to (B \times D)$.
Vamos agora sobrecarregar ainda mais esse $\times$:

%%{{{ df: direct_product_of_groups 
\definition Produtos diretos.
\label{direct_product_of_groups}%
Sejam $\cal G_1 = \sset {G_1} {\ast_1}$ e $\cal G_2 = \sset {G_2} {\ast_2}$ grupos.
Definimos o grupo
$$
\cal G_1 \times \cal G_2 = \sset {G_1 \times G_2} {\ast},
$$
onde $\ast$ é a operação definida pela
$$
\tup{x_1, x_2} \ast \tup{y_1, y_2} = \tup{x_1 \ast_1 y_1, x_2 \ast_2 y_2}.
$$
%%}}}

%%{{{ x: direct_product_of_groups_is_a_group 
\exercise.
\label{direct_product_of_groups_is_a_group}%
Prove que realmente é um grupo.

\solution
{%
\def\xx{\tup{x_1,x_2}}%
\def\yy{\tup{y_1,y_2}}%
\def\zz{\tup{z_1,z_2}}%
Precisamos verificar as leis (G0)--(G3).
\crproofpart{(G0).}
Tome $\xx, \yy \in G_1\times G_2$.
Calculamos
\compute
\xx \ast \yy
&= \tup{x_1 \ast_1 y_1, x_2 \ast_2 y_2} \by {def.~$\ast$}
&\in G_1 \times G_2.                    \by {$G_1$ e $G_2$ fechados pelas suas operações}
\endcompute
e logo $G_1\times G_2$ é $\ast$-fechado.
\crproofpart{(G1).}
Tome $\xx, \yy, \zz \in G_1\times G_2$.
Calculamos:
$$
\align
\paren{\xx \ast \yy} \ast \zz
&= \tup{x_1 \ast_1 y_1, x_2 \ast_2 y_2} \ast \zz \\
&= \tup{\paren{x_1 \ast_1 y_1} \ast_1 z_1, \paren{x_2 \ast_2 y_2} \ast_2 z_2} \\
&= \tup{x_1 \ast_1 \paren{y_1 \ast_1 z_1}, x_2 \ast_2 \paren{y_2 \ast_2 z_2}} \\
&= \xx \ast \paren{\tup{y_1 \ast_1 z_1, y_2 \ast_2 z_2}} \\
&= \xx \ast \paren{\yy \ast \zz}.
\endalign
$$
\proofpart{(G2).}
Afirmação: o $\tup{e_1,e_2}\in G_1\times G_2$ é a $\ast$-identidade.
Prova da afirmação: tome $\xx \in G_1\times G_2$ e calcule:
$$
\tup{e_1, e_2} \ast \xx
= \tup{e_1 \ast_1 x_1, e_2 \ast_2 x_2}
= \xx
= \tup{x_1 \ast_1 e_1, x_2 \ast_2 e_2}
= \xx \ast \tup{e_1, e_2}.
$$
\proofpart{(G3).}
Seja $\xx \in G_1 \times G_2$.
Afirmação: o $\tup{\ginv{x_1}, \ginv{x_2}}$ é o $\ast$-inverso dele.
Realmente temos:
$$
\align
\xx \ast \tup{\ginv{x_1}, \ginv{x_2}}
&= \tup{x_1 \ast_1 \ginv{x_1}, x_2 \ast_2 \ginv{x_2}}
 = \tup{e_1, e_2} \\
\tup{\ginv{x_1}, \ginv{x_2}} \ast \xx
&= \tup{\ginv{x_1} \ast_1 x_1, \ginv{x_2} \ast_2 x_2}
 = \tup{e_1, e_2}
\endalign
$$
Assim concluimos nossa prova.
}

\endexercise
%%}}}

%%{{{ df: gop 
\definition grupo oposto.
\label{gop}%
{%
\def\G{{\ssetfont G}}%
Seja $\G = \sset G {\ast, \ginv{}, \gid}$ grupo.
Definimos no $\carrier\G$ a operação binária $\ast'$ pela:
$$
x \ast' y = y \ast x.
$$
Chamamos o $\sset G {\ast'}$ de \dterm{grupo oposto do $\G$},
e o denotamos por $\gop\G$.
}
%%}}}

%%{{{ x: gop_is_a_group 
\exercise.
\label{gop_is_a_group}%
{%
\def\G{{\ssetfont G}}%
Justifique o nome escolhido na~\ref{gop}:
demonstre que o $\gop\G$ é um grupo.
}

\endexercise
%%}}}

\blah.
Chegam os exemplos por enquanto.
Vamos começar ver a \emph{teoria} de grupos, investigando propriedades que
todos os grupos necessariamente têm.
Ou seja, procuramos as \emph{conseqüências das leis} (G0)--(G3).

\endsection
%%}}}

%%{{{ First consequences 
\section Primeiras conseqüências.
\label{First_consequences_of_group_laws}%

%%{{{ lm: uniqueness_of_identity_in_group 
\lemma unicidade da identidade.
\label{uniqueness_of_identity_in_group}%
\ii{unicidade!da identidade}%
Em todo grupo $G$ existe único elemento $e$ que satisfaz a (G2).
\sketch.
Seja $G$ grupo.
Sabemos que existe pelo menos uma identidade no $G$ pela (G2),
então precisamos mostrar que existe no máximo uma (unicidade).
Vamos supor que $e_1, e_2$ são identidades do $G$, e usando
as leis~(G0)--(G2) mostrar que $e_1 = e_2$.
\qes
\proof.
Seja $G$ grupo.
Sabemos que $G$ tem pelo menos uma identidade graças à (G2),
então o que precisamos mostrar é sua unicidade mesmo.
Suponha que $e_1,e_2\in G$ tais que $e_1,e_2$ são identidades do $G$;
em outras palavras:
$$
\align
\text{para todo $a\in G$},\quad & e_1\ast a \eqlabel L a \eqlabel R a\ast e_1   \tag{1}\\
\text{para todo $b\in G$},\quad & e_2\ast b \eqlabel L b \eqlabel R b\ast e_2.  \tag{2}
\endalign
$$
Agora exatamente a mesma prova pode ser escrita em dois caminhos
meio diferentes:
\crtabproofalt{Caminho 1:}
Temos
\compute
e_1
&= e_1 \ast e_2  \by {pela (2R), com $b\asseq e_1$}
&= e_2           \by {pela (1L), com $a\asseq e_2$}
\endcompute
e provamos o que queremos: $e_1 = e_2$, ou seja,
em cada grupo existe única identidade.
\crtabproofalt{Caminho 2.}
Temos
\compute
e_1 \ast e_2 &= e_1  \by {pois $e_2$ é uma R-identidade (2R)}
e_1 \ast e_2 &= e_2  \by {pois $e_1$ é uma L-identidade (1L)}
\endcompute
e concluimos o desejado $e_1 = e_2$.
\qed
%%}}}

\blah.
Uma prova errada desse lema aparece
no~\ref{bust_proof_of_uniqueness_of_identity_in_group},
onde peço identificar seus erros.

%%{{{ Q: What have we just won? 
\question.
O que acabamos de ganhar?
%%}}}

%%{{{ A: The right to use the definite article 
\blah Resposta.
Ganhamos o direito de usar o artigo definido:
para cada grupo~$\cal G$ falar \emph{da}~identidade do~$\cal G$,
em vez \emph{duma}~identidade do~$\cal G$.
Observe que dado algum $a\in \cal G$ ainda não podemos falar sobre
\emph{o}~inverso de~$a$, mas apenas sobre \emph{um}~inverso de~$a$,
pois por enquanto a~(G3) garanta que pelo menos um inverso existe.
Vamos resolver isso agora.
%%}}}

%%{{{ beware: bound_variables_in_proof_of_uniqueness_of_identity_in_group 
\beware.
\label{bound_variables_in_proof_of_uniqueness_of_identity_in_group}%
\ii{variável!ligada}%
Os $a$ e $b$ que aparecem nas~(1)--(2) na prova do~\ref{uniqueness_of_identity_in_group}
são \emph{variáveis ligadas} aos correspondentes <<para todo ${\thole} \in G$>>
e logo, ``nascem'' com essa frase e ``morrem'' no fim da mesma linha!%
\footnote{Veja~a~\ref{Bound_and_free_variables} também.}
Daí, não faz sentido afirmar logo após das~(1)--(2) algo do tipo $e = a \ast e$, pois o $a$ não foi declarado!
Podemos escrever as duas afirmações sem usar o nome $a$:
\emph{para cada elemento do $G$, operando com o~$e_1$ ao qualquer lado (direito ou esquerdo), o resultado é o próprio elemento}.
E para enfatizar ainda mais a independência do~$a$ que aparece na~(1) com o~$b$ que aparece na~(2) escolhemos variáveis diferentes.
Mas isso é \emph{desnecessário}, em geral vamos reusar variáveis ligadas quando não gera confusão---e aqui não geraria nenhuma.
%%}}}

%%{{{ x: rewrite_proof_with_same_bound_var 
\exercise.
\label{rewrite_proof_of_uniqueness_of_identity_in_group_with_same_bound_var}%
O que muda na prova do~\ref{uniqueness_of_identity_in_group} se usar a mesma
variável ligada nas afirmações~(1) e~(2)?

\solution
É apenas escrever
$$
\align
\text{para todo $a\in G$},\quad & e_1\ast a \eqlabel L a \eqlabel R a\ast e_1 \tag{1}\\
\text{para todo $a\in G$},\quad & e_2\ast a \eqlabel L a \eqlabel R a\ast e_2 \tag{2}
\endalign
$$
e depois
\compute
e_1
&= e_1 \ast e_2     \by {pela (2R), com $a\asseq e_1$}
&= e_2.             \by {pela (1L), com $a\asseq e_2$}
\endcompute
Observe que os $a$ que aparecem nas instanciações $a \asseq \dots$ são completemante independentes.
Ou seja, nada muda mesmo!

\endexercise
%%}}}

%%{{{ lm: uniqueness_of_inverses_in_group 
\lemma unicidade dos inversos.
\label{uniqueness_of_inverses_in_group}%
\ii{unicidade!dos inversos}%
Em todo grupo $G$, cada $a\in G$ tem
exatamente um inverso $\ginv a$ que satisfaz a (G3).
\sketch.
Supondo que existe um certo $a \in G$ que possui inversos
$a_1,a_2\in G$, mostramos que necessariamente $a_1 = a_2$.
Ganhamos isso como corolário do~\ref{cancellation_laws_in_group}.
(Como?)
\qes
\proof.
Seja $\sset G {\ast, e}$ grupo, e suponha que existem $a,a_1,a_2\in G$
tais que $a_1,a_2$ são inversos de $a$, ou seja,
\compute
a_1 \ast a &\eqlabel L e \eqlabel R a \ast a_1  \bytag {$a_1$ é um inverso de $a$} 1
a_2 \ast a &\eqlabel L e \eqlabel R a \ast a_2. \bytag {$a_2$ é um inverso de $a$} 2
\endcompute
Vamos mostrar que $a_1 = a_2$.
Temos:
\compute
a_1 \ast a &= a_2 \ast a \by {pelas (1L), (2L)}
a_1        &= a_2        \by {pelo~\refn{cancellation_laws_in_group}~(GCR)}
\endcompute
e \emph{ficamos devendo} provar a (GCR) do~\ref{cancellation_laws_in_group}.
\qed
%%}}}

%%{{{ beware: Proof dependencies 
\beware Dependências de demonstrações.
Até realmente demonstrar as leis
de can\-ce\-la\-men\-to~(\refn{cancellation_laws_in_group}) não temos
a unicidade dos inversos~(\refn{uniqueness_of_inverses_in_group}).
Dado um elemento $a$ dum grupo $G$ não podemos ainda falar \emph{do}
inverso do $a$, nem usar a notação $\ginv a$ (seria mal-definida), etc.%
\footnote{%
Na verdade, se a gente usa como definição de grupo a \refn{group_def_210},
temos como usar a notação $\ginv a$ sim, mas ainda não podemos afirmar que
$\ginv a$ é \emph{a} inversa do $a$.  \emph{Uma}, sim.
}
Crucialmente, não podemos usar nada disso em nossa prova
do~\refn{cancellation_laws_in_group};
caso contrário criamos uma loope de dependências.
``Forward dependencies'' são perigosos exatamente por causa disso,
e nós as evitamos mesmo.%
\footnote{Aqui escolhi essa abordagem para enfatizar a importância de ficar
alertos para identificar chances de afirmar e provar lêmmata separadamente,
os usando em nossa prova e para provar outros teoremas depois a vontade.
Fazemos isso exatamente no mesmo jeito que um bom programador
percebe padrões nos seus programas e suas funções e separa certas partes para
outras funções, as chamando depois a vontade.}
%%}}}

%%{{{ lm: cancellation_laws_in_group 
\lemma Leis de cancelamento.
\label{cancellation_laws_in_group}%
Seja $\ssetfont G = \sset G {\ast, \gid}$ grupo.
Então as leis de cancelamento pela esquerda e pela direita
$$
\alignat2
\pforall {a,x,y\in G}  &\bracket{a\ast x = a\ast y \implies x=y}  &\tag{GCL} \\
\pforall {a,x,y\in G}  &\bracket{x\ast a = y\ast a \implies x=y}  &\tag{GCR}
\endalignat
$$
são válidas em $G$.
\sketch.
Sejam $a,x,y\in G$ tais que
$$
a \ast x = a \ast y.   \tag{1}
$$
Queremos provar $x=y$.
Tome a~(1) então, e usando umas das leis de grupo---comece com a~(G3)---chegue no desejado $x=y$, provando assim a~(GCL).
A~(GCR) é similar.
\qes
\proof.
Sejam $a,x,y\in G$ tais que
$$
a \ast x = a \ast y.   \tag{1}
$$
Pela (G3) o $a$ possui inverso no $G$;
daí, seja $a_0$ \emph{um} inverso de $a$, ou seja,
$$
a_0 \ast a \eqlabel L e  \eqlabel R a \ast a_0.  \tag{2}
$$
Agora temos:
\compute
a_0 \ast (a \ast x) &= a_0 \ast (a \ast y)  \by {pela (1)}
(a_0 \ast a) \ast x &= (a_0 \ast a) \ast y  \by {pela (G1): $\ast$ é associativa}
e \ast x            &= e \ast y             \by {pela escolha do $a_0$: (2L)}
x                   &= y                    \by {pela definição do $e$}
\endcompute
Provamos assim a~(GCL).
A~(GCR) é completamente simétrica (e vamos precisar a~(2R) em vez da~(2L)).
\qed
%%}}}

%%{{{ x: converses_of_cancellation_laws 
\exercise.
\label{converses_of_cancellation_laws}%
Os conversos das leis de cancelamento~(GCL)~\&~(GCR) são válidos?

\hint
Sim; mas por quê?

\hint
Não precisamos nem saber que $G$ é um grupo nem nada sobre $\ast$, etc.

\solution
Se $x=y$ isso quis dizer que podemos substituir a vontade em cada
\emph{expressão} que envolve $x$ e $y$, uns $x$'s por $y$'s, e vice versa.
Nesse caso, começa com o
$$
a \ast x
$$
e troca a única instância de $x$ nessa expressão por $y$, e já chegamos no
$$
a \ast y
$$
ou seja, $a \ast x = a \ast y$.

\endexercise
%%}}}

%%{{{ x: refute_the_diffside_cancellation_law 
\exercise.
\label{refute_the_diffside_cancellation_law}%
Refuta: para todo grupo $\sset G {\ast, e}$ e $a,x,y\in G$
$$
a\ast x = y\ast a \implies x=y
$$

\hint
Não tem como achar um contraexemplo em grupos abelianos.

\hint
Tem contraexemplo no $\sym 3$.

\hint
Procuramos $a,x,y$ num grupo tais que
$$
ax = ya \nimplies x = y,
$$
ou seja, tais que $ax = ya$ e $x \neq y$.
Mas, o que podemos concluir se $ax = ya$?
$$
ax = ya \implies x = \ginv a y a.
$$
Então nossos $a,x,y$ tem que ser tais que
$x = \ginv a y a$ e mesmo assim $x \neq y$.
Pensando nesses membros como processos e na operação como
``seguindo'' (exatamente a intuição da composição de funções),
para conseguir um contraexemplo, precisamos achar $a$ e $y$
tais que:
fazendo o $a$, depois o $y$, e depois desfazendo o $a$, não
vai ter o mesmo efeito com o processo de fazer apenas o $y$.

\solution
No $\sym 3$, temos
$$
\phi (\psi\phi) = (\phi\psi) \phi
$$
e mesmo assim
$$
\psi\phi \neq \phi\psi.
$$

\endexercise
%%}}}

%%{{{ x: why_is_this_not_a_counterexample_of_the_diffside_cancellation_law
\exercise.
\label{why_is_this_not_a_counterexample_of_the_diffside_cancellation_law}%
Um aluno achou o seguinte contraexemplo para refutar a lei
no~\refn{refute_the_diffside_cancellation_law}:
$$
\text{nos reais com multiplicação, temos $0\ntimes 1 = 2\ntimes 0$ mas $1\neq 2$.}
$$
Por que sua resposta é errada?

\hint
O que exatamente é um contraexemplo nesse caso?

\endexercise
%%}}}

%%{{{ x: uniqueness_of_inverses_in_group_proof_without_cancellation 
\exercise.
\label{uniqueness_of_inverses_in_group_proof_without_cancellation}%
Ache uma prova do~\ref{uniqueness_of_inverses_in_group}
que não precisa das leis de cancelamento.

\endexercise
%%}}}

%%{{{ remark: what is your group structure? 
\remark Qual a estrutura dos teus grupos?.
Suponha que na nossa estrutura não temos a operação unária de ${}^{-1}$.
Provando finalmente a unicidade dos inversos
(\refn{uniqueness_of_inverses_in_group}) ganhamos então em cada
grupo $G$ uma \emph{função} (unária) de inverso
$$
\ginvt : G \to G.
$$
Sua \emph{totalidade} já era garantida pela~(G3), que nesse caso é a:
$$
\alignat2
\pforall {a\in G} \pexists {y\in G} &\bracket{y\ast a = e = a \ast y}          &\tag{G3}\\
\intertext{%
e agora acabamos de ganhar sua \emph{determinabilidade} com
o~\ref{uniqueness_of_inverses_in_group}.
Ou seja: \emph{função!}
Podemos finalmente definir uma notação para denotar o inverso
de qualquer $a\in G$.
Similarmente, se na nossa estrutura não temos a constante $e$,
então provando a unicidade da identidade ganhamos o direito de
definir uma notação para \emph{a} identidade dum grupo $G$.
Cuidado, pois agora a (G2) tá apenas afirmando a existência
\emph{duma} identidade:
}
\pexists {e\in G} \pforall {a \in G}&\bracket{e\ast a = a = a\ast e}           &\tag{G2}
\endalignat
$$
mas graças ao \ref{uniqueness_of_identity_in_group} sabemos
que é única então podemos definir uma notação pra ela.
Vamos fazer essas duas coisas agora:
%%}}}

%%{{{ df: gid 
\definition identidade para estruturas incompletas.
\label{gid}%
\sdefined {\gidof {\sholed G}} {a identidade do grupo $G$}%
\sdefined {\gid} {a identidade dum grupo implicito pelo contexto}%
Seja $\sset G \ast$ grupo.
Denotamos a única identidade de $G$ por
$\gidof G$, ou simplesmente $\gid$ se o grupo $G$ já é
implícito pelo contexto.
%%}}}

%%{{{ df: ginv ; gid 
\definition inversos para estruturas incompletas.
\label{ginv}%
\sdefined {\ginv {\sholed a}} {o inverso de $a$ num grupo}%
Seja $\sset G \ast$ ou $\sset G {\ast,e}$ grupo.
Para qualquer $a\in G$, definimos o
$$
\ginv a \defeq \text{o único inverso de $a$ no $G$}.
$$
%%}}}

%%{{{ beware: choice_of_group_structure_justifications 
\beware a escolha de estrutura: escrevendo justificativas.
\label{choice_of_group_structure_justifications}
Um matemático tá trabalhando com grupos $\sset G \ast$,
e ta querendo justificar que
$$
a \ast \gidof G = a.
$$
Qual seria a justificativa que ele vai escrever?
Ele não pode dizer <<pela (G2)>>, pois a (G2)
ta afirmando apenas a existência duma identidade;
ela não ta afirmando nada sobre esse $\gidof G$ ali.
A justificativa dele seria:
\standout
<<pela definição do $\gidof G$>>.
\endstandout
No outro lado, um matemático que trabalha com grupos
cuja estrutura já tem a constante $e$ nela, ou seja,
com grupos $\sset G {\ast, e}$ ou $\sset G {\ast, {}^{-1}, e}$,
justificaria o mesmo passo assim:
\standout
<<pela (G2R)>>.
\endstandout
Similarmente sobre a justificativa de uma igualdade como a
$$
\ginv a \ast a = \gidof G.
$$
Um matemático que trabalha com $\sset G {\ast, {}^{-1}, e}$
justificaria com um simples
\standout
<<pela (G3L)>>.
\endstandout
Mas para os matemáticos que não tem a operação de inverso
na sua estrutura, a justificativa seria
\standout
<<pela definição do $\ginv a$>>.
\endstandout
Nesse texto vou usar ámbas as abordagens.
%%}}}

\blah.
Tendo ganhado unicidade da identidade e dos inversos,
vamos responder agora em duas perguntas.

%%{{{ Q1: When is y the inv(a)? 
\question 1.
Num grupo $G$, dado $a\in G$,
o que precisamos mostrar para provar que um certo $y\in G$ é o inverso de $a$?
%%}}}

%%{{{ wrong answer 
\note Resposta errada.
Basta mostrar que $a \ast y = e$
(ou, alternativamente, que $y \ast a = e$)
pois, \emph{graças à unicidade dos inversos},
apenas um membro do grupo pode satisfazer essa equação,
e logo necessariamente $y = \ginv a$.
%%}}}

%%{{{ Q2: When is u the identity? 
\question 2.
Num grupo $G$, o que precisamos mostrar para provar que um certo $u\in G$ é a identidade do grupo?
%%}}}

%%{{{ wrong answer 
\note Resposta errada.
Basta achar um $a\in G$ tal que $a \ast u = a$
(ou, alternativamente, tal que $u \ast a = a$),
pois, \emph{graças à unicidade da identidade},
apenas um membro do grupo pode satisfazer essa equação,
e logo necessariamente $u = e$.
%%}}}

%%{{{ Where's the mistake? 
\note Cadê o erro?.
O \emph{raciocínio} nas duas respostas é errado numa maneira parecida:
\endgraf
Na (1), pode ser que $y$ satisfaz a $a\ast y = e$ sem $y$ ser o inverso do $a$.
\emph{E isso não violaria a unicidade do inverso $\ginv a$},
pois pela definição de \emph{inverso do $a$}, ambas equações $a \ast y = e = y \ast a$
precisam ser satisfeitas, e talvez $y \ast a \neq e$.
\endgraf
Na (2), pode ser que $u$ satisfaz $a \ast u = a$ para algum membro $a \in G$ sem $u$ ser a identidade do grupo.
\emph{E isso não violaria a unicidade da identidade $e$},
pois pela definição de \emph{identidade do $G$}, o $u$ precisa satisfazer ambas as $a \ast u = e = u \ast e$ e mesmo se satisfaria ambas isso não seria sufiziente: ele tem que as satisfazer não apenas \emph{para algum} $a\in G$ que deu certo, mas \emph{para todo} $a\in G$!
Ou seja: o fato que achamos \emph{algum} $a \in G$ tal que $a \ast u = a (= u \ast a)$
não quis dizer que esse $u$ merece ser chamado \emph{a identidade do $G$} ainda,
pois talvez tem membros $c \in G$ tais que $c \ast u \neq c$ ou $u \ast c \neq c$.
%%}}}

%%{{{ warning: wrong_reasoning_nimplies_wrong_claim_group_eg 
\warning.
\label{wrong_reasoning_nimplies_wrong_claim_group_eg}%
Os raciocínios acima sendo errados não quis dizer que as afirmações também são!
Na verdade, nos dois casos podemos realmente ganhar o que queremos:
identidades e inversos \emph{mais baratos}, sem pagar todo o preço das definições.
Ambos resultados seguem como corolários diretos do~\ref{group_latin_square}
que vamos provar daqui a pouco.
%%}}}

\blah.
Por enquanto, vamos continuar pesquisando o que mais podemos concluir assim
que tivermos um grupo~$G$, e voltaremos logo nessas duas questões.

%%{{{ Q: Can we conclude something about these? 
\question.
Se $a,b$ são membros de algum grupo $\sset G {\ast,e}$, podemos concluir algo sobre os\dots
$$
\align
\ginv {e}           &\askeq \dots?\\
\ginvp{\ginv a}     &\askeq \dots?\\
\ginvp{a \ast b}    &\askeq \dots?
\endalign
$$
%%}}}
\spoiler.

%%{{{ A: yes, but we need to prove them 
\blah Resposta.
Sim:
$$
\align
\ginv  e            &\askeq e\\
\ginvp{\ginv a}     &\askeq a\\
\ginvp{a \ast b}    &\askeq \ginv b \ast \ginv a.
\endalign
$$
Mas precisamos provar cada uma delas.
%%}}}

%%{{{ different_interpretations_of_same_eq 
\note Interpretações diferentes.
\label{different_interpretations_of_same_eq}%
Considere a primeira afirmação acima:
$$
\ginv e = e.
$$
De quantas maneiras podemos ler (entender) essa equação,
e o que seria uma prova de cada uma dessas maneiras?
$$
\xxalignat3
\text{\crcase{Maneira 1:}}&&
\tunderbrace {\ginv \gid} {isso}
&\tunderbrace {=} {é}
\tunderbrace {\gid} {a identidade do grupo.}&&\\\\
\text{\case{Maneira 2:}}&&
\tunderbrace {\alertR \gid} {\alertR {isso}}
&\tunderbrace {=} {é}
\tunderbrace {\ginv {\alertB \gid}} {o inverso de $\alertB \gid$.}&&\\\\
\text{\case{Maneira 3:}}&&
\tunderbrace {\ginv \gid} {isso}
&\tunderbrace {=} {é}
\tunderbrace {\gid} {isso.}&&\text{\phantom{\case{Maneira 0:}}}
\endxxalignat
$$
Com a primeira, o que precisamos mostrar é que o objeto $\ginv \gid$
satisfaz a definição de ser a identidade do grupo, ou seja:
$$
\text{para todo $a \in G$, $\ginv \gid \ast a = a = a \ast \ginv \gid$}.
$$
Com a segunda, precisamos mostrar que a \alertR{coisa vermelha}
é o inverso da \alertB{coisa azul}.
Mas o que significa ser inverso de algo?
Precisamos mostrar que:
$$
\align
\alertR \gid \ast \alertB \gid &= \gid\\
\alertB \gid \ast \alertR \gid &= \gid.
\endalign
$$
Com a terceira, a única coisa que podemos fazer é começar calcular
até finalmente chegar nessa igualdade.
%%}}}

%%{{{ advice: read_the_same_equation_in_different_ways 
\advice.
\label{read_the_same_equation_in_different_ways}%
Cada vez que tu queres provar uma igualdade que envolve certas
noções, tente ``ler'' o que a igualdade realmente afirma em
várias maneiras diferentes.  Cada uma é uma chance para te dar
uma idéia de como prová-la!
%%}}}

%%{{{ lemma: inverse_of_identity_in_group 
\lemma inverso da identidade.
\label{inverse_of_identity_in_group}%
Em todo grupo $G$, $\ginv e = e$.
\proof.
Basta mostrar que $e$ é o inverso de $e$, ou seja,
que ele satisfaz $ee = e$, algo imediato pela definição da identidade $e$.
\qed
%%}}}

\blah.
Das três maneiras analizadas acima, escolhi a segunda.
Investigue as outras duas:

%%{{{ x 
\exercise.
Ache uma demonstração alternativa do~\ref{inverse_of_identity_in_group},
baseada na primeira maneira do~\refn{different_interpretations_of_same_eq}.

\solution
Precisamos mosrar que
$$
\text{para todo $a \in G$, $\ginv e \ast a = e = a \ast \ginv e$}.
$$
Seja $a \in G$.
Vamos mostrar que o $\ginv e$ ``deixa o $a$ em paz'' pelos dois lados.
Calculamos:
\compute
\ginv e \ast a
&= \ginv e \ast (e \ast a)  \by {$a = e\ast a$}
&= (\ginv e \ast e) \ast a  \by {G1}
&= e \ast a                 \by {def.~de $\ginv e$}
&= a                        \by {def.~de $e$}
\endcompute
Ou outro lado é similar.

\endexercise
%%}}}

%%{{{ x 
\exercise.
E uma baseada na terceira.

\solution
Calculamos:
\compute
\ginv e
&= \ginv e \ast e   \by {def.~$e$}
&= e                \by {def.~$\ginv e$}
\endcompute

\endexercise
%%}}}

%%{{{ lm: inverse_of_inverse_in_group 
\lemma inverso de inverso.
\label{inverse_of_inverse_in_group}%
Em todo grupo $G$, $\ginvp {\ginv a} = a$ para todo $a\in G$.
\sketch.
Uma maneira de ler a afirmação: {\proclaimstyle <<$a$ é o inverso de $\ginv a$>>}.
Usando o que significa ser inverso de alguém chegamos no resultado.
Alternativamente, usamos as definições dos inversos envolvidos para ganhar duas equações.
Com elas, chegamos na equação desejada.
\qes
\proof.
Vamos ver duas maneiras de demonstrar isso:
\crproofalt{Maneira 1:}
Basta demonstrar que $a$ satisfaz a propriedade de
ser inverso do $\ginv a$:
$$
a \ginv a \eqlabel L e \eqlabel R \ginv a a
$$
e ámbas são imediatas: a (L) pela (G3R), e a (R) pela (G3L).
\crproofalt{Maneira 2:}
Pelas definições de $\ginvp{\ginv a}$ e $\ginv a$ ganhamos
as equações:
\compute
\ginvp{\ginv a} \ast \ginv a &= e   \by {def.~$\ginvp{\ginv a}$}
a               \ast \ginv a &= e.  \by {def.~$\ginv a$}
\intertext{Logo}
\ginvp{\ginv a} \ast \ginv a &= a \ast \ginv a
\endcompute
e cancelando agora pela direita (GCR), chegamos na desejada
$\ginvp{\ginv a} = a$.
\qed
%%}}}

%%{{{ x: cd 
\exercise.
Desenha um diagrama cuja comutatividade é a lei que tu acabou de provar.

\solution
$$
\cdopt{sep=2cm}
A   \ar[r, "\ginvt"]\ar[dr, "\id"'] \| A \ar[d, "\ginvt"] \\
                                    \| A
\endcd
$$

\endexercise
%%}}}

%%{{{ remark: where did the inversion come from 
\remark.
É comum adivinhar erroneamente que em geral
$\ginvp{a \ast b} = \ginv a \ast \ginv b$.
O erro é feito pois, acostumados com um certo grupo \emph{bem especial} como o
$\sset {\reals_{\neq0}} {\ntimes}$ onde essa lei realmente é valida,
generalizamos para o caso geral de grupos, sem perceber algo estranho e
esquisito que acontece nessa equação.  Repensanso em nosso exemplo-guia de
grupos, o~$\sym 3$, o que significa~$a \ast b$?
<<Faça a~$b$, depois a~$a$.>>
E o que signfica $\ginvp{a \ast b}$ então?
<<Desfaça a~$\paren{a \ast b}$.>>
E se aplicar uma transformação~$b$, e depois mais uma~$a$, qual seria o jeito
para desfazer tudo isso e voltar na configuração inicial?
<<Desfaça a~$a$, e depois desfaça a $b$.>>
Ou seja,~$\ginv b \ast \ginv a$.
Isso é bem natural sim: para desfazer uma seqüência de ações, começamos
desfazenso a última, depois a penúltima, etc., até finalmente desfazer
a primeira.
Sendo o inverso então, faz sentido que a ordem é a inversa também!
E nos reais, por que não foi a inversa?
Foi sim!
É apenas que o~$\sset {\reals_{\neq0}} {\ntimes}$ é um grupo abeliano;
em outras palavras a ``ordem que acontecem os membros'' não importa.
Mas tudo isso é apenas uma \emph{intuição correta} para adivinhar essa lei.
Precisamos prová-la.  Bora!
%%}}}

%%{{{ lm: inverse_of_product_in_group 
\lemma inverso de produto.
\label{inverse_of_product_in_group}%
Em todo grupo $G$, $\ginvp{a\ast b} = \ginv b \ast \ginv a$
para todo $a,b\in G$.
\sketch.
Queremos mostrar que $\ginv b \ast \ginv a$ é o inverso do $a \ast b$.
Mas o que <<ser o inverso do $a \ast b$>> significa?
Precisamos verificar que o $\ginv b \ast \ginv a$ satisfaz a definição:
$$
\paren{\ginv b \ast \ginv a} \ast \paren{a \ast b} = e = \paren{a \ast b} \ast \paren{\ginv b \ast \ginv a}.
$$
Agora só basta fazer esse cálculo mesmo.
\qes
\proof.
Calculamos
\compute
\paren{\ginv b \ast \ginv a} \ast \paren{a \ast b}
&= \paren{\paren{\ginv b \ast \ginv a} \ast a} \ast b   \by {assoc.}
&= \paren{\ginv b \ast \paren{\ginv a \ast a}} \ast b   \by {assoc.}
&= \paren{\ginv b \ast e} \ast b                        \by {def.~$\ginv a$}
&= \paren{\ginv b} \ast b                               \by {def.~$e$}
&= e                                                    \by {def.~$\ginv b$}
\endcompute
A $\paren{a \ast b} \ast \paren{\ginv b \ast \ginv a} = e$ é similar.
\qed
%%}}}

%%{{{ x: cd 
\exercise.
Desenha um diagrama cuja comutatividade é a lei que tu acabou de provar.

\hint
A idéia é descrever cada lado da
$$
\ginvp{a\ast b} = \ginv b \ast \ginv a
$$
como um caminho.
Pense em duas listas de instruções para ser aplicadas no $\tup{a,b}$,
tais que:
seguindo uma das listas acabamos no $\ginv b \ast \ginv a$,
e seguindo a outra no $\ginvp{a\ast b}$.
Para o lado $\ginvp{a\ast b}$ existe apenas uma maneira razoável
de ``quebrá-lo'' em sub-passos.
Para o lado $\ginv b \ast \ginv a$ existem duas equivalentes.
Escolha uma, ou desenha as duas no mesmo diagrama.

\hint
Podes começar com os conjuntos seguintes:
$$
\cdopt{column sep=1cm, row sep=1cm}
            \| G\times G\ar[d]\ar[rrrr] \|           \| \| \| G\ar[dd] \\
            \| G\times G\ar[d]          \|           \| \| \|   \\
            \| G\times G\ar[rrrr]       \|           \| \| \| G
\endcd
$$
A coluna esquerda corresponde num caminho do $\tup{a,b}$
para o $\tup{\ginv b, \ginv a}$.

\hint
Substitui a coluna esquerda por dois caminhos formando o rombo
na esquerda (ele comuta):
$$
\cdopt{column sep=6mm, row sep=2cm}
                        \| |[alias=N]| G\times G \|                      \| \| \| |[alias=NE]| G \\
|[alias=W]| G\times G   \|                       \||[alias=E]| G\times G \| \| \|                \\
                        \| |[alias=S]| G\times G \|                      \| \| \| |[alias=SE]| G
\ar[from=N,to=W]
\ar[from=N,to=E]
\ar[from=W,to=S]
\ar[from=E,to=S]
\ar[from=N,to=NE]
\ar[from=NE,to=SE]
\ar[from=S,to=SE]
\endcd
$$
Agora só basta botar nomes nas setas.

\solution
Uma tal diagrama é o seguinte:
$$
\cdopt{column sep=6mm, row sep=2cm}
                        \| |[alias=N]| G\times G \|                      \| \| \| |[alias=NE]| G \\
|[alias=W]| G\times G   \|                       \||[alias=E]| G\times G \| \| \|                \\
                        \| |[alias=S]| G\times G \|                      \| \| \| |[alias=SE]| G
\ar[from=N,to=W,"\swap"']
\ar[from=N,to=E,"\ginvt\times\ginvt"]
\ar[from=W,to=S,"\ginvt\times\ginvt"']
\ar[from=E,to=S,"\swap"]
\ar[from=N,to=NE,"\ast"]
\ar[from=NE,to=SE,"\ginvt"]
\ar[from=S,to=SE,"\ast"]
\endcd
$$
onde $\swap(x,y) = \tup{y,x}$.

\endexercise
%%}}}

%%{{{ lm: group_latin_square 
\lemma resolução de equações: Latin square.
\label{group_latin_square}%
Seja $G$ grupo.
Para quaisquer $a,b,x,y\in G$,
cada uma das equações abaixo tem resolução única para $x$ e $y$:
$$
\xalignat2
a\ast x &= b
&
y\ast a &= b
\endxalignat
$$
\sketch.
Aplicando o inverso de $a$ em cada equação pelo lado certo,
achamos que as soluções necessariamente são
$x = \ginv a \ast b$ e $y = b \ast \ginv a$.
\qes
\proof.
Aplicando $(a^{-1}\ast)$ nos dois lados da primeira
e $(\ast a^{-1})$ nos dois lados da segunda temos:
$$
\xalignat2
  a\ast x = b &\impliesbecause{$\ginv a\ast$} \ginv a\ast \paren{a\ast x} = a^{-1} \ast b 
& y\ast a = b &\impliesbecause{$\ast\ginv a$} \paren{x\ast a}\ast \ginv a = b \ast \ginv a
\\
&\implies\paren{\ginv a\ast a}\ast x = \ginv a \ast b
&&\implies y\ast \paren{a\ast \ginv a} = b \ast \ginv a
\\
&\implies e \ast x = \ginv a \ast b
&&\implies y\ast e = b \ast \ginv a
\\
&\implies x = \ginv a \ast b
&&\implies y = b \ast \ginv a
\endxalignat
$$
\qed
%%}}}

%%{{{ remark: ab_eq_c_each_determined_by_other_two 
\remark.
\label{ab_eq_c_each_determined_by_other_two}%
Isso quis dizer que dada uma equação $a \ast b = c$,
cada um dos $a,b,c$ é determinado pelos outros dois!
Assim, podemos \emph{definir} por exemplo o objeto $x$
como \emph{a única solução da} $a\ast x = b$, etc.
%%}}}

%%{{{ cor: cheaper_ginv 
\corollary inversos mais baratos.
\label{cheaper_ginv}%
Seja $G$ grupo e $a,y \in G$
tais que $a\ast y = e$ ou $y \ast a = e$.
Logo $y = \ginv a$.
%%}}}

%%{{{ cor: cheaper_gid 
\corollary identidade mais barata.
\label{cheaper_gid}%
Seja $G$ grupo $u\in G$.
Se para algum $a\in G$, $au = a$ ou $ua = a$, então $u$ é a identidade do grupo:
$u = e$.
%%}}}

%%{{{ x: cheaper_ginv_and_gid_by_cancellation 
\exercise.
\label{cheaper_ginv_and_gid_by_cancellation}%
Ganhamos esses resultados (\ref{cheaper_ginv} e~\refn{cheaper_gid})
como corolários do~\ref{group_latin_square}.
Mostre como ganhá-los como corolários das leis de cancelamento.

\endexercise
%%}}}

%%{{{ x: abelian_iff_inv_of_prod_sameorder 
\exercise.
\label{abelian_iff_inv_of_prod_sameorder}%
Seja $G$ grupo.
Prove a equivalência:
$$
\text{$G$ abeliano} \iff \text{para todo $a,b\in G$, $\ginvp{ab} = \ginv a \ginv b$}.
$$

\solution
\lrdir.
Calculamos:
\compute
\ginvp{ab}
&= \ginv b \ginv a      \by {pelo~\ref{inverse_of_product_in_group}}
&= \ginv a \ginv b.     \by {$G$ abeliano}
\endcompute
\rldir.
Calculamos:
\compute
ab
&= \ginvp{\ginvp{ab}}               \by {pelo~\ref{inverse_of_inverse_in_group}}
&= \ginvp{\ginv b \ginv a}          \by {pelo~\ref{inverse_of_product_in_group}}
&= \ginvp{\ginv b} \ginvp{\ginv a}  \by {pela hipótese}
&= b a.                             \by {pelo~\ref{inverse_of_inverse_in_group}~($\times2$)}
\endcompute

\endexercise
%%}}}

%%{{{ criterion: cancellation_based_group_def 
\criterion Definição de grupo com cancelamento.
\label{cancellation_based_group_def}%
Seja $\ssetfont G = \sset G \ast$ um conjunto \emph{finito} estruturado
que satisfaz:
$$
\align
\pforall {a,b\in G}    &\bracket{a\ast b \in G}                    \tag{G0} \\
\pforall {a,b,c\in G}  &\bracket{a\ast(b\ast c) = (a\ast b)\ast c} \tag{G1} \\
\pforall {a,x,y\in G}  &\bracket{a\ast x = a\ast y \implies x=y}   \tag{GCL}\\
\pforall {a,x,y\in G}  &\bracket{x\ast a = y\ast a \implies x=y}   \tag{GCR}
\endalign
$$
Então $\ssetfont G$ é um grupo.
\proof.
\ref{cancellation_based_group_def_proof}
\qed
%%}}}

%%{{{ x: cancellation_based_group_def_only_valid_for_finite_G 
\exercise.
Mostre que não podemos apagar o ``finito'' das nossas hipoteses.

\hint
Procure contraexemplo!

\solution
Veja~\ref{how_come_the_cancellation_laws_hold_in_nongroup_without_inverses}.

\endexercise
%%}}}

%%{{{ criterion: onesided_group_def 
\criterion Definição unilateral ``one-sided'' de grupo.
\label{onesided_group_def}%
Seja $\ssetfont G = \sset G {\ast,e}$ um conjunto estruturado que satisfaz:
$$
\align
\pforall {a,b\in G}                 &\bracket{a \ast b \in G}                    \tag{G0}  \\
\pforall {a,b,c\in G}               &\bracket{a \ast (b \ast c) = (a \ast b) \ast c} \tag{G1}  \\
\pforall {a \in G}                  &\bracket{a \ast e = a}                      \tag{G2R} \\
\pforall {a\in G} \pexists {y\in G} &\bracket{a \ast y = e}                     \tag{G3R} \\
\intertext{%
Então $\ssetfont G$ é um grupo.
Similarmente se adicionar as
}
\pforall {a \in G}                  &\bracket{e \ast a = a}                      \tag{G2L} \\
\pforall {a\in G} \pexists {y\in G} &\bracket{y \ast a = e}                      \tag{G3L}
\endalign
$$
\proof.
\ref{onesided_group_def_proof}.
\qed
%%}}}

%%{{{ x: onesided_group_def_catch 
\exercise.
\label{onesided_group_def_catch}%
Verifique que mesmo se conseguir provar as
$$
\align
\pforall {a \in G}                    &\bracket{e \ast a = a}   \tag{G2L} \\
\pforall {a \in G} \pexists {y \in G} &\bracket{y \ast a = e}   \tag{G3L}
\endalign
$$
isso não nos permite deduzir trivialmente as (G2) e (G3)!
Explique o porquê.

\endexercise
%%}}}

%%{{{ x: splitsided_group_notdef 
\exercise.
\label{splitsided_group_notdef}%
Podemos substituir a (G3R) do~\ref{onesided_group_def} por
$$
\align
\pforall {a \in G} \pexists {y \in G} &\bracket{y \ast a = e}   \tag{G3L}
\endalign
$$
e ainda concluir que $\ssetfont G$ é grupo?
Ou seja, se a operação possui R-identidade,
e se cada membro tem L-inverso, o $\ssetfont G$
é necessariamente um grupo?
(Obviamente a resposta na pergunta simétrica deve ser a mesma.)

\hint
Não!

\hint
Procure um contraexemplo.
(Claramente, a operação não pode ser comutativa.)

\hint
Dá pra construir contraxemplo com apenas $2$ membros.

\hint
Considere como operação binária a $\outl$.

\solution
Seja $A = \set{\idr,a}$ um conjunto com dois membros.
Definimos a operação $\ast$ pela:
$$
x \ast y = x.
$$
Confirmamos que $\sset A \ast$ satisfaz todas as
(G0),(G1),(G2R),(G3L), mas mesmo assim não é um
grupo: não tem identidade, pois a $\idr$ não serve
como L-identidade:
$$
\idr \ast a = \idr \neq a.
$$

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Cayley tables 
\section Tabelas Cayley.
\label{Cayley_tables}%

%%{{{ Q: In how many ways can we define an operation to create a finite group? 
\question.
De quantas maneiras podemos definir uma operação binária $\ast$
num conjunto finito $G$, tal que $\sset G \ast$ é um grupo?
%%}}}
\spoiler.

%%{{{ What determines an operation 
\note O que determina uma operação.
O que significa \emph{definir uma operação} (binária)?
Seguindo nossa definição de igualdade (extensional) entre funções,
precisamos deixar claro para qualquer $\tup{x,y}\in G\times G$,
seu único valor $x \ast y \in G$.
Vamos brincar com os casos mais simples.
Se $\card G = 0$, não tem como virar um grupo,
pois todo grupo tem pelo menos um membro: sua identidade.
Se $\card G = 1$, só tem uma operação possível, pois não existe
nenhuma opção para o valor $e \ast e$: necessariamente $e \ast e = e$.
E essa opção realmente vira-se o $\sset G \ast$ um grupo (trivial).
%%}}}

%%{{{ 234_groups 
\note Os casos 2,3,4.
Vamos dizer que temos um conjunto $G$ com $\card G = 4$.
Não sabemos nada sobre seus membros, podem ser números, letras, pessoas,
funções, conjuntos, sapos, sei-lá:
$$
G = \set{ \bullet, \bullet, \bullet, \bullet }.
$$
Então faz sentido começar nossa investigação dando uns nomes para
esses membros, por exemplo $a,b,c,d$, onde não vamos supor nada mais
sobre eles exceto que são distintos dois-a-dois.
$$
\text{<<Sejam $G\eqass\set{a,b,c,d}$.>>}
$$
Sera que podemos fazer algo melhor?
Querendo tornar o $G$ em grupo, sabemos que ele vai ter exatamente uma
identidade, então melhor denotá-la com $e$,
e escolher nomes para os outros três membros do $G$:
$$
G = \set {e, a, b, c}.
$$
Similarmente, caso que $\card G = 2$ ou $3$, teremos
$G = \set {e, a}$
ou
$G = \set {e, a, b}$
respectivamente.
%%}}}

%%{{{ Cayley tables 
\note Tabelas Cayley.
\tdefined{tabela!Cayley}%
{\Cayley[tabela]}%
Temos então que ver o que podemos botar nos $\faded?$ para completar
as \dterm{tabelas Cayley} abaixo:
$$
\xalignat3
\matrix
\ast& e & a \\
e   & \faded? & \faded? \\
a   & \faded? & \faded?
\endmatrix
&&
\matrix
\ast& e & a & b \\
e   & \faded? & \faded? & \faded? \\
a   & \faded? & \faded? & \faded? \\
b   & \faded? & \faded? & \faded?
\endmatrix
&&
\matrix
\ast& e & a & b & c \\
e   & \faded? & \faded? & \faded? & \faded? \\
a   & \faded? & \faded? & \faded? & \faded? \\
b   & \faded? & \faded? & \faded? & \faded? \\
c   & \faded? & \faded? & \faded? & \faded?
\endmatrix
&
\endxalignat
$$
Mas, não todos os $\faded?$ realmente representam uma escolha,
pois certos deles são determinados; e cada vez que fazemos uma escolha
para um deles, possivelmente nossas opções próximas deminuiam.
Para começar, como $e\ast x = x = x \ast e$ para qualquer $x$ do grupo,
a primeira linha e a primeira coluna da tabela já são determinadas:%
\footnote{De fato, foi por isso que Cayley realmente nem escreveu a coluna
e a linha ``exterior'', tomando a convenção que o elemento que aparece
primeiro é a sua identidade.
Para um grupo de três elementos então, ele começaria assim:
$$
\matrix
a & b       & c       \\
b & \faded? & \faded? \\
c & \faded? & \faded?
\endmatrix
\qquad
\text{que, seguindo nossa convenção com \sq{$e$}, escreveríamos}
\qquad
\matrix
e & a       & b       \\
a & \faded? & \faded? \\
b & \faded? & \faded?
\endmatrix
$$
}
$$
\xalignat3
\matrix
\ast& e & a \\
e   & e & a \\
a   & a & \faded?
\endmatrix
&&
\matrix
\ast& e & a & b \\
e   & e & a & b \\
a   & a & \faded? & \faded? \\
b   & b & \faded? & \faded?
\endmatrix
&&
\matrix
\ast& e & a & b & c \\
e   & e & a & b & c \\
a   & a & \faded? & \faded? & \faded? \\
b   & b & \faded? & \faded? & \faded? \\
c   & c & \faded? & \faded? & \faded?
\endmatrix
&
\intertext{Exatamente por causa dessa observação, em geral omitimos a
primeira coluna e a primeira linha dessas tabelas, escrevendo as três
tabelas acima nesse jeito:}
\matrix
e & a \\
a & \faded?
\endmatrix
&&
\matrix
e & a & b \\
a & \faded? & \faded? \\
b & \faded? & \faded?
\endmatrix
&&
\matrix
e & a & b & c \\
a & \faded? & \faded? & \faded? \\
b & \faded? & \faded? & \faded? \\
c & \faded? & \faded? & \faded?
\endmatrix
&
\endxalignat
$$
%%}}}

%%{{{ Q: how can we replace the blanks? 
\question.
O que tu podes botar nos\/ $\faded?$ para chegar num grupo?
O que muda se tu queres construir um grupo abeliano?
%%}}}
\spoiler.

%%{{{ 2 members 
\note 2 membros.
Vamos começar no caso mais simples, onde temos apenas um $\faded?$ para preencher.
Em teoria temos duas opções: $e,a$.  Mas precisamos verificar se o conjunto
realmente torna-se um grupo ou não.  Escolha $a$:
$$
\matrix
e & a \\
a & \alert{a}
\endmatrix
$$
Qual seria o inverso do $a$?
Nenhum!
Assim o~(G3) será violado, ou seja, não podemos escolher o $a$.
Se escolher nossa única outra opção ($e$) temos:
$$
\matrix
e & a \\
a & \alert{e}
\endmatrix
$$
Que realmente é um grupo.
%%}}}

%%{{{ x: Verify! 
\exercise.
Verifique!

\endexercise

%%}}}

%%{{{ x: find_all_groups_of_order_3 
\exercise.
\label{find_all_groups_of_order_3}%
Ache todas as operações possíveis que tornam um conjunto com $3$ membros um grupo.

\hint
Só tem uma maneira.  Qual?  Por quê?

\solution
Só tem uma maneira:
$$
\matrix
e & a & b\\
a & b & e\\
b & e & a
\endmatrix
$$
Realmente não temos nenhuma opção em nenhum dos $\faded?$.
O~\ref{find_the_rules_of_grupoku} investiga o porquê.

\endexercise
%%}}}

%%{{{ Playing ``grupoku'' 
\note Jogando ``Grupoku''.
\tdefined{Grupoku}%
Investigar todas as possíveis escolhas para os~$\faded?$ parece como um jogo
de Sudoku, só que nossa restricção não é com a soma dos números de cada linha e
cada coluna como no Sudoku---nem poderia ser isso: nossos membros possivelmente
nem são números---mas as leis~(G0)--(G3) que tem que ser satisfeitas.
E caso que queremos criar um grupo abeliano, a~(GA) também.
%%}}}

%%{{{ x: find_the_rules_of_grupoku 
\exercise.
\label{find_the_rules_of_grupoku}%
Que restricções pode afirmar que temos nesse jogo de ``Grupoku'',
graças todos os resultados que temos provado até agora sobre grupos?
E se queremos um grupo abeliano, muda o quê?

\endexercise
%%}}}

%%{{{ x: find_all_groups_of_order_4 
\exercise.
\label{find_all_groups_of_order_4}%
Ache todas as operações possíveis que tornam um conjunto com $4$
membros um grupo.

\hint
\emph{Essencialmente} são apenas $2$.
Se achar mais, verifique que renomeando seus membros umas viram iguais,
e só tem dois que realmente não tem como identificá-las,
mesmo renomeanos seus membros.
Tudo isso vai fazer bem mais sentido daqui umas secções onde vamos
estudar o conceito de isomorfia~(\refn{Group_morphisms}).

\solution
\emph{Essencialmente} são apenas $2$:
$$
\xalignat2
\matrix
e & a & b & c \\
a & b & c & e \\
b & c & e & a \\
c & e & a & b
\endmatrix
&&
\matrix
e & a & b & c \\
a & e & c & b \\
b & c & e & a \\
c & b & a & e
\endmatrix
&
\endxalignat
$$
O primeiro é conhecido como o grupo cíclico de ordem $4$;
o segundo como {\Klein[four-group]}Klein four-group.
Se tu achaste mais, verifique que renomeando seus membros
umas viram iguais, e só tem dois que realmente não tem como
identificá-las, mesmo renomeanos seus membros.
Tudo isso vai fazer bem mais sentido daqui umas secções onde vamos
estudar o conceito de isomorfia~(\refn{Group_morphisms}).

\endexercise
%%}}}

%%{{{ x: find_all_groups_of_order_0_and_1 
\exercise.
\label{find_all_groups_of_order_0_and_1}%
Tem grupos de ordem 1?  De 0?

\solution
De ordem $1$ sim.  Cada um tem a mesma forma: seu único elemento é sua identidade.
De ordem $0$, não: a lei (G2) \emph{manda a existência} de um certo membro do grupo (a sua identidade).

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Powers and orders 
\section Potências e ordens.

%%{{{ df: powers_in_group 
\definition.
\label{powers_in_group}%
\sdefined {{\sholed a}^{\sholed m}} {$a \ast \dotsb \ast a$ ($m$ vezes)}
Seja $a$ elemento dum grupo $\sset G {\ast,e}$.
Definimos suas potências $a^{\ast n}$ onde $n\in\nats$ recursivamente:
$$
\align
a^{\ast 0}     &\defeq e\\
a^{\ast {n+1}} &\defeq a \ast a^{\ast n}
\endalign
$$
Quando a operação $\ast$ é entendida pelo contexto
escrevemos apenas $a^n$ em vez de $a^{\ast n}$.
%%}}}

%%{{{ x: powers_in_group_altdef 
\exercise.
\label{powers_in_group_altdef}%
Demostre que a definição alternativa de exponenciação ao natural
$$
\align
a^{\ast 0}     &= e\\
a^{\ast {n+1}} &= a^{\ast n} \ast a
\endalign
$$
é equivalente.

\hint%%{{{
Como o próprio ``operador'' de exponenciar fica escondido na notação
comum $a^b$, melhor escrever temporariamente as duas definições como:
$$
\xalignat2
a \uparrow_1 0 &= e &
a \uparrow_2 0 &= e \\
a \uparrow_1 (n+1) &= a \ast (a \uparrow_1 n) &
a \uparrow_2 (n+1) &= (a \uparrow_2 n) \ast a.
\endxalignat
$$
Agora tem uma notação melhor para provar o que queremos: ${\uparrow_1} = {\uparrow_2}$.
O que significa que duas operações (funções) são iguais?
%%}}}

\hint%%{{{
Precisamos mostrar que:
$$
\text{para todo $a\in G$ e todo $n\in\nats$,}\quad
a \uparrow_1 n = a \uparrow_2 n
$$
ou, simbolicamente:
$$
\align
\pforall {a \in G}
&\lforall {n\in\nats} {a \uparrow_1 n = a \uparrow_2 n}.
\intertext{\emph{Seja $a\in G$.}  Agora queremos provar:}
&\lforall {n\in\nats} {a \uparrow_1 n = a \uparrow_2 n}.
\endalign
$$
Como provar isso?
%%}}}

\hint%%{{{
As definições envolvidas são recursivas.
%%}}}

\hint%%{{{
Ou seja: indução.
%%}}}

\hint%%{{{
\proofpart{Base:} provar que $a \uparrow_1 0 = a \uparrow_2 0$.
%%}}}

\hint%%{{{
Seja $k\in\nats$ tal que $a \uparrow_1 k = a \uparrow_2 k$ (hipótese indutiva).
Queremos mostrar que
$$
a \uparrow_1 (k+1) = a \uparrow_2 (k+1).
$$
%%}}}

\hint%%{{{
Seguindo as dicas anteriores, provavelmente tu chegou aqui:
\compute
a \uparrow_1 (k+1)
&= a \ast (a \uparrow_1 k)   \by {def.~$\uparrow_1$}
&= a \ast (a \uparrow_2 k)   \by {HI}
\intertext{\dots e agora?
\emph{Se} $\ast$ fosse comutativa (ou seja, se o grupo fosse abeliano),
a gente \emph{poderia} continuar assim:}
&= (a \uparrow_2 k) \ast a   \by {comutatividade~(GA)}
&= a \uparrow_2 (k+1).       \by {def.~$\uparrow_2$}
\intertext{\emph{Só que não!}
Sobre o $G$ sabemos apenas que é um grupo, então não podemos contar na
comutatividade da sua operação $\ast$.
(Inclusive, se a $\ast$ fosse comutativa o resultado seria
trivial e nem precisaria prova por indução.)
Voltando no passo que tivemos colado}
a \uparrow_1 (k+1)
&= a \ast (a \uparrow_1 k)   \by {def.~$\uparrow_1$}
&= a \ast (a \uparrow_2 k)   \by {HI}
\endcompute
percebemos que precisamos ``abrir mais'' a expressão $(a \uparrow_2 k)$,
aplicando a definição de $\uparrow_2$, mas não podemos, pois não sabemos se $k=0$ ou não.
Neste momento então percebemos que saber a veracidade dessa equação apenas para o valor $n=k$ não é suficiente.
Tu vai precisar o $n=k-1$ também.
\endgraf
Ou seja, tu vai precisar \emph{duas} bases ($n=0,1$),
e supor que tem um $k \geq 2$ tal que ambos os $k-1$ e $k-2$ satisfazem a
$a \uparrow_1 n = a \uparrow_2 n$.
Ou seja, tu ganharás as \emph{duas} hipoteses indutivas:
$$
\align
a \uparrow_1 (k-1) &= a \uparrow_2 (k-1) \tag{HI1}\\
a \uparrow_1 (k-2) &= a \uparrow_2 (k-2) \tag{HI2}
\endalign
$$
e só bastará provar que $a \uparrow_1 k = a \uparrow_2 k$.
%%}}}

\solution%%{{{
Seja $a \in G$.
Vamos provar que para todo $n\in\nats$, $a \uparrow_1 n = a \uparrow_2 n$
por indução no $n$.
\endgraf\noindent
\proofpart{Bases $n=0,1$:}
Temos
$$
\computed
a \uparrow_1 0
&= e               \by {def.~$\uparrow_1$}
&= a \uparrow_2 0  \by {def.~$\uparrow_2$}
\endcomputed
\qqqquad
\computed
a \uparrow_1 1
&= a \ast (a \uparrow_1 0)  \by {def.~$\uparrow_1$}
&= a \ast e                 \by {def.~$\uparrow_1$}
&= a                        \by {def.~$e$}
&= e \ast a                 \by {def.~$e$}
&= (a \uparrow_2 0) \ast a  \by {def.~$\uparrow_2$}
&= a \uparrow_2 1           \by {def.~$\uparrow_2$}
\endcomputed
$$
\noindent
\proofpart{Passo indutivo:}
Seja $k\in\nats$, tal que $k\geq 2$ e:
$$
\align
a \uparrow_1 (k-1) &= a \uparrow_2 (k-1) \tag{HI1}\\
a \uparrow_1 (k-2) &= a \uparrow_2 (k-2).\tag{HI2}
\endalign
$$
Precisamos provar que $a \uparrow_1 k = a \uparrow_2 k$.
Calculamos:
\compute
a \uparrow_1 k
&= a \ast \paren{a \uparrow_1 (k-1)}                \by {def.~$\uparrow_1$}
&= a \ast \paren{a \uparrow_2 (k-1)}                \by {HI1}
&= a \ast \paren{\paren{a \uparrow_2 (k-2)} \ast a} \by {def.~$\uparrow_2$}
&= a \ast \paren{\paren{a \uparrow_1 (k-2)} \ast a} \by {HI2}
&= \paren{a \ast \paren{a \uparrow_1 (k-2)}} \ast a \by {associatividade~(G1)}
&= \paren{a \uparrow_1 (k-1)} \ast a                \by {def.~$\uparrow_1$}
&= \paren{a \uparrow_2 (k-1)} \ast a                \by {HI1}
&= a \uparrow_2 k.                                  \by {def.~$\uparrow_2$}
\endcompute
Pelo principio da indução segue que para todo $n\in\nats$,
$a \uparrow_1 n = a \uparrow_2 n$.
Como $a$ foi arbitrário membro de $G$, isso termina nossa prova que
${\uparrow_1} = {\uparrow_2}$.
%%}}}

\endexercise
%%}}}

\blah.
Acabaste de provar um teorema bem mais geral do que parece
no enunciado do~\ref{powers_in_group_altdef}!
É o seguinte:

%%{{{ thm: associative_with_identity_exp_defs_equiv 
\theorem.
\label{associative_with_identity_exp_defs_equiv}%
Seja $A$ um conjunto estruturado e~$\ast$~uma operação
binária e associativa no~$A$, com identidade $u$.
As duas definições de potências
$$
\xalignat2
a^{\ast0}     &= u &
a^{\ast0}     &= u \\
a^{\ast{n+1}} &= a \ast a^n &
a^{\ast{n+1}} &= a^n \ast a
\endxalignat
$$
são equivalentes, ou seja, as duas operações
definidas são iguais.
\proof Provado.
No~\ref{powers_in_group_altdef}, pois as únicas coisas que
precisamos na sua prova foram exatamente as hipoteses
desse teorema.
\qed
%%}}}

%%{{{ thm: properties_of_exp_in_general 
\theorem.
\label{properties_of_exp_in_general}%
A operação de exponenciação definida
no~\ref{associative_with_identity_exp_defs_equiv}
satisfaz as leis:
\beginol
\item{\rm (1)} $\pforall {n,m\in\nats} \lforall {a \in A} {a^{m+n}        = a^m \ast a^n}$;
\item{\rm (2)} $\pforall {n,m\in\nats} \lforall {a \in A} {a^{m\ntimes n} = (a^m)^n}$;
\item{\rm (3)} $\lforall {n\in\nats}   {\gid^n = \gid}$.
\endol
\proof Já demonstrado.
Como observamos no~\ref{properties_of_function_iterations} também,
quando provamos por indução as leis nos exercícios~\refn{law_of_natexp_1},
\refn{law_of_natexp_2}, e~\refn{law_of_natexp_3},
usamos apenas a \emph{associatividade} e a \emph{identidade} da
multiplicação e \emph{não usamos sua definição}.
Logo a mesma demonstração serve aqui, trocando a multiplicação por nossa $\ast$.
\qed
%%}}}

%%{{{ x: sq_of_prod_not_prod_of_sq 
\exercise.
\label{sq_of_prod_not_prod_of_sq}%
Mostre que, \emph{em geral}, $(a \ast b)^2 \neq a^2 \ast b^2$.

\endexercise
%%}}}

%%{{{ beware: for which values of w have we defined a^w? 
\beware.
Neste momento então, para qualquer grupo $G$ e qualquer $a\in G$,
o símbolo $a^w$ é definido \emph{apenas} para $w \asseq -1, 0, 1, 2, \dots$
e nada mais!
Vamos agora estender para os valores $w \asseq -2, -3, -4, \dots$
num jeito razoável.
%%}}}

%%{{{ Q: what do you think a^{-2} should mean? 
\question.
O que você acha que deveria ser denotado por $a^{-2}$?
%%}}}
\spoiler.

%%{{{ A 
\blah Resposta.
Bem, tem duas interpretações, ambas razoáveis:
$$
a^{-2} \askeq
\paths{
\paren{\ginv a}^2 & (o quadrado do inverso do $a$) \cr
\pathween {\dots\orword\dots}
\ginvp{a^2}       & (o inverso do quadrado do $a$)
}
$$
Prove que as duas interpretações são equivalentes, ou seja:
%%}}}

%%{{{ x: inv_of_square_eq_square_of_inv 
\exercise.
\label{inv_of_square_eq_square_of_inv}%
Seja $G$ grupo.  Para todo $a\in G$,
$\paren{a^{-1}}^2 = \paren{a^2}^{-1}$.
Ou seja, o diagrama
$$
\cdopt{sep=2cm}
G \ar[r, "\ginv\bhole"] \ar[d, "\bhole^2"] \| G \ar[d, "\bhole^2"]\\
G \ar[r, "\ginv\bhole"]                    \| G
\endcd
$$
comuta.

\hint
\ref{different_interpretations_of_same_eq}
e~\ref{read_the_same_equation_in_different_ways}.

\hint
Tem como provar isso numa linha só!
Se não enxergar como, seja $a\in G$.
O que tu precisas mostrar, é que $\paren{\ginv a}^2$ é o inverso do $a^2$.
O que significa <<ser o inverso do $a^2$>>?

\hint
$
\paren{\ginv a}^2 \ast {a^2}
\askeq e
\askeq {a^2} \ast \paren{\ginv a}^2
$.

\solution
Graças ao~\ref{cheaper_ginv}, basta provar que para todo $a\in G$,
$\paren{\ginv a}^2 \ast a^2 = e$.
Seja $a\in G$ então.  Calculamos:
\compute
\paren{a^{-1}}^2 \ast {a^2}
&= (\ginv a \ast \ginv a) \ast {a^2}             \by {def.~$\paren{\ginv a}^2$}
&= (\ginv a \ast \ginv a) \ast \paren{a\ast a}   \by {def.~$a^2$}
&= \paren{(\ginv a \ast \ginv a) \ast a}\ast a   \by {ass.}
&= \paren{\ginv a \ast (\ginv a \ast a)}\ast a   \by {ass.}
&= \paren{\ginv a \ast e}\ast a                  \by {def.~$\ginv a$}
&= \ginv a \ast a                                \by {def.~$e$}
&= e                                             \by {def.~$\ginv a$}
\endcompute
Logo $\paren{\ginv a}^2$ é o inverso de $a^2$.
\endgraf
Mas, um segundo!
Nessa maneira fizemos bem mais trabalho do que precisamos.
Observe que praticamente repetimos aqui a prova
do~\ref{inverse_of_product_in_group}!
Seria melhor simplesmente usá-lo,
chegando assim nessa prova bem mais simples:
\compute
\ginvp{a^2}
&= \ginvp{aa}           \by {def.~$a^2$}
&= \ginv a \ginv a      \by {inv.~prod.~(\ref{inverse_of_product_in_group})}
&= \paren{\ginv a}^2.   \by {def.~$\paren{\ginv a}^2$}
\endcompute

\endexercise
%%}}}

%%{{{ x: inv_of_npow_eq_npow_of_inv 
\exercise.
\label{inv_of_npow_eq_npow_of_inv}%
Generalize o~\ref{inv_of_square_eq_square_of_inv} para $n\in\nats$:
\emph{para todo grupo $G$ e todo $n\in\nats$, se $a\in G$ então
$\paren{\ginv a}^n = \ginvp{a^n}$}.

\hint
As potências de elementos de grupo foram definidas
\emph{recursivamente}.

\hint
Indução.

\endexercise
%%}}}

%%{{{ df: negpowers_in_group 
\definition.
\label{negpowers_in_group}%
Seja $a$ elemento dum grupo $\sset G {\ast,e}$.
Definimos para todo $n\in\nats_{>0}$.
$$
a^{-n} \defeq \paren{\ginv a}^n
$$
%%}}}

%%{{{ x: negpowers_in_group_altdef 
\exercise.
Demostre que a definição alternativa de exponenciação ao inteiro negativo
$$
a^{-n} \defeq \ginvp {a^n}
$$
é equivalente; ou seja prove que para todo $n\in\nats$,
$$
\paren{\ginv a}^n = \ginvp {a^n}.
$$

\endexercise
%%}}}

%%{{{ property: properties_of_powers_in_groups 
\property Potências.
\label{properties_of_powers_in_groups}%
Sejam $G$ grupo, $a \in G$, e $m,n\in\ints$.
Temos:
\item{\rm (1)} $a^m \ast a^n = a^{m+n}$;
\item{\rm (2)} $(a^m)^n = a^{m\ntimes n}$;
\item{\rm (3)} $\gid^n = \gid$;
\item{\rm (4)} $\ginvp {a^n} = \paren{\ginv a}^n$.
\sketch.
Demonstramos a (4) primeiro para $m,n\in\nats$ por
indução---as (1)--(3) já provamos~(\ref{properties_of_exp_in_general}).
Depois consideramos os casos de inteiros negativos para as quatro leis.
\qes
%%}}}

%%{{{ x: square_of_product_abelian_criterion
\exercise.
\label{square_of_product_abelian_criterion}%
Seja $G$ grupo tal que para todo $a,b \in G$, $(ab)^2 = a^2 b^2$.
Logo, $G$ é abeliano.

\hint
Sejam $x,y\in G$.
Calcule o $(xy)^2$ em dois jeitos.

\solution
Sejam $x,y\in G$.
Pela hipótese temos:
$$
\align
(xy)^2 &= x^2y^2 = xxyy;
\intertext{e pela definição de $(xy)^2$ temos}
(xy)^2 &= xyxy.
\endalign
$$
Ou seja
$$
\align
xxyy &= xyxy
\intertext{e cancelando os $x$ pela esquerda
e os $y$ pela direita, chegamos no desejado:}
xy &= yx.
\endalign
$$

\endexercise
%%}}}

%%{{{ df: order_of_member_in_group 
\definition Ordem de membro em grupo.
\label{order_of_member_in_group}%
\tdefined{ordem!de membro em grupo}%
\sdefined {\gord {\sholed a}} {a ordem do elemento $a$ num grupo}%
Seja $\sset G {\ast,e}$ grupo e $a\in G$.
Chamamos \dterm{ordem} de $a$ o menor positivo $n\in\nats$ tal que
$a^n = e$, se tal $n$ existe; caso contrário, dizemos que o $a$ tem ordem infinita.
Usamos a mesma notação como no caso de ordem de grupos:
$\gord a$, $\tord a$, ou $\bord a$, com os mesmos cuidados.
Logo:
$$
\gord a =
\knuthcases{
\min \setst {n\in\nats_{>0}} {a^n = e}, & se $\setst {n\in\nats_{>0}} {a^n = e} \neq \emptyset$\cr
\infty,                                 & caso contrário.
}
$$
%%}}}

%%{{{ eg: orders_of_members_of_S3 
\example.
\label{orders_of_members_of_S3}%
No $\sym 3$, temos
$$
\xalignat3
\gord {\id} &= 1 & \gord {\phi}         &= 2  &  \gord {\psi}   &= 3\\
            &    & \gord {\phi\com\psi} &= 2  &  \gord {\psi^2} &= 3.\\
            &    & \gord {\psi\com\phi} &= 2  &  
\endxalignat
$$
\endexample
%%}}}

%%{{{ x: verify the numbers of orders_of_members_of_S3 
\exercise.
Verifique os números do~\ref{orders_of_members_of_S3}.

\endexercise
%%}}}

%%{{{ x: nonzero_power_is_gid_implies_finite_order 
\exercise.
\label{nonzero_power_is_gid_implies_finite_order}%
Seja $G$ grupo e $a\in G$.
Se existe $m\in\ints_{\neq 0}$ tal que $a^m = e$, então $\gord a < \infty$.

\hint
Precisamos mostrar que existe $n\in\nats_{>0}$ com $a^n = e$.

\hint
Se $m>0$, tome $n\leteq m$.  Se não?

\solution
Precisamos mostrar que existe $n\in\nats_{>0}$ com $a^n = e$.
Se $m>0$, o conjunto $N \leteq \setst {n\in\nats_{>0}} {a^n = e}$ não é vazio,
então pelo princípio da boa ordem~\ii{princípio!da boa ordem}(PBO)
possui elemento mínimo e logo
$\gord a = \min N < \infty$.
Se $m<0$, observe que $-m > 0$, e calcule:
$$
a^{-m} = \ginvp{a^m} = \ginv e = e,
$$
e novamente
$N\neq\emptyset$ e $\gord a < \infty$.

\endexercise
%%}}}

%%{{{ lm: a_has_exactly_gord_a_powers 
\lemma.
\label{a_has_exactly_gord_a_powers}%
Sejam $G$ grupo e $a\in G$, e suponha $\gord a = n\in\nats$.
Existem exatamente $n$ distintas potências de $a$.
\sketch.
As potências de $a$ são as:
$$
\dotsc, a^{-2}, a^{-1}, a^0, a^1, a^2, \dotsc, a^{n-1}, a^n, a^{n+1}, a^{n+2}, \dotsc
$$
Queremos provar que, no final das contas, nesta lista aparecem exatemente $n$
distintos membros de $G$.  Ou seja,
$$
\card{\setst {a^k} {k\in\ints}} = n.
$$
Consideramos os
$$
a^0, a^1, \dotsc, a^{n-1}
$$
e usando a definição de $\gord a$ provamos:
\endgraf
\proofpart{Existência:} os $a^0,\dotsc,a^{n-1}$ são distintos dois-a-dois.
\endgraf\noindent
Ou seja: para todo $i,j\in \set{0,\dotsc,n-1}$ com $i\neq j$, temos $a^i \neq a^j$.
\crtabproofpart{Unicidade:} para todo $M\in\ints$ o $a^M$ é um dos $a^0,\dotsc,a^{n-1}$.
\endgraf\noindent
Sabemos diretamente pela sua definição que $a^0 = e$, e que $a^n = e$, pois $\gord a = n$.
Com pouca imaginação chegamos na idéia que a cadeia de membros
$$
\alignat{12}
&\dotsc,\ && a^{-2},\ && a^{-1},\ && a^0,\ && a^1,\ && a^2,\ && \dotsc,\ && a^{n-1},\ && a^n,\ && a^{n+1},\ && a^{n+2},\ && \dotsc\\
\intertext{é feita por uma copia de $a^0, \dotsc, a^{n-1}$ se repetindo infinitamente para as duas direções:}
&\dotsc,\ && a^{n-2},\ && a^{n-1},\ && a^0,\ && a^1,\ && a^2,\ && \dotsc,\ && a^{n-1},\ && a^0,\ && a^1,\ && a^2,\ && \dotsc
\endalignat
$$
Aplicando a divisão de \Euclid[divisão]Euclides~(\ref{euclidean_division})
no~$M$ por~$n$, ganhamos $q,r\in\ints$ tais que:
$$
M = q\ntimes n + r,\qquad 0 \leq r < n.
$$
Só basta calcular o $a^M$ para verificar que realmente é um dos $a^0, \dotsc, a^{n-1}$.
\qes
\proof.
\proofpart{Existência:}
existem $n$ potências de $a$.
\endgraf\noindent
Provamos isso demonstrando que os $a^0,\dotsc,a^{n-1}$ são distintos dois-a-dois.
Sejam $i,j\in \set{0,\dotsc,n-1}$ com $i\neq j$.
\emph{Sem perda de generalidade}, suponha que $i<j$, ou seja:
$$
0 \leq i < j < n.
$$
Para chegar num absurdo, suponha que $a^i = a^j$.
Assim temos:
$$
\align
\munderbrace{aa\dotsb a} i &= \munderbrace{aa\dotsb aaa\dotsb a} j
\intertext{E como $i<j$, quebramos o lado direito assim:}
\munderbrace{aa\dotsb a} i &= \munderbrace{\moverbrace{aa\dotsb a} i \moverbrace{aa\dotsb a} {j-i}} j
\intertext{Ou seja,}
a^i &= a^i a^{j-i}
\intertext{e logo}
e &= a^{j-i}
\endalign
$$
pelo~\ref{cheaper_gid}.
Achamos então uma potência de $a$ igual à identidade $e$:
$a^{j-i} = e$.  Como $0 < j-i < n$, isso contradiza a definição
de $n$ como a ordem de $a$:
$n = \gord a$.
Logo $a^i \neq a^j$, que foi o que queremos provar.
\endgraf\noindent
\proofpart{Unicidade:}
os $a^0,\dotsc,a^{n-1}$ são as \emph{únicas} potências de $a$.
Ou seja, para todo $M\in\ints$ o $a^M$ é um dos $a^0,\dotsc,a^{n-1}$.
\endgraf\noindent
Tome $M\in \ints$.
Aplicando a divisão de \Euclid[divisão]Euclides~(\ref{euclidean_division})
no~$M$ por~$n$, ganhamos $q,r\in\ints$ tais que:
$$
M = q\ntimes n + r,\qquad 0 \leq r < n.
$$
Só basta calcular o $a^M$ para verificar que realmente é um dos $a^0, \dotsc, a^{n-1}$:
$$
a^M
= a^{q\ntimes n + r}
= a^{q\ntimes n} a^r
= \paren{a^n}^q a^r
= e^q a^r
= e a^r
= a^r
$$
e como $0\leq r < n$, provamos o que queriamos provar.
\qed
%%}}}

%%{{{ x: a_has_exactly_gord_a_powers_without_reductio 
\exercise.
\label{a_has_exactly_gord_a_powers_without_reductio}%
Leia a demonstração do~\ref{a_has_exactly_gord_a_powers}
e escreva uma que não usa \emph{reductio ad absurdum}.

\solution
Sejam $i,j \in \set{0,\dotsc,n-1}$ tais que $a^i = a^j$.
Preciso mostrar que $i=j$.
Sem perda de generalidade suponha que $i \leq j$, ou seja:
$$
0 \leq i \leq j < n.
$$
Agora temos
$$
\align
\munderbrace{aa\dotsb a} i &= \munderbrace{aa\dotsb aaa\dotsb a} j
\intertext{E como $i \leq j$, quebramos o lado direito assim:}
\munderbrace{aa\dotsb a} i &= \munderbrace{\moverbrace{aa\dotsb a} i \moverbrace{aa\dotsb a} {j-i}} j
\intertext{Ou seja,}
a^i &= a^i a^{j-i}
\intertext{e logo}
e &= a^{j-i}
\endalign
$$
pelo~\ref{cheaper_gid}.
Achamos então uma potência de $a$ igual à identidade $e$:
$a^{j-i} = e$.
Logo $j-i \geq n$ ou $j-i = 0$, pela definição da $\gord a$.
A primeira alternativa é impossível pela escolha dos $i,j$,
e logo concluimos que $j-i=0$, ou seja, $i=j$.

\endexercise
%%}}}

%%{{{ Q: a^m = e => ? ; o(a) = infty => ? 
\question.
Se $a^m = e$ para algum $m\in\ints$, o que podemos concluir sobre o $m$ e a $\gord a$?
Se $\gord a = \infty$, o que podemos concluir sobre todas as potências de $a$?
%%}}}
\spoiler.

%%{{{ lm: a_exp_m_is_e_iff_gord_a_divides_m 
\lemma.
\label{a_exp_m_is_e_iff_gord_a_divides_m}%
Sejam $\sset G \ast$ grupo, $a\in G$, e $m\in\ints$.
Logo
$$
a^m = e \iff \gord a \divides m.
$$
\proof.
\proofpart{\rldir:}
Como $\gord a \divides m$,
temos $m = k\gord a$ para algum $k\in\ints$.
Calculamos:
$$
a^m
= a^{k\gord a}
= a^{\gord a k}
= \paren{a^{\gord a}}^k
= \gid^k
= \gid.
$$
\proofpart{\lrdir:}
Para provar que $\gord a \divides m$,
aplicamos o~\ref{euclidean_division} da divisão de Euclides\Euclid[lema da divisão],
dividindo o $m$ por $\gord a$, e ganhando assim inteiros $q$ e $r$ tais que
$$
m = \gord a q + r
\qquad
0\leq r < \gord a.
$$
Vamos provar que o resto $r=0$.
Calculamos:
$$
e
= a^m
= a^{\gord a q + r}
= a^{\gord a q} \ast a^r
= \paren{a^{\gord a}}^q \ast a^r
= \gid^q \ast a^r
= \gid \ast a^r
= a^r.
$$
Ou seja, $a^r = \gid$ com $0\leq r < \gord a$,
então pela definição de $\gord a$
como o mínimo inteiro positivo $n$ que satisfaz a $a^n = \gid$,
o $r$ não pode ser positivo.
Logo $r=0$ e $\gord a \divides m$.
\qed
%%}}}

%%{{{ lm: infinite_order_of_a_guarantees_all_powers_distinct 
\lemma.
\label{infinite_order_of_a_guarantees_all_powers_distinct}%
Sejam $G$ grupo e $a\in G$.  Se $\gord a = \infty$,
então as potências de $a$ são distintas dois-a-dois.
\sketch.
Precisamos provar que para todo $r,s\in\ints$,
$$
a^r = a^s \implies r = s.
$$
Sem perda de generalidade suponhamos $s\leq r$ e usando a hipótese
chegamos em $a^{r-s} = e$; e como a ordem de $a$ é infinita,
temos $r-s=0$ e logo $r=s$.
\qes
\proof.
Precisamos provar que para todo $r,s\in\ints$,
$$
a^r = a^s \implies r = s.
$$
Sem perda de generalidade suponhamos $s\leq r$ e usando a hipótese
temos
$$
a^sa^{r-s} = a^s
$$
e logo $a^{r-s} = e$ (\ref{cheaper_gid}).
Agora, como $\gord a = \infty$, usando o contrapositivo
do~\ref{nonzero_power_is_gid_implies_finite_order} obtemos que não existe
nenhum inteiro $m\neq 0$ tal que $a^m=e$.  Logo $r-s = 0$, ou seja $r = s$.
\qed
%%}}}

\endsection
%%}}}

%%{{{ Choosing_the_axioms 
\section Escolhendo os axiomas.
\label{Choosing_the_axioms}%

\blah.
Como escolhemos as leis~(G0)--(G3)?
Por que essas?
Por que não botamos a~(GA)?
Por que botamos a~(G3)?
Vamos discutir pouco sobre essas perguntas.

%%{{{ More theorems or more models? 
\note Mais teoremas ou mais modelos?.
Óbvio que adicionando mais leis na definição de grupo,
a gente poderia demonstrar mais teoremas.
Mas o que ganhamos em teoremas, perdemos em generalidade
da nossa teoria: menos coisas vão acabar sendo \dterm{modelos}
dos nossos axiomas, e logo esse bocado de teoremas que
vamos conseguir demonstrar não poderá ser aproveitado
em muitos contextos diferentes.
Adicionando a~(GA) nos axiomas de grupo por exemplo,
os $\sym n$ iam parar de ser grupos, e não teriamos
nenhum teorema ``de graça'' pra eles.
Como eu afirmei na introdução desse capítulo,
a escolha~(G0)--(G3) tem um equilibrio muito bom entre
riquesa da teoria e diversidade de modelos.
Faz sentido tirar o~(G3)?
Claro que sim; chegamos numa estrutura com mais modelos
(e menos teoremas), que com certeza vale a pena estudar.
O nome dessa estrutura é \dterm{monóide}, que estudamos
no~\refn{Algebraic_structures}.
%%}}}

%%{{{ Avoid redundancies 
\note Evite redundâncias.
Vamos dizer que estamos escolhendo as leis para a definição de grupo.
Já escolhemos as~(G0)--(G3), mas queremos que em cada grupo seja
possível cancelar pela esquerda~(GCL) e pela direita~(GCR).
Mesmo assim, não faz sentido adiconar as~(GCL)--(GCR) como leis,
pois como a gente descobriu no~\ref{cancellation_laws_in_group},
ámbas são \emph{teoremas} da teoria dos~(G0)--(G3).
Similarmente, escolhemos os axiomas~(G2) e~(G3) que garantam
a existência \emph{duma} identidade e para cada membro \emph{dum}
inverso, em vez de botar como leis as proposições mais fortes
que afirmam as \emph{unicidades} deles também.
Por quê?
A resposta é parecida: se for possível, preferimos limitar
nossos axiomas nas versões mais fracas possíveis para elaborar
nossa teoria.
Nesse caso, a gente também descobriu que mesmo com os~(G2)--(G3)
as unicidades são garantidas na nossa teoria, agora como
\emph{teoremas}~(\refn{uniqueness_of_identity_in_group}
e~\refn{uniqueness_of_inverses_in_group}).
%%}}}

%%{{{ Clarity and intuitiveness 
\note Clareza e intuitividade \vs mão-de-vaca.
\label{clarity_and_intuitiveness}%
No outro lado, optamos para botar as leis~(G2)--(G3),
em vez do par mais fraco~(G2L)--(G3L),
ou do~(G2R)--(G3R), que como tu sabes---ou como tu
vai descobrir quando finalmente resolver
o~\ref{onesided_group_def_proof}---qualquer
um par poderia substituir o par~(G2)--(G3), sem
afetar a teoria pois os~(G2)--(G3) viram teoremas
nesse caso~(\ref{onesided_group_def}).
Por que não escolher como axiomas dos grupos os
(G0),(G1),(G2L),(G3L) então?
Aqui é mais difícil justificar essa escolha.
Queremos achar um \emph{equilíbrio} entre a
economia, fraqueza, e quantidade dos axiomas num
lado; e a clareza e intuitividade no outro.
Não queremos exagerar nem no lado de clareza
(sendo redundantes), nem no lado de economia
(sendo mão-de-vaca).
Escolhendo as~(G2L)--(G3L) como axiomas, daria
um toque asimétrico na definição do que é um grupo.
Pelas leis apareceria (erroneamente) que a operação
dum grupo trata seus dois lados em maneiras diferentes,
prejudicando ou favorecendo um em comparação com o outro.
Botamos então como leis as~(G2)--(G3) e demonstramos
como \emph{critérion}~(\refn{onesided_group_def}) que
assim que os~(G0),(G1),(G2L),(G3L) são satisfeitos,
temos um grupo (e similarmente para os~(G2R)--(G3R)).
Nossas leis escolhidas ((G0)--(G3)) estão falando
claramente para nosso coração.  Cada um é simples;
descreve uma propriedade simples e significante.
Imagine se alguém definir que o
$\sset G {\ast, \ginv{}, \gid}$ é um \dterm{grupo}
sse
satisfaz uma lei única e bizarra, como a
$$
\lforall
{a,b,c \in G}
{\paren{\ginvp{c \ast \ginvp{a \ast b}} \ast (c \ast \ginv b)} \ast \ginvp{\ginv b \ast b} = a}.
\tag{GKUN}
$$
Dá pra entender no teu coração qualquer coisa sobre
o $G$ e sua alma?
Dá pra entender, olhando par essa lei única,
se sua operação tem identidade?  Se ela é associativa?
Pelo incrível que aparece, eu nem tô brincando sobre
a lei (GKUN).  Realmente, \Kunen{}Kunen construiu o
(GKUN) e demonstrou que a teoria do (GKUN) sozinho
e a mesma da teoria dos (G1)+(G2)+(G3)
(veja~\cite{kunensinglegroup})!
Ou seja:
$$
\text{$\ssetfont G$ satisfaz a (GKUN)}
\wowiff
\text{$\ssetfont G$ é grupo}.
$$
Considerei aqui a (G0) como automaticamente garantida
(e logo redundante) pelo fato de ter uma operação (total)
na minha estrutura.
A volta é muito fácil, e tu demonstrarás agora
no~\ref{group_implies_kunen}; deixo o converso para
o~\ref{kunen_implies_group}.
%%}}}

\TODO Clarificar single axioms; elaborar e mostrar mais.

%%{{{ x: group_implies_kunen 
\exercise.
\label{group_implies_kunen}%
Demonstre a {\rldir}.

\hint
Sejam $a,b,c \in G$.
Calcule:
\compute
\paren{\ginvp{c \ginvp{a b}} (c \ginv b)} \ginvp{\ginv b b}
&= \paren{\ginvp{c \ginvp{a b}} (c \ginv b)} (\ginv b \ginvp{\ginv b}) \obvious
&= \paren{\ginvp{c \ginvp{a b}} (c \ginv b)} (\ginv b b) \\
&\eqvdots
&= a
\endcompute

\solution
Sejam $a,b,c \in G$.
Calculamos:
\compute
\paren{\ginvp{c \ginvp{a b}} (c \ginv b)} \ginvp{\ginv b b}
&= \paren{\ginvp{c \ginvp{a b}} (c \ginv b)} (\ginv b \ginvp{\ginv b}) \obvious
&= \paren{\ginvp{c \ginvp{a b}} (c \ginv b)} (\ginv b b) \\
&= \paren{\ginvp{c \ginvp{a b}} (c \ginv b)} \gid \\
&= \ginvp{c \ginvp{a b}} (c \ginv b) \\
&= \paren{\ginvp{\ginvp{a b}} \ginv c} (c \ginv b) \\
&= \paren{(a b) \ginv c} (c \ginv b) \\
&= (a b) (\ginv c c) \ginv b \\
&= (a b) e \ginv b \\
&= (a b) \ginv b \\
&= a (b \ginv b) \\
&= a e \\
&= a.
\endcompute

\endexercise
%%}}}

%%{{{ Modularity 
\note Modularidade.
Também é bom ter \emph{modularidade} entre nossos
axiomas, em tal forma que facilita tirar um, botar
outro, e chegar numa teoria diferente mas
interessante também.
Continuando no mesmo exemplo da definição unilateral
de grupos, suponha que tiramos o~(G3L), que é
nosso axioma de L-inversos.
Onde chegamos?
Numa estrutura verdadeiramente L-lateral---esquisito!
%%}}}

%%{{{ proving_the_unprovability 
\note Demonstrando a indemonstabilidade.
\label{proving_the_unprovability}%
Alguém poderia pensar (ra\-zo\-avel\-mente) que a inclusão
do~(G3) nos axiomas de grupos foi desnecessária.
A gente deveria derivá-lo como conseqüência do resto dos axiomas,
na mesma maneira que demonstramos tantas outras proposições.
Aceitando o desafio começamos pensar para achar uma
demonstração do~(G3) a partir dos~(G0)--(G2).
E o tempo passa, passa, e passa\dots
\endgraf
E não conseguimos demonstrar.
\emph{Isso não quis dizer que o~(G3) é indemonstrável!}
Talvez amanha a gente terá uma idéia nova e conseguir demonstrá-lo;
ou talvez amanhã um rapaz mais esperto vai achar uma demonstração.
Mas, nesse caso, não vai não.
Pois podemos \emph{demonstrar} que o~(G3) é realmente
\emph{indemonstrável} pelos~(G0)--(G2).
%%}}}

%%{{{ proving_the_unprovability_method 
\exercise.
\label{proving_the_unprovability_method}%
Como?
O que seria um argumento convencente sobre isso?
E em geral, como podemos demonstrar
a indemonstrabilidade duma proposição $\psi$
a partir dumas proposições $\phi_1,\dots,\phi_n$?
Depois de deixar claro tua estratégia demonstre
que realmente:
\beginul
\li (GA) não é uma conseqüência dos (G0)--(G3);
\li (G3) não é uma conseqüência dos (G0)--(G2);
\li (G2) não é uma conseqüência dos (G0)--(G1);
\li (G1) não é uma conseqüência do  (G0).
\endul

\hint
Basta achar um \emph{modelo} (ou seja, algo que
satisfaz as leis) que não satisfaz a proposição
que queremos mostrar sua indemonstrabilidade.
Qual modelo tu escolheria para cada uma delas?

\hint
Para a~(GA) basta achar um grupo que não
seja abeliano;
para a~(G3) basta achar um \dterm{monóide}
(ou seja, algo que satisfaz as~(G0)--(G2))
que não é um grupo;
para a~(G2) basta achar um \dterm{semigrupo}
(ou seja, algo que satisfaz as~(G0)--(G1))
que não é um monóide;
para a~(G1) basta achar um \dterm{magma}
(ou seja, algo que satisfaz a~(G0))
que não é um semigrupo.

\solution
Basta achar um \emph{modelo} (ou seja, algo que
satisfaz as leis) que não satisfaz a proposição
que queremos mostrar sua indemonstrabilidade.
\crproofpart{Para a~(GA)}
tome o $\sym 3$, que é grupo mas não abeliano
($\phi\psi\neq\psi\phi$).
\crproofpart{Para a~(G3)}
tome o $S$ do~\ref{strings_with_concat_is_not_a_group}
que ja verificámos que não satisfaz a~(G3), e que
tu já demonstrou~(\ref{verify_all_group_laws_for_strings})
que ele goza das outras:~(G0)--(G2).
\crproofpart{Para a~(G2)}
considere um conjunto $A = \set{a,b}$ com operação $\ast$
a $\outl$:
$$
x \ast y = x.
$$
Facilmente o $\sset A \ast$ satisfaz as (G0)--(G1) mas
não possui identidade.
\crproofpart{Para a~(G1)}
tome o $\nats$ com a exponenciação: o conjunto obviamente
é fechado, mas a operação não é associativa:
$$
2^(1^2) \neq (2^1)^2.
$$

\endexercise
%%}}}

\blah.
Não se preocupe demais com essas questões; com mais experiência
e maduridade tu vai reconhecer e apreciar os motivos dessas escolhas,
e tu elaborarás teu próprio gosto, instinto, e talento, para escolher
axiomas.
Mas chega!
Voltamos a estudar a teoria dos grupos agora.

\endsection
%%}}}

%%{{{ Subgroups 
\section Subgrupos.

%%{{{ df: subgroup 
\definition Subgrupo.
\label{subgroup}%
\tdefined{subgrupo}%
\tdefined{subgrupo!trivial}%
\sdefined {\sholed H \subgroup \sholed G} {$H$ é um subgrupo de $G$}
Seja $\sset G {\ast,e}$ grupo.
Um subconjunto $H\subset G$ é um \dterm{subgrupo} de $G$ sse
$H$ é um grupo com a mesma operação $\ast$.
Escrevemos $H \subgroup G$.
Chamamos os $\set e$ e $G$ \dterm{subgrupos triviais} de $G$.
%%}}}

%%{{{ remark: is it really the same op really? 
\remark A mesma mesmo?.
Na~\ref{subgroup} falamos que $H$ é um grupo com \emph{a mesma operação} $\ast$.
Literalmente as duas operações são diferentes, pois seus domínios são diferentes.
O que entendemos com essa frase aqui é que o conjunto $H$ é um grupo com operação
\emph{a restricção da $\ast$ no $H\times H$}.
Com símbolos, $\sset H {\resfunsub \ast {H\times H}}$ é um grupo.
(Lembre-se a~\ref{fresto}.)
%%}}}

%%{{{ x: singleton_e_is_a_subgroup 
\exercise.
\label{singleton_e_is_a_subgroup}%
Verifique que para todo grupo $\sset G {\ast,e}$, temos $\set e \subgroup G$.

\endexercise
%%}}}

%%{{{ eg: Numbers 
\example Números reais.
(1) Considere o grupo $\sset \reals {+}$.
Observe que $\rats$ e $\ints$ são subgrupos dele, mas $\nats$ não é.
\endgraf\noindent
(2) Considere o grupo $\sset {\reals_{\neq0}} {\ntimes}$.
Observe que $\set{1, -1}$, $\rats_{\neq0}$, e para qualquer
$\alpha\in\reals_{\neq0}$ o conjunto $\setst {\alpha^k} {k\in\ints}$ são todos
subgrupos dele, mas $\ints$ e $\setst {\alpha^n} {n\in\nats}$ não são.
\endexample
%%}}}

%%{{{ x: rationals 
\exercise.
Considere o grupo $\ssetfont Q \leteq \sset {\rats\setminus\set0} {\ntimes}$
e seus subconjuntos:
$$
\align
Q_1 &\leteq \setst { p/q } { p, q \in \ints,\ \text{$p$ e $q$ ímpares} }\\
Q_2 &\leteq \setst { p/q } { p, q \in \ints,\ \text{$p$ ímpar, $q$ par} }\\
Q_3 &\leteq \setst { p/q } { p, q \in \ints,\ \text{$p$ par, $q$ ímpar} }.
\endalign
$$
Para quais dos $i=1,2,3$ temos $Q_i \subgroup \ssetfont Q$?

\endexercise
%%}}}

%%{{{ property: empty_is_never_a_subgroup 
\property.
\label{empty_is_never_a_subgroup}%
$H\subgroup G \implies H \neq\emptyset$.
\proof.
Como $H$ é um grupo, necessariamente $e\in H$.
\qed
%%}}}

%%{{{ x: some_subgroups_of_additive_ints 
\exercise.
\label{some_subgroups_of_additive_ints}%
\sdefined {\sholed m \ints} {o conjunto de todos os múltiplos do $m$}%
Prove que para todo $m\in\ints$, $m\ints \subgroup \sset \ints +$,
onde $m\ints \defeq \setst {km} {k \in \ints}$.

\endexercise
%%}}}

%%{{{ x: some_nontrivial_subgroups_of_multiplicative_reals 
\exercise.
\label{some_nontrivial_subgroups_of_multiplicative_reals}%
Ache uns subgrupos não-triviais do
$\sset {\reals\setminus\set0} {\ntimes}$.

\endexercise
%%}}}

%%{{{ remark: ass_for_free_in_subgroup
\remark Associatividade de graça.
\label{ass_for_free_in_subgroup}%
Seja $\sset G \ast$ grupo, e tome um $H\subset G$.
Para ver se $H \subgroup G$, seguindo a definição,
precisamos verificar as (G0)--(G3) no $\sset H \ast$.
Mas a lei~(G1) da associatividade não tem como ser violada no $\sset H \ast$.
O que significaria violar essa lei?
$$
\text{Teriamos $a,b,c \in H$, tais que $a\ast (b\ast c) \neq (a \ast b) \ast c$.}
$$
Mas como $H \subset G$, nos teriamos o mesmo contraexemplo para a (G1) de $G$,
impossível pois $G$ é um grupo mesmo (e a operação é a mesma).
Logo, jamais precisaramos verificar a~(G1) para um possível subgrupo.
%%}}}

\blah.
E isso não é o único ``desconto'' que temos quando queremos provar
que~$H \subgroup G$.  Vamos ver mais dois critéria agora:

%%{{{ criterion: nonempty_subgroup_criterion 
\criterion Subgrupo.
\label{nonempty_subgroup_criterion}%
Se $H$ é um subconjunto não vazio do grupo $\sset G {\ast,e}$, então:
$$
\rightbrace{
\alignedat3
\textrm{(0)} & \quad &                      & \emptyset \neq H \subset G                 &\qquad &\textrm{($H$ é n\~ao vazio)}\\
\textrm{(1)} & \quad & \pforall {a,b \in G} & \bracket{a, b \in H \implies a\ast b \in H}  &\qquad &\textrm{($H$ é $\ast$-fechado)}\\
\textrm{(2)} & \quad & \pforall {a \in G}   & \bracket{a \in H    \implies \ginv a \in H}  &\qquad &\textrm{($H$ é $^{-1}$-fechado)}
\endalignedat
}
\implies
H \subgroup G
$$
\sketch.
Observamos que a associatividade é garantida pelo fato que $G$ é grupo,
então basta provar que $e\in H$.
Por isso, usamos a hipótese $H\neq\emptyset$ para tomar um $a\in H$
e usando nossas (poucas) hipoteses concluimos que $e\in H$ também.
\qes
\proof.
Precisamos verificar as leis (G0)--(G3) para o $\sset H {\ast}$.
Os (1) e (2) garantam as (G0) e (G3) respectivamente,
e o fato que $G$ é grupo garanta a (G1) também.
Basta verificar a (G2), ou seja, que $e\in H$:
\stepproof
\proofsteptby {Tome $a\in H$.}      {$H\neq\emptyset$\,}
\thereforemby {\ginv a \in H}       {pela (ii)}
\thereforemby {a\ast \ginv a \in H} {pela (i)}
\thereforemby {e \in H}             {def.~$\ginv a$}
\endstepproof
\qed
%%}}}

%%{{{ The skeleton of the proof 
\note O esqueleto dessa demonstração.
Vamos lembrar o tema de arvores, escrevendo a prova
do~\ref{nonempty_subgroup_criterion} assim:
$$
\Proofm {
\A    {h\in H}
\I1-------------- {\phantom{$H$ $\ginv{}$-fechado}}
   {\ginv h\in H}
\A                        {h \in H}
\I2--------------------------------- {\phantom{$H$ $\ast$-fechado}}
           {\ginv h h \in H}
    \I1-------------------------- {\phantom{def.~$\ginv h$}}
               {e \in H}
}
$$
Quais são as justificações de cada linha de inferência?
$$
\Proofm {
\A    {h\in H}
\I1-------------- {$H$ $\ginv{}$-fechado}
   {\ginv h\in H}
\A                        {h \in H}
\I2--------------------------------- {$H$ $\ast$-fechado}
           {\ginv h h \in H}
    \I1-------------------------- {def.~$\ginv h$}
               {e \in H}
}
$$
%%}}}

%%{{{ remark: shorter formulas 
\remark.
Observe que como $H\subset G$, a afirmação
$$
\lforall {a,b \in G} {a,b\in H \implies ab \in H}
$$
é equivalente à
$$
\lforall {a,b \in H} {ab \in H}.
$$
No próximo critério vamos escrever nessa forma mais curta.
%%}}}

%%{{{ criterion: finite_subgroup_criterion 
\criterion Subgrupo finito.
\label{finite_subgroup_criterion}%
Se $\sset G {\ast,e}$ é um grupo e $H$ é um subconjunto finito e não vazio do $G$,
fechado sobre a operação $\ast$, então $H$ é um subgrupo de $G$.
Em símbolos:
$$
\rightbrace{
\alignedat2
\textrm{(0)} \quad & \emptyset \neq H \finsubset G        &\qquad &\textrm{($H$ é \emph{finito} e n\~ao vazio)}\\
\textrm{(1)} \quad & \lforall{a, b \in H}{a\ast b \in H}    &\qquad &\textrm{($H$ é $\ast$-fechado)}
\endalignedat
}
\implies
H \subgroup G
$$
\sketch.
Basta demonstar o (2) para aplicar o~\ref{nonempty_subgroup_criterion}.
Tome um $a\in H$ e considere a seqüência das suas potências
$a, a^2, a^3, \dotsc \in H$.
Como o $H$ é finito vamos ter um elemento repetido,
$a^r = a^s$ com inteiros $r > s > 0$, e usamos isso
para achar qual dos $a, a^2, a^3, \dotsc$ deve ser o $\ginv a$,
provando assim que $\ginv a\in H$.
\qes
\proof.
Graças ao~\ref{nonempty_subgroup_criterion}, basta mostrar que todos os membros
de $H$ têm seu inverso dentro do $H$.
Tome um $a\in H$ e considere a seqüência das suas potências positivas:
\compute
a, a^2, a^3, \dotsc &\in H \by {graças à hipótese (1)}
\endcompute
Como o $H$ é finito vamos ter um elemento repetido,
$a^r = a^s$ para alguns distintos positivos $r,s \in \nats$.
Sem perda de generalidade, suponha $r > s$.
Temos
$$
\align
\toverbrace{a\ast a \ast \dotsb \ast a}{$r$ vezes}
&=\toverbrace{a\ast a \ast \dotsb \ast a}{$s$ vezes}
\intertext{e como $r>s$, reescrevemos assim:}
\toverbrace{
\tunderbrace{a\ast a \ast \dotsb \ast a}{$r-s$ vezes}
\ast
\tunderbrace{\cancel{a\ast a \ast \dotsb \ast a}}{$s$ vezes}
}{$r$ vezes}
&=\toverbrace{\cancel{a\ast a \ast \dotsb \ast a}}{$s$ vezes}.
\intertext{Agora operando nos dois lados pela direita por $\ginvp{a^s}$:}
\toverbrace{a\ast a \ast \dotsb \ast a}{$r-s$ vezes}
&=e
\intertext{Ou seja, $e = a^{r-s}$ e acabamos de provar que $e\in H$.
Observe que $r-s>0$, então temos pelo menos um $a$ na esquerda:}
\toverbrace{a\ast \tunderbrace{a \ast \dotsb \ast a}{$r-s-1$ vezes}}{$r-s$ vezes}
&=e
\endalign
$$
e agora \emph{precisamos} considerar dois casos:
\endgraf\noindent
\case{Caso $r-s = 1$:}
Nesse caso então temos $e = a^1 = a$,
e logo $\ginv a = \ginv e = e = a \in H$.
\endgraf\noindent
\case{Caso $r-s > 1$:}
Nesse caso, temos $e = aa^{r-s-1}$, ou seja,
achamos o inverso do $a$: é o $a^{r-s-1}$, e ele pertence no $H$, pois é potência positiva de $a$ (e $H$ é fechado pela operação).
\endgraf
Em ambos dos casos mostramos que $\ginv a \in H$ e podemos
aplicar o~\ref{nonempty_subgroup_criterion} para concluir o desejado
$H\subgroup G$.
\qed
%%}}}

%%{{{ criterion: subgroup_one_test 
\criterion subgrupo: ``one-test''.
\label{subgroup_one_test}%
Se $G$ é um grupo e $\emptyset\neq H \subset G$ tal que
$$\text{para todo $a,b\in H$},\ a\ginv b\in H,$$
então $H\subgroup G$.  Em símbolos:
$$
\rightbrace{
\aligned
\textrm{(0)} \quad & \emptyset \neq H \subset G \\
\textrm{(1)} \quad & \lforall {a, b \in H} {a\ast \ginv b \in H}
\endaligned
}
\implies
H \subgroup G
$$
\proof.
\ref{subgroup_one_test_proof}.
\qed
%%}}}

%%{{{ remark: the converses of all criteria above are obviously true 
\remark.
Em todos esses critérios, as direções {\rldir} também são válidas
(e suas demonstrações devem ser óbvias).
%%}}}

%%{{{ x: subgroup_one_test_proof 
\exercise.
\label{subgroup_one_test_proof}%
Prove o~\ref{subgroup_one_test}.

\hint
Prove primeiro que $H$ é fechado pelos inversos, tomando um $h\in H$
e demonstrando que $\ginv h \in H$.
Depois basta provar que $H$ é fechado pela operação, tomando
$a,b\in H$ e demostrando que $ab \in H$.

\solution
Como $H\neq\emptyset$, tome $h\in H$.
Pela hipótese, $h\ginv h\in H$, ou seja $e\in H$.
Como $e,h\in H$, de novo pela hipótese temos $e\ginv h \in H$,
ou seja $\ginv h \in H$.
Temos então que o $H$ é fechado pelos inversos.
Basta provar que é fechado pela operação de $G$ também:
tomando $a,b\in H$, ganhamos $a,\ginv b\in H$,
então pela hipótese $a\ginvp{\ginv b} \in H$, ou seja, $ab \in H$.

\endexercise
%%}}}

%%{{{ x: subgroup_is_an_order 
\exercise.
\label{subgroup_is_an_order}%
Mostre que $\subgroup$ é uma relação de ordem:
$$
\gather
G \subgroup G\\
K \subgroup H \mland H \subgroup G \implies K\subgroup G\\
H \subgroup G \mland G \subgroup H \implies H = G.
\endgather
$$

\endexercise
%%}}}

%%{{{ x: Matrices 
\exercise Matrizes.
Verificamos que
$$
G \leteq \setst{ \matrixp{a & b\\c & d}\in\reals^{2\times2}} {ad - bc \neq 0 }
$$
com multiplicação é um grupo no~\ref{matrix_group_examples}.
Considere seus subconjuntos:
$$
\xalignat2
G_{\rats} &\leteq \setst{ \matrixp{a & b\\c & d}\in\rats^{2\times2}} {ad - bc \neq 0 }&\quad H &\leteq \setlst { \matrixp{a & b\\0 & d}      } { a,b,d \in\reals,\ ad \neq 0 }\\
G_{\ints} &\leteq \setst{ \matrixp{a & b\\c & d}\in\ints^{2\times2}} {ad - bc \neq 0 }&\quad K &\leteq \setlst { \matrixp{1 & b\\0 & 1}      } { b\in\reals }                 \\
G_{\nats} &\leteq \setst{ \matrixp{a & b\\c & d}\in\nats^{2\times2}} {ad - bc \neq 0 }&\quad L &\leteq \setlst { \matrixp{a & 0^{\phantom{-1}}\\0 & a^{-1}} } { a\in\reals,\ a\neq 0 }
\endxalignat
$$
Para cada relação de $\subset$ válida entre 2 dos 7 conjuntos acima,
decida se a correspondente relação~$\subgroup$ também é válida.

\endexercise
%%}}}

%%{{{ eg: Modular arithmetic 
\example Aritmética modular.
Considere o grupo $\sset {\finord 6} {+_6}$ onde $+_6$ é a adição modulo $6$.
Os $\set{0,2,4}$ e $\set{0,3}$ são seus únicos subgrupos não-triviais.
\endexample
%%}}}

%%{{{ eg: Permutations 
\example Permutações.
O $\set{\id, \phi}$ é um subgrupo de $\sym 3$, onde $\phi = \permc{1 & 2}$.
\endexample
%%}}}

%%{{{ x: find all subgroups of \sym 3 
\exercise.
Ache todos os subgrupos do $\sym 3$.

\hint
São 6.  Ache todos.

\solution
Os seguintes são todos os subgrupos do $\sym 3$:
$$
\xalignat6
&\set {\id} &
&\set {\id, \phi} &
&\set {\id, \phi\psi} &
&\set {\id, \psi\phi} &
&\set {\id, \psi, \psi^2} &
&\sym 3.
\endxalignat
$$

\endexercise
%%}}}

%%{{{ eg: Real functions 
\example Funções reais.
Seja $F = (\reals\to\reals_{\neq0})$ com operação a
multiplicação pointwise~(\ref{pointwise_operation}).
Os subconjuntos seguintes de $F$ são todos subgrupos dele:
$$
\xalignat2
&\setstt {f\in F} {$f$ continua} &
&\setst  {f\in F} {f(0) = 1} \\
&\setstt {f\in F} {$f$ constante} &
&\setstt {f\in F} {$f(r) = 1$ para todo $r\in\rats$}
\endxalignat
$$
\endexample
%%}}}

%%{{{ eg: Sets 
\example Conjuntos.
Sejam $A$ conjunto, e $X\subset A$.
Lembra que $\sset {\pset A} {\symdiff}$ é um
grupo~(\ref{pset_with_setops_group}).
Os $\set{\emptyset, X}$, $\set{\emptyset, X, A\setminus X}$,
e $\set{\emptyset, X, A\setminus X, A}$ são todos subgrupos dele,
mas o $\set{\emptyset, X, A}$ não é.
\endexample
%%}}}

%%{{{ x: why not? 
\exercise.
Por que não?

\hint
(G0).

\solution
O $H = \set{\emptyset, X, A}$ em geral não é um subgrupo, pois pode violar a
lei~(G0) no caso que $A\setminus X \notin H$, pois~$A \symdiff X = A \setminus X$.

\endexercise
%%}}}

%%{{{ x: intersection_of_subgroups_is_a_subgroup 
\exercise.
\label{intersection_of_subgroups_is_a_subgroup}%
Seja $G$ grupo, e $H_1,H_2\subgroup G$.
Então $H_1\inter H_2 \subgroup G$.

\hint
Precisa mostrar que $H_1\inter H_2 \neq \emptyset$ e que é fechado sobre a
operação do grupo e sobre inversos.

\hint
Para mostrar que é fechado sobre a operação do grupo
suponha $a,b\in H_1\inter H_2$ e mostre que
$ab\in H_1\inter H_2$.
Similarmente, para mostrar que é fechado sobre os inversos,
suponha $a\in H_1\inter H_2$ e mostre que
$\ginv a \in H_1\inter H_2$.

\solution%%{{{
Temos $H_1\inter H_2 \subset G$.
Observe primeiramente que $H_1\inter H_2\neq \emptyset$,
pois $e\in H_1$ e $e\in H_2$ (os dois sendo subgrupos de $G$).
Agora mostramos que o $H_1\inter H_2$ é fechado pela operação:
\stepproof
\proofsteptnb {$a,b \in H_1\inter H_2$}
\thereforetby {$a,b \in H_1$ e $a,b\in H_2$} {def.~$\inter$}
\thereforetby {$ab  \in H_1$ e $ab\in H_2$}  {$H_1$ e $H_2$ grupos}
\thereforetby {$ab  \in H_1\inter H_2$}      {def.~$\inter$}
\intertext{e pelos inversos:}
\proofsteptnb {$a \in H_1\inter H_2$}
\thereforetby {$a      \in H_1$ e $a\in H_2$}      {def.~$\inter$}
\thereforetby {$a^{-1} \in H_1$ e $a^{-1}\in H_2$} {$H_1$ e $H_2$ grupos}
\thereforetby {$a^{-1} \in H_1\inter H_2$}         {def.~$\inter$}
\endstepproof
e o resultado segue graças ao~\ref{nonempty_subgroup_criterion}.
%%}}}

\endexercise
%%}}}

%%{{{ x: union_of_subgroups_is_a_subgroup_wrong 
\exercise.
\label{union_of_subgroups_is_a_subgroup_wrong}%
Trocamos o $\inter$ para $\union$
no~\ref{intersection_of_subgroups_is_a_subgroup}.
\item{(i)} Ache o erro na prova seguinte:
\quote
<<Como $H \leteq H_1\inter H_2 \subset G$,
precisamos mostrar que $H$ é fechado sobre a operação:
\stepproof
\proofsteptnb {$a,b \in H_1\union H_2$}
\thereforetby {$a,b \in H_1$ ou $a,b\in H_2$}   {def.~$\union$}
\thereforetby {$ab \in H_1$ ou $ab\in H_2$}     {$H_1$ e $H_2$ grupos}
\thereforetby {$ab \in H_1\union H_2$}          {def.~$\union$}
\intertext{e sobre os inversos:}
\proofsteptnb {$a \in H_1\union H_2$}
\thereforetby {$a \in H_1$ ou $a\in H_2$}           {def.~$\union$}
\thereforetby {$a^{-1} \in H_1$ ou $a^{-1}\in H_2$} {$H_1$ e $H_2$ grupos}
\thereforetby {$a^{-1} \in H_1\union H_2$}          {def.~$\union$}
\endstepproof
Logo, $H_1 \union H_2 \subgroup G$.>>
\endquote
\item{(ii)} Prove que a proposição não é válida.

\endexercise
%%}}}

%%{{{ x: arbitrary_intersection_of_subgroups_is_a_subgroup 
\exercise.
\label{arbitrary_intersection_of_subgroups_is_a_subgroup}%
Generalize a~\ref{intersection_of_subgroups_is_a_subgroup} para
intersecções arbitrárias:
se $G$ é um grupo, e $\scr H$ uma família não vazia de subgrupos de $G$,
então $\Inter {\scr H} \subgroup G$.

\endexercise
%%}}}

%%{{{ x: ongruence_mod_H_teaser 
\exercise.
\label{congruence_mod_H_teaser}%
\def\RH{\rel {R_H}}%
Seja $G$ conjunto e $H\subgroup G$.
Defina no $G$ a relação $\RH$ pela
$$
a \RH b \defiff a\ginv b \in H.
$$
Decida se a relação $\RH$ é uma
relação de ordem parcial, de ordem total, de equivalência, ou nada disso.

\hint
É uma relação de equivalência.
Prove as 3 propriedades!

\solution
\def\RH{\rel {R_H}}%
\proofpart{Reflexiva:}
Seja $a\in G$.
Calculamos:
$$
\align
a \RH a
&\iff a\ginv a\in H\\
&\iff e\in H
\endalign
$$
que é verdade pois $H\subgroup G$.
\crproofpart{Transitiva:}
Sejam $a,b,c \in G$ tais que $a \RH b$ e $b \RH c$.
Precisamos mostrar que $a \RH c$, ou seja, mostrar que $a\ginv c \in H$.
Temos
\compute
a\ginv b &\in H  \bytag {$a \RH b$} 1
b\ginv c &\in H  \bytag {$b \RH c$} 2
(a\ginv b) (b \ginv c) &\in H \by {pelas (1) e (2) pois $H\subgroup G$}
\endcompute
Logo $a\ginv b b \ginv c = a \ginv c \in H$.
\crproofpart{Simmétrica:}
Sejam $a,b \in G$ tais que $a \RH b$, ou seja, $a\ginv b \in H$\fact1.
Vamos provar que $b \RH a$, ou seja, queremos $b\ginv a \in H$.
Mas como $H$ é fechado pelos inversos, pela~\byfact1~temos que
$\ginvp{a\ginv b}\in H$.
Mas calculando
\compute
\ginvp{a\ginv b}
&= \ginvp{\ginv b} \ginv a      \by {inv.~de~op.}
&= b \ginv a                    \by {inv.~de~inv.}
\endcompute
ou seja, $b\ginv a \in H$.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Generators 
\section Geradores.
\label{Group_generators}%

%%{{{ df: subgroup_generated_by_a 
\definition.
\label{subgroup_generated_by_a}%
\tdefined{grupo}[subgrupo!gerado por elemento]%
\sdefined {\generate {\sholed a}} {o subgrupo gerado por o elemento $a$}%
Sejam $G$ grupo e $a\in G$.
Chamamos o
$$
\align
\generate{a}
&\defeq \setst {a^m} {m\in\ints}\\
&= \set{\dotsc,a^{-2},a^{-1},a^0,a^1,a^2,\dotsc}
\endalign
$$
o \dterm{subgrupo de $G$ gerado por $a$}.
%%}}}

%%{{{ x: justify_subgroup_on_subgroup_generated_by_a 
\exercise.
\label{justify_subgroup_on_subgroup_generated_by_a}%
Justifica a palavra ``subgrupo'' na~\ref{subgroup_generated_by_a}.
Ou seja, prove que para qualquer grupo $G$ e qualquer $a\in G$,
$\generate a \subgroup G$.

\hint
Use o~\ref{nonempty_subgroup_criterion}.

\solution
Graças ao~\ref{nonempty_subgroup_criterion},
precisamos verificar que $\generate a$ é fechado pela operação e pelos inversos.
\endgraf\noindent
\proofpart{Fechado pela operação:}
Sejam $h_1,h_2\in\generate a$.
Logo
$h_1 = a^{k_1}$\fact1
e 
$h_2 = a^{k_2}$\fact2
para alguns $k_1,k_2\in\ints$.
Precisamos mostrar que $h_1h_2\in\generate a$.
Calculamos:
\compute
h_1h_2
&= a^{k_1} a^{k_2}  \by {pelas~\byfact1,\byfact2}
&= a^{k_1 + k_2}    \by {pela~\ref{properties_of_powers_in_groups}~(1)}
&\in \generate a.   \by {def.~$\generate a$, pois $k_1+k_2\in\ints$}
\endcompute
\proofpart{Fechado pelos inversos:}
Seja $h \in \generate a$,
logo $h = a^k$ para algum $k\in\ints$.
Pela~\ref{properties_of_powers_in_groups}~(3),
$$
\ginv h = \ginvp {a^k} = a^{-k} \in \generate a.
$$

\endexercise
%%}}}

%%{{{ x: Cyclic group of e 
\exercise.
Seja $\sset G {\ast,e}$ grupo.
Calcule o $\generate e$.

\solution
$\generate e = \set {e}$.

\endexercise
%%}}}

%%{{{ Calculate some sets and subgroups of ints 
\exercise.
Nos inteiros com adição, calcule os
$\generate 4$,
$\generate 4 \inter \generate 6$,
$\generate 4 \inter \generate {15}$,
e
$\generate 4 \union \generate 6$.
\endgraf\noindent
Quais deles são subgrupos do $\ints$?

\endexercise
%%}}}

%%{{{ Q: How would you generalize gen a to gen A? 
\question.
Como tu generalizarias o
<<subgrupo gerado por $a\in G$>>
para
<<subgrupo gerado por $A \subset G$>>?
Ou seja, como definirias o $\generate A$ para qualquer $A \subset G$?
%%}}}

Falando de \emph{generalização}, a idéia é que queremos definir o $\gen A$ num jeito
\emph{razoável} e tal que $\gen {\set a} = \gen a$.

\spoiler.

%%{{{ A wrong generalization of <a> to <A> 
\note.
\label{wrong_generalization_of_gord_a_to_gord_A}%
Queremos generalizar o conceito de geradores para definir $\generate A$,
onde $A\subset G$.
Seguindo ingenuamente a definição de $\generate a$,
uma primeira abordagem seria botar
$$
\generate A = \setst {a^m} {a \in A,\  m \in\ints}
$$
e chamar $\generate A$ o subgrupo de $G$ gerado por $A$.\mistake
%%}}}

%%{{{ x: find_the_problem_in_wrong_generalization_of_gord_a_to_gord_A 
\exercise.
\label{find_the_problem_in_wrong_generalization_of_gord_a_to_gord_A}%
Qual o problema com a definição de $\generate A$ acima?

\hint
Calcule o $\generate {4,6}$ no $\sset \ints +$.

\hint
Ele é um subgrupo?

\endexercise
%%}}}

%%{{{ x: subgroup_generated_by_two_members 
\exercise.
\label{subgroup_generated_by_two_members}%
Tentando generalizar primeiramente para o caso mais simples de <<subgrupo gerado por dois membros $a,b\in G$>>,
alguém definiu o $\gen {a,b}$ para quaisquer $a,b \in G$ assim:
$$
\generate {a,b} \defeq \setst {a^m b^n} {m,n \in \ints}.
$$
Existe um problema.  Qual?

\hint
Se $G$ fosse abeliano, daria certo.

\solution
O problema é que não podemos chamar isso \emph{subgrupo}, pois não é garantidamente fechado pela operação.
Por exemplo,
sabendo que $a \in \gen{a,b}$ e $a\ast b\in\gen{a,b}$, deveriamos ter
$(ab)a \in \gen{a,b}$, mas o $(ab)a$ \emph{em geral} não pode ser escrito na
forma $a^m b^n$.
Uma outra observação similar que serve também é que o inverso de
$ab \in \gen{a,b}$ é o $\ginv b \ginv a$ que também \emph{em geral} não
pode ser escrito na forma $a^m b^n$.

\endexercise
%%}}}

\blah.
Vamos finalmente definir o $\gen A$.

%%{{{ df: subgroup_generate_A_direct 
\definition direta.
\label{subgroup_generate_A_direct}%
\tdefined{grupo}[subgrupo!gerado por subconjunto]%
\sdefined {\generate {\sholed A}} {o subgrupo gerado por o conjunto $A$}%
Sejam $\sset G \ast$ grupo e $A\subset G$.
Chamamos o
$$
\generate A
\defeq
\setstt {a_0\ast\dotsb\ast a_{k-1}}
        {$k\in\nats$;\ $i\in\finord k$;\ $a_i \in A$ ou $\ginv{a_i} \in A$}.
$$
o \dterm{subgrupo de $G$ gerado por $A$}.
Ou seja, os membros de $\generate A$ são os produtos finitos feitos por
membros de $A$ e seus inversos.
Abusando a notação, escrevemos também $\generate {a_1, a_2,\dotsc, a_n}$
para o $\generate {\set{a_1, a_2,\dotsc, a_n}}$.
%%}}}

%%{{{ remark: why_e_is_in_every_generated_subgroup 
\remark.
\label{why_e_is_in_every_generated_subgroup}%
Lembre-se (\ref{operating_on_an_empty_list_of_objects}) que para $k=0$
a expressão acima é a identidade $e$,
e logo $e \in \generate A$ para qualquer $A$.
%%}}}

%%{{{ property: equivalent_formulations_for_generate_A 
\property.
\label{equivalent_formulations_for_generate_A}%
As alternativas definições são equivalentes:
$$
\generate A
=
\leftbrace{
\aligned
& \setst  {a_0^{m_0}\ast\dotsb\ast a_{k-1}^{m_{k-1}}}
          {k\in\nats;\ i\in\finord k;\ m_i \in \ints;\ a_i \in A} \\
& \setst  {a_0^{m_0}\ast\dotsb\ast a_{k-1}^{m_{k-1}}}
          {k\in\nats;\ i\in\finord k;\ m_i \in \set{-1,1};\ a_i \in A} \\
& \setstt {a_0\ast\dotsb\ast a_{k-1}}
          {$k\in\nats$;\ $i\in\finord k$;\ $a_i \in A$ ou $\ginv{a_i} \in A$}.
\endaligned
}
$$
%%}}}

%%{{{ x: check_that_a_word_satisfies_all_three_definitions_for_generate_A 
\exercise.
\label{check_that_a_word_satisfies_all_three_definitions_for_generate_A}%
Sejam $G$ grupo e um subconjunto dele $A=\set{a,b,c,d}$.
Mostre que $a^3b^{-2}cb^3d^{-1} \in \generate A$ para todas
as três definições equivalentes da~\ref{equivalent_formulations_for_generate_A}.
Ou seja, para cada um desses conjuntos, decida quais são todas as atribuições
necessárias que satisfazem o ``filtro'' de cada conjunto.

\solution
Pela sua forma, já é óbvio que
$$
\align
a^3b^{-2}cb^3d^{-1}
&\in \setst {a_0^{m_0}\ast\dotsb\ast a_{k-1}^{m_{k-1}}}
            {k\in\nats;\ i\in\finord k;\ m_i \in \ints;\ a_i \in A}.
\intertext{Basta tomar $k\asseq 5$ e}
&
\alignedat2
a_0 &\asseq a  & m_0 &\asseq 3  \\
a_1 &\asseq b  & m_1 &\asseq -2 \\
a_2 &\asseq c  & m_2 &\asseq 1  \\
a_3 &\asseq b  & m_3 &\asseq 3  \\
a_4 &\asseq d  & m_4 &\asseq -1
\endalignedat
\intertext{e pronto!  Mas para mostrar que}
a^3b^{-2}cb^3d^{-1}
&\in \setst {a_0^{m_0}\ast\dotsb\ast a_{k-1}^{m_{k-1}}}
            {k\in\nats;\ i\in\finord k;\ m_i \in \set{-1,1};\ a_i \in A} 
\intertext{não podemos fazer a mesma escolha, pois cada um dos $m_i$
pode ser ou $1$ ou $-1$.  Basta só aumentar o $k$, e tomando $k \asseq 10$ e}
&
\alignedat4
a_0 &\asseq a  & m_0 &\asseq 1  & a_5 &\asseq c  & m_5 &\asseq 1 \\
a_1 &\asseq a  & m_1 &\asseq 1  & a_6 &\asseq b  & m_6 &\asseq 1 \\
a_2 &\asseq a  & m_2 &\asseq 1  & a_7 &\asseq b  & m_7 &\asseq 1 \\
a_3 &\asseq b  & m_3 &\asseq -1 & a_8 &\asseq b  & m_8 &\asseq 1 \\
a_4 &\asseq b  & m_4 &\asseq -1 & a_9 &\asseq d  & m_9 &\asseq -1.
\endalignedat
\intertext{Finalmente para provar que}
a^3b^{-2}cb^3d^{-1}
&\in \setstt {a_0\ast\dotsb\ast a_{k-1}}
             {$k\in\nats$;\ $i\in\finord k$;\ $a_i \in A$ ou $\ginv{a_i} \in A$}.
\intertext{o $k$ é o mesmo, $k\asseq 10$, e basta escolher nossos $a_i$'s
em tal forma que cada um deles ou é membro de $A$ ou seu inverso é.  Fácil:}
&
\alignedat2
a_0 &\asseq a        & a_5 &\asseq c \\
a_1 &\asseq a        & a_6 &\asseq b \\
a_2 &\asseq a        & a_7 &\asseq b \\
a_3 &\asseq \ginv b  & a_8 &\asseq b \\
a_4 &\asseq \ginv b  & a_9 &\asseq \ginv d.
\endalignedat
\endalign
$$

\endexercise
%%}}}

%%{{{ df: group_word 
\definition Palavra.
\label{group_word}%
Chamamos dum termo feito por membros dum grupo $G$ operados entre si
de \dterm{palavra} de $G$.  Especificando um subconjunto $A\subset G$,
uma $A$-palavra seria uma palavra de $G$ feita usando apenas membros
de $A$ e seus inversos.
%%}}}

%%{{{ Some_examples_of_words 
\example.
\label{some_examples_of_words}%
Seja $G$ grupo e $A=\set{w,x,y,z}$ um subconjunto de $G$.
Umas $A$-palavras são as:
$$
\xalignat5
& wxyz  &
& \ginv x &
& wwwwwww &
& wxx\ginv yyyyw\ginv zw &
& \ginv z\ginv z \ginv z y \ginv y z z x \ginv x z
\intertext{Podemos usar exponentes para abreviar essas palavras:}
& wxyz  &
& \ginv x &
& w^7 &
& wx^2\ginv yy^3w\ginv zw &
& z^{-3} y \ginv y z^2 x \ginv x z.
\intertext{e as vezes até usamos um ``overline'' para indicar os inversos:}
& wxyz  &
& \overline x &
& w^7 &
& w\,x^2\,\overline y\,y^3\,w\,\overline z\,w &
& \overline z^3\,y\,\overline y\,z^2\,x\,\overline x\,z.
\endxalignat
$$
Observe que começando com uma palavra podemos \emph{computar} seu valor,
sendo uma palavra onde não aparecem consecutivos objetos canceláveis,
aplicando um passo cada vez: selecionando um tal par e o apagando.

\endexample
%%}}}

%%{{{ remark: generate_A is the set of all values of A-words 
\remark.
Com essa definição o $\generate A$ é feito por os valores de todas
as $A$-palavras.
%%}}}

%%{{{ x: Calculate <> and <G> 
\exercise.
Dado grupo $G$,
calcule os $\generate \emptyset$ e $\generate G$.

\hint
Considere o ``produto vazio'' igual ao $e\in G$.

\solution
Temos
$$
\align
\generate \emptyset &= \set{e} \\
\generate G         &= G.
\endalign
$$

\endexercise
%%}}}

%%{{{ x: justify_subgroup_on_subgroup_generate_A_direct 
\exercise.
\label{justify_subgroup_on_subgroup_generate_A_direct}%
Prove que $\generate A \subgroup G$ para qualquer grupo $G$ e qualquer $A\subset G$.

\endexercise
%%}}}

%%{{{ Q: How would you describe bottom-up and top-down for generate_A? 
\question.
Temos duas mais caracterizações do~$\generate A$ especialmente
importantes: bottom-up e top-down.  A gente já encontrou algo
similar, definindo os fechos de relações (especialmente o fecho
transitivo) no \ref{Relations},~\refn{Closures}.
Como descreverias os dois processos para definir o $\generate A$?
%%}}}
\spoiler.

%%{{{ generated_subgroup_bottom_up_informally 
\note Bottom-up, informalmente.
\label{generated_subgroup_bottom_up_informally}%
Começamos com um conjunto~$T$ onde botamos todos os elementos que desejamos
no subgrupo (os elementos de~$A$ nesse caso),
e enquanto isso não forma um grupo, ficamos nos perguntando \emph{por que não}.
A resposta sempre é que (pelo menos) uma lei de grupo ((G0)--(G3)) está sendo
violada.
Vendo as leis, isso sempre quis dizer que um certo elemento tá faltando:
\beginul
\li (G0) violada: para alguns~$s,t \in T$, o~$s\ast t \notin T$.
\li (G1) violada é impossível (veja~\ref{ass_for_free_in_subgroup}).
\li (G2) violada: a identidade~$e \notin T$.
\li (G3) violada: para algum~$t \in T$, seu inverso~$\ginv t \notin T$.
\endul
E agora?
\beginul
\li (G0) violada? Resolução: adicione o $st$: $T\union \set{st}$.
\li (G2) violada? Resolução: adicione o $e$: $T\union \set{e}$.
\li (G3) violada? Resolução: adicione o $\ginv t$: $T\union \set{\ginv t}$.
\endul
Como resolver cada um desses 3 possíveis problemas então?
Adicionando os membros culpados!  E depois?  Se o conjunto já virou
um grupo, paramos.  Se não, continuamos.
Ficamos \emph{adicionando} os membros culpados (os faltantes)
e repetindo a mesma pergunta, até chegar num conjunto que não viola
nenhuma das leis, ou seja, um grupo mesmo.
É o conjunto~$T$ que tem todos os elementos de~$A$ e todos os
necessários de~$G$ para formar um grupo.
\endgraf
Cuidado: é tentoso pensar como resolução \emph{retirar} os $s,t$, no caso da
(G0), ou o $t$ no caso da (G3).  Por exemplo, alguém poderia pensar que o
problema no caso da violada (G0), foi a presença dos $s,t$ no $T$; mas não é!
O problema é a ausência do $st$.  Lembre nossa intuição: queremos começar com o
$A$ e sem perder nenhum dos seus membros, chegar num subgrupo de $G$, adicionando
apenas os necessários.
%%}}}

%%{{{ thm: generated_subgroup_bottom_up_formally 
\theorem Bottom-up, formalmente.
\label{generated_subgroup_bottom_up_formally}%
Sejam $G$ grupo e $A \subset G$.
Definimos a seqüência de conjuntos:
$$
\align
A_0     &= A\\
A_{n+1} &= A_n
\union \tunderbrace {\setst {ab} {a,b \in A_n}} {(G0)}
\union \tunderbrace {\set e} {(G2)}
\union \tunderbrace {\setst {\ginv a} {a \in A_n}} {(G3)}.
\endalign
$$
Logo temos:
$$
\gather
A = A_0 \subset A_1 \subset A_2 \subset A_3 \subset \dotsb\\
\generate A = \Union_{n=0}^{\infty} A_n.
\endgather
$$
\sketch.
Provar $A_n \subset A_{n+1}$ para todo $n\in\nats$ é imediato
por indução.  Para a afirmação principal,
que $\generate A = \Union_{n=0}^{\infty} A_n$,
provamos cada direção separadamente:
para a {\lrdirset}, tome um arbitrário membro $\alpha \in \generate A$
e ache $w\in\nats$ tal que $\alpha \in A_w$;
para a {\rldirset}, basta provar que cada um dos $A_0, A_1, A_2, \dots$
é subconjunto de $\generate A$.  Podes---alias, deves---usar indução.
\qes
%%}}}

%%{{{ eg: tree_for_a_member_of_generate_A 
\example.
\label{tree_for_a_member_of_generate_A}%
Pensando em como demonstrar formalmente o~\ref{generated_subgroup_bottom_up_formally},
talvez ajuda considerar um exemplo específico para entender melhor como funciona.
Considere então um $A=\set{a,b}\subset G$ e um $a^3b^{-8}\in\generate A$.
Como podemos provar que $a^3b^{-8} \in \Union_n A_n$?
Basta achar um $n\in\nats$ tal que $a^3b^{-8}\in A_n$; mas qual $n$ serve aqui?
Vamos plantar uma árvore abreviada e rascunhosa:
$$
\Proofm {
   \A {b \in A}
\I1-------------- {}
    {b \in A_0}
               \A {b \in A}
            \I1-------------- {}
                {b \in A_0}
\I2--------------- {}
    {b^2 \in A_1}
               \A {b \in A}
            \I1-------------- {}
                {b \in A_0}
            \I1-------------- {}
                {b \in A_1}
\I2--------------- {}
    {b^3 \in A_2}
               \A {\vdots}
            \I1-------------- {}
                {b \in A_2}
\I2--------------- {}
    {b^4 \in A_3}
\I1--------------- {}
       {\vdots}
\I1--------------- {}
    {b^7 \in A_6}
               \A {\vdots}
            \I1-------------- {}
                {b \in A_6}
\I2--------------- {}
    {b^8 \in A_7}
\I1----------------- {}
    {b^{-8} \in A_8}
                           \A {a \in A}
                      \I1------------------ {}
                            {a \in A_0}
                      \I1------------------ {}
                           {a^2 \in A_1}
                                                  \A {a \in A}
                                              \I1--------------- {}
                                                   {a \in A_0}
                                               \I1-------------- {}
                                                   {a \in A_1}
                      \I2--------------------------------------- {}
                                   {a^3 \in A_2}
                               \I1------------------ {}
                                   {a^3 \in A_8}
\I2-------------------------------------------------- {}
                {a^3 b^{-8} \in A_9}
}
$$
Então já sabemos que o $n\asseq 9$ é suficiente e logo concluimos
que $a^3 b^{-8} \in \Union_n A_n$.
\endexample
%%}}}

%%{{{ x: tree_for_a_member_of_generate_A_justifications 
\exercise.
\label{tree_for_a_member_of_generate_A_justifications}%
Justifique as linhas de inferência da árvore
do~\ref{tree_for_a_member_of_generate_A}.

\solution
A parte esquerda parece assim:
$$
\Proofm {
   \A {b \in A}
\I1-------------- {(1)}
    {b \in A_0}
                    \A {b \in A}
                 \I1-------------- {(2)}
                     {b \in A_0}
\I2---------------------------- {(3)}
         {b^2 \in A_1}
                          \A {b \in A}
                       \I1-------------- {(4)}
                           {b \in A_0}
                       \I1-------------- {(5)}
                           {b \in A_1}
   \I2------------------------------- {(6)}
              {b^3 \in A_2}
                                            \A {\vdots}
                                         \I1-------------- {(7)}
                                             {b \in A_2}
\I2------------------------------------------------------ {(8)}
                   {b^4 \in A_3}
              \I1--------------- {*}
                     {\vdots}
              \I1--------------- {*}
                  {b^7 \in A_6}
                                         \A {\vdots}
                                     \I1-------------- {(9)}
                                         {b \in A_6}
              \I2----------------------------------- {(10)}
                            {b^8 \in A_7}
                     \I1--------------------- {(11)}
                           {b^{-8} \in A_8}
}
$$
Onde as justificativas são:
\beginil
\item{(1):} def.~$A_0$
\item{(2):} def.~$A_0$
\item{(3):} def.~$A_1$~(G0)
\item{(4):} def.~$A_0$
\item{(5):} $A_0 \subset A_1$ (\refn{generated_subgroup_bottom_up_formally})
\item{(6):} def.~$A_2$~(G0)
\item{(7):} $A \subset A_2$ (\refn{generated_subgroup_bottom_up_formally})
\item{(8):} def.~$A_3$~(G0)
\item{(9):} $A \subset A_6$ (\refn{generated_subgroup_bottom_up_formally})
\item{(10):} def.~$A_7$~(G0)
\item{(11):} def.~$A_8$~(G3)
\endil
Nas (*) usamos a regra inferida:
$$
\Proofm {
     \A {x^k \in A_m}
\I1-------------------- {$x\in A$}
   {x^{k+1} \in A_{m+1}}
}
\qquad\leadsto\qquad
\Proofm {
\A {x^k \in A_k}
                 \A {x \in A_0}
                \I1------------- {$A_0\subset A_k$}
                    {x \in A_k}
\I2----------------------------- {def.~$A_{k+1}$: (G0)}
        {x^2 \in A_{k+1}}
}
$$
O resto da arvore é justificado numa maneira parecida.

\endexercise
%%}}}

%%{{{ x: tree_for_a_member_of_generate_A_shorter 
\exercise.
\label{tree_for_a_member_of_generate_A_shorter}%
Com uma arvore mais baixa demonstre que $a^3 b^{-8} \in A_5$.

\hint
Tem como mostrar $b^{-8} \in A_4$.

\hint
$$
\Proofm {
   \A {b \in A}
\I1-------------- {}
    {b \in A_0}
\I1--------------- {}
    {b^2 \in A_1}
\I1--------------- {}
    {b^4 \in A_2}
\I1--------------- {}
    {b^8 \in A_3}
}
$$
Como justificar cada linha?

\solution
$$
\Proofm {
   \A {b \in A}
\I1-------------- {}
    {b \in A_0}
\I1--------------- {*}
    {b^2 \in A_1}
\I1--------------- {*}
    {b^4 \in A_2}
\I1--------------- {*}
    {b^8 \in A_3}
\I1----------------- {}
    {b^{-8} \in A_4}
                           \A {a \in A}
                      \I1------------------ {}
                            {a \in A_0}
                      \I1------------------ {*}
                           {a^2 \in A_1}
                                                  \A {a \in A}
                                              \I1--------------- {}
                                                   {a \in A_0}
                                               \I1-------------- {}
                                                   {a \in A_1}
                      \I2--------------------------------------- {}
                                   {a^3 \in A_2}
                               \I1------------------ {}
                                   {a^3 \in A_4}
\I2-------------------------------------------------- {}
                {a^3 b^{-8} \in A_5}
}
$$
Onde explicamos a regra inferida (*):
$$
\Proofm {
\A {x \in A_m}
\I1-------------- {*}
   {x^2 \in A_{m+1}}
}
\qquad\leadsto\qquad
\Proofm {
\A {x \in A_k}
\A {x \in A_k}
\I2----------------- {}
   {x^2 \in A_{k+1}}
}
$$
A parte esquerda com pouco mais detalhe parece assim:
$$
\Proofm {
   \A {b \in A}
\I1-------------- {}
    {b \in A_0}
                   \A {b \in A}
                \I1-------------- {}
                    {b \in A_0}
\I2-------------------------------- {}
           {b^2 \in A_1}
                           \A {\vdots}
                        \I1-------------- {}
                            {b^2 \in A_1}
        \I2-------------------------- {}
           {b^4 \in A_2}
                           \A {\vdots}
                        \I1-------------- {}
                            {b^4 \in A_2}
        \I2--------------------------- {}
                {b^8 \in A_3}
}
$$

\endexercise
%%}}}

%%{{{ generated_subgroup_top_down_informally 
\note Top-down, informalmente.
\label{generated_subgroup_top_down_informally}%
Começamos considerando o próprio $G$ como um possível candidato para ser
o subgrupo de $G$ gerado por o conjunto $A$.  No final das contas,
$G \subgroup G$, e também $G \supset A$.
Mas no~$G$ existe possível ``lixo'': membros fora do~$A$ cuja presença não
foi justificada como necessária pelas leis de grupo.
Precisamos filtrar esse lixo, para ficar apenas com os membros ``necessários''.
Quais são esses membros?
Bem, se conseguir formar um subgrupo $H \subgroup G$
tal que $H\supset A$ e que \emph{não} tem alguns dos membros,
isso quis dizer que eles não são realmente necessários; ou seja, é lixo.
Então quem fica mesmo?
Ficam apenas aqueles que pertencem a \emph{todos} os subgrupos de $G$
que contêm o $A$.  Estes membros são exatamente os membros do $\generate A$.
%%}}}

%%{{{ top_down_heart_level 
\note Top-down: nível coração.
\label{top_down_heart_level}%
Vamos pensar em nosso alvo (o $\generate A$) como o \emph{menor} de todos
os subgrupos de $G$ que contêm o $A$.  O que significa esse ``menor''?
Menor em qual ordem?  Não ligamos sobre quantidade de elementos aqui.
Menor quis dizer subgrupo---lembra que $\subgroup$ é uma
ordem~(\ref{subgroup_is_an_order}), né?---ou $\subset$-menor,
que \emph{nesse caso} acaba sendo equivalente.
O que tudo isso quis dizer?
Queremos definir o $\generate A$ como
\emph{aquele} conjunto $\overline A$ que satisfaz:
(i) $A \subset \overline A \subgroup G$; e
(ii) para todo $K$ tal que $A \subset K \subgroup G$,
temos $\overline A \subgroup K$.
Observe que nada muda se trocar o $\subgroup$ por $\subset$ na última condição,
pois como $\generate A$ e $K$ são subgrupos de $G$, as afirmações
$\overline A \subset K$ e $\overline A \subgroup K$ são equivalentes.
\endgraf
Podemos parar nossa definição aqui?  Não, pois esse ``aquele'' acima
não foi merecido ainda: como sabemos que existe tal conjunto?
Felizmente, graças à (ii), se tal conjunto existe,
ele é único~(\ref{uniqueness_of_minimum_subgroup_containing_A}).
\endgraf
Começamos com a família~$\scr H$ de \emph{todos} os subgrupos de~$G$
que contêm o~$A$:
$$
\scr H = \setst {H} {A \subset H \subgroup G}.
$$
Afirmamos que o conjunto que procuramos é o $\Inter \scr H$.
Basta verificar que ele satisfaz todas as condições,
algo que tu vai fazer agora nos exercícios abaixo, mas antes disso\dots
%%}}}

%%{{{ x: intersection_of_possibly_empty_family_in_top_down_heart_level 
\exercise.
\label{intersection_of_possibly_empty_family_in_top_down_heart_level}%
Mesmo verificando essas três coisas, ainda falta provar algo!
Temos um erro sutil mas importantíssimo;
\emph{como se fosse} uma possível divisão por zero!
Ache o que é, e prove o que precisas provar para corrigi-lo.

\solution
Precisamos verificar que a família $\scr H$ tem pelo menos um membro
antes de intersectar (veja a resolução do~\ref{Inter_emptyset}).
Fato, pois já temos um membro dela: o próprio $G$!
É imediato verificar que $G \in \scr H$, e logo $\scr H \neq \emptyset$.

\endexercise
%%}}}

%%{{{ x: intersection_of_cal_H_is_a_subgroup 
\exercise.
\label{intersection_of_cal_H_is_a_subgroup}%
$\Inter \scr H \subgroup G$.

\solution
Imediato pelo~\ref{arbitrary_intersection_of_subgroups_is_a_subgroup},
pois $\scr H$ e não vazia e todos os seus membros são subgrupos.

\endexercise
%%}}}

%%{{{ x: intersection_of_cal_H_contains_A 
\exercise.
\label{intersection_of_cal_H_contains_A}%
$A \subset \Inter \scr H$.

\solution
Pela definição da $\scr H$, para todo $H \in \scr H$ temos $A \subset H$.
Logo $A \subset \Inter \scr H$.
Isso deveria ser óbvio, e resolvido desde~\ref{Inter_of_supsets_supset}.

\endexercise
%%}}}

%%{{{ x: intersection_of_cal_H_is_contained_in_every_other_candidate 
\exercise.
\label{intersection_of_cal_H_is_contained_in_every_other_candidate}%
Para cada candidato $K$ com $A \subset K \subgroup G$, temos
$\Inter \scr H \subgroup K$.

\hint
Como já provamos que $\Inter \scr H$ é um grupo, e como $K$ também
é grupo, basta provar $\Inter \scr H \subset K$.

\solution
Seja $K$ tal que $A \subset K \subgroup G$.
Como já provamos que $\Inter \scr H$ é um grupo, e como $K$ também
é grupo, basta provar $\Inter \scr H \subset K$.
Mas, pela sua escolha, $K$ é um dos membros da família $\scr H$,
e logo $\Inter \scr H \subset K$.
Se isso não é óbvio, resolva o~\ref{Inter_is_contained_in_every_member}.

\endexercise
%%}}}

%%{{{ x: uniqueness_of_minimum_subgroup_containing_A 
\exercise.
\label{uniqueness_of_minimum_subgroup_containing_A}%
Demonstre que realmente a condição (ii) acima garanta que se tal conjunto
existe, ele é único.

\solution
Isso não é nada demais do que unicidade do mínimo, se existe,
algo fácil para provar num contexto geral para qualquer ordem
(\ref{uniqueness_of_min_max}).
Mas vamos ver essa prova nesse contexto especifico aqui.
Suponha que $\overline A, A'$ ambos satisfazem a (i)--(ii).
Vamos provar que $\overline A = A'$.
Como $\overline A$ satisfaz a (ii) e $A'$ satisfaz a (i), temos
$$
\overline A \subgroup A'.
$$
No outro lado, $A'$ satisfaz a (ii) e $\overline A$ satisfaz a (i), logo
$$
A' \subgroup \overline A.
$$
Logo $\overline A = A'$, pois a relação de subgrupo é
antisimétrica~(\ref{subgroup_is_an_order}).

\endexercise
%%}}}

%%{{{ thm: generated_subgroup_top_down_formally 
\theorem Top-down, formalmente.
\label{generated_subgroup_top_down_formally}%
Sejam $G$ grupo e $A\subset G$.
Logo
$$
\generate A = \Inter \setst { H \subgroup G } { A \subset H }.
$$
\sketch.
Seja $\scr H = \setst { H \subgroup G } { A \subset H }$.
Provamos cada direção separadamente:
Para a {\lrdirset}, tome um arbitrário membro $\alpha \in \generate A$
e um arbitrário $H \subgroup G$ tal que $H \supset A$,
e mostre que $\alpha\in H$.
Para a {\rldirset}, tome um $\alpha$ que pertence a todos
os subgrupos de $G$ que contêm o $A$ e mostre que
ele pode ser escrito na forma desejada (da definição de~$\generate A$).
\qes
%%}}}

\blah.
Ou seja, temos três definições equivalentes de \dterm{subgrupo gerado por $A$}.

%%{{{ df: cyclic_group 
\definition Grupo cíclico.
\label{cyclic_group}%
\tdefined {Grupo}[cíclico]%
Um grupo $G$ é \dterm{cíclico} sse existe $a\in G$ tal que $\generate a = G$.
%%}}}

%%{{{ x: cyclic_and_noncyclic_groups 
\exercise.
\label{cyclic_and_noncyclic_groups}%
Quais dos seguintes são grupos cíclicos?
$$
\xalignat8
& \sset \reals + &
& \sset \rats +  &
& \sset \ints +  &
& \sset {\reals_{\neq0}} \ntimes &
& \sset {\rats_{\neq0}} \ntimes  &
& \sset {\ints_6} {+_6} &
& \sset {\ints_6\setminus\set0} {\ntimes_6} &
& \sym 3
\endxalignat
$$

\solution
O $\sset \reals +$ não é.
O $\sset \rats +$ também não.
O $\sset \ints +$ é: $\generate 1 = \sset \ints +$.
O $\sset {\reals_{\neq0}} \ntimes$ não é.
O $\sset {\rats_{\neq0}} \ntimes$ também não é.
O $\sset {\ints_6} {+_6}$ é: $\generate 1 = \sset {\ints_6} {+_6}$
O $\sset {\ints_6\setminus\set0} {\ntimes_6}$ nem é grupo!
O $\sym 3$ não é.

\endexercise
%%}}}

%%{{{ x: generators_of_additive_Z6
\exercise.
\label{generators_of_additive_Z6}%
Ache todos os membros geradores de $\sset {\ints_6} {+_6}$.

\hint
Ele tem dois.

\solution
$\generate 1 = \generate 5 = \ints_6$.

\endexercise
%%}}}

%%{{{ x: generators_of_S3 
\exercise.
\label{generators_of_S3}%
Ache todos os geradores $A$ de $\sym 3$ com tamanho $2$.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ A detour: bottom-up and top-down 
\section Um desvio: bottom-up e top-down.
\label{Bottom_up_and_top_down}%

%%{{{ Thingies and subthingies
\note Bichos e subbichos.
As idéias de bottom-up e top-down são tão fundamentais que vale a pena
desviar um pouco do nosso estudo de grupos para discutir e generalizar
o que acabou de acontecer.
Vamos dizer que temos um tipo de coisas que gostamos e estudamos.
Aqui esse tipo de coisas foi o grupo, mas queremos ver essas
idéias num contexto ainda mais abstrato e geral.
Então não vamos especificar esse tipo.
Vamos chamar esses objetos de \dterm{bichos}.
Suponha agora que cada bicho tem ``por trás'' um associado conjunto.
Por exemplo, os grupos e em geral os conjuntos estruturados tem seus carrier sets.
Então faz sentido de unir, intersectar, etc., bichos.
Suponha também que cada bicho tem algo que faz seu conjunto ser especial:
sua estrutura, umas leis, etc.
Assim, já temos como definir o que significa \dterm{subbicho}:
\emph{$B_0$ é subbicho do bicho $B$ sse $B_0 \subset B$ e $B_0$ também é um bicho}.
Agora comece com um bicho $B$, e considere um subconjunto $S \subset B$,
que não é necessariamente um subbicho.
Queremos definir o \dterm{subbicho gerado por $S$}.
Precisamos:
\beginol
\li saber que a relação de ``subbicho'' é uma ordem;
\li saber que intersecção arbitrária de bichos é bicho.
\endol
Agora podemos definir o \dterm{subbicho gerado por $S$} para ser o menor subbicho
de $B$ que contem o $S$, ou seja, a intersecção
$$
\align
\generate S &= \Inter \setstt {C} {$C$ é subbicho de $B$ que contem o $S$}.
\intertext{Curtamente: dados $S \subset B$, temos}
\generate S &= \Inter_{\mathclap{S \subset C \leq B}} C,
\endalign
$$
onde $\leq$ aqui significa ``subbicho''.
%%}}}

\blah.
Essas construções aparecem o tempo todo, para vários bichos:
espaços topológicos, $\sigma$-algebras, espaços vetoriais, relações transitivas,
modelos de lógica, etc.
Aqui vamos usar como exemplo para ilustrar o processo os \emph{conjuntos convexos}
do plano euclideano $\reals^2$:

%%{{{ df: convex_set_in_plane 
\definition Conjuntos convexos.
\label{convex_set_in_plane}%
Seja $C \subset \reals^2$.
Chamamos o $C$ \dterm{convexo} sse
para todo $P, Q \in C$, o segmento $\segment {PQ} \subset C$.
%%}}}

\TODO Add figures.

%%{{{ x: which_sets_are_convex 
\exercise.
\label{which_sets_are_convex}%
Desenha os subconjuntos seguintes de $\reals^2$:
\beginol
\li $\emptyset$;
\li $\set{\tup{0,0}}$;
\li $\set{\tup{0,0},\tup{0,1}}$;
\li $\set{\tup{0,0},\tup{0,1},\tup{1,0},\tup{1,1}}$;
\li $\setst {\tup{x,y}} {x^2+y^2 = 1}$;
\li $\setst {\tup{x,y}} {x^2+y^2 \leq 1}$;
\li $\setst {\tup{x,y}} {x^2+y^2 < 1}$;
\li $\setst {\tup{x,0}} {0\leq x < 1}$;
\li $\setst {\tup{x,y}} {\max\set{\abs x, \abs y} < 1}$.
\li $\setst {\tup{x,y}} {x + y > 1}$.
\endol
Quais deles são convexos?

\endexercise
%%}}}

%%{{{ x: find_the_convex_hulls 
\exercise.
\label{find_the_convex_hulls}%
Para cada um dos conjuntos do~\ref{which_sets_are_convex}
que não é convexo, desenha seu fecho convexo.

\endexercise
%%}}}

%%{{{ x: convex_sets_have_the_intersection_property 
\exercise.
\label{convex_sets_have_the_intersection_property}%
Prove que os conjuntos convexos têm a propriedade de intersecção:
se $\scr C$ é uma família não vazia de conjuntos convexos, então
$\Inter \scr C$ é um conjunto convexo.

\endexercise
%%}}}

\blah.
Logo, \emph{podemos definir} o \dterm{fecho convexo} (ou \dterm{convex hull})
dum subconjunto $S\subset\reals^2$ usando a abordagem top-down.

%%{{{ df: convex_hull_bottom_up 
\definition.
\label{convex_hull_bottom_up}%
Seja $S\subset\reals^2$.
Definimos a seqüência de conjuntos $\seqn S n$ pela recursão:
$$
\align
S_0     &= S \\
S_{n+1} &= S_n \union \setstt {M \in \reals^2} {existem $P,Q \in S_n$ tais que $M$ é um ponto no segmento $\segment {PQ}$}.
\endalign
$$
Agora definimos o \dterm{fecho convexo} (ou \dterm{convex hull}) $\hull S$ de $S$ pela
$$
\hull S \defeq \Union_{n=0}^\infty S_n.
$$
%%}}}

%%{{{ x: convex_hull_bottom_up_deserves_the_name 
\exercise.
\label{convex_hull_bottom_up_deserves_the_name}%
Prove que o convex hull $\hull S$ dum $S \subset \reals^2$ merece seu nome:
(i) $\hull S$ é convexo mesmo e contem o $S$; (ii) qualquer convexo $C$ que contem o $S$, está contido no $\hull S$.

\endexercise
%%}}}

%%{{{ Q: how_can_we_define_the_convex_hull_top_down 
\question.
\label{how_can_we_define_the_convex_hull_top_down}%
Como podemos definir o fecho convexo dum conjunto $S\subset\reals^2$ ``top-down''?
%%}}}
\spoiler.

%%{{{ A 
\blah Resposta.
Precisamos ter pelo menos um conjunto convexo que contem o $S$,
verificar que intersecção arbitrária de conjuntos convexos é conjunto convexo,
e que a relação ``subconjunto convexo'' é uma ordem.
A última coisa é trivial.  As outras duas, deixo como exercícios
pra ti~(\refn{at_least_one_convex_contains_S}
e~\refn{intersection_of_convex_is_convex}).
Com essas coisas podemos definir o $\convexhull S$ como
$$
\convexhull S = \Inter \setst {C} {S \subset C \leq \reals^2}
$$
onde $\leq$ é a relação de ``subconjunto convexo''.
Assim $\convexhull S$:
(i) é convexo e contem o $S$;
(ii) esta contido em qualquer conjunto que satisfaz a (i).
A argumentação é exatamente a mesma com o caso de grupos
(\ref{top_down_heart_level} e os exercícios o seguindo:
\refn{intersection_of_cal_H_is_a_subgroup};
\refn{intersection_of_cal_H_contains_A};
\refn{intersection_of_cal_H_is_contained_in_every_other_candidate}).
%%}}}

%%{{{ x: intersection_of_convex_is_convex 
\exercise.
\label{intersection_of_convex_is_convex}%
A intersecção de uma família não vazia de conjuntos convexos é um conjunto convexo.

\endexercise
%%}}}

%%{{{ x: at_least_one_convex_contains_S 
\exercise.
\label{at_least_one_convex_contains_S}%
Seja $S$ um subconjunto do plano.
Demonstre que a família de todos os conjuntos convexos que
contêm o $S$ não é vazia.

\endexercise
%%}}}

\blah.
Chega para agora.
No~\ref{Lattices} vamos revisitar esse assunto num contexto abstrato.

\endsection
%%}}}

%%{{{ Group_conjugation 
\section Conjugação de grupo.
\label{Group_conjugation}%

%%{{{ df: conjugates_of_group_element 
\definition Conjugados.
\label{conjugates_of_group_element}%
\tdefined{conjugado}[de elemento de grupo]%
Seja $G$ grupo e $a\in G$.
Para qualquer $g\in G$, o $ga\ginv g$ é chamado
um \dterm{conjugado} de $a$.
%%}}}

%%{{{ df: conjugation_of_group 
\definition conjugação.
\tdefined{conjugação}[de grupo]%
\sdefined {\gconjrel} {conjugação de grupo}%
\iisee{relação!conjugação}{conjugação}%
Seja $G$ um grupo.
A \dterm{conjugação do $G$}
é a relação ${\gconjrel} : \reltype{G,G}$ definida pela
$$
\align
a \gconjrel b
&\defiff \text{$a$ é um conjugado de $b$}\\
&\intiff \lexists {g\in G} {a = gb\ginv g}.
\endalign
$$
%%}}}

%%{{{ x: gconjrel_is_an_eqrel 
\exercise.
\label{gconjrel_is_an_eqrel}%
Seja $G$ grupo.  A conjugação $\gconjrel$ do $G$
é uma relação de equivalência.

\solution
\proofpart{Reflexividade:}
Seja $a \in G$.
Procuramos $g\in G$ tal que $a = ga\ginv g$.
Como $a = e a \ginv e$, temos que realmente $a \gconjrel a$.
\endgraf
\proofpart{Simetria:}
Sejam $a,b \in G$ tais que $a \gconjrel b$.
Daí, seja $x\in G$ tal que $a = xb\ginv x$.
Operando pela esquerda com $\ginv x$ e pela direita com $x$, temos:
$$
\ginv x a x = \ginv x x b \ginv x x = b.
$$
Mas $x = \ginvp {\ginv x}$, ou seja
$b = \ginv x a \ginvp{\ginv x}$
e logo $b \gconjrel a$.
\endgraf
\proofpart{Transitividade:}
Sejam $a,b,c \in G$ tais que $a \gconjrel b$ e $b \gconjrel c$.
Daí, sejam $x,y \in G$ tais que:
\compute
a &= x b \ginv x \\
b &= y c \ginv y.
\intertext{Substituindo a segunda na primeira, temos}
a &= x \paren{ y c \ginv y } \ginv x                \\
  &= \paren{ xy } c \paren{ \ginv y \ginv x} \by {ass.}
  &= \paren{ xy } c \ginvp{ xy }.            \by {inverso de produto (\refn{inverse_of_product_in_group})}
\endcompute
Ou seja, $a \gconjrel c$.

\endexercise
%%}}}

%%{{{ df: conjugacy_class 
\definition Classe de conjugação.
\label{conjugacy_class}%
\tdefined{classe de conjugação}%
\sdefined {\gcl {\sholed a}} {a classe de conjugação de $a$}%
Seja $G$ grupo e $a\in G$.
A \dterm{classe de conjugação} de $a$ é o conjunto
$$
\gcl a \defeq \setst {ga\ginv g} {g \in G},
$$
ou seja, $\gcl a$ é a classe de equivalência do $a$
através da relação <<é um conjugado de>>.
%%}}}

%%{{{ x: conjugacy_class_of_e 
\exercise.
\label{conjugacy_class_of_e}%
Seja $G$ grupo.
Calcule a $\gcl e$.

\hint
$\gcl e = \set{e}$.
Por quê?

\endexercise
%%}}}

%%{{{ x: conjugacy_classes_of_S3 
\exercise.
\label{conjugacy_classes_of_S3}%
Ache todas as classes de conjugação de $\sym 3$.

\hint
Já achou uma no \ref{conjugacy_class_of_e}.

\endexercise
%%}}}

%%{{{ df: conjugator 
\definition conjugadores.
\label{conjugator}%
\tdefined{conjugador}[$g$-]%
\sdefined {\gconj {\sholed g}} {o $g$-conjugador}%
Seja $G$ grupo e $g\in G$.
Definimos a função $\gconj g : G \to G$ pela
$$
\gconj g x = gx\ginv g.
$$
Chamamos a $\gconj g$ de \dterm{$g$-conjugador}.
Observe que o conjugador $\gconj g$ é um ator:
$\actorS g {\ginv g}$.
%%}}}

%%{{{ x: conjugators_respect_powers 
\exercise.
\label{conjugators_respect_powers}%
Sejam $G$ grupo e $g,a\in G$.
Para todo $n\in\nats$, $\paren{ga\ginv g}^n = g a^n \ginv g$.
Em outras palavras, a conjugação por membro respeita as potências:
$$
\gconj g (a^n) = \paren{\gconj g a}^n
$$
para todo $n\in\nats$.

\hint
Indução.

\solution
Provamos por indução.
Observe que
$$
\align
(ga\ginv g)^0 &= e \\
g a^0 \ginv g &= g e \ginv g = g \ginv g = e.
\endalign
$$
Agora seja $k\in\nats$ tal que
$$
(ga\ginv g)^k = g a^k \ginv g. \tag{H.I.}
$$
Calculamos
\compute
(ga\ginv g)^{k+1}
    &= (ga\ginv g)^k (ga\ginv g) \\
    &= (ga^k\ginv g) (ga\ginv g) \by {pela H.I.}
    &= ga^k(\ginv g g)a\ginv g \\
    &= ga^ka\ginv g \\
    &= ga^{k+1}\ginv g.
\endcompute

\endexercise
%%}}}

%%{{{ x: exponentiation_respects_conjugation 
\exercise.
\label{exponentiation_respects_conjugation}%
Se $x,y$ são conjugados, então para todo $n\in\nats$,
$x^n$ e $y^n$ também são.

\hint
Lembre o~\ref{conjugators_respect_powers}.

\solution
Isso é um corolário imediato
do~\ref{conjugators_respect_powers}:
Como $x,y$ conjugados, temos $x = gy\ginv g$ para algum $g\in G$.
E agora calculamos:
\compute
x^n
&= \paren{gy\ginv g}^n \\
&= gy^n\ginv g.  \by {pelo \refn{conjugators_respect_powers}}
\endcompute
e logo $x^n,y^n$ conjugados também.

\endexercise
%%}}}

\blah.
A idéia de conjugação deve aparecer meio aleatória
pra ti neste momento, mas não tanto como logo depois
da definição (agora pelo menos tu já demonstrou
muitas propriedades interessantes).
Logo vamos descobrir que os subgrupos que são
\emph{fechados pela conjugação} (ou \emph{fechados pelos conjugados}\/)
são muito interessantes.  Paciência.

\endsection
%%}}}

%%{{{ Problems intermission 
\problems Intervalo de problemas.

%%{{{ prob: group_actors_are_bijective_proof 
\problem.
\label{group_actors_are_bijective_proof}%
Sejam $G$ grupo e $a,b\in G$.
Definimos as funções $f,g,h : G \to G$ pelas
$$
\xalignat3
f(x) &= ax  &
g(x) &= xa  &
h(x) &= axb.
\endxalignat
$$
Prove que as $f,g,h$ são bijecções e ache suas inversas.

\solution
\proofpart{Injectividade:}
$$
f(x) = f(y)
\implies ax = ay
\implies x = y.
$$
\proofpart{Sobrejectividade:}
Seja $y \in G$.
Considere o $\ginv a y \in G$.
Observe que
$$
f(\ginv a y)
= a (\ginv a y)
= (a \ginv a) y
= y.
$$
A $\finv f$ é definida pela:
$$
\finv f (y) = \ginv a y
$$
pois, de fato, $f(\ginv a y) = a \ginv a y = y$.
Similar para a $g$.
Sobre a $h$, observe que $h = g\of f$ e logo ela é bijetora
como composição de bijetoras, e sua inversa é dada
pela~\ref{finv_of_fcompose}.

\endproblem
%%}}}

%%{{{ prob: how_come_the_cancellation_laws_hold_in_nongroup_without_inverses 
\problem.
\label{how_come_the_cancellation_laws_hold_in_nongroup_without_inverses}%
Na~\ref{First_consequences_of_group_laws} provamos que as leis de cancelamento
implicam a existência de únicos inversos.
Lembre-se que o $\sset {\nats} {+}$ não é um grupo pois não satisfaz a (G3).
Mesmo assim, no $\sset {\nats} {+}$ ambas as leis de cancelamento são válidas.
Então, isso implica a existência de inversos únicos!
Qual o erro aqui?

\hint
O que precisamos na prova do fato que as leis de cancelamento implicam
a existência de inversos únicos?

\solution
Na prova do fato que as leis de cancelamento implicam a existência
de inversos únicos, \emph{usamos} a (G3) que garanta a existência,
e provamos a unicidade.  No caso do $\sset {\nats} {+}$ não temos a
(G3) (existência de inversos).  Então nossa prova nesse caso mostra
que cada membro de $\sset {\nats} +$ tem \emph{no máximo} um inverso,
algo que realmente é verdade: o $0$ tem exatamente um, e nenhum dos
outros tem.

\endproblem
%%}}}

%%{{{ prob: bust_proof_of_uniqueness_of_identity_in_group 
\problem.
\label{bust_proof_of_uniqueness_of_identity_in_group}%
Considere essa suposta prova da unicidade da identidade~(\ref{uniqueness_of_identity_in_group}):
\quote
\indent<<Seja $G$ grupo e suponha que temos identidades $e_1,e_2 \in G$.
Seja $a\in G$.
Como $e_1$ é identidade, temos $a \ast \ginv a = e_1$\fact1.
Como $e_2$ é identidade, também temos $a \ast \ginv a = e_2$\fact2.
Pelas \byfact1~e~\byfact2, como os lados esquerdos são iguais,
o lados direitos também são.
Ou seja, $e_1 = e_2$ que foi o que queremos provar.>>
\endquote
Identifique todos os erros nessa tentativa de prova.

\endproblem
%}}}

%%{{{ prob: onesided_group_def_proof 
\problem leis unilaterais de grupo.
\label{onesided_group_def_proof}%
Demonstre o~\ref{onesided_group_def}.
Cuidado: lembre-se o~\ref{onesided_group_def_catch}.

\hint
Para evitar as chances de ``roubar'' sem querer,
use uma notação adaptada às novas leis:
chame $\idr$ a identidade-direita grantida pela (G2R);
$\invl a$ para os inversos-direitos grantidos pela (G3R); e
$\invr a$ para os inversos-esquerdos garantidos pela (G3L).

\hint
Precisas mostrar as (G2)--(G3).
Ou seja, verificar que o $\idr$ é uma identidade-esquerda,
$$
\align
\pforall {a\in G} & \bracket{\idr a = a}            \tag{G2'}\\
\intertext{e que para todo $a\in G$,
seu inverso direito $\invr a$ é um inverso esquerdo também:}
\pforall {a\in G} &\bracket{\invr a \ast a = \idr}. \tag{G3'}
\endalign
$$

\hint
Para demonstrar a (G2') tome um $a\in G$ e comece com:
\compute
\idr \go a
&= (\idr \go a) \go \idr \\
&= \idr \go (a \go \idr) \\
&= \idr \go (a \go (\; \alert? \go \invr{\alert?}\;)) \by {qual membro de $G$ serve aqui?}
&\eqvdots \\
&= a
\endcompute
Para a (G3'), o lemma seguinte pode ajudar:
$$
\lforall {g \in G} {gg = g \implies g = \idr}.
$$
Use isso para demonstrar que um inverso direito é esquerdo também.

\hint
Para a (G2'), qual produto podes botar no lugar do $(\;?\;)$ da dica anterior?
Sabendo que (G2R) é válida, faz sentido substituí-lo com um termo
$\paren{x \invr x}$ para algum $x\in G$, mas qual seria esse $x$?
\emph{Não precisamos adivinhar ainda!}
Continue assim com um $x$ não-especificado por enquanto,
e logo tu vai chegar numa expressão que vai te ajudar escolher teu $x$ para
continuar, pois tu vai querer que esse $x$ ``anula'' a coisa que aparecerá
na sua esquerda.
\endgraf
Para a (G3'), teu objectivo é demonstrar que dado qualquer $a \in G$,
$\invr a a = \idr$; e o Lemma te oferece um critério para
decidir que algo é o $\idr$.  Use!

\solution
Vamos demonstrar em detalhe o critério unilateral direito.
A demonstração do esquerdo é simétricamente análoga.
\proofpart{Demonstração da (G2').}
Preciso demonstrar que a identidade direita $\idr$
é uma identidade esquerda.  Seja $a \in G$.
Basta verificar que $\idr a \askeq a$.
Calculamos:
\compute
\idr a
&= \idr a \idr                       \by {def.~$\idr$}
&= \idr a (\invr a \invr {\invr a})  \by {def.~$\invr {\invr a}$}
&= \idr (a \invr a) \invr {\invr a}  \\
&= \idr \idr \invr {\invr a}         \by {def.~$\invr a$}
&= (\idr \idr) \invr {\invr a}       \\
&= \idr \invr {\invr a}              \by {def.~$\idr$}
&= (a \invr a) \invr {\invr a}       \by {def.~$\invr a$}
&= a (\invr a \invr {\invr a})       \\
&= a \idr                            \by {def.~$\invr {\invr a}$}
&= a.                                \by {def.~$\idr$}
\endcompute
onde botei parenteses apenas para ajudar a leitura;
seu uso sendo opcional graças a (G1).
\endgraf
Para demonstrar o (G3'), eu vou usar o Lemma:
$$
\lforall {g \in G} {gg = g \implies g = \idr}.
$$
\proofpart{Demonstração do Lemma.}
Seja $g\in G$.  Temos
\compute
gg = g
&\implies (gg)\invr g = g \invr g  \by {$(\go g)$}
&\implies g(g\invr g) = \idr       \by {(G1); def.~$\invr g$}
&\implies g \idr = \idr            \by {def.~$\invr g$}
&\implies g = \idr                 \by {def.~$\idr$}
\endcompute
\proofpart{Demonstração da (G3').}
Vou demonstrar que para todo $a \in G$, o $\invr a$ é um inverso
esquerdo do $a$.  Seja $a \in G$ então; preciso mostrar que
$\invr a a \askeq \invr \gid$.
Verificamos que $(\invr a a)(\invr a a) = (\invr a a)$:
\compute
(\invr a a)(\invr a a)
&= \invr a (a\invr a) a  \by {(G1)}
&= \invr a (\idr) a      \by {def.~$\invr a$}
&= (\invr a \idr) a      \by {(G1)}
&= \invr a a.            \by {def.~$\idr$}
\endcompute
e logo pelo Lemma concluimos que $(\invr a a) = \idr$.

\endproblem
%%}}}

%%{{{ prob: cancellation_based_group_def_proof 
\problem.
\label{cancellation_based_group_def_proof}%
Prove o~\ref{cancellation_based_group_def}.

\hint
Como podemos usar o fato que um conjunto é finito?

\hint
O $G$ é finito, logo sejam $G \eqass \set{a_1, \dotsc, a_n}$.

\hint
Seja $g \in G = \set{a_1, \dotsc, a_n}$.
Considere o $Ga \defeq \setst {ga} {a \in G} = \set{ga_1, \dotsc, ga_n}$.
E agora?

\endproblem
%%}}}

%%{{{ prob: cancellation_based_group_def_both_cancellations 
\problem.
\label{cancellation_based_group_def_both_cancellations}%
Podemos apagar um dos (GCL), (GCR) das hipoteses do~\ref{cancellation_based_group_def}?

\hint
Não.
Como podemos demonstrar isso?

\hint
Basta achar um contraexemplo: um conjunto estruturado $\sset G \ast$
tal que $G$ é finito e satisfaz as (G0),(G1),(GCL) mas mesmo assim
não é um grupo; isso mostraria que não podemos apagar o (GCR).
Similarmente para o (GCL).

\endproblem
%%}}}

%%{{{ prob: Futurama 
\problem Futurama.
\label{Futurama}%
No episódio <<The prisoner of Benda>> do seriado
\ii{Futurama}\emph{Futurama},
a galera resolve seu problema usando teoria dos grupos!
Um teorema ficou enunciado e demonstrado por \Keeler{}Keeler,
o escritor desse episódio, e foi a primeira (e provavelmente única)
vez que um teorema matemático foi publicado num seriado!
O teorema ficou conhecido como o <<\ii{teorema}[futurama]Futurama theorem>>.
Assista o episódio, entenda o enunciado do teorema, e demonstre!

\endproblem
%%}}}

%%{{{ df: group_center 
\definition Centro.
\label{group_center}%
\tdefined{grupo}[centro]%
\sdefined {\gcenter {\sholed G}} {o centro do grupo $G$}%
Dado um grupo $G$, definimos seu \dterm{centro} $\gcenter G$
como o conjunto de todos os membros de $G$ que ``comutam'' com todos os membros de $G$:
$$
\gcenter G \defeq \setstt {z \in G} {para todo $g\in G$, $zg = gz$}.
$$
%%}}}

%%{{{ prob: center_G_is_a_subgroup 
\problem.
\label{center_G_is_a_subgroup}%
Mostre que dado um grupo $G$, seu centro $\gcenter G \subgrp G$.

\solution
Primeiramente observe que $\gcenter G\neq\emptyset$:
$e \in \gcenter G$ pois para todo $g\in G$, $eg=e=ge$ pela definição de $e$.
Como $\emptyset \neq \gcenter G \subset G$, precisamos apenas mostrar que:
\endgraf\noindent
\proofpart{Fechado pela operação:}
Sejam $x,y\in \gcenter G$.
Para provar que $xy\in \gcenter G$,
verificamos que o $(xy)$ comuta com todos os elementos de $G$.
Seja $g\in G$.
Calculamos:
\compute
(xy)g
&= x(yg)  \by {(G1)}
&= x(gy)  \by {$y\in \gcenter G$}
&= (xg)y  \by {(G1)}
&= (gx)y  \by {$x\in \gcenter G$}
&= g(xy). \by {(G1)}
\endcompute
\endgraf\noindent
\proofpart{Fechado pelos inversos:}
Seja $x\in \gcenter G$.
Para provar que $\ginv x\in \gcenter G$,
verificamos que o $\ginv x$ comuta com todos os elementos de $G$.
Seja $g\in G$.
Calculamos:
\compute
\ginv x g
&= \ginvp{\ginvp{\ginv x g}}         \by {inv.~de~inv.}
&= \ginvp{\ginv g {\ginvp{\ginv x}}} \by {inv.~de~prod.}
&= \ginvp{\ginv g x}                 \by {inv.~de~inv.}
&= \ginvp{x \ginv g}                 \by {$x \in \gcenter G$}
&= \ginvp{\ginv g} \ginv x           \by {inv.~de~prod.}
&= g \ginv x.                        \by {inv.~de~inv.}
\endcompute

\endproblem
%%}}}

%%{{{ prob: identifier_of_all 
\problem.
\label{identifier_of_all}%
Seja $G$ grupo finito.
Existe inteiro $N>0$ tal que para todo $a \in G$, $a^N = e$.

\hint
Tem como construir mesmo esse $N$.

\hint
Sejam $G \eqass \set {a_1, \dotsc, a_n}$ os $n$ membros de $G$.

\hint
Dado $a \in G$ sabemos que $a^{\gord a} = e$.

\solution
Sejam $G \eqass \set {a_1, \dotsc, a_n}$ os $n>0$ membros de $G$.
O inteiro $N$ que procuramos é o
$$
N \asseq \Prod_{i=1}^n \gord {a_i}.
$$
Para confirmar, seja $w \in \set{1,\dotsc,n}$
(assim temos uma arbitrário membro de $G$, o $a_w$).
Basta mostrar que $a_w^N = e$:
\compute
a_w^N
&= a_w^{\gord{a_1}\dotsb\gord{a_n}}
   \by {def.~$N$}
&= a_w^{\gord{a_w}\paren{\gord{a_1}\dotsb\gord{a_{w-1}}\gord{a_{w+1}}\dotsb\gord{a_n}}}
   \by {ensino fundamental}
&= \paren{a_w^{\gord{a_w}}}^{\gord{a_1}\dotsb\gord{a_{w-1}}\gord{a_{w+1}}\dotsb\gord{a_n}}
   \by {\ref{properties_of_powers_in_group}-(2)}
&= e^{\text{coisa}}
   \by {def.~$\gord {a_w}$}
&= e.
   \by {\ref{properties_of_powers_in_group}-(3)}
\endcompute

\endproblem
%%}}}

%%{{{ prob: all_subgroups_of_additive_ints 
\problem.
\label{all_subgroups_of_additive_ints}%
No~\ref{some_subgroups_of_additive_ints} tu provaste que para todo $m\in\ints$,
$m\ints \subgroup \sset \ints +$.  Demonstre que esses são \emph{todos} os
subgrupos de $\sset \ints +$.  Ou seja: para todo $H \subgroup \sset\ints+$,
existe $t \in \ints$ tal que $H = t\ints$.

\endproblem
%%}}}

%%{{{ prob: weird_convex 
\problem.
\label{weird_convex}%
Seja $Q$ o conjunto de todos os pontos do cíclo com ângulo racional:
$$
Q = \setst {\tup{\cos\theta, \sin\theta}} {\theta\in[0,2\pi)\inter\rats}.
$$
Considere a seqüência
$$
Q = Q_0 \subset Q_1 \subset Q_2 \subset Q_3 \subset \dotsb
$$
obtenida pela bottom-up construção da~\refn{Bottom_up_and_top_down}.
(i) Qual conjunto é o convex hull $\generate Q$ do $Q$?
(ii) Descreva o conjunto $Q_1$.
(iii) Tem $Q_i = Q_{i+1}$ para algum $i\in\nats$?

\endproblem
%%}}}

%%{{{ prob: weird_convex_hard 
\problem.
\label{weird_convex_hard}%
No~\ref{weird_convex}, $Q_1 = Q_2$?

\hint
Não!  O $Q_1$ tem ``buracos'' nele, e o $Q_2$ não tem!
Tem com achar um tal buraco no $Q_1$.

\hint
$(0,0) \in Q_2 \setminus Q_2$.  Por quê?

\hint
Para ``passar pelo $(0,0)$'', uma corda obrigatoriamente
tem que ser uma diámetro.

\hint
Por enquanto só podemos responder ``não'' por causa desse
buraco.  Tem outros buracos?
Paciência até o~\ref{Cantors_paradise}, onde revisitamos essa
pergunta nos seus problemas.

\endproblem
%%}}}

%%{{{ prob: conjugates_have_the_same_order 
\problem.
\label{conjugates_have_the_same_order}%
Membros da mesma classe de conjugação tem a mesma ordem.

\hint
Separe os casos em $\gord a = n \in\nats$ e $\gord a = \infty$.

\hint
Lembre o~\ref{exponentiation_respects_conjugation}
e o~\ref{conjugacy_class_of_e}.

\solution
Sejam $a,b$ conjugados.
\crcase{Caso que $\gord a < \infty$.}
\crproofpart{Resolução 1.}
Preciso mostrar:
(i) $b^n = e$;
(ii) para todo $m$ com $0<m<n$, $b^m \neq e$.
\endgraf
(i) Pelo~\ref{exponentiation_respects_conjugation},
temos que $a^n$ e $b^n$ são conjugados,
mas $a^n = e$, e a classe de conjugação de $e$ é o singleton $\set{e}$
(\ref{conjugacy_class_of_e}).
Logo $b^n = e$.
\endgraf
(ii) Pela mesma observação cada suposto $b^m = e$
obrigaria $a^m = e$ também.
Logo $\gord b = n$.
\crproofpart{Resolução 2.}
Pelo~\ref{exponentiation_respects_conjugation}
temos $a^{\gord a}$ conjugado com $b^{\gord a}$.
Logo $b^{\gord a} = e$ e logo $\gord b \divides \gord a$.
Similarmente $\gord a \divides \gord b$ e logo $\gord a = \gord b$
pois ambos são naturais.
\crcase{Caso que $\gord a = \infty$.}
Tenho que para todo $n > 0$, $a^n \neq e$,
e preciso mostrar a mesma coisa sobe os $b^n$.
De novo, de qualquer suposto contraexemplo $m\in \nats$ com $b^m = e$
concluimos $a^m = e$ que é absurdo pois $\gord a = \infty$.
\endgraf
Para uma resolução mais poderosa e simples,
veja o~\ref{conjugates_look_alike}.

\endproblem
%%}}}

%%{{{ prob: G abelian iff something with conjugates 
\problem.
Ache uma propriedade interessante que tem a ver com conjugados,
tal que para todo grupo $G$,
$$
\text{$G$ abeliano} \iff \text{essa propriedade}.
$$
Prove tua afirmação!

\hint
Num grupo abeliano, o que podes afirmar se $a \gconjrel b$?
(A próxima dica já tem a resposta, depois disso vai faltar
só demonstrá-la.)

\hint
$$
\text{$G$ abeliano} \iff (\gconjrel) = (\eqof G)
$$
Demonstre!

\endproblem
%%}}}

%%{{{ prob: kunen_implies_group 
\problem.
\label{kunen_implies_group}%

\endproblem
%%}}}

\TODO Elaborar.

\endproblems
%%}}}

%%{{{ Congruences and cosets 
\section Congruências e coclasses.
\label{Group_congruences_and_cosets}%

%%{{{ The relation R was actually congruence mod subgroup 
\note.
A relação de equivalência que definimos no~\ref{congruence_mod_H_teaser}
não é tão desconhecida como talvez apareceu ser.
Vamos investigar.
%%}}}

%%{{{ congruence mod H 
\note Congruência módulo subgrupo.
Seja $G$ grupo e $H\subgroup G$.
Definimos
$$
a \cong b \pmod H \defiff a\ginv b \in H.
$$
Usamos também a notação $a \congR H b$.
%%}}}

%%{{{ x: mod_int_as_a_special_case_of_mod_subgroup 
\exercise.
\label{mod_int_as_a_special_case_of_mod_subgroup}%
Justifique a notação da~\ref{equivalence_mod_subgroup} a comparando com a
congruência módulo algum inteiro da~\ref{congruence}.
Ou seja, mostre como a definição nos inteiros é apenas um caso especial da definição nos grupos.

\hint
Tome $G \asseq \sset\ints+$ e $H \asseq \sset{m\ints}+$.
E agora?  O que cada uma das
$$
\xalignat2
a \cong b &\pmod m &
a \cong b &\pmod H
\endxalignat
$$
tá dizendo nesse caso?

\endexercise
%%}}}

%%{{{ Investigating the congruence 
\note Investigando a congruência.
\label{investigation_of_equivalence_mod_subgroup}%
Vamos supor que temos um grupo $G$ e um subgrupo $H\subgroup G$.
Tomamos $a,b\in G$ e queremos ver se $a\cong b\pmod H$.
Separamos em casos:
\beginil
\item{\case{Caso 1:}} os dois elementos $a$ e $b$ estão no $H$;
\item{\case{Caso 2:}} um dos elementos está dentro do $H$, o outro fora;
\item{\case{Caso 3:}} os dois estão fora do $H$.
\endil
\topinsert
\centerline{
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestbase;
\node at (-1,0.5)    (a) {$\bullet$};
\node at (-0.5,-0.5) (b) {$\bullet$};
\node[above right, outer sep=1pt] at (a) {$a$};
\node[above right, outer sep=1pt] at (b) {$b$};
\endtikzpicture
%%}}}
\hfil
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestbase;
\node at (-1,0.5)   (a) {$\bullet$};
\node at (1,-0.5)   (b) {$\bullet$};
\node[above right, outer sep=1pt] at (a) {$a$};
\node[above right, outer sep=1pt] at (b) {$b$};
\endtikzpicture
%%}}}
\hfil
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestbase;
\node at (0.5,1)    (a) {$\bullet$};
\node at (1,-0.5)   (b) {$\bullet$};
\node[above right, outer sep=1pt] at (a) {$a$};
\node[above right, outer sep=1pt] at (b) {$b$};
\endtikzpicture
%%}}}
}
\botcaption{}
Os 3 casos da Investigação~\refn{investigation_of_equivalence_mod_subgroup}.
\endcaption
\endinsert
\noindent
Para cada caso, queremos decidir se:
\beginil
\item{(i)} podemos concluir que $a \cong b \pmod H$;
\item{(ii)} podemos concluir que $a \ncong b \pmod H$;
\item{(iii)} nenhum dos (i)--(ii).
\endil
Vamos ver qual dos (i)--(iii) aplica no \casestyle{caso 1}.
Temos
$$
a \cong b \pmod H \iff a\ginv b \in H
$$
Como $b\in H$ e $H$ é um grupo ($H\subgroup G$) concluimos que
$\ginv b \in H$.
Agora, como $a, \ginv b \in H$ ganhamos $a\ginv b\in H$, ou seja,
$a \cong b \pmod H$:
\topinsert
\centerline{
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestcase1base;
\node[color=blue,inner sep=1pt] at (-1.5,-0.5)  (binv)  {$\bullet$};
\draw[->,dashed,color=blue] (b)--(binv);
\node[above,  outer sep=1pt] at (binv) {$\ginv b$};
\endtikzpicture
%%}}}
\hfil
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestcase1base;
\node[inner sep=1pt] (binv)  at (-1.5,-0.5)  {$\bullet$};
\node[color=blue,inner sep=1pt] (abinv)  at (-0.75,-0.75) {$\bullet$};
\node[above, outer sep=1pt] at (binv) {$\ginv b$};
\node[below, inner sep=1pt, outer sep=1pt] at (abinv) {$a\ginv b$};
\draw[|-,color=blue]  (a)    edge[out=240,  in=135] (abinv);
\draw[|->,color=blue] (binv) edge[out=60, in=135] (abinv);
\endtikzpicture
%%}}}
}
\botcaption{}
Os passos do \casestyle{caso 1} do~\refn{investigation_of_equivalence_mod_subgroup}.
\endcaption
\endinsert
%%}}}

%%{{{ x: do case 2 
\exercise.
\label{investigation_of_equivalence_mod_subgroup_case_2}%
Decida qual dos (i)--(iii) aplica no \casestyle{caso 2}
do~\refn{investigation_of_equivalence_mod_subgroup}.

\hint
Sem perda de generalidade, podes supor que $a \in H$ e $b \notin H$.
Comece desenhando como fizermos no \casestyle{caso 1}.

\hint
Mostre que $b^{-1}\notin H$.  (Qual seria o problema se $b^{-1} \in H$?)

\hint
Se $b{-1} \in H$ seu inverso também deveria estar no $H$, pois $H$ é um grupo.

\hint
Suponha que $ab^{-1} \in H$ para chegar num absurdo, mostrando assim que necessariamente,
$a \ncong b \pmod H$.  Cuidado:
$$
xy \in H \nimplies x \in H \mland y \in H.
$$

\hint
Mostre que $a^{-1}\in H$.

\solution%%{{{
Sem perda de generalidade, suponha $a\in H$ e $b\notin H$.
Primeiramente mostramos que $b^{-1} \notin H$:
$$
b^{-1}\in H \implies \paren{b^{-1}}^{-1} \in H \implies b \in H,
$$
logo $b^{-1}\notin H$.
Para chegar num absurdo, vamos supor que $ab^{-1} \in H$.
\topinsert
\centerline{
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestcase2base;
\endtikzpicture
%%}}}
\hfil
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestcase2base;
\node[inner sep=1pt, color=blue] at (0,1.5) (binv) {$\bullet$};
\draw[->,dashed,color=blue] (b) edge[out=180, in=225] (binv);
\node[above, inner sep=3pt, outer sep=1pt] at (binv) {$\ginv b$};
\endtikzpicture
%%}}}
\hfil
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestcase2base;
\node[inner sep=1pt] at (0,1.5) (binv) {$\bullet$};
\node[color=red] at (-0.5,-1) (abinv) {$\bullet$};
\node[above, inner sep=3pt, outer sep=1pt] at (binv) {$\ginv b$};
\node[below, inner sep=1pt, outer sep=1pt] at (abinv) {$a\ginv b$};
\endtikzpicture
%%}}}
}
\medskip
\centerline{
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestcase2base;
\node[inner sep=1pt] at (0,1.5) (binv) {$\bullet$};
\node[inner sep=1pt, color=blue] at (-1.25,-1) (ainv) {$\bullet$};
\node[color=red] at (-0.5,-1) (abinv) {$\bullet$};
\draw[->,dashed,color=blue] (a) to (ainv);
\node[below, inner sep=1pt, outer sep=1pt] at (ainv) {$\ginv a$};
\node[above, inner sep=3pt, outer sep=1pt] at (binv) {$\ginv b$};
\node[below, inner sep=1pt, outer sep=1pt] at (abinv) {$a\ginv b$};
\endtikzpicture
%%}}}
\hfil
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestcase2base;
\node at (0,1.5) (binv) {$\bullet$};
\node at (-1.25,-1) (ainv) {$\bullet$};
\node[color=red] at (-0.5,-1) (abinv) {$\bullet$};
\node[below, inner sep=1pt, outer sep=1pt] at (ainv) {$\ginv a$};
\node[below, inner sep=1pt, outer sep=1pt] at (abinv) {$a\ginv b$};
\node[above, outer sep=1pt] at (binv) {$\ginv b$};
\draw[|-]  (ainv)  edge[out=60, in=250] (binv);
\draw[|->,color=red] (abinv) edge[out=90, in=250] (binv);
\endtikzpicture
%%}}}
\hfil
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestcase2base;
\node at (0,1.5) (binv) {$\bullet$};
\node at (-1.25,-1) (ainv) {$\bullet$};
\node[inner sep=1pt,color=blue] at (1,1) (abinv) {$\bullet$};
\node[below, inner sep=1pt, outer sep=1pt] at (ainv) {$\ginv a$};
\node[below, inner sep=1pt, outer sep=1pt] at (abinv) {$a\ginv b$};
\node[above, outer sep=1pt] at (binv) {$\ginv b$};
\draw[-,dashed,color=blue] (a) edge[out=20,  in=160] (abinv);
\draw[->,dashed,color=blue] (b) edge[out=110, in=160] (abinv);
\endtikzpicture
%%}}}
}
\botcaption{}
Os passos da resolução do~\ref{investigation_of_equivalence_mod_subgroup_case_2}.
\endcaption
\endinsert
\noindent
Vamos deduzir a contradição $b^{-1}\in H$.
Para conseguir isso, observamos que $a^{-1} \in H$ (pois $a\in H$),
e logo
$$
\overbrace{\underbrace{\vphantom{(}a^{-1}}_{\in H}\underbrace{(ab^{-1})}_{\in H}}^{\dsize b^{-1}} \in H.
$$
\noindent
Achamos assim nossa contradição:
$$
b^{-1} = eb^{-1} = (a^{-1}a)b^{-1} = a^{-1}(ab^{-1}) \in H.
$$
Concluimos então que $ab^{-1} \notin H$, ou seja $a \ncong b \pmod H$.
%%}}}

\endexercise
%%}}}

%%{{{ x: do case 3 
\exercise.
Decida qual dos (i)--(iii) aplica no \casestyle{caso 3} do~\refn{investigation_of_equivalence_mod_subgroup}.

\hint
Ache dois exemplos com $a,b\notin H$, tais que num
$a \cong b \pmod H$ e no outro $a \ncong b \pmod H$.

\hint
Um exemplo consiste em: um grupo $G$, um subgrupo $H\subgroup G$, e dois elementos $a,b\in G\setminus H$ tais que satisfazem (ou não) a congruência $a\cong b \pmod H$.

\hint
Procure teus exemplos no grupo dos inteiros com adição $\sset \ints +$.

\hint
Tome $G \leteq \sset \ints +$, $H \leteq 2\ints$, $a \leteq 1$, $b \leteq 3$
e observe que $1 \cong 3 \pmod {2\ints}$.

\hint
Não é possível achar o outro exemplo com o mesmo subgrupo $2\ints$,
mas pode sim no $3\ints$.

\solution%%{{{
No grupo $G\leteq\sset \ints +$ considere seu subgrupo $H\leteq 5\ints$.
Temos:
$$
\xalignat2
\rightbrace{
\aligned
G&\leteq \sset \ints +\\
H&\leteq 5\ints\\
a&\leteq 1  \\
b&\leteq 6  
\endaligned
}
&\implies a \cong b \pmod H
&
\rightbrace{
\aligned
G&\leteq \sset \ints +\\
H&\leteq 5\ints\\
a&\leteq 1  \\
b&\leteq 3  
\endaligned
}
&\implies a \ncong b \pmod H,
\endxalignat
$$
porque $1 + (-6) = -5 \in 5\ints$ e $1 + (-3) = -2 \notin 5\ints$ respectivamente.
%%}}}

\endexercise
%%}}}

%%{{{ def: cosets 
\definition Coclasses.
\label{coset}%
\tdefined{coclasse}%
\iisee{coset}{coclasse}%
\sdefined {\sholed a H} {o left-coset do $H\subgrp G$ através do $a\in G$}%
\sdefined {H\sholed a} {o right-coset do $H\subgrp G$ através do $a\in G$}%
Seja $G$ grupo e $H\subgrp G$.  Para $a\in G$ definimos
$$
\xalignat2
aH &\defeq \setst {ah} {h\in H}
&
Ha &\defeq \setst {ha} {h\in H}.
\endxalignat
$$
Chamamos o $aH$ a \dterm{coclasse esquerda} do $H$ através de $a$,
e similarmente o $Ha$ sua \dterm{coclasse direita}.
Também usamos os termos
\dterm{coclasse (lateral) à esquerda/direita},
e também chamamos as coclasses de \dterm{cosets}.
%%}}}

%%{{{ Q: What w \in Ha means? 
\question.
O que significa que algum $w \in Ha$?
Como podemos usá-lo se é dado?
Como podemos matá-lo se é alvo?
%%}}}
\spoiler.

%%{{{ A: what_belonging_to_Ha_means 
\note Respostas.
\label{what_belonging_to_Ha_means}%
Pela definição do conjunto $Ha$ com a notação set-builder,
$$
w \in Ha \defiff \lexists {h\in H} {w = ha}.
$$
Então ganhando $w \in Ha$ como dado, nos permite ``sejar''
um tal membro de $H$: \emph{seja $h\in H$ tal que $w = ha$}.
E para matar esse alvo precisamos mostrar como escrever
nosso $w$ como produto de algum membro do $H$ e do $a$.
Ou seja, procuramos algo que encaixa no $\holed?$:
$$
w = \munderbrace {\holed?} {\in H} a.
$$
Não esqueça: assim que achar um tal objeto que satisfaz
a equação acima, precisa demonstrar que ele pertence ao $H$.
%%}}}

%%{{{ warning: only_declare_variables 
\warning Declare apenas variáveis no conjunto!.
\label{only_declare_variables}%
É comum escrever algo do tipo:
\quote
Seja $ha \in Ha$.
\endquote
Não escreva assim, pois é perigoso roubar sem querer!
Em vez disso, podes escrever:
\quote
Seja $w \in Ha$.  Logo seja $h \in H$ tal que $w = ha$.
\endquote
É provável que esse $w$ tem um papel ``bobo'' aí, e realmente
podemos evitá-lo (
Quando ``sejamos'' algo como um membro arbitrário dum conjunto
usamos apenas uma variável!  Nem constantes, nem termos que
involvem operações.  Imagine alguem escrevendo:
<<seja $3\in\ints$>>, ou <<seja $x^2 \in \reals$>>.
Não!  A operação $\dhole^2$ já é definida, e logo para
qualquer real $r$ o real $r^2$ já é definido!
Para dar um exemplo para quem programou em linguagem similar à C.
Tu escreverias essas declarações?
\sourcecode onlydeclarevars.c;
Espero que não!
%%}}}

%%{{{ remark: picking_in_Ha_via_H 
\remark ou, até melhor, no seu conjunto de índices!.
\label{picking_in_Ha_via_H}%
No outro lado, como o $Ha$ é um conjunto indexado por outro conjunto (o $H$),
para tomar um arbitrário membro de $Ha$, basta tomar um arbitrário $h\in H$.
(Lembra da~\ref{picking_elements_from_indexed_sets}?)
Escrevendo então
\quote
Seja $h \in H$.
\endquote
Já temos um arbitrário membro de $Ha$: o $ha$.
%%}}}

%%{{{ warning: what_does_Ha_eq_Hb_really_mean 
\warning.
\label{what_does_Ha_eq_Hb_really_mean}%
Vamos supor que temos uns $a,b\in G$ e algum $H = \set{h_1,\dotsc,h_n}$.
Logo são definidos os
$$
\matrix
\format
\l &~\c~& \c\; & \c\;  & \c\;  & \c\;  & \c\;    & \c\; & \l \\
H  & =  & \{   & h_1,  & h_2,  & h_3,  & \dotsc, & h_n  & \}; \\
Ha & =  & \{   & h_1a, & h_2a, & h_3a, & \dotsc, & h_na & \}; \\
Hb & =  & \{   & h_1b, & h_2b, & h_3b, & \dotsc, & h_nb & \}.
\endmatrix
$$
\endgraf
(1) Agora suponha que sabemos que $Ha = Hb$:
$$
\matrix
\format
\c   &~\c~& \c\; & \c\;  & \c\;  & \c\;  & \c\;    & \c\; & \l \\
Ha   & =  & \{   & h_1a, & h_2a, & h_3a, & \dotsc, & h_na & \} \\
\veq & \\
Hb   & =  & \{   & h_1b, & h_2b, & h_3b, & \dotsc, & h_nb & \}.
\endmatrix
$$
É um \emph{erro grave} concluir que
$$
\matrix
\format
\c   &~\c~& \c\; & \c\;  & \c\;  & \c\;  & \c\;    & \c\; & \l \\
Ha   & =  & \{   & h_1a, & h_2a, & h_3a, & \dotsc, & h_na & \} \\
\veq &    &      & \veq  & \veq  & \veq  &         & \veq & \\
Hb   & =  & \{   & h_1b, & h_2b, & h_3b, & \dotsc, & h_nb & \}.
\endmatrix
$$
A igualdade desses conjuntos nos permite apenas concluir que
cada $h_ia$ é igual a um dos $h_jb$ e vice versa.  Nada mais!
\endgraf
(2) E agora suponha que queremos provar que $Ha = Hb$.
Pela definição de igualdade de conjuntos, precisamos provar $Ha \subset Hb$
e $Ha \supset Hb$.  Mas!  Se a gente conseguir provar
que realmente para todo $i$, $h_ia = h_ib$, isso seria
ainda mais forte, e obviamente suficiente para concluir
que $Ha=Hb$, mas \emph{não necessário}.
%%}}}

%%{{{ x: What can we conclude if for some i, h_i a = h_i b?
\exercise.
O que podemos concluir se no (1) acima para \emph{algum} $i$,
$h_ia = h_ib$?

\solution
Que $a = b$ (pela~(GCL))---e logo que \emph{para todo} $i$,
$h_ia = h_ib$.

\endexercise
%%}}}

%%{{{ x: every_coset_is_nonempty 
\exercise.
\label{every_coset_is_nonempty}%
Nenhuma coclasse de $H$ é vazia.

\solution
Qualquer coclasse de $H$ tem a forma $Ha$ ou $aH$ para
algum $a\in G$.  Observe que o proprio $a \in Ha$, pois
$$
a = \munderbrace {e} {\in H} a \in Ha,
$$
e similarmente $a\in aH$.

\endexercise
%%}}}

%%{{{ x: Ha_eq_H_iff_a_in_H 
\exercise.
\label{Ha_eq_H_iff_a_in_H}%
Sejam $G$ grupo, $H\subgrp G$, e $a \in G$.
$$
Ha = H \iff a \in H.
$$

\solution
\proofpart{\lrdir.}
Suponha $Ha = H$.
Como $e \in H$, então $ea \in Ha$, mas $ea = a$ e pronto.
Numa linha só:
$$
a = ea \in Ha = H.
$$
\crproofpart{\rldir.}
Suponha $a \in H$.
Para provar $Ha = H$ separamos as duas direcções:
{\lrdirset}.
Seja $x \in Ha$, e logo seja $h \in H$ tal que $x = ha$.
Mas $a \in H$ e logo $ha \in H$ pois $H$ é fechado pela operação do grupo.
Ou seja, $x\in H$.
{\rldirset}.
Seja $h \in H$.
Para mostrar que $h \in Ha$ procuramos $h' \in H$ tal que $h = h'a$.
Tome $h' \asseq h\ginv a$ e confirma que $h = h \ginv a a$,
e logo $h \in Ha$ pois $h\ginv a \in H$.
Sabemos disso pois $H$ sendo subgrupo de $G$ é fechado pelos inversos
(logo $\ginv a \in H$) e pela operação também, e logo $h\ginv a \in H$.

\endexercise
%%}}}

\blah.
Uma conseqüência imediata do \ref{Ha_eq_H_iff_a_in_H} é que
$$
a \notin H \iff Ha \neq H.
$$
Mas assim que souber que $a\notin H$ podemos concluir
algo bem mais forte que $Ha \neq H$:

%%{{{ x: a_notin_H_implies_H_and_Ha_disjoint 
\exercise.
\label{a_notin_H_implies_H_and_Ha_disjoint}%
O que?  Como?

\hint
Podemos concluir que:
\emph{se $a \notin H\subgroup G$ então $H$ e $Ha$ são disjuntos.}

\solution
Podemos concluir que:
\emph{se $a \notin H\subgroup G$ então $H$ e $Ha$ são disjuntos:}
Suponha que $H$ e $Ha$ tem algum membro em comum $h$.
Vamos chegar numa contradição, provando assim que
$H\inter Ha=\emptyset$.
Como $h \in Ha$, logo seja $h_1\in H$ tal que $h = h_1a$.
Passando o $h_1$ para o outro lado, temos
$$
\munderbrace {\ginvp{h_1} h} {\in H} = \munderbrace {a} {\notin H}
$$
que é absurdo.

\endexercise
%%}}}

\blah.
E se escolher um $b\in G$ fora do $H$ e fora do $Ha$?

%%{{{ x: every_coset_disjoint_from_all_others 
\exercise.
\label{every_coset_disjoint_from_all_others}%
Mostre que se $a,b \in G$ tais que $b\notin Ha$
então $Hb$ e $Ha$ são disjuntos.
(Que $Hb$ e $H$ são disjuntos já sabemos graças
ao~\ref{a_notin_H_implies_H_and_Ha_disjoint}.)

\solution
Suponha que $Ha$ e $Hb$ tem algum membro em comum $w$.
Logo sejam $h_a,h_b\in H$ tais que $w = h_a a$ e $w = h_b b$.
Logo
$$
h_a a = h_b b
$$
e passando o $h_b$ para o outro lado temos:
$$
\munderbrace {\munderbrace {\ginvp{h_b} h_a} {\in H} a} {\in Ha} = b
$$
que contradiz que $b \notin Ha$.

\endexercise
%%}}}

%%{{{ Q: How many cosets? 
\question.
\emph{Dados um grupo $G$ e $H\subgroup G$, quantas coclasses tem o $H$?
Ou seja, qual é a cardinalidade do conjunto $\setst {Ha} {a\in G}$?}
%%}}}

\blah.
Vamos ver a resposta daqui a pouco (\ref{index_of_subgroup}
e~\ref{lagrange_theorem}).

%%{{{ df: cosetsL_and_cosetsR 
\definition.
\label{cosetsL_and_cosetsR}%
\sdefined {\cosetsL {\sholed H}} {a família das coclasses esquerdas do subgrupo $H$ (grupo implícito)}%
\sdefined {\cosetsR {\sholed H}} {a família das coclasses direitas do subgrupo $H$ (grupo implícito)}%
Vamos denotar a família de todas as coclasses esquerdas
e direitas do $H$ assim:
$$
\xalignat2
\cosetsL H &\defeq \setst {aH} {a \in G}; &
\cosetsR H &\defeq \setst {Ha} {a \in G}.
\endxalignat
$$
Observe que ambos os $\cosetsL H,\cosetsR H$ são indexados
pelo mesmo conjunto $G$.
Como o grupo $G$ é implícito pelo contexto não precisamos especificá-lo
na notação; mas caso que não é, escrevemos $\cosetsLin H G$ e
$\cosetsRin H G$ respectivamente.
%%}}}

%%{{{ lemma: cosets_form_a_partition 
\lemma.
\label{cosets_form_a_partition}%
\ii{partição}%
Sejam $G$ grupo e $H\subgroup G$.
A família de todas as coclasses direitas de $H$
é uma partição de $G$, e a mesma coisa é verdade
sobre a família das suas coclasses esquerdas.
Ou seja, cada uma das famílias $\cosetsL H$
e $\cosetsR H$ é uma partição do $G$.
\sketch.
Para a $\cosetsR H$, por exemplo, precisamos demonstrar:
\beginil
\item{(P1)} $\Union \cosetsR H \supset G$;
ou seja: para todo $x\in G$, existe coclasse $H'$ com $x \in H'$;
\item{(P2)} as coclasses no $\cosetsR H$ são disjuntas duas-a-duas;
\item{(P3)} nenhuma coclasse é vazia ($\emptyset \notin \cosetsR H$).
\endilnoskip
Para o (P1) tomamos um arbitrário $x\in G$ e achamos
uma coclasse de $H$ que o $x$ esteja dentro.
O (P3) já provamos no~\ref{every_coset_is_nonempty}.
Essencialmente provamos o (P2) também,
no~\ref{every_coset_disjoint_from_all_others}.
Mas para variar, demonstramos que para todo $a,b \in G$,
$$
Ha \inter Hb \neq \emptyset \implies Ha=Hb.
$$
Tome um elemento comum $w\in Ha\inter Hb$.  Logo
$$
h_a a = w = h_b b
\qqquad
\text{para alguns $h_a, h_b\in H$}.
$$
Manipulamos a $h_a a = h_b b$ para mostrar que $Ha = Hb$.
\qes
\proof.
Vamos demonstrar que $\cosetsR H$ é uma partição do $G$.
A demonstração que $\cosetsL H$ também é, é similar.
Precisamos provar:
\beginil
\item{(P1)} $\Union \cosetsR H \supset G$;
ou seja: para todo $x\in G$, existe coclasse $H'$ com $x \in H'$;
\item{(P2)} as coclasses no $\cosetsR H$ são disjuntas duas-a-duas;
\item{(P3)} nenhuma coclasse é vazia ($\emptyset \notin \cosetsR H$).
\endilnoskip
(P1) Como $H$ é um grupo, sabemos que $e\in H$, então para qualquer $x\in G$,
temos que $x = ex \in Hx$, ou seja todos os elementos de $G$ pertencem em
alguma coclasse.
(P3) Toda coclasse direita de $H$, tem a forma $Ha$ para algum $a\in G$,
e tem pelo menos um elemento: esse mesmo $a$ (a gente provou
isso no~\ref{every_coset_is_nonempty}).
Para o (P2) suponha que $Ha\inter Hb\neq \emptyset$ e tome $w\in Ha\inter Hb$.
Logo
$$
h_aa = w = h_bb
\qqquad
\text{para alguns $h_a, h_b\in H$}.
$$
Para provar que $Ha = Hb$, mostramos que $Ha\subset Hb$ e $Hb\subset Ha$.
Suponha então que $x \in Ha$, logo $x = ha$ para algum $h\in H$.
Precisamos mostrar que $x \in Hb$.
Calculamos:
$$
\align
x= ha
&= h\paren{\ginv {h_a} h_a}a\\
&= h\ginv {h_a} \paren{h_a a}\\
&= h\ginv {h_a} \paren{h_b b}\\
&= \paren{h \ginv {h_a} h_b}b\\
&\in Hb.
\endalign
$$
A outra direção ($Ha \supset Hb$) é similar.
\qed
%%}}}

%%{{{ thm: cosets_of_H_eq_quoset_G_congmodR 
\theorem.
\label{cosets_of_H_eq_quoset_G_congmodR}%
\ii{partição}%
\ii{relação!de equivalência}%
Sejam $G$ grupo e $H\subgroup G$.
A família $\cosetsR H = \setst {Ha} {a\in G}$ é uma partição do $G$
e sua correspondente relação de equivalência é a congruência $\congR H$
módulo-direito $H$.  Equivalentemente:
$$
\quoset G {\congR H} \;=\; \cosetsR H
$$
\proof.
Vamos denotar por $\eqclassimp a$ a classe de equivalência de
$a\in G$ (através da relação $\congR H$).
Queremos provar que
$\quoset G {\congR H} = \cosetsR H$, ou seja
$$
\setst { \eqclassimp a } {a \in G}
=
\setst { Ha } {a \in G}.
$$
Esses conjuntos são indexados pelo mesmo conjunto (o $G$),
logo basta provar que para todo $a\in G$, $\eqclassimp a = Ha$.
(Veja o~\ref{indexed_sets_equality}.)
\crproofpart{\lrdirset:}
Suponha $x \in \eqclassimp a$.
Logo $x \cong a \pmod H$, ou seja, $x\ginv a \in H$.
Pela definição de $Ha$ então temos
$$
Ha\ni
\munderbrace {\paren{x\ginv a}} {\in H} a
= x\paren{\ginv a a}
= x.
$$
\proofpart{\rldirset:}
Suponha que $x\in Ha$.
Logo $x=ha$ para algum $h\in H$ e queremos mostrar que $ha\in\eqclassimp a$,
ou seja $ha \cong a \pmod H$.
Confirmamos:
$$
\paren{ha} \ginv a
= h \paren{a\ginv a}
= h
\in H
$$
e pronto.
\qed
%%}}}

%%{{{ Q: Why the RIGHT cosets? 
\question.
Por que as coclasses \emph{direitas?}
Tudo até agora na nossa teoria foi justo e simétrico.
Nenhuma lei de grupo e nenhum resultado que provamos
favoreceu um lado ou o outro.
Imagine se a gente tivesse conseguido, por exemplo, provar a lei
de cancelamento para um lado e não para o outro.  Seria bizarro,
pois todos os nossos dados trataram os dois lados na mesma maneira.
E, até pior, nossa relação de congruência já provamos que é simétrica!
Como pode ser então que ela favoreceu a família das coclasses direitas?
Por que o $\quoset G {\congR H}$ acabou sendo a partição $\cosetsR H$
e não a $\cosetsL H$?
%%}}}
\spoiler.

%%{{{ A 
\blah Resposta.
Na questão acima tem uma mentira!
Tem uma coisa que usamos aqui que não tratou os dois lados em maneira igual!
É a relação de congruência módulo $H$!
No seu lado \emph{direito} aparece o inverso dum membro do grupo.
Por isso não seria justo usar a notação que temos usado!
Começando agora, vamos usar a notação justa e própria
$$
a \cong b \pmodR H \iff a\ginv b \in H \iff b\ginv a \in H.
$$
%%}}}

%%{{{ Q: How would you define pmodL ?
\question.
Como tu definarias (diretamente) a relação de equivalência que corresponde
à partição das coclasses esquerdas?
%%}}}
\spoiler.

%%{{{ df: equivalence_mod_subgroup 
\definition Equivalência módulo subgrupo.
\label{equivalence_mod_subgroup}%
\tdefined{equivalência}[módulo subgrupo]%
\tdefined{módulo!subgrupo}%
\sdefined
    {\sholed a \cong {\sholed b} \pmodL {\sholed H}}
    {$a,b$ são equivalentes módulo-esquerdo $H \subgroup G$}%
\sdefined
    {\sholed a \cong {\sholed b} \pmodR {\sholed H}}
    {$a,b$ são equivalentes módulo-direito $H \subgroup G$}%
\sdefined
    {\sholed a \congL {\sholed H} {\sholed b}}
    {$a \cong b \pmodL H$}%
\sdefined
    {\sholed a \congR {\sholed H} {\sholed b}}
    {$a \cong b \pmodR H$}%
Seja $G$ grupo e $H\subgroup G$.
Definimos
$$
\xalignat2
a \cong b \pmodL H &\defiff \ginv a b \in H; &
a \cong b \pmodR H &\defiff a \ginv b \in H.
\endxalignat
$$
Usamos também as notações $a \congL H b$ e $a \congR H b$.
%%}}}

%%{{{ remark: same is true for left cosets 
\remark.
Voltando ao~\ref{cosets_of_H_eq_quoset_G_congmodR},
simetricamente temos
$\quoset G {\congL H} = \cosetsL H$,
onde $\cosetsL H = \setst {aH} {a\in G}$.
%%}}}

%%{{{ x: a_ginvb_smells_like_division 
\exercise.
\label{a_ginvb_smells_like_division}%
A operação $\tup{a,b} \mapsto a\ginv b$ tá aparecendo mais e mais.
Como tu chamaria essa operação binária?

\solution
Um nome que faz sentido pensar aqui seria \emph{divisão}, se pensar
multiplicativamente; e \emph{subtraição}, se pensar aditivamente.
Mas pra ser mais específicos ainda deveriamos mudar incluir como
adjectivo o lado: \emph{divisão direita} ou \emph{subtraição direita}.
Como assim divisão/subtraição ``direita''?  Nunca escutamos isso
antes, mas isso é porque nossa operação (multiplicação de números
ou adição de números) foi comutativa, então $a\ginv b$ e $\ginv b a$
eram sempre o mesmo número.  Mas aqui no contexto geral de grupo
podem ser diferentes, então faz sentido incluir os lados mesmo!

\endexercise
%%}}}

%%{{{ Does it still seem weird? 
\note.
Talvez ainda parece estranho:
o que a afirmação <<$a\ginv b \in H$>> tem a ver com a
<<os $a,b$ pertencem à mesma coclasse direita de $H$>>?
Observe que, se $a,b$ pertencem à mesma coclasse direita de $H$,
então para algum $c \in G$ temos $a,b \in Hc$, e logo
$a = h_a c$ e $b = h_b c$ para alguns $h_a, h_b \in H$.
Vamo lá:
$$
a \ginv b \in H
\iff
h_a c \ginvp{h_b c} \in H
\iff
h_a c \ginv c \ginv {h_b} \in H
\iff
h_a \ginv {h_b} \in H
\quad\text{que é verdade.}
$$
Conversamente,
$$
a\ginv b \in H
\implies
\paren{a \ginv b} b \in Hb
\implies
a \paren{\ginv b b} \in Hb
\implies
a \in Hb
$$
e logo $a,b$ pertencem à mesma coclasse de $H$: $a,b \in Hb$.
Espero que ficou mais claro agora.
%%}}}

%%{{{ Actors 
\note Atores.
Fixe um $a \in G$.  Como tu provaste
no~\ref{group_actors_are_bijective_proof}, isso determina duas
funções $G \to G$, que no problema chamei de $f,g$.
Vamos relembrá-las e dar um nome e notação especial:
%%}}}

%%{{{ df: group_actors
\definition Atores.
\label{group_actors}%
Sejam $G$ grupo e $a\in G$.  Considere as operações de
``operar com $a$ pela esquerda'' e pela direita
$$
\xalignat2
&\lam x {ax} & &\lam x {xa}.
\intertext{que vamos chamar de $a$-\dterm{ator} esquerdo e direito respectivamente.
As notações que vamos usar para essas funções são:}
\actorL a     & \eqtype G \to G & \actorR a     & \eqtype G \to G \\
\actorL a (x) & = ax            & \actorR a (x) & = xa. \\
\endxalignat
$$
Ainda mais, para todo par de membros $a,b\in G$ temos um ator definido pela
$$
\align
\actorS a b     &\eqtype G \to G \\
\actorS a b (x) &= axb.
\endalign
$$
%%}}}

%%{{{ x: actorS_as_composition_of_L_and_R 
\exercise.
\label{actorS_as_composition_of_L_and_R}%
$\actorS a b = \actorL a \fcom \actorR b = \actorR b \fcom \actorL a$.

\solution
Sejam $a,b \in G$.
Calculamos:
\compute
\actorS a b x
&= axb                                    \by {def.~$\actorS a b$}
&= a(xb)                                  \by {assoc.}
&= a\paren{ \actorR b x }                 \by {def.~$\actorR b$}
&= \actorL a {\paren{ \actorR b x }}      \by {def.~$\actorL a$}
&= \paren{\actorL a \fcom \actorR b} (x). \by {def.~$\fcom$}
\endcompute
Provamos a outra igualdade similarmente.

\endexercise
%%}}}

%%{{{ lemma: group_actors_are_bijective 
\lemma.
\label{group_actors_are_bijective}%
Todos as funções-atores são bijecções.
\proof \proofname~já feita no~\ref{group_actors_are_bijective_proof}.
\qed
%}}}

%%{{{ lemma: cosets_are_equinumerous_finite_case 
\lemma.
\label{cosets_are_equinumerous_finite_case}%
Todas as coclasses dum finito $H\subgrp G$ têm a mesma
quantidade de elementos com o próprio $H$ (e logo entre si também).
\sketch.
Seja $n\in\nats = \card{H}$, e sejam $h_1,\dotsc,h_n$ os membros de $H$:
$$
\align
H  &= \set{h_1, h_2, h_3, \dotsc, h_n}.
\intertext{Para qualquer $a\in G$ temos}
Ha &= \set{h_1a, h_2a, h_3a, \dotsc, h_na}.
\endalign
$$
Queremos provar que a quantidade dos dois conjuntos acima
é a mesma.  Primeiramente, como poderia ser diferente?
Ambos parecem ter $n$ elementos, mas isso não garanta
cardinalidade $n$ pois pode ter repetições no $Ha$.
No $H$ não pode, pois definimos o $n$ para ser a cardinalidade de $H$.
Basta provar então que os
$$
h_1a, h_2a, h_3a, \dotsc, h_na
$$
são distintos dois-a-dois, e logo, são $n$ também.
\qes
\proof.
Seja $n\in\nats = \card{H}$, e sejam $h_1,\dotsc,h_n$ os membros de $H$:
$$
\align
H  &= \set{h_1, h_2, h_3, \dotsc, h_n}.
\intertext{Para qualquer $a\in G$ temos}
Ha &= \set{h_1a, h_2a, h_3a, \dotsc, h_na}.
\endalign
$$
Queremos provar que o $Ha$ também tem $n$ elementos.
Basta provar então que os
$$
h_1a, h_2a, h_3a, \dotsc, h_na
$$
são distintos dois-a-dois, e logo, são $n$ também.
Mas isso é imediato:
\compute
h_ua = h_va
&\implies h_u = h_v \by {(GCR)}
&\implies u = v     \by {pois os $h_i$'s são distintos dois-a-dois}
\endcompute
A demonstração sobre as coclasses esquerdas é similar.
\qed
%%}}}

%%{{{ remark: cosets are equinumerous even when infinite 
\remark.
O~\ref{cosets_are_equinumerous_finite_case} é
válido até no caso que $H$ é infinito!
Mas não se preocupe agora com isso,
deixe para o~\ref{cosets_are_equinumerous}.
%%}}}

\blah.
Vamos agora generalizar a notação que usamos as coclasses de
``multiplicação de subgrupo por elemento'' para
``multiplicação de subgrupo por subgrupo''.

%%{{{ df: HK 
\definition.
\label{HK_of_groups}%
Seja $G$ grupo e $H,K\subgroup G$.  Definimos
$$
HK \defeq \setst {hk} {h\in H,\ k\in K}.
$$
%%}}}

%%{{{ x: group_juxtaposition_is_associative 
\exercise.
Demonstre que a operação denotada por juxtaposição
no~\ref{HK} é associativa.

\endexercise
%%}}}

%%{{{ Q: are HK and KH subgroups of G? 
\question.
$HK = KH$?
$HK \subgroup G$?
$KH \subgroup G$?
%%}}}

%%{{{ eg: calculate_HK_KH_S3 
\example.
\label{calculate_HK_KH_S3}%
No grupo $\sym 3$, sejam seus subgrupos
$$
\xalignat2
H &\leteq \set{ \id, \phi }
&
K &\leteq \set{ \id, \psi\phi }.
\endxalignat
$$
Calcule os $HK$ e $KH$ e decida se $HK=KH$ e se $HK$ e $KH$ são subgrupos de $\sym 3$.

\solution%%{{{
Pela definição
$$
\xalignat2
HK &= \setst {hk} {h\in H,\ k\in K}
& 
KH &= \setst {kh} {h\in H,\ k\in K}
\\
&= \set{
\id\compose\id,
\id\compose(\psi\compose\phi),
\phi\compose\id,
\phi\compose(\psi\compose\phi)
}
&
&= \set{
\id\compose\id,
\id\compose\phi,
(\psi\compose\phi)\compose\id,
(\psi\compose\phi)\compose\phi)
}
\\
&= \set{ \id, \psi\phi, \phi, \phi\psi\phi }
&
&= \set{ \id, \phi, \psi\phi, \psi\phi^2 }
\\
&= \set{ \id, \psi\phi, \phi, \psi^2}
&
&= \set{ \id, \phi, \psi\phi, \psi }.
\endxalignat
$$
Observamos que $HK\neq KH$ (pois, por exemplo, $\psi \in KH$ mas $\psi \notin HK$).
E nenhum deles é subgrupo de $\sym 3$.
%%}}}
\endexample
%%}}}

\blah.
Então descobrimos que, em geral, nem $HK=KH$, nem $HK\subgroup G$,
nem $KH\subgroup G$ são garantidos.
Pode acontecer que $HK \subgroup G$ mas $KH \not\subgroup G$?
E o que a igualdade $HK=KH$ tem a ver com a ``subgrupidade'' dos $HK$ e $KH$?
Vamos responder em todas essas perguntas com o teorema seguinte:

%%{{{ thm: HK = KH <=> HK subgrp G 
\theorem.
\label{HK_equals_KH_iff_HK_subgroup}%
Seja $G$ grupo e subgrupos $H,K \subgrp G$.  Então:
$$
HK = KH
\iff
HK \subgrp G
$$
\sketch.
Para a direção \lrdir, precisamos mostrar que $HK$ é fechado
sobre a operação e fechado sobre os inversos.
Tomamos aleatórios $h_1k_1,h_2k_2\in HK$ e aplicando as propriedades
de grupo e nossa hipótese, mostramos que $(h_1k_1)(h_2k_2) \in HK$.
Similarmente para os inversos:
consideramos um arbitrário elemento $hk\in HK$ e mostramos que seu
inverso $\ginvp{hk} \in HK$.
Aqui, alem da hipótese precisamos o~\ref{inverse_of_product_in_group}.
Para a direção \rldir, mostramos as ``$\subset$'' e ``$\supset$''
separadamente, usando idéias parecidas.
\qes
%%{{{ proof 
\proof.
\lrdir:
Precisamos mostrar que $HK$ é fechado sobre a operação e fechado sobre os inversos.
Tomamos aleatórios $h_1k_1,h_2k_2\in HK$ e calculamos:
\compute
(h_1k_1)(h_2k_2)
&= h_1(k_1h_2)k_2 \by {ass.}
&= h_1(h_3k_3)k_2\quad\text{para alguns $h_3\in H$ e $k_3 \in K$} \by {$k_1h_2\in KH = HK$}
&= (h_1h_3)(k_3k_2)\by {ass.}
&\in HK
\endcompute
Para os inversos temos:
$$
\ginvp {h_1k_1} = \ginv{k_1} \ginv{h_1} \in KH = HK.
$$
\endgraf
\rldir:
Mostramos as ``$\subset$'' e ``$\supset$'' separadamente.
``$\subset$'':
Tome $x \in HK$, logo $x^{-1} \in HK$ e $x^{-1} = hk$ \emph{para alguns}
$h\in H$ e $k\in K$.  Como $H$ e $K$ são sub\emph{grupos} de $G$ seus inversos
também estão em $H$ e $K$ respectivamente.
Mas
$$
x = \ginvp{\ginv x} = \ginvp{hk} \ginv k \ginv h \in KH.
$$
``$\supset$'':
Tome $x \in KH$, logo $x = kh$ \emph{para alguns} $k\in K$, $h\in H$.
Logo $\ginv k \in K$ e $\ginv h \in H$.
Como $HK\subgrp G$, basta apenas provar que $\ginv x \in HK$ pois isso
garantará que $x \in HK$ também.
Realmente, $\ginv x = \ginvp{kh} = \ginv h \ginv k \in HK$.
\qed
%%}}}
%%}}}

\endsection
%%}}}

%%{{{ Lagrange theorem 
\section O teorema ``de Lagrange''.
\label{Lagrange_theorem}%

\blah.
Talvez não é tão óbvio que temos já descoberto um teorema interessante!
Ele é conhecido como \emph{teorema de \Lagrange[teorema]Lagrange},
mesmo que não foi \Lagrange{}Lagrange que o provou na sua generalidade,
mas apenas num caso especifico---mais detalhes nas notas históricas.
Vamos formular e provar o teorema, mas primeiro uma definição simples
e relevante.

%%{{{ df: index_of_subgroup 
\definition Índice.
\label{index_of_subgroup}%
\tdefined{grupo}[índice de subgrupo]%
\sdefined {\groupind {\sholed G} {\sholed H}} {o índice do subgrupo $H$ no grupo $G$}%
\sdefined {\altgroupind {\sholed G} {\sholed H}} {$\groupind G H$ (notação alternativa)}%
Sejam $G$ grupo e $H\subgroup G$.
O \dterm{índice} de $H$ no $G$ é o número de coclasses direitas de $H$ no $G$.
O denotamos com os símbolos $\groupind G H$ ou $\altgroupind G H$.
%%}}}

%%{{{ remark: it doesn't matter if you choose cosetsL or cosetsR 
\remark.
Escolhemos acima as coclasses direitas, mas isso não é essencial:
escolhendo as esquerdas o número ia sempre ser o mesmo,
como tu provarás agora:
%%}}}

%%{{{ x: number_of_cosets_independend_of_side 
\exercise.
\label{number_of_cosets_independend_of_side}%
Sejam $G$ grupo, $H\subgrp G$.
Prove que o número de coclasses à esquerda de $H$ é o mesmo
com o número de coclasses à direita de $H$:
$$
\card{\cosetsL H} = \card{\cosetsR H}.
$$

\endexercise
%%}}}

%%{{{ thm: lagrange_theorem 
\theorem Lagrange.
\label{lagrange_theorem}%
\Lagrange[teorema]%
\ii{teorema}[Lagrange]%
Seja $G$ grupo finito e $H\subgroup G$.
Então $\groupord H \divides \groupord G$.
\proof.
Sabemos que o $G$ pode ser particionado pelos right cosets de $H$,
e que cada um deles tem a mesma cardinalidade $o(H)$ com o próprio $H$.
Logo,
$$
\gord G = \groupind G H \gord H,
$$
e temos o que queremos provar.
\qed
%%}}}

%%{{{ remark: lagrange_reformulated 
\remark.
\label{lagrange_reformulated}%
O teorema de Lagrange então afirma que
$$
\groupind G H  =  \card G / \card H.
$$
%%}}}

%%{{{ eg: HK and KH had no chances of being subgroups 
\example eles não tinham nenhuma chance de ser subgrupos.
No~\ref{calculate_HK_KH_S3} achamos que
$$
\xalignat2
HK &= \set{ \id, \psi\phi, \phi, \psi^2} &
KH &= \set{ \id, \phi, \psi\phi, \psi }.
\endxalignat
$$
E afirmamos que nenhum dos dois é subgrupo do $G$.
Por quê?
Em vez de fazer o trabalho tedioso e verificar se cada um
dos $HK,KH$ é um subgrupo do $\sym 3$, observamos que cada
um tem $4$ elementos---verifique que são \emph{realmente} $4$.
Mas, graças ao Lagrange~(\refn{lagrange_theorem}) $\sym 3$ não
tem subgrupos de ordem $4$, pois $4$ não divide o $6$.  Pronto.
\endexample
%%}}}

%%{{{ Corollaries as exercises 
\note Corolários.
{\Lagrange[teorema!corolário]}%
Graças ao teorema de Lagrange~\refn{lagrange_theorem}
ganhamos muitos corolários diretamente,
como tu vai verificar agora resolvendo os exercícios seguintes:
%%}}}

%%{{{ x: subgroups_of_group_with_prime_order_proof 
\exercise.
\label{subgroups_of_group_with_prime_order_proof}%
Seja $G$ grupo com $\gord G = p$, onde $p$ primo.
Quais são todos os subgrupos de $G$?

\hint
Se $H\subgroup G$, pelo teorema de Lagrange temos que
$\gord H \divides \gord G$.  Quais são os divisores de $\gord G$?

\solution
Se $H\subgroup G$, pelo teorema de Lagrange temos que
$\gord H \divides \gord G = p$, logo $\gord H = 1$ ou $p$.
No primeiro caso $H = \set e$, no segundo, $H = G$.
Ou seja:
\emph{um grupo com ordem primo não tem subgrupos não-triviais}.

\endexercise
%%}}}

%%{{{ corollary: subgroups_of_group_with_prime_order 
\corollary.
\label{subgroups_of_group_with_prime_order}%
Um grupo com ordem primo não tem subgrupos não-triviais.
\proof Demonstrado no~\ref{subgroups_of_group_with_prime_order_proof}.
\qed
%%}}}

%%{{{ corollary: order_of_a_divides_order_of_G 
\corollary.
\label{order_of_a_divides_order_of_G}%
Seja $G$ grupo finito e $a\in G$.  Então $\gord a \divides \gord G$.
\proof Demonstrarás no~\ref{order_of_a_divides_order_of_G_proof}.
\qed
%%}}}

\blah.
Já resolveste o~\ref{identifier_of_all}?
O próximo corolário oferece uma resolução mais elegante:

%%{{{ corollary: a_to_the_order_of_G_is_e 
\corollary.
\label{a_to_the_order_of_G_is_e}%
Seja $G$ grupo finito e $a\in G$.
Então $a^{\gord G} = e$.
\proof Demonstrarás no~\ref{a_to_the_order_of_G_is_e_proof}.
\qed
%%}}}

%%{{{ x: order_of_a_divides_order_of_G_proof 
\exercise.
\label{order_of_a_divides_order_of_G_proof}%
Demonstre o~\ref{order_of_a_divides_order_of_G}.

\hint
Se achar um subgrupo $H\subgroup G$ com $\gord H = \gord a$,
acabou (graças ao Lagrange).

\hint
Lembra que $\generate a$ é um subgrupo do $G$\dots?

\hint
\dots e que sua ordem é $\gord {\generate a} = \gord a$?

\solution
Sabemos que $\generate a$ é um subgrupo de $G$, com ordem
$\gord {\generate a} = \gord a$,
e pelo teorema de Lagrange, como $\generate a \subgroup G$
e $G$ é finito temos
$$
\gord a = \gord {\generate a} \divides \gord G.
$$

\endexercise
%%}}}

%%{{{ x: a_to_the_order_of_G_is_e 
\exercise.
\label{a_to_the_order_of_G_is_e_proof}%
Demonstre o~\ref{a_to_the_order_of_G_is_e}.

\hint
\ref{order_of_a_divides_order_of_G}.

\solution
Graças ao~\ref{order_of_a_divides_order_of_G} temos que
$\gord a \divides \gord G$, ou seja, $\gord G = k\gord a$ para algum
$k\in\ints$.
Agora calculamos:
$$
a^{\gord G}
= a^{k\gord a}
= a^{\gord a k}
= \paren{a^{\gord a}}^k
= e^k
= e.
$$

\endexercise
%%}}}

%%{{{ The idea behind Lagrange 
\note A idéia atrás do teorema de Lagrange.
Temos um grupo finito $G$, e um subgrupo $H \subgrp G$.
Vamos conseguir arrumar \emph{todos os membros de $G$}
numa tabela:
$$
\matrix
\format
& \quad\c\quad & \quad\c\quad & \quad\c\quad & \ \ \c\ \  & \quad\c\quad \\
& \bullet  & \bullet  & \bullet  & \dots   & \bullet\\
& \bullet  & \bullet  & \bullet  & \dots   & \bullet\\
& \phantom\bullet \\
& \vdots   & \vdots   & \vdots   & \ddots  & \vdots \\
& \phantom\bullet \\
& \bullet  & \bullet  & \bullet  & \dots   & \bullet
\endmatrix
$$
Sua primeira linha será feita por todos os membros de $H$.
Sabendo que $G$ é finito, temos que $H$ também é, e
logo essa primeira linha será finita também.
Vamos chamar $n$ a $\gord H$, e logo $h_1,\dots,h_n$
os $n$ membros de $H$.
Então a primeira linha tem tamanho $n$, e é a seguinte:
$$
\matrix
\format
\l   &\l\qqquad & \l\quad & \l\quad & \l\quad & \l\quad & \l    \\
H\phantom{a''} &:
& h_1\phantom{a''}
& h_2\phantom{a''}
& h_3\phantom{a''}
& \dots
& h_n\phantom{a''}\\
\endmatrix
$$
Vamos mostrar como botar o resto dos membros de $G$ nessa tabela.
Na verdade, tem uma chance que não tem mais elementos para
botar: isso acontece se $H = G$.  Nesse caso não temos
mais nada pra fazer, já conseguimos o que queriamos.
Mas, no caso geral, existem membros de $G$ fora do $H$.
Seja $a\in G$ um deles, ou seja, $a \notin H$.
Agora bota todos os elementos seguintes na tabela:
$$
\matrix
\format
\l   &\l\qqquad & \l\quad & \l\quad & \l\quad & \l\quad & \l    \\
H\phantom{a''} &:
& h_1\phantom{a''}
& h_2\phantom{a''}
& h_3\phantom{a''}
& \dots
& h_n\phantom{a''}\\
Ha   &:         & h_1 a   & h_2 a   & h_3 a   & \dots   & h_n a \\
\endmatrix
$$
Agora \emph{afirmamos} sobre os elementos novos que:
\beginil
\item{--} eles são realmente $n$, ou seja, distintos dois-a-dois;
\item{--} eles são realmente novos, ou seja, nenhum deles é igual a algum
dos membros que já estava na tabela.
\endil
Se provar essas afirmações, saberemos que temos exatamente $2n$
membros de $G$ já arrumados na nossa tabela.
E depois?
Caso que $G$ não tenha mais elementos, não temos nada mais pra fazer,
pois já conseguimos o que queriamos.
Caso que tenha membros de $G$ fora deles, seja $a'\in G$ um deles,
ou seja, $a'$ não é nenhum dos membros já listados.
E agora bota todos os elementos seguintes na tabela:
$$
\matrix
\format
\l   &\l\qqquad & \l\quad & \l\quad & \l\quad & \l\quad & \l    \\
H\phantom{a''} &:
& h_1\phantom{a''}
& h_2\phantom{a''}
& h_3\phantom{a''}
& \dots
& h_n\phantom{a''}\\
Ha   &:         & h_1 a   & h_2 a   & h_3 a   & \dots   & h_n a \\
Ha'  &:         & h_1 a'  & h_2 a'  & h_3 a'  & \dots   & h_n a'
\endmatrix
$$
Novamente, \emph{afirmamos} sobre os elementos novos que:
\beginil
\item{--} eles são realmente $n$;
\item{--} eles são realmente novos.
\endil
\emph{E por aí vai.}
Sabemos que o processo vai terminar depois duma quantidade finita
de passos, pois o $G$ é finito.
Quando terminar então, teriamos conseguido arrumar todos os seus
membros numa tabela de largura $n$ e altura igual à quantidade
de coclasses direitas do $H$ no $G$, ou seja,
altura $m \asseq \groupind G H$.
$$
\matrix
\format
\l   &\l\qqquad & \l\quad & \l\quad & \l\quad & \l\quad & \l    \\
H    &:         & h_1     & h_2     & h_3     & \dots   & h_n   \\
Ha   &:         & h_1 a   & h_2 a   & h_3 a   & \dots   & h_n a \\
Ha'  &:         & h_1 a'  & h_2 a'  & h_3 a'  & \dots   & h_n a'\\
& \phantom\bullet \\
\phantom h\vdots&\phantom:& \phantom h\vdots& \phantom h\vdots & \phantom h\vdots & \ddots  & \phantom h\vdots\\
& \phantom\bullet \\
Ha'' &:         & h_1 a'' & h_2 a'' & h_3 a'' & \dots   & h_n a''
\endmatrix
$$
\endgraf
A única coisa que basta fazer então, é provar todas as afirmações que
deixamos sem prova acima.
Mudando os nomes dos $a, a', \dots, a''$ para $a_2, a_3, \dots, a_m$,
queremos provar para quaisquer $i,j\in\set{2,\dotsc,m}$ as seguintes:%
\footnote{Talvez aparece estranha a escolha de índices que começa com ${}_2$,
mas é muito conveniente aqui, pois o índice final ${}_m$ já seria a
própria altura da tabela.
Se ficou triste por a falta do $a_1$, tome $a_1\asseq e$ e vai dar certo:
a primeira coclasse de $H$ (o próprio $H$), seria o $Ha_1$ nesse caso.
Mas nada disso é necessário!}
\beginil
\item{(1)} $h_1a_i, h_2a_i, \dotsc, h_na_i$ são realmente $n$, ou seja,
distintos dois-a-dois;
\item{(2)} $h_1a_i, h_2a_i, \dotsc, h_na_i$ são realmente novos, ou seja:
\itemitem{(2a)} nenhum deles é igual a algum dos $h_1,h_2,\dotsc,h_n$;
\itemitem{(2b)} nenhum deles é igual a algum dos $h_1a_j, h_2a_j, \dotsc, h_na_j$
para $j < i$.
\endil
\endgraf
Nenhuma delas é difícil pra provar---na verdade, \emph{nos já demonstramos} todas.%
\footnote{A~(1) é o~\ref{cosets_are_equinumerous_finite_case};
a~(2) é o~(ii) do~\refn{cosets_form_a_partition}.}
Mesmo assim, bora prová-las novamente aqui com uns ``one-liners'':
$$
\gather
h_ua_i = h_va_i \implies h_u = h_v \implies u=v;\tag{1}\\
h_ua_i = h_v    \implies a_i = \ginv{h_u}h_v \implies \text{$a_i \in H$, que é absurdo};\tag{2a}\\
h_ua_i = h_va_j \implies a_i = \ginv{h_u}h_va_j \implies \text{$a_i \in Ha_j$, que é absurdo}.\tag{2b}
\endgather
$$
Pronto!
%%}}}

%%{{{ warning: converse_of_lagrange_is_invalid 
\warning.
\label{converse_of_lagrange_is_invalid}%
Não seja tentado para aplicar o ``converso''.
Sabendo que $d \divides \gord G$, \emph{não podemos concluir}
que o $G$ possui subgrupos de ordem $d$ (\ref{converse_of_lagrange_is_invalid_proof})
%%}}}

%%{{{ x: dividing_the_additive_group_of_ints 
\exercise dividindo o grupo aditivo dos inteiros.
\label{dividing_the_additive_group_of_ints}%
Qual é o índice do $\sset {4\ints} + \subgrp \sset \ints +$?  Generalize para o $m\ints$.

\endexercise
%%}}}

%%{{{ x: dividing_the_additive_group_of_reals 
\exercise dividindo o grupo aditivo dos reais.
\label{dividing_the_additive_group_of_reals}%
Qual o $\groupind {\sset \ints +} {\sset \reals +}$?

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Number_theory_revisited 
\section Teoria dos números revisitada.
\label{Number_theory_revisited}%

%%{{{ x: the_multiplicative_group_Zp 
\exercise.
\label{the_multiplicative_group_Zp}%
Seja $p$ primo e defina
$\cal Z_p = \sset {\finord p \setminus \set0} {\ntimes}$
onde $\ntimes$ é a multiplicação módulo~$p$.
Mostre que $\cal Z_p$ é um grupo e ache sua ordem.

\endexercise
%%}}}

%%{{{ x: the_multiplicative_group_Zn 
\exercise.
\label{the_multiplicative_group_Zn}%
Seja $n\in\nats$ com $n>1$ e defina
$\cal Z_n = \sset {\setst {a \in \finord n} {\gcd a n = 1}} {\ntimes}$
onde $\ntimes$ é a multiplicação módulo~$n$.
Mostre que $\cal Z_n$ é um grupo e ache sua ordem.

\endexercise
%%}}}

\blah.
Já estamos em posição de ganhar o ``teorema pequeno de Fermat'' e sua
generalização, o teorema de congruências
de~\Euler{}Euler~\refn{euler_congruence_theorem}
como um corolário\Lagrange[teorema!corolário]{} fácil
das nossas novas ferramentas grupoteóricas.

%%{{{ cor: euler_congruence_theorem_as_corollary_of_lagrange 
\corollary Teorema de Euler.
\label{euler_congruence_theorem_as_corollary_of_lagrange}%
Sejam $a,m\in\ints$ com $\gcd a m = 1$.
Então
$$
a^{\tot m} \cong 1 \pmod m.
$$
\sketch.
Conseqüência do teorema de~\Lagrange{}Lagrange~\refn{lagrange_theorem}
graças ao~\ref{the_multiplicative_group_Zn}.
\qes
%%}}}

\blah.
Ainda mais resultados podem ser derivados como
corolários\Lagrange[teorema!corolário]{} do
teorema de Lagrange:
no~\ref{euclids_theorem_as_corollary_of_lagrange}
por exemplo tu ganhas o fato que tem uma
infinidade de primos
(teorema de~\Euclid{}Euclides, \refn{primes_is_infinite}).

\endsection
%%}}}

%%{{{ The_quotient_group 
\section O grupo quociente.
\label{The_quotient_group}%

%%{{{ As soon as you've got a subgroup 
\note Assim que tiver um subgrupo\dots.
Vamos começar com um certo grupo $G$, bagunçado assim:
$$
\tikzpicture
\tikzi quogrpbase;
\tikzi quogrpoutsidemess;
\tikzi quogrpinsidemess;
\endtikzpicture
$$
Identificamos nele um subgrupo $H \subgroup G$:
$$
\tikzpicture
\tikzi quogrpbase;
\tikzi quogrpoutsidemess;
\tikzi quogrpsubgroupelems;
\node at (N) {$H$};
\endtikzpicture
$$
Assim que fizermos isso, o grupo toda se arruma em
dua maneiras, uma a partir das coclasses esquerdas
e uma a partir das direitas:
$$
\xalignat2
\cosetsL H &=
\gathered
\tikzpicture
\tikzi quogrppartitionednonames;
\tikzi quogrpLpartitionedmistake;
\endtikzpicture
\endgathered
&
\cosetsR H &=
\gathered
\tikzpicture
\tikzi quogrppartitionednonames;
\tikzi quogrpRpartitioned;
\endtikzpicture
\endgathered
\endxalignat
$$
%%}}}

%%{{{ Q: what is wrong with the picture above? 
\question.
Tem algo errado na figura acima.
O que é?
%%}}}
\spoiler.

%%{{{ A: we should have used different names 
\blah Resposta.
Não sabemos que cada um dos representantes que desenhamos
na partição $\cosetsL H$ vai acabar sendo um representante
da correspodente coclasse direita.  Pode ser, por exemplo
que o $q \in Hp$, e logo $Hp = Hq$.  Para formar a partição
escolhemos cada vez um membro fora das coclasses que já
formamos, mas ninguém garanta que andando pelas coclasses
esquerdas e esclohendo os $p,q,r,s,t,u,v$, vamos conseguir
escolher os mesmos como representantes das coclasses
direitas.
Em geral então, a imagem deve ser alterada para usar
nomes diferentes nos representantes, por exemplo:
$$
\xalignat2
\cosetsL H &=
\gathered
\tikzpicture
\tikzi quogrppartitionednonames;
\tikzi quogrpLpartitioned;
\endtikzpicture
\endgathered
&
\cosetsR H &=
\gathered
\tikzpicture
\tikzi quogrppartitionednonames;
\tikzi quogrpRpartitioned;
\endtikzpicture
\endgathered
\endxalignat
$$
%%}}}

%%{{{ eg: cosets_of_K_subgroup_S3 
\example.
\label{cosets_of_K_subgroup_S3}%
Considere o subgrupo $K \subgroup \sym 3$:
$$
K \leteq \set{ \id, \psi\phi }.
$$
Calcule todos os left e right cosets de $K$ no $\sym 3$,
e decida se as duas colecções são iguais.

\solution
Queremos calcular primeiramente todas as coclasses de $K$.
Como $\gord K = 2$, e o $G$ tem $6$ membros em total,
sabemos que o $K$ tem $3$ coclasses esquerdas, e $3$ coclasses direitas:
$$
\xalignat4
\text{esquerdas:} &  & K &= \set {\id, \psi\phi }  &   \holed? K &= \set{\holed?,\holed?}  &  \holed? K &= \set{ \holed?, \holed? }   \\
\text{direitas:}  &  & K &= \set {\id, \psi\phi }  &   K\holed?  &= \set{\holed?,\holed?}  &  K\holed?  &= \set{ \holed?, \holed? }
\endxalignat
$$
Vamos escolher o primeiro representante para escrever a primeira coclasse esquerda ``própria'' de $K$.
Temos $4$ opções, pois se escolher qualquer um dos dois membros do $K$, vamos ``cair'' na mesma coclasse $K$.
Escolhemos o $\psi$.  Calculamos:
$$
\psi K = \set { \psi, \psi\psi\phi } = \set { \psi, \psi^2\phi } = \set { \psi, \phi\psi }.
$$
Observe que seria a mesma coclasse esquerda, se tivemos escolhido o $\phi\psi$.
Vamos calcular a última.  Qual seria o represetante agora?
Precisamos evitar todos os membros de $K$ e de $\psi K$.
Vamos escolher o $\phi$, e bora calular o $\phi K$.  Ou não?
Não precisamos fazer nenhum cálculo, pois so sobraram $2$ membros de $\sym 3$, então esses $2$ formam a última coclasse esquerda:
$$
\phi K = \set { \phi, \psi^2 }.
$$
Basta calcular as coclasses direitas agora.  Para a primeira, escolhemos de novo o $\psi$, já que observamos que $\psi\notin K$.  Calculamos:
$$
K \psi = \set { \psi, \psi\phi\psi } = \set { \psi, \phi }.
$$
Qual seria o representante ta próxima?  Aqui não pode ser novamente o $\phi$, pois o $\phi$ apareceu no $K\psi$.
Escolhemos um dos dois restantes então, vamos tomar o $\psi^2$, e junto com o último restante ele forma a última coclasse direita:
$$
K \psi^2 = \set { \psi^2, \phi\psi }.
$$
Finalmente achamos todas:
$$
\xalignat2
\cosetsL K &= \set {
\aligned
     K &= \set {\id, \psi\phi}, \\
\psi K &= \set {\psi, \phi\psi}, \\
\phi K &= \set {\phi, \psi^2}
\endaligned
} & 
\cosetsR K &= \set {
\aligned
K       &= \set {\id, \psi\phi}, \\
K\psi   &= \set {\phi, \psi}, \\
K\psi^2 &= \set {\psi^2, \phi\psi}
\endaligned
}.
\endxalignat
$$
Para responder na pergunta, precisamos comparar as duas
\emph{colecções}, ou seja a pergunta é:
$$
\set{ K, \psi K, \phi K }
\askeq
\set{ K, K\psi, K\psi^2 }
$$
e facilmente observamos que não são iguais, pois, por exemplo,
$\psi K$ não é igual a nenhuma das coclasses direitas,
algo que verificamos comparando o conjunto $\psi K$
com cada um dos conjuntos $K, K\psi, K\psi^2$.
\endexample
%%}}}

%%{{{ x: cosets_of_H_N_subgroup_S3 
\exercise.
\label{cosets_of_H_N_subgroup_S3}%
Calcule todas as coclasses esquerdas e direitas dos
$$
\xalignat3
H &\leteq \set{ \id, \phi }&
N &\leteq \set{ \id, \psi, \psi^2 }
\endxalignat
$$
Quantas coclasses direitas diferentes cada um deles tem?
Quantas esquerdas?  Explique sua resposta.
A família $\cosetsR H$ de todas as coclasses direitas de $H$ é igual
à família $\cosetsL H$ de todas as esquerdas?
Similarmente para as $K$ e $N$.

\endexercise
%%}}}

%%{{{ Notation 
\note Notação.
Observe que definimos os $aH$, $Ha$, e $HK$, num grupo $G$
para \emph{subgrupos} $H,K\subgroup G$.
Mas não usamos nenhuma propriedade de subgrupo mesmo.
Podemos realmente estender essa notação para arbitrários
\emph{subconjuntos} de $G$, e, por que não,
até usar notação como a seguinte abominação:
$$
g_1ABg_2B\ginv{g_3}Ag_1CB
\defeq
\setst {g_1abg_2b'\ginv{g_3}a'g_1cb''}
{
a, a' \in A,\ 
b, b', b'' \in B,\ 
c \in C
}
$$
dados $g_1,g_2,g_3\in G$ e $A,B,C\subset G$.
Observe primeiramente que \emph{precisamos} usar variáveis diferentes
para cada instância de elemento de $A$, etc.
Observe também que todos esses objetos que escrevemos juxtaposicionando
elementos e subconjuntos de $G$ são subconjuntos de $G$ se usamos
pelo menos um subconjunto de $G$ na expressão:
$$
\xalignat2
g_1abg_5ab' &\in G &
g_1aBg_5ab' &\subset G.
\endxalignat
$$
Finalmente, \emph{confira} que graças à associatividade da operação do grupo $G$,
não precisamos botar parenteses:
$$
g_1ABg_2B\ginv{g_3}Ag_1CB
= g_1A(Bg_2B)\ginv{g_3}(Ag_1CB)
= (g_1A)(Bg_2)(B\ginv{g_3})(Ag_1)(CB)
= \dotsb
$$
etc.
%%}}}

%%{{{ df: normal_subgroup 
\definition Subgrupo normal.
\label{normal_subgroup}%
\tdefined{subgrupo}[normal]%
\sdefined {\sholed N \normal \sholed G} {$N$ é um subgrupo normal de $G$}%
\iisee{normal}{subgrupo normal}%
Seja $G$ grupo e $N\subgroup G$.
O $N$ é um \dterm{subgrupo normal} de $G$
sse a família das suas coclasses esquerdas
e a das suas coclasses direitas são iguais.
Em símbolos,
$$
N \normal G \defiff \cosetsL N = \cosetsR N.
$$
%%}}}

%%{{{ x: subgroup_of_abelian_is_normal 
\exercise.
\label{subgroup_of_abelian_is_normal}%
Se $H \subgroup G$ num $G$ abeliano, então $H \normal G$.

\endexercise
%%}}}

%%{{{ x: cosets_of_subgroup_of_index_2 
\exercise.
\label{cosets_of_subgroup_of_index_2}%
Se $H\subgroup G$ de índice $2$, então $H \normal G$.

\solution
Suponha $H\subgroup G$ com 
Precisamos mostrar que $aH = Ha$ para todo $a\in G$.
Como o índice de $H$ é 2, só tem 2 cosets, logo, fora do próprio $H$, seu
complemento $G\setminus H$ tem que ser um coset.
Agora para qualquer $aH$ com $a \notin H$, temos
$$
aH = G\setminus H = Ha.
$$

\endexercise
%%}}}

%%{{{ The quotient group 
\note.
Acabamos de identificar certos subgrupos dum grupo $G$---que chamamos
\dterm{normais}---com uma propriedade legal:
a colecção de todas as suas coclasses esquerdas é a mesma com
a colecção de todas as suas coclasses direitas.
(Na verdade a situação é bem mais legal que isso---continue lendo.)
Começando então com um $N\normal G$, podemos falar \emph{da} partição
correspodente de $G$, sem especificar se estamos considerando a colecção
das coclasses esquerdas ou das direitas.
Ou seja, nesse caso, as relações de equivalência
$$
\dhole \cong \dhole \pmodL N
\qqqqtext{e}
\dhole \cong \dhole \pmodR N
$$
são a \emph{mesma} relação:
%%}}}

%%{{{ df: congruence_mod_N 
\definition congruência módulo subgrupo.
\label{congruence_mod_N}%
\tdefined{congruência}[módulo subgrupo]%
\tdefined{módulo!subgrupo}%
\sdefined
    {{\sholed a} \cong {\sholed b} \pmod {\sholed N}}
    {$a,b$ são congruentes módulo o subgrupo normal $N$}%
Sejam $G$ grupo e $N \normal G$.
Definimos a relação binária
$$
\dhole \cong \dhole \pmod N
$$
que chamamos de \dterm{congruência módulo $N$}.
%%}}}

%%{{{ As soon as we have a normal subgroup 
\note Assim que tiver um subgrupo normal\dots.
Vamos começar com um certo grupo $G$:
$$
\tikzpicture
\tikzi quogrpbase;
\tikzi quogrpoutsidemess;
\tikzi quogrpinsidemess;
\endtikzpicture
$$
Agora identificamos nele um subgrupo \emph{normal} $N\normal G$.
Assim que fizermos isso, todo o $G$ se arruma
graças à partição de todas as coclasses de $N$:
$$
\gathered
\tikzpicture
\tikzi quogrpbase;
\tikzi quogrpoutsidemess;
\tikzi quogrpsubgroupelems;
\node at (N) {$N$};
\endtikzpicture
\endgathered
\qquad\leadsto\qquad
\gathered
\tikzpicture
\tikzi quogrppartitionednonames;
\tikzi quogrppartitioned;
\endtikzpicture
\endgathered
$$
E agora comece se afastar mais e mais, até não dá mais pra ver
os pontinhos \emph{dentro} dessas classes, e até as próprias
classes viram pontinhos:
$$
\tikzpicture
\tikzi quogrpzoomout;
\endtikzpicture
$$
Denotamos esse conjunto por $\quogrp G N$:
$$
\quogrp G N = \setst {Ng} {g \in G}
$$
Observe que esse conjunto é o
{\ii{conjunto}[quociente]}\emph{conjunto quociente} de $G$
através da relação de congruência módulo $N$.%
\footnote{Lembra-se que dada qualquer relação de equivalência
num conjunto, definimos seu conjunto quociente?
Veja a~\ref{quoset}.}
%%}}}

%%{{{ So what? 
\note E daí?.
Isso é verdade mesmo se o $N$ não fosse normal:
podemos definir os (dois) conjuntos quocientes
$\quoset G {\congL N}$ e $\quoset G {\congR N}$.
Mas assim estamos esquecendo \emph{a alma} do $G$:
o $G$ é um \emph{grupo}.
Desde o~\ref{Relations} (\refn{quoset}) sabemos que podemos
dividir um \emph{conjunto} (por uma relação de equivalência)
e o resultado (quociente) é novamente o mesmo tipo de coisa:
\emph{conjunto}.
Aqui dividimos um \emph{grupo} e o quociente foi o que?
A melhor coisa que podemos dizer é\dots~\emph{conjunto!}
Péssimo!  O resultado perdeu seu alma!
Por isso os subgrupos normais são \emph{muito} legais:
o quociente retenha a alma do grupo original!
%%}}}

%%{{{ What is stopping us, exactly? 
\note O que exatamente é o problema?.
Suponha então que temos um $H \subgrp G$.
Gostariamos de definir a operação $\ast$ no
$\quoset G {\congL H}$ em tal forma que
$$
aH \ast bH \pseudodefeq (a \ast_G b)H.
$$
O problema é que a operação $\ast$ que estamos
tentando definir não tem acesso nos $a,b$ das suas entradas $aH,bH$
respectivamente, e logo o seu valor $aH \ast bH$ não pode depender
das escolhas desses representantes.
Ou seja, \emph{não temos como demonstrar que $\ast$ é bem-definida},
e logo \emph{não podemos usar a igualdade acima como definição 
de operação}---por isso o $\pseudodefeq$.
Voltando no desenho anterior a situação ficará mais clara;
vou pintar todos os membros da $aH$ de vermelho e todos os
membros da $bH$ de azul:
$$
\tikzpicture[scale=2]
\tikzi quogrppartitionednonames;
\tikzi quogrppartitioned2colors;
\tikzi quogrpLpartitioned;
\endtikzpicture
$$
Querendo usar a ``definição'' da operação $\ast$ acima
escolhemos o $a \in aH$ e o $b \in bH$ e procuramos
o $a \ast_G b$; vamos dizer que achamos aqui no $gH$:
$$
\tikzpicture[scale=2]
\tikzi quogrppartitionednonames;
\tikzi quogrppartitioned2colors;
\tikzi quogrpLpartitioned;
\node[text=magenta] at (ab) {$\bullet$};
\node at (ab) {\pointL {ab}};
\endtikzpicture
$$
agora escolhendo \emph{outros representantes} $a',b'$ das
$aH,bH$
(onde pelo menos uma das $a'\neq a$ e $b'\neq b$ é válida)
procuramos o $a' \ast_G b'$.  O que acontece se ele
não pertence à mesma coclasse $gH$?
Talvez caiu na $cH$:
$$
\tikzpicture[scale=2]
\tikzi quogrppartitionednonames;
\tikzi quogrppartitioned2colors;
\tikzi quogrpLpartitioned;
\node at (a2)  {\pointL {a'}};
\node at (b2)  {\pointL {b'}};
\node[text=magenta] at (ab)  {$\bullet$};
\node[text=magenta] at (ab0) {$\bullet$};
\node at (ab)  {\pointL {ab}};
\node at (ab0) {\pointL {a'b'}};
\endtikzpicture
$$
Assim a $\ast$ \emph{não é bem-definida} (e logo
o $\quoset G {\congL H}$ não tem nenhuma chance de
virar grupo com ela.
É exatamente isso que aproveitamos nos subgrupos \emph{normais:}
eles não deixam isso acontecer, pois garantam que
o produto de quaisquer representantes das $aH,bH$ vai sempre
cair dentro da mesma coclasse, e logo apenas a $gH$ será pintada
roxa aqui no nosso desenho
$$
\tikzpicture[scale=2]
\tikzi quogrppartitionednonames;
\tikzi quogrppartitioned3colors;
\tikzi quogrpLpartitioned;
\node at (a2)  {\pointL {a'}};
\node at (b2)  {\pointL {b'}};
\node at (ab2) {\pointL {a'b'}};
\node at (ab)  {\pointL {ab}};
\endtikzpicture
$$
e logo aqui teriamos
$$
aH \ast bH = gH \quad \bigparen{= (ab)H}.
$$
%%}}}

%%{{{ beware: not_well_defined_function_danger_quogrp 
\beware.
\label{not_well_defined_function_danger_quogrp}%
Caso que o problema de não ser bem-definida não é óbvio,
primeiramente volte a re-estudar os:
\ref{not_well_defined_function_danger_argument_name_dependence}
e~\ref{not_well_defined_function_danger_choice_dependence}.
Agora observe que o $aH$ é na verdade um membro $a$ de $G$
\emph{operado} com um subgrupo $H$ de $G$; e isso resulta
num certo subconjunto de $G$: uma coclasse (esquerda) de $H$.
\endgraf
Então: as entradas da $\ast$ são coclasses esquerdas de $H$,
por exemplo podem ser as
$$
\xalignat2
aH &\eqass \set{a,a_1,a_2,a_3,a_4,a_5} &
bH &\eqass \set{b,b_1,b_2,b_3,b_4,b_5}
\endxalignat
$$
e agora
$$
\set{a,a_1,a_2,a_3,a_4,a_5}
\ast
\set{b,b_1,b_2,b_3,b_4,b_5}
= ?
$$
Observe que aqui temos
$$
\xalignat2
aH &= a_1H = \dotsb = a_5H &
bH &= b_1H = \dotsb = b_5H.
\endxalignat
$$
Parece então que tentamos definir a $\ast$ pela
$$
A \ast B = ab,\quad
\text{onde $a$ é algum membro de $A$ e $b$ de $B$}
$$
mas para essa ser uma definição de função mesmo
temos uma tarefa para fazer:
\emph{precisamos provar que seu valor $A \ast B$
não depende das escolhas desses ``representantes'' $a$ e $b$}
(\ref{not_well_defined_function_danger_choice_dependence}).
Até conseguir provar isso, não podemos considerar a $\ast$ uma função
\ii{função}[bem-definida]\emph{bem-definida}.
Vamos voltar se preocupar com o mesmo tipo de coisa logo
no~\ref{not_well_defined_function_danger_firstiso}.
%%}}}

%%{{{ Q: How can we turn the quotient set into a group? 
\question.
Como podemos definir uma operação interessante $\ast$
nos elementos de $\quogrp G N$, tal que o
$\sset {\quogrp G N} \ast$ vira um grupo?
Qual seria sua identidade?
Para cada um dos seus membros, qual seria o seu inverso?
Para cada dois dos seus membros, qual seria o seu produto?
%%}}}
\spoiler.

%%{{{ df: quogrp 
\definition Grupo quociente.
\label{quogrp}%
\tdefined{grupo}[quociente]%
\sdefined {\quogrp {{\sholed G}} {{\sholed N}}} {o grupo quociente de $G$ módulo $N$}%
Sejam $G$ grupo e $N \normal G$.
O conjunto
$$
\quoset G {\congmod N}
\quad
\bigparen{ =
\munderbrace {\setst { aN } { a \in G }} {\cosetsL N}
=
\munderbrace {\setst { Na } { a \in G }} {\cosetsR N}
}
$$
com operação a $\ast$ definida pela
$$
Na \ast Nb \defeq N(ab)
$$
é chamado o \dterm{grupo quociente de $G$ módulo $N$},
e é denotado por $\quogrp G N$.
\mistake
%%}}}

%%{{{ Q: Everything alright with quogrp ? 
\question.
Tá tudo bem com a~\ref{quogrp}?
%%}}}
\spoiler.

%%{{{ A: No: you must prove that it is well-defined: 
\blah Resposta.
A operação $\ast$ não é automaticamente ``bem-definida'':
precisamos demonstrar que realmente o lado direito não
depende na escolha dos representantes $a$ e $b$.
Falei ``precisamos''?  Quis dizer \emph{precisas}.
Agora:
%%}}}

%%{{{ x: nop_is_well_defined 
\exercise.
\label{nop_is_well_defined}%
Demonstre que a $\ast$ definida acima é bem-definida.

\endexercise
%%}}}

%%{{{ lemma: operation_for_cosets_of_normal 
\lemma.
\label{operation_for_cosets_of_normal}%
Sejam $G$ grupo, $N \normal G$, e $a,b \in G$.
$$
(Na)\ast(Nb) = (Na)(Nb) \quad \Bigparen{= \setst {uv} {u \in Na, v \in Nb}}
$$
\sketch.
Como $(Na)\ast(Nb) = N(ab)$, mostramos cada direção da
$$
g \in (Na)(Nb) \iff g \in N(ab)
$$
separadamente.
Sem detalhes, temos
$$
\xalignat2
&
\aligned
g \in (Na)(Nb)
&\implies g = (n_a a) (n_b b) \\
&\implies g = n_a (a n_b) b \\
&\impliesbecause{$^{(\normal)}$} g = n_a (n_b' a) b \\
&\implies g = \munderbrace {\munderbrace{(n_a n_b')} {\in N} (a b)} {\in N (ab)}
\endaligned
&&
\aligned
g \in N(ab)
&\implies g = n(ab)\\
&\implies g = \munderbrace{\munderbrace{(na)} {\in Na} \munderbrace{\vphantom(b\vphantom)} {\in Nb}} {\in (Na)(Nb)}
\endaligned
\endxalignat
$$
onde os nomes das variáveis introduzidas devem indicar uns
dos detalhes omitidos.
\qes
\proof.
Mostramos cada direção da
$$
g \in (Na)(Nb) \iff g \in N(ab)
$$
separadamente.
\crproofpart{\lrdir}.
Suponha $g \in (Na)(Nb)$.
Logo sejam $a'\in Na$ e $b' \in Nb$ tais que $g = a'b'$.
Pelas definições dos $Na$ e $Nb$, sejam $n_a,n_b \in N$
tais que $a' = n_a a$ e $b' = n_b b$.
Logo temos
$$
g = (n_a a) (n_b b) = n_a (a n_b) b
$$
Mas como $a n_b \in aN$ e $aN = Na$ (pois $N\normal G$),
temos que $a n_b$ = $n_b' a$ para algum $n_b' \in N$.
Logo
$$
g = n_a (n_b' a) b = (n_a n_b') (a b) \in N (ab)
$$
pois $n_a n_b' \in N$.
\crproofpart{\rldir}.
Suponha $g \in N(ab)$.
Logo seja $n\in N$ tal que $g = n(ab)$.
Logo temos
$$
g = n(ab) = (na)b \in (Na)(Nb)
$$
pois $na \in Na$ e $b \in Nb$.
\qed
%%}}}

\blah.
Para merecer esse nome, o $\quogrp G N$ deve ser um grupo mesmo.
Vamos provar isso agora.

%%{{{ thm: quogrp_is_a_group 
\theorem.
\label{quogrp_is_a_group}%
Sejam $G$ grupo e $N\normal G$.
O $\quogrp G N$ é um grupo.
\sketch.
Graças ao~\ref{onesided_group_def}, basta verificar que
$\quogrp G N$ com sua operação (\ref{quogrp}) satisfaz uma
definição unilateral de grupo: (G0),(G1),(G2L),(G3L).
Observe que o $\quogrp G N$ é indexado pelo $N$,
e logo para solicitar um membro arbitrário do $\quogrp G N$,
basta tomar um arbitrário membro $a \in N$.
\crproofpart{(G0):}
Sejam $a,b \in N$.
Realmente $(Na)(Nb) = N(ab) \in \quogrp G N$.
\crproofpart{(G1):}
Sejam $a,b,c \in N$.
Calculando verificamos que $((Na)(Nb))(Nc) = (Na)((Nb)(Nc))$.
\crproofpart{(G2L):}
Procuramos um membro de $\quogrp G N$ que satisfaz a lei de identidade esquerda.
O candidato óbvio é o próprio $N = Ne$.
Basta confirmar essa afirmação, ou seja, mostrar que para todo $a \in N$,
temos $N(Na) = Na$.
\crproofpart{(G3L):}
Para mostrar que cada um dos membros de $\quogrp G N$ tem um inverso esquerdo,
seje $a \in N$ e mostre como achar um inverso esquerdo de $Na \in \quogrp G N$.
Aqui o candidato que faz sentido considerar é o $N(\ginv a)$.
\qes
\proof.
Graças ao~\ref{onesided_group_def}, basta verificar que
$\quogrp G N$ com sua operação (\ref{quogrp}) satisfaz uma
definição unilateral de grupo: (G0),(G1),(G2L),(G3L).
\proofpart{(G1):}
Sejam $a,b,c \in N$.
Calculamos:
$$
\bigparen{(Na)(Nb)}(Nc)
= \bigparen{N(ab)}(Nc)
= N\paren{(ab)c}
= N\paren{a(bc)}
= (Na)\bigparen{N(bc)}
= (Na)\bigparen{(Nb)(Nc)}.
$$
\proofpart{(G2L):}
Procuramos um membro de $\quogrp G N$ que satisfaz a lei de identidade esquerda.
Afirmação: o $N \in \quogrp G N$ é uma identidade esquerda do $\quogrp G N$.
Para provar essa afirmação precisamos mostrar que para todo $a \in N$,
temos $N(Na) = Na$.
Realmente, seja $a \in N$.
Calculamos:
$$
N(Na) = (Ne)(Na) = N(ea) = Na.
$$
\proofpart{(G3L):}
Seja $a \in N$.
Afirmação: o $N(\ginv a)$ é um inverso esquerdo de $Na$.
Para provar essa afirmação precisamos verificar que:
$$
(N(\ginv a)) (Na) = N.
$$
Calculamos:
$$
\paren{N(\ginv a)}(Na)
= N(\ginv a a)
= Ne
= N
$$
e pronto.
\qed
%%}}}

\blah.
Seria importante se convencer que essa coisa legal realmente não
é compartilhada por subgrupos não-normais.
Faça agora o:

%%{{{ x: not_normal_subgroup_makes_soulless_quoset 
\exercise.
\label{not_normal_subgroup_makes_soulless_quoset}%
Mostre que para qualquer $H \not\normal G$ as $\congL H$ e
$\congR H$ não são congruências e logo nenhum dos
$\quoset G {\congL H}$ $\quoset G {\congR H}$ pode virar
um grupo com a alma do $G$.

\endexercise
%%}}}

%%{{{ Congruences 
\note Congruências.
\label{congruences}%
Teve mais algo dessatisfatório com as relações $\congL H$
e $\congR H$ baseadas num $H \subgroup G$, mesmo que ambas
são relações de equivalência sim!  Eles não são garantidas
pra ser\dots~\emph{congruências:}
%%}}}

%%{{{ df: congruence_in_group 
\definition congruência (em grupo).
\label{congruence_in_group}%
Uma relação de equivalência $\sim$ num grupo $\ssetfont G = \sset G {\ast, \ginv{}, \gid}$
é uma \dterm{congruência} de $G$ sse $\sim$ é \dterm{compatível com a estrutura} do $\ssetfont G$:
$$
\align
\pforall {a,b,a',b' \in G} & \bracket {a \sim b \mland a' \sim b' \implies a \ast a' \sim b \ast b'} \\
\pforall {a,b \in G}       & \bracket {a \sim b \implies \ginv a \sim \ginv b} \\
                           & \gid \sim \gid.
\endalign
$$
%%}}}

%%{{{ remark: automaticly compatible with gid 
\remark.
Observe que a última linha não oferece absolutamente nada na definição
de \emph{congruência} pois a $\sim$ sendo relação de equivalência é reflexiva.
%%}}}

%%{{{ corollary: congmod_N_is_a_congruence 
\corollary.
Se $N \normal G$ então $\congmod N$ é uma congruência.
\proof Demonstrado no \ref{nop_is_well_defined}.
\qed
%%}}}

\blah.
No \ref{Universal_algebra} estudamos mais congruências num
contexto mais geral, não apenas para grupos.

%%{{{ x: congL_and_congR_not_congruences_counterexample 
\exercise.
\label{congL_and_congR_not_congruences_counterexample}%
Mostre grupo $G$ e $H \subgroup G$ tais que $\congL H$ e $\congR H$
não são congruências.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Normal_subgroups 
\section Subgrupos normais.
\label{Normal_subgroups}%

\secintro
Na~\ref{The_quotient_group} definimos os
\emph{subgrupos normais} como aqueles cujas coclasses
esquerdas e direitas formam a mesma partição.
Aqui encontramos umas definições equivalentes que
superficialmente parecem bastante diferentes.

%%{{{ df: normal_equivalent_definitions 
\definition definições de normal.
\label{normal_equivalent_definitions}%
\tdefined{subgrupo}[normal]%
As afirmações seguintes são equivalentes (e logo cada
uma pode servir como definição de $N \normal G$):
$$
N \normal G
\defiff
N \subgrp G
\mland
\text{qualquer uma das:}\ \ 
\leftbrace{
\aligned
\text{(i)}~   & \cosetsL N = \cosetsR N \\
\text{(ii)}~  & \congL N \;=\; \congR N \\
\text{(iii)}~ & \text{$N$ é fechado pelos conjugados} \\
\text{(iv)}~  & \lforall {g\in G} {gN\ginv g \subset N} \\
\text{(v)}~   & \lforall {g\in G} {gN\ginv g = N} \\
\text{(vi)}~  & \lforall {g\in G} {gN = Ng},
\endaligned
}
$$
lembrando que $\cosetsL N$ e $\cosetsR N$ são as colecções de left
e right cosets de $N$ respectivamente (\ref{cosetsL_and_cosetsR}),
e $\congL N$ e $\congR N$ as equivalências módulo-esquerdo e
módulo-direito $N$ respectivamente (\ref{equivalence_mod_subgroup}).
Se demonstrar tudo isso---algo que vamos fazer junto logo---seria
massa pois:
cada vez que vamos ter como dado que $N \normal G$, a gente
vai ganhar \emph{toda} essa afirmação de graça; e dualmente,
cada vez que vamos querer demonstrar que $N \normal G$, a gente
vai ter a liberdade de escolher qualquer uma dessas e pronto!
%%}}}

%%{{{ x: which_normal_altdef_will_never_be_our_goal 
\exercise.
\label{which_normal_altdef_will_never_be_our_goal}%
Qual dessas não faria sentido escolher nunca querendo demonstrar
que $N \normal G$?

\hint
A $\lforall {g\in G} {gN\ginv g = N}$.  Por quê?

\solution
A $\lforall {g\in G} {gN\ginv g = N}$, pois escolhendo
a $\lforall {g\in G} {gN\ginv g \subset N}$, a gente teria
menos trabalho pra fazer.

\endexercise
%%}}}

%%{{{ closed_under_conj_meaning 
\note Fechado pelos que?.
\tdefined{fechado}[pelos conjugados]%
O que significa \emph{fechado pelos conjugados?}
Significa \emph{fechado pela relação de conjugação};
em símbolos:
$$
\align
\pforall {n \in N} & \bracket{\text{todos os conjugados do $n$ pertencem ao $N$}} \\
\intertext{ou seja,}
\pforall {n \in N} &
\lforall {g \in G}
{ gn\ginv g \in N }.
\endalign
$$
%%}}}

%%{{{ remark: closed_under_conjugation_swap_quantifiers 
\remark trocando a ordem dos quantificadores.
\label{closed_under_conjugation_swap_quantifiers}%
{%
\def\bla{\mathrm{bla}}%
Observe que podemos trocar a ordem dos quantificadores
pois são do mesmo tipo:
$$
\pforall {n\in N}
\lforall {g\in G}
{ gn\ginv g \in N }
\iff
\pforall {g\in G}
\munderbrace {
\lforall{n\in N}
{ gn\ginv g \in N }
}
{ gN\ginv g \subset N }.
$$
Vamos dar uma olhada detalhada agora,
caso que a parte sublinhada acima pareceu estranha.
Lembre-se como tomamos membros arbitrários dum conjunto
indexado (\ref{picking_elements_from_indexed_sets}
e~\ref{only_declare_variables}).
Provando a afirmação
$$
\align
\pforall {n\in N} &\bracket{\text{algo sobre o $gn\ginv g$}}
\intertext{ganhamos que todos os membros do $gN\ginv g$ satisfazem
esse algo, pois o conjunto $gN\ginv g$ é indexado por o $N$.
Aqui o algo é o <<pertencer ao $N$>>.
Ou seja:}
\pforall {n\in N} &\bracket{gn\ginv g \in N}
\endalign
$$
afirma que todos os membros de $gN\ginv g$ pertencem ao $N$,
ou seja, $gN\ginv g \subset N$.
}
%%}}}

%%{{{ thm: normal_equivalent_definitions_are_equivalent 
\theorem.
\label{normal_equivalent_definitions_are_equivalent}%
\ii{subgrupo!normal}%
Sejam $G$ grupo, e $N\subgroup G$.
Os (i)--(vi) da~\ref{normal_equivalent_definitions} são
equivalentes.
\proof.
\proofpart{(i)\tiff(ii).}
Demonstrado no~\ref{Relations} (veja \ref{eqrel_quoset_partition_summary}).
\crproofpart{(iii)\tiff(iv).}
Demonstrado no~\ref{closed_under_conjugation_swap_quantifiers}.
\crproofpart{(iv)\tiff(v).}
A {\rldir} é trivial, pois o que precisamos provar
($N \normal G$) é obviamente uma afirmação mais fraca da nossa hipótese.
Para a {\lrdir}, suponha $N \normal G$ e seja $g\in G$.
Já temos a inclusão $gN\ginv g \subset N$, então só basta provar
a $N \subset gN\ginv g$.  Seja $n \in N$.
Como $n \in N$ e $N$ normal, temos $\ginv g n \ginvp{\ginv g} \in N$.
Logo
$$
\munderbrace {g \paren{\ginv g n \ginvp{\ginv g}} \ginv g} {=n} \in gN\ginv g.
$$
\crproofpart{(iii)\timplies(vi)}
Tome $n \in N$; assim $gn\ginv g$ é
um arbitrário membro do $gN\ginv g$.
Basta mostrar que $gn\ginv g \in N$.
Mas $gn \in gN = Ng$ e logo $gn = n'g$ para algum
$n' \in N$.
Calculamos:
$$
gn\ginv g = n'g \ginv g = n' \in N.
$$
\crproofpart{As outras implicações são pra ti:}
\ref{normal_equivalent_definitions_are_equivalent_rest_of_proof}.
\qed
%%}}}

\blah.
Um corolário bem útil da (vi) é o seguinte:

%%{{{ cor: normal_commutes_with_every_subset_via_subset_product 
\corollary.
\label{normal_commutes_with_every_subset_via_subset_product}%
Sejam $G$ grupo, $N \normal G$.
Para todo $A \subset G$, $AN = NA$.
\proof.
Numa linha só:
$$
AN = \Union_{a \in A} aN = \Union_{a \in A} Na = NA.
$$
\qed
%%}}}

%%{{{ beware: g n g^{-1} \neq n 
\beware.
Se tivemos $N \normal G$ temos sim que $gn\ginv g \in N$ para todo $n\in N$,
mas isso \emph{não garanta} que $gn\ginv g = n$ não!
Sabemos que para todo $n\in N$, temos $gn\ginv g = n'$ \emph{para algum}
$n' \in N$, mas nada nos permite concluir que esse $n'$ é nosso $n$.
Isso quis dizer que em geral não podemos demonstrar que
$$
\align
\famst {gn\ginv g} {n\in N} &= \famst {n} {n\in N}
\intertext{como famílias indexadas por o mesmo conjunto $N$, mas mesmo
assim conseguimos provar que os \emph{conjuntos} são iguais sim:}
\setst {gn\ginv g} {n\in N} &= \setst {n} {n\in N},
\intertext{ou seja,}
gN\ginv g &= N.
\endalign
$$
Parecidamente, sabendo que $gN=Ng$ e tendo um $n\in N$, \emph{não}
podemos concluir que $gn=ng$, mas pelo menos sabemos que
$$
gn = n'g,
\quad\text{para algum $n' \in N$}.
$$
%%}}}

%%{{{ x: gnginvg_neq_n 
\exercise.
\label{gnginvg_neq_n}%
Ache um contraexemplo que mostra que não necessariamente
$gn\ginv g = n$, mesmo com $n\in N \normal G$.

\endexercise
%%}}}

%%{{{ x: normal_equivalent_definitions_are_equivalent_rest_of_proof 
\exercise.
\label{normal_equivalent_definitions_are_equivalent_rest_of_proof}%
Demonstre o que falta para estabelecer que todas
as (i)--(vi) do~\ref{normal_equivalent_definitions_are_equivalent}
são equivalentes.

\endexercise
%%}}}

%%{{{ x: subset_product_of_subgroup_and_normal_is_subgroup 
\exercise.
\label{subset_product_of_subgroup_and_normal_is_subgroup}%
Se $S \subgroup G$ e $N\normal G$, então $SN \subgroup S$.

\hint
\proofalt{Maneira 1:}
imediato pelos:
\ref{HK_equals_KH_iff_HK_subgroup} e~\ref{normal_commutes_with_every_subset_via_subset_product}.
\crproofalt{Maneira 2:}
Use o ``one-test''~\ref{subgroup_one_test}.
Observe que
$SN$ é indexado pelo conjuto $S\times N$ e logo basta tomar
um arbitrário par $\tup{s,n} \in S \times N$ para ganhar
um arbitrário membro do $SN$: o $sn$.

\hint
Se escolheste investigar a segunda maneira da dica anterior:
\endgraf
Tome $s_1,s_2 \in S$ e $n_1,n_2 \in N$; assim o $s_1n_1$
e $s_2n_2$ são dois arbitrários membros do $SN$.
Basta demonstrar que $(s_1n_1)\ginvp{s_2n_2} \in SN$.

\endexercise
%%}}}

%%{{{ x: inter_of_subgroup_and_normal_is_normal_in_subgroup 
\exercise.
\label{inter_of_subgroup_and_normal_is_normal_in_subgroup}%
Se $S \subgroup G$ e $N\normal G$, então $S \inter N \normal S$.

\hint
Temos $S \inter N \subgroup N \subgroup G$ como intersecção de subgrupos
(veja exercícios~\refn{intersection_of_subgroups_is_a_subgroup}
e~\refn{subgroup_is_an_order}).
Para mostrar que $S \inter N \normal S$,
tente provar que $S\inter N$ é fechado pelos conjugados no $S$.

\solution
Temos $S \inter N \subgroup N \subgroup G$ como intersecção de subgrupos
(veja exercícios~\refn{intersection_of_subgroups_is_a_subgroup}
e~\refn{subgroup_is_an_order}).
Basta mostrar que $S \inter N \normal S$,
ou seja, que $S\inter N$ é fechado pelos conjugados no $S$.
Tome $x \in S\inter N$ e $h\in S$.
Temos:
\compute
h x \ginv h &\in S  \by {$S \subgroup G$}
h x \ginv h &\in N  \by {$N \normal G$}
\endcompute
Logo $hx\ginv h \in S \inter N$.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Problems intermission 
\problems Intervalo de problemas.

%%{{{ prob: converse_of_lagrange_is_invalid_proof 
\problem.
\label{converse_of_lagrange_is_invalid_proof}%
Justifique o~\ref{converse_of_lagrange_is_invalid}:
mostre grupo $G$ e um divisor $d \divides \gord G$
tal que $G$ não possui nenhum grupo de ordem $d$.

\endproblem
%%}}}

%%{{{ prob: euclids_theorem_as_corollary_of_lagrange 
\problem Teorema de Euclides.
\label{euclids_theorem_as_corollary_of_lagrange}%
Mostre como provar o teorema de Euclides~\refn{primes_is_infinite}
como um corolário de {\Lagrange[teorema!corolário]}Lagrange.

\hint
Para chegar num absurdo, suponha que $P$ é o maior primo.
Considere o número $2^P - 1$.

\hint
Como o $2^P - 1$ não é primo,
seja $q$ um fator primo do $2^P - 1$.
Então
$$
2^P - 1 \cong 0 \pmod q.
$$

\hint
Temos
$$
2^P \cong 1 \pmod q.
$$
O que podemos concluir sobre a ordem de $2$ no grupo\dots
Em qual grupo mesmo?

\endproblem
%%}}}

%%{{{ prob: wilsons_theorem_proof_using_groups 
\problem Teorema de Wilson.
\label{wilsons_theorem_proof_using_groups}%
Demonstre o teorema de {\Wilson[teorema]}Wilson
$$
\text{$n$ é primo} \iff \facp{n-1} \cong -1 \pmod n
$$
usando o conhecimento da teoria dos grupos até agora.

\endproblem
%%}}}

%%{{{ prob: cosets_are_equinumerous 
\problem.
\label{cosets_are_equinumerous}%
Demonstre o~\ref{cosets_are_equinumerous_finite_case}
mesmo quando $H$ é infinito.

\hint
Sendo o $H$ infinito, basta provar que o $Ha$ também é?

\hint
Deixe a pergunta da dica anterior para o~\ref{Cantors_paradise}.
Por enquanto, demonstre uma bijecção entre $H$ e $Ha$.

\hint
A restricção (\ref{fresto}) no $H$ do $a$-ator direito (\ref{group_actors}).

\hint
Já sabemos que é injetora (\ref{group_actors_are_bijective}).
Basta provar que é sobre o $Ha$.

\solution
Seja $a\in G$.
Basta provar que $Ha$ e $H$ têm a mesma quantidade de elementos
(a demonstração sobre as coclasses esquerdas é similar).
Vamos fazer isso mostrando uma bijecção entre os dois conjuntos.
Primeiramente observe que a função $\actorR a : G \to G$
é injetora (\ref{group_actors_are_bijective})
e logo sua restricção $\actorR a \resto {H}$ também é.
Basta mostrar que ela é sobrejetora no $Ha$.
Seja $d \in Ha$, e logo pela definição de $Ha$ seja $h \in H$
tal que $d = ha$.
Temos então $\actorR a \resto {H} (h) = d$,
e logo $\actorR a \resto {H}$ é sobrejetora no $Ha$.

\endproblem
%%}}}

%%{{{ prob: one_congruence_implies_normal 
\problem.
\label{one_congruence_implies_normal}%
Seja $G$ grupo e $N \subgrp G$ tal que $\congL N$ ou $\congR N$
é uma congruência (\ref{congruence_in_group}).
A afirmação $N \normal G$ é correta?
Responda <<sim>> e demonstre; ou <<não>> e refuta;
ou <<talvez>> e mostre um exemplo e um contraexemplo.

\endproblem
%%}}}

%%{{{ prob: subgroup_product_of_normal_is_normal 
\problem.
\label{group_subset_product_of_normal_is_normal}%
Sejam $G$ grupo e $N,M \normal G$.
Afirmação:
$$
NM \normal G.
$$
Se a afirmação é demonstrável demonstre; se é refutável refuta;
caso contrário mostre que não é nem demonstrável nem refutável.

\hint
A afirmação é válida;
demonstre.

\hint
Mostre que $NM$ é fechado pelos conjugados.

\endproblem
%%}}}

\endproblems
%%}}}

%%{{{ Symmetries 
\section Simetrias.
\label{Symmetries}%

%%{{{ eg: [symmetry_eg] flip around a bisector 
\example.
\label{symmetry_eg}%
A transformação $T$ que gira o triangulo por volta do
eixo mostrado por um ângulo $\pi$, é uma simetria
do triangulo.
$$
\gathered
\tikzpicture
\node[inner sep=0pt] at (0,1.732)   (A) {};
\node[inner sep=0pt] at (-1,0)      (B) {};
\node[inner sep=0pt] at (1,0)       (C) {};
\node[inner sep=0pt,outer sep=0pt] at (0,0.577) (G) {};
\draw[color=red] (-.5,0.866) -- (B) -- (C);
\draw[color=blue] (-.5,0.866) -- (A) -- (C);
\node[color=blue,xshift=-3mm] at (A) {$A$};
\node[color=red,xshift=-2mm,yshift=1mm] at (B) {$B$};
\node[xshift=2mm,yshift=2mm] at (C) {$C$};
\draw[dashed] (1,0) -- +(150:2.5cm) node [pos=0.83] {\rotator{150}};
\draw[dashed] (1,0) -- +(330:5mm);
\endtikzpicture
\endgathered
\qquad
\text{vira assim pela $T$:}
\qqquad
\gathered
\tikzpicture
\node[inner sep=0pt] at (0,1.732)   (A) {};
\node[inner sep=0pt] at (-1,0)      (B) {};
\node[inner sep=0pt] at (1,0)       (C) {};
\node[inner sep=0pt,outer sep=0pt] at (0,0.577) (G) {};
\draw[color=blue] (-.5,0.866) -- (B) -- (C);
\draw[color=red] (-.5,0.866) -- (A) -- (C);
\node[color=red,xshift=-3mm] at (A) {$B$};
\node[color=blue,xshift=-2mm,yshift=1mm] at (B) {$A$};
\node[xshift=2mm,yshift=2mm] at (C) {$C$};
\draw[dashed] (1,0) -- +(150:2.5cm);
\draw[dashed] (1,0) -- +(330:5mm);
\endtikzpicture
\endgathered
$$
\endexample
%%}}}

%%{{{ What is a symmetry? (1) 
\note O que é uma simetria (1).
Ok, então <<simetria>> é uma \emph{transformação} que leva uma forma
geométrica para outra, tal que o resultado fica exatamente em cima
da forma original: se desenhar a forma-depois em cima da forma-antes,
cada ponto da forma-depois vai cair em cima dum ponto da forma-antes.
Isso é bem informal, mas nosso objectivo não é estudar simetrias
geométricas neste momento, apenas dar uma intuição com
``palavras da rua'' então essa descrição deve servir para nos guiar.
Mas isso \emph{não é suficiente} para chamar uma transformação de
simetria.
%%}}}

%%{{{ noneg: [symmetry_noneg] flip just the base 
\nonexample.
\label{symmetry_noneg}%
Considere a transformação $T'$
que deixa todos os pontos dos lados $AB$ e $AC$ em paz,
mas vira todos os pontos do interior do $BC$ para a outra direção:
$$
\gathered
\tikzpicture
\node[inner sep=0pt] at (0,1.732)   (A) {};
\node[inner sep=0pt] at (-1,0)      (B) {};
\node[inner sep=0pt] at (1,0)       (C) {};
\node[inner sep=0pt,outer sep=0pt] at (0,0.577) (G) {};
\draw (A) -- (C) -- (B);
\draw[color=red] (-.5,0.866) -- (B);
\draw[color=blue] (-.5,0.866) -- (A);
\node[xshift=-3mm] at (A) {$A$};
\node[xshift=-2mm,yshift=1mm] at (B) {$B$};
\node[xshift=2mm,yshift=2mm] at (C) {$C$};
\draw[dashed] (0,.577) -- +(150:1.2) node [pos=.666] {\rotator{150}};
\endtikzpicture
\endgathered
\qquad
\text{vira assim pela $T'$:}
\qqquad
\gathered
\tikzpicture
\node[inner sep=0pt] at (0,1.732)   (A) {};
\node[inner sep=0pt] at (-1,0)      (B) {};
\node[inner sep=0pt] at (1,0)       (C) {};
\node[inner sep=0pt,outer sep=0pt] at (0,0.577) (G) {};
\draw (A) -- (C) -- (B);
\draw[color=blue] (-.5,0.866) -- (B);
\draw[color=red] (-.5,0.866) -- (A);
\node[xshift=-3mm] at (A) {$A$};
\node[xshift=-2mm,yshift=1mm] at (B) {$B$};
\node[xshift=2mm,yshift=2mm] at (C) {$C$};
\draw[dashed] (0,.577) -- +(150:1.0);
\endtikzpicture
\endgathered
$$
\endnonexample
%%}}}

%%{{{ Q: What would you add to exclude symmetry_noneg ?
\question.
O que tu adicionaria na ``definição'' de simetria acima
para excluir transformações como essa do~\ref{symmetry_noneg}?
%%}}}
\spoiler.

%%{{{ What is a symmetry? (2) 
\note O que é uma simetria (2).
\tdefined{isometria}%
Observe que existe uma diferença importante entre a transformação
do~\ref{symmetry_eg} e aquela do~\ref{symmetry_noneg}:
a primeira \emph{preserva as distâncias}, a segunda não.
Vamos chamar as transformações $T$ e $T'$ respectivamente.
Tome quaisquer dois pontos $x,y$ no triângulo, e meça sua
distância $d(x,y)$.
A transformação $T$ garanta que
$$
d(x,y) = d(Tx, Ty)
$$
para todos os $x,y$, mas a $T'$ não:
existem $x,y$ tais que $d(x,y) \neq d(T'x, T'y)$.
Isso é o que faltou da nossa primeira tentativa de dizer
o que é uma simetria:
ela tem que \emph{preservar as distâncias},
ou seja, ser uma \dterm{isometria}.
%%}}}

%%{{{ x: Show that symmetry_noneg is not a symmetry 
\exercise.
Demonstre (informalmente no desenho) que a transformação $T'$
do~\ref{symmetry_noneg} não é uma simetria.

\hint
Ela não é uma isometria.
Demonstre!

\hint
Precisa achar dois pontos $p,q$ no triângulo tal que
a distância $d(p,q) \neq d(T'p, T'q)$.

\endexercise
%%}}}

%%{{{ Q: Which are all the symmetries of an equilateral triangle? 
\question.
Quais são todas as simetrias dum triângulo equilátero?
%%}}}
\spoiler.

%%{{{ dih3_symmetries 
\note As simetrias dum triângulo equilátero.
\label{dih3_symmetries}%
Fixa um triângulo equilátero.
Aqui todas as suas simetrias:
$$
\xalignat3
&\tikzpicture
\tikzi dih3base;
\draw[dashed] (0,1.732) -- +(270:2.5cm) node [pos=0.83] {\rotator{90}};
\draw[dashed] (0,1.732) -- +(90:5mm);
\node (label) at (-.5, -.5) {$\Delta_1$};
\endtikzpicture
&&
\tikzpicture
\draw[color=white,dashed] (0,1.732) -- +(270:2.5cm);
\draw[color=white,dashed] (0,1.732) -- +(90:5mm);
\tikzi dih3base;
\draw[dashed] (-1,0) -- +(30:2.5cm) node [pos=0.83] {\rotator{30}};
\draw[dashed] (-1,0) -- +(210:5mm);
\node (label) at (1.1, 1.5) {$\Delta_2$};
\endtikzpicture
&&
\tikzpicture
\draw[color=white,dashed] (0,1.732) -- +(270:2.5cm);
\draw[color=white,dashed] (0,1.732) -- +(90:5mm);
\tikzi dih3base;
\draw[dashed] (1,0) -- +(150:2.5cm) node [pos=0.83] {\rotator{150}};
\draw[dashed] (1,0) -- +(330:5mm);
\node (label) at (-1.0, 1.5) {$\Delta_3$};
\endtikzpicture
\\
&\tikzpicture
\tikzi dih3rotbase;
\draw[->] (0,.877) arc (90:210:0.3);
\node (label) at (-.9, 1.1) {$R_{\frac{2\pi}3}$};
\endtikzpicture
&&
\tikzpicture
\tikzi dih3rotbase;
\draw[->] (0,.877) arc (90:330:0.3);
\node (label) at (-.9, 1.1) {$R_{\frac{4\pi}3}$};
\endtikzpicture
&&
\tikzpicture
\tikzi dih3base;
\node (label) at (-1.1, 1.1) {$I$};
\endtikzpicture
\endxalignat
$$
Tem $6$ simetrias então
$$
\Delta_1, \Delta_2, \Delta_3, R, R', I
$$
onde escrevemos $R$ e $R'$ para as $R_{\frac{2\pi}3}$
e $R_{\frac{4\pi}3}$ respectivamente.
%%}}}

%%{{{ Q: How can we turn dih3 into a group? 
\question.
Como podemos definir uma operação no conjunto de todas as simetrias
dum triângulo equilateral, tal que ele vira um grupo?
%%}}}
\spoiler.

%%{{{ df: dih_n 
\definition Os grupos dihedrais.
\label{dih_n}%
\tdefined{grupo}[dihedral]%
\iisee{dihedral}{grupo dihedral}%
O \dterm{grupo dihedral} $\dih n$ (também $\dihalt n$)
é o grupo das simetrias dum $n$-gono regular, com operação
a composição $\fcom$ (vendo as simetrias como
transformações---ou seja, funções):
$B \fcom A$ é a simetria que criamos aplicando primeiramente
a $A$ e depois a $B$.%
\footnote{Alternativamente escrevemos isso como
$A \dcom B$ (notação diagramática,~\refn{diagrammatic_notation}).
Tendo esclarecido qual das~$\fcom$ e~$\dcom$ usamos---e com
a mesma preguiça notacional que temos elaborado
em vários outros casos até agora---escrevemos simplesmente $AB$,
denotando assim a operação do grupo com juxtaposição.}
%%}}}

%%{{{ x: dih_n is indeed a group 
\exercise.
Verifique que o $\dih n$ realmente é um grupo.

\endexercise
%%}}}

%%{{{ x: dih_4 
\exercise.
\label{dih_4}%
Ache todas as simetrias dum quadrado.

\hint
São $8$.

\solution
Aqui todas as simetrias dum quadrado:
$$
\xalignat4
&\tikzpicture
\tikzi dih4base;
\node at (label) {$I$};
\endtikzpicture
&&
\tikzpicture
\tikzi dih4rotbase;
\draw[->] (.4,0) arc (0:90:.4);
\node at (label) {$R$};
\endtikzpicture
&&
\tikzpicture
\tikzi dih4rotbase;
\draw[->] (.4,0) arc (0:180:.4);
\node at (label) {$R'$};
\endtikzpicture
&&
\tikzpicture
\tikzi dih4rotbase;
\draw[->] (.4,0) arc (0:270:.4);
\node at (label) {$R''$};
\endtikzpicture
\\
&\tikzpicture
\tikzi dih4base;
\draw[dashed] (-1.07,-1.07) -- (1.07,1.07) node [pos=0.5] {\rotator{45}};
\node at (label) {$\Delta_1$};
\endtikzpicture
&&
\tikzpicture
\tikzi dih4base;
\draw[dashed] (-1.07,1.07) -- (1.07,-1.07) node [pos=0.5] {\rotator{-45}};
\node at (label) {$\Delta_2$};
\endtikzpicture
&&
\tikzpicture
\tikzi dih4base;
\draw[dashed] (-1.2,0) -- (1.2,0) node [pos=0.5] {\rotator{0}};
\node at (label) {$H$};
\endtikzpicture
&&
\tikzpicture
\tikzi dih4base;
\draw[dashed] (0,-1.2) -- (0,1.2) node [pos=0.5] {\rotator{90}};
\node at (label) {$V$};
\endtikzpicture
\endxalignat
$$

\endexercise
%%}}}

%%{{{ x: gord_dih_n 
\exercise.
\label{gord_dih_n}%
Qual a $\gord{\dih n}$?

\endexercise
%%}}}

%%{{{ Dih n notation warning 
\warning Notação.
O que simbolizamos aqui por $\dih n$ em certos textos aparece
como $\dih {2n}$.  A gente botou a quantidade $n$ de ângulos do
$n$-gono no índice do símbolo, mas tem gente que bota a quantidade
de simetrias do $n$-gono como índice, e como tu acabou de ver
no~\ref{gord_dih_n}, essa quantidade é $2n$.
De qualquer forma, nenhuma dessas notações é standard.%
\footnote{Mesmo assim, a nossa notação faz mais sentido, pois:
(i) quando definimos o grupo dihedral $\dih n$ já sabemos a quantidade
de ângulos ($n$) mas por enquanto não sabemos quantos membros esse grupo
tem (até resolver o~\ref{gord_dih_n});
(ii) já temos uma notação para a ordem dum grupo,
então não perdemos acesso nela optando para o nosso $\dih n$.}
Então tome cuidado quando tu encontra em outros textos
o símbolo $\dih m$.%
\footnote{Se o $m$ é ímpar, não existe ambigüidade.  Óbvio?}
%%}}}

%%{{{ What a discovery!  Or is it? 
\note Que descoberta!  Ou não?.
Então, nosso amigo chegou feliz com sua descoberta
desse grupo interessante.
Mas, mais cedo ou mais tarde, a gente com certeza vai perceber algo:
esse grupo $\dih 3$ \emph{parece ser} o $\sym 3$!
Nosso amigo não achou um grupo realmente novo e original,
mas apenas re-descobriu o grupo $\sym 3$ que conhecemos
desde o início desse capítulo!
Em qual sentido os dois grupos ``são praticamente a mesma coisa''?
Esse é o assunto da~\ref{Group_morphisms},
mas podemos já dar uma primeira resposta informal:
\emph{como grupos, eles comportam no mesmo jeito}.
%%}}}

%%{{{ Are they equal then? 
\note Então são iguais?.
Não!
A palavra certa para esse caso é \dterm{isómorfos} ou
\dterm{isomórficos}, que já encontramos no contexto de
conjuntos~(\ref{isomorphic_sets}).
Lembre-se que isómorfos são aqueles que têm a mesma forma
(\ref{etymology_of_isomorphic}), mas também que o que significa
``forma'' depende do contexto.
Aqui seria \emph{a estrutura de grupos}.
Grupos isómorfos têm exatamente as mesmas \emph{propriedades grupoteóricas}.
%%}}}

%%{{{ Group-theoretic properties 
\note Propriedades grupoteóricas.
\label{grouptheoretic_properties}%
\tdefined{propriedade}[grupoteórica]%
Essas são propriedades que o grupista não consegue enxergar com
seus olhos grupoteóricos.
Uns exemplos:
\beginul
\li <<ele tem membro cuja ordem é $2$>>;
\li <<ele é cíclico>>;
\li <<ele tem dois membros que são seus próprios inversos>>;
\li <<ele possui $3$ subgrupos normais>>;
\li <<ele tem exatamente $4$ membros>>.
\endul
A última talvez não parece ser muito grupoteórica, mas de fato
o grupista entende essa afirmação---talvez se reformulá-la como
<<ele tem ordem $4$>> não vai aparecer estranho.
Uns nãœxemplos:
\beginul
\li <<seus membros são conjuntos>>;
\li <<seus membros são números>>;
\li <<ele tem membro que é singleton>>;
\endul
Por outro lado, o conjuntista, com seus olhos conjuntoteóricos
consegue enxergar todas as diferenças entre o $\dih 3$ e $\sym 3$:
de fato, ele vai responder que são diferentes---e ainda mais:
disjuntos!
Os membros do $\dih 3$ são transformações dos pontos dum plano;
os membros do $\sym 3$ são permutações, ou seja,
bijecções de $\set{1,2,3}$ para $\set{1,2,3}$.
\endgraf
E para o grupista?
\emph{O que são} os membros de grupo é irrelevante.
Ele não tá nem aí sobre a natureza dos membros, ou seus nomes,
ou sua aparência!
O que importa pra ele são suas propriedades grupoteóricas e nada mais:
o inverso desse é aquele; o produto desses é aquilo;
a identidade é essa; esse aqui é um gerador; esses aqui são conjugados;
etc.
%%}}}

%%{{{ eg: why dih 4 is not isomorphic with sym 4
\example.
O $\dih 4$ não é isómorfo com o $\sym 4$.

\solution
Como $\gord{\dih 4} = 8 \neq 24 = \gord{\sym 4}$,
já sabemos que os dois grupos não são isomórficos.
\endexample
%%}}}

%%{{{ x: why dih 4 is not isomorphic with Z/8Z 
\exercise.
Explique porque o $\dih 4$ não é isómorfo com o grupo aditivo
$\ints_8$ dos inteiros com adição módulo $8$.

\solution
Basta achar uma propriedade grupoteórica que um dos dois grupos tem
e o outro não.  Uns exemplos:
\beginil
\item{--} <<{\thole} é abeliano>>:
satisfeita por $\ints_8$ mas não por $\dih 4$;
\item{--} <<{\thole} é cíclico>>:
satisfeita por $\ints_8$ mas não por $\dih 4$;
\item{--} <<{\thole} tem $3$ membros de ordem $2$>>:
satisfeita por $\dih 4$ mas não por $\ints_8$;
\endil
etc.

\endexercise
%%}}}

%%{{{ eg: is dih 4 cyclic? 
\example.
O $\dih 4$ é um grupo cíclico?

\solution
Para ver se $\dih 4$ é um grupo cíclico ou não, conferimos
para cada membro $a$ dele, se $a$ pode gerar o grupo inteiro
ou não.
Calculamos:
$$
\xalignat2
\gen I     &= \set {I}          & \gen {\Delta_1} &= \set {I, \Delta_1} \\
\gen R     &= \set {I,R,R',R''} & \gen {\Delta_2} &= \set {I, \Delta_2} \\
\gen {R'}  &= \set {I,R'}       & \gen H          &= \set {I, H} \\
\gen {R''} &= \gen R            & \gen V          &= \set {I, V}
\endxalignat
$$
Nenhum desses subgrupos gerados é o próprio $\dih 4$,
e logo $\dih 4$ não é um grupo cíclico.
\endexample
%%}}}

%%{{{ hasse_diagrams_first_encounter 
\note Diagramas Hasse.
\label{hasse_diagrams_first_encounter}%
\tdefined{Hasse}[diagrama]%
Quando temos uma ordem parcial $\leq$ definida num conjunto,
podemos desenhar os membros do conjunto num diagrama
chamado \dterm{diagrama Hasse}\Hasse{}.
Desenhamos os membros do conjunto e botamos uma linha
\emph{subindo} dum membro $x$ para outro $y$ sse $x\leq y$ e,
ainda mais, não tem nenhum $w$ entre os dois ($x \leq w \leq y$).
(Fique lendo até os exemplos e vai fazer sentido.)
No~\ref{Posets} vamos trabalhar demais com esses diagramas;
agora é uma boa oportunidade introduzi-los nesse contexto.
Qual contexto exatamente?  Qual o conjunto e qual a ordem?
Lembre-se que $\subgrp$ é uma ordem parcial entre grupos
(\ref{subgroup_is_an_order}), ou seja, o conjunto de todos
os subgrupos dum dado grupo é ordenado pela $\subgrp$.
Bora desenhar então!
%%}}}

%%{{{ hasse_dih_3 
\example O Hasse das simetrias do triângulo.
\label{hasse_dih_3}%
$$
\tikzpicture
\node (top)     at (0,  0 ) {$\moverbrace{\set{I,R,R',\Delta_1,\Delta_2,\Delta_3}}{\dih 3}$};
\node (ir1r2)   at (-3, -2) {$\set{I,R,R'}$};
\node (id1)     at (-1, -2) {$\set{I,\Delta_1}$};
\node (id2)     at (1,  -2) {$\set{I,\Delta_2}$};
\node (id3)     at (3,  -2) {$\set{I,\Delta_3}$};
\node (bot)     at (0,  -4) {$\set{I}$};
\draw (top) -- (ir1r2);
\draw (top) -- (id1);
\draw (top) -- (id2);
\draw (top) -- (id3);
\draw (bot) -- (ir1r2);
\draw (bot) -- (id1);
\draw (bot) -- (id2);
\draw (bot) -- (id3);
\endtikzpicture
$$
\endexample
%%}}}

%%{{{ hasse_dih_4 
\exercise O Hasse das simetrias do quadrado.
\label{hasse_dih_4}%
Fiz do $\dih 3$; faça do $\dih 4$.

\hint
$$
\tikzpicture
\tikzi hassedih4;
\node (top)     at (top)     {$\moverbrace{\set{I,R,R',R'',\Delta_1,\Delta_2,H,V}}{\dih 4}$};
\node (id1d2r)  at (id1d2r)  {$?$};
\node (ir1r2r3) at (ir1r2r3) {$?$};
\node (ihvr1)   at (ihvr1)   {$?$};
\node (id2)     at (id2)     {$?$};
\node (id1)     at (id1)     {$?$};
\node (ir2)     at (ir2)     {$?$};
\node (ih)      at (ih)      {$?$};
\node (iv)      at (iv)      {$?$};
\node (bot)     at (bot)     {$?$};
\endtikzpicture
$$

\hint
$$
\tikzpicture
\tikzi hassedih4;
\node (top)     at (top)     {$\moverbrace{\set{I,R,R',R'',\Delta_1,\Delta_2,H,V}}{\dih 4}$};
\node (id1d2r)  at (id1d2r)  {$?$};
\node (ir1r2r3) at (ir1r2r3) {$\set{I,R,R',R''}$};
\node (ihvr1)   at (ihvr1)   {$?$};
\node (id2)     at (id2)     {$?$};
\node (id1)     at (id1)     {$?$};
\node (ir2)     at (ir2)     {$?$};
\node (ih)      at (ih)      {$?$};
\node (iv)      at (iv)      {$?$};
\node (bot)     at (bot)     {$\set{I}$};
\tikzi hassedih4edges;
\endtikzpicture
$$

\solution
$$
\tikzpicture
\tikzi hassedih4nodes;
\node (top)     at (top)     {$\moverbrace{\set{I,R,R',R'',\Delta_1,\Delta_2,H,V}}{\dih 4}$};
\node (id1d2r)  at (id1d2r)  {$\set{I,\Delta_1,\Delta_2,R'}$};
\node (ir1r2r3) at (ir1r2r3) {$\set{I,R,R',R''}$};
\node (ihvr1)   at (ihvr1)   {$\set{I,H,V,R'}$};
\node (id2)     at (id2)     {$\set{I,\Delta_2}$};
\node (id1)     at (id1)     {$\set{I,\Delta_1}$};
\node (ir2)     at (ir2)     {$\set{I,R'}$};
\node (ih)      at (ih)      {$\set{I,H}$};
\node (iv)      at (iv)      {$\set{I,V}$};
\node (bot)     at (bot)     {$\set{I}$};
\tikzi hassedih4edges;
\endtikzpicture
$$

\endexercise
%%}}}

%%{{{ x: dih_4_isomorphic_to_what 
\exercise.
\label{dih_4_isomorphic_to_what}%
Consegues achar um grupo diferente,
que é isomórfico com o $\dih 4$?

\hint
Não pode ser o $\sym 4$ obviamente, por questão de tamanho!

\hint
Mas olhe dentro do $\sym 4$: no seus subgrupos!

\hint
Renomeia teus $A,B,C,D$ para $1,2,3,4$.
Agora veja cada uma das simetrias do $\dih 4$, para onde ela
leva cada número, e escreva sua permutação correspondente do $\sym 4$.
Basta provar que esse conjunto realmente é um subgrupo de $\sym 4$.

\endexercise
%%}}}

%%{{{ x: minimal_generator_for_dih_3 
\exercise.
\label{minimal_generator_for_dih_3}%
Qual é o menor tamanho de gerador $A \subset \dih 3$,
com $\gen{A} = \dih 3$?
Mostre um tal gerador.

\endexercise
%%}}}

%%{{{ x: minimal_generator_for_dih_4 
\exercise.
\label{minimal_generator_for_dih_4}%
E sobre o $\dih 4$?

\endexercise
%%}}}

%%{{{ x: rectangle_symmetries 
\exercise Simetrias de rectângulo.
\label{rectangle_symmetries}%
Ache todas as simetrias do rectângulo.

\endexercise
%%}}}

%%{{{ x: circle_symmetries 
\exercise As simetrias do cíclo.
Ache todas as simetrias do cíclo.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Morphisms 
\section Morfismos.
\label{Group_morphisms}%

%%{{{ Idea 
\note Idéia.
Queremos formalizar a idéia de <<o grupo $\dih 3$ \emph{parece com} o $\sym 3$>>.
O que precisa ser satisfeito (ou mostrado) para convencer alguém que,
no final das contas, trabalhar com um grupo $\cal A$ é
\emph{essencialmente a mesma coisa} de trabalhar com um grupo $\cal B$?
%%}}}

%%{{{ pseudodf: group_homomorphism_first_attempt 
\pseudodefinition homomorfismo.
\label{group_homomorphism_first_attempt}%
Sejam $\cal A, \cal B$ grupos.
A função $\phi : A \to B$ é um \dterm{homomorfismo} de $\cal A$ para $\cal B$
sse ela \emph{preserva a estrutura de $\cal A$ no $\cal B$}.
%%}}}

%%{{{ Preserving the structure 
\note Preservando a estrutura.
\tdefined{preservar}[estrutura]%
\tdefined{respeitar}[estrutura]%
Antes de entender o que significa <<preservar uma estrutura>>, vamos
lembrar: o que é a estrutura dum grupo?
É sua alma: num grupo temos a sua operação (binária), podemos pegar inversos (operação unária),
e temos também em cada grupo um membro especial chamado identidade do grupo (constante).
Ou seja, \dterm{preservar a estrutura} faz sentido significar as três coisas seguintes:
$$
\xalignat2
&\text{preservar a operação:}   & \phi(x \ast_A y)    &= \phi(x) \ast_B \phi(y)   \tag{i}   \\
&\text{preservar os inversos:}  & \phi(\ginvt_A (x))  &= \ginvt_B\paren{\phi(x)}  \tag{ii}  \\
&\text{preservar a identidade:} & \phi(e_A)           &= e_B.                     \tag{iii}
\endxalignat
$$
Também usamos o termo \dterm{respeitar}, muitas vezes como sinônimo de
preservar mas não sempre---então tome cuidado com as definições,
especialmente se a estrutura envolve relações.
%%}}}

%%{{{ Two paths 
\note Dois caminhos.
Considere que temos uma \emph{função} $\phi$ de $\cal A$ para $\cal B$.
Comece no grupo $\cal A$ (o domínio de $\phi$) e tome uns membros
$a_1,\dots,a_n$ do seu carrier set $A$.
Faça quaisquer coisas aí que a estrutura de grupo te permite fazer:
tome inversos, combine eles com a operação do grupo, etc.
Assim tu chega num certo membro $x$ do grupo $\cal A$.
Agora use a $\phi$ nesse resultado $x$, passando assim
para um certo membro $y$ do grupo $\cal B$.
Alternativamente, \emph{começando com os mesmos membros}
$a_1,\dots,a_n$ do~$\cal A$,
use a~$\phi$~logo no início em cada um deles para passar ao grupo $\cal B$,
chegando assim nuns membros $b_1,\dots,b_n$ do~$\cal B$.
Sendo num grupo agora, podes performar exatamente as mesmas operações, na mesma
ordem, nos correspondentes membros que tu fez antes (no grupo $\cal A$),
e assim tu chegarás num certo resultado $b$ no $\cal B$.
Vamos chamar a função $\phi$ um homomorfismo exatamente quando ela garanta que
em qualquer situação como essa, os dois caminhos de $\cal A$ para $\cal B$,
chegam no mesmo membro, ou seja, $b = y$.
%%}}}

%%{{{ note: Diagramas comutativos 
\note Diagramas comutativos.
Essa idéia é bem melhor desenhada do que escrita, usando diagramas comutativos.
Por exemplo, a lei (iii) é equivalente à comutatividade do diagrama seguinte:
$$
\cdopt{sep=2cm}
A   \ar[r, "\phi"]\ar[d, "\ginvt_A"'] \| B\ar[d, "\ginvt_B"]\ \\
A   \ar[r, "\phi"]                    \| B
\endcd
$$
%%}}}

%%{{{ x: cd_for_respects_operation 
\exercise.
\label{cd_for_respects_operation}%
Desenha um diagrama cuja comutatividade é a lei (i).

\solution
$$
\cdopt{sep=2cm}
A\times A   \ar[r, "\phi \times \phi"]\ar[d, "\ast_A"'] \| B\times B \ar[d, "\ast_B"]\ \\
A           \ar[r, "\phi"]                              \| B
\endcd
$$

\endexercise
%%}}}

%%{{{ Different structures for groups 
\note Diferentes estruturas para grupos.
Já viermos como definir ``grupo'' como conjunto estruturado usando três
estruturas diferentes:
$$
\xalignat3
\sset A {\ast_A} &
&\sset A {\ast_A, e_A} &
&\sset A {\ast_A, \ginvt_A, e_A}. &
\endxalignat
$$
Então, dependendo na estrutura que escolhemos para nossa definição
de grupo, precisamos definir ``morfismo'' em forma diferente:
No caso de estrutura $\sset A {\ast_A}$ o morfismo deve satisfazer
o~(i); no caso de $\sset A {\ast_A, e_A}$, os~(i)~e~(iii), e no caso
de $\sset A {\ast_A, \ginvt_A, e_A}$ todos os~(i)--(iii).
\emph{Parece então que chegamos no primeiro ponto onde a estrutura
escolhida na definição de grupo será crucial.}
Felizmente, como nos vamos provar logo após, as leis de grupo
são suficientes para garantir que qualquer função $\phi$ que
satisfaz apenas o~(i)~acima, obrigatoriamente satisfaz
os~(ii)~e~(iii) também!
Mesmo assim, vamos botar em nossa definição todos os~(i)--(iii),
pois isso captura melhor a idéia geral de ``homomorfismo''.
E assim que provar nossa afirmação ganhamos um critérion forte
para decidir se alguma função é um homomorfismo.
%%}}}

%%{{{ df: group_homomorphism 
\definition homomorfismo.
\label{group_homomorphism}%
\tdefined{homomorfismo}[de grupos]%
\sdefined
    {\phi : {\sholed {\cal A}} \to {\sholed {\cal B}}}
    {$\phi$ é um homomorfismo do $\cal A$ para o $\cal B$}%
\sdefined
    {\phi : {\sholed A} \homto {\sholed B}}
    {$\phi$ é um homomorfismo do $A$ para o $B$}%
Sejam $\cal A = \sset A {\ast_A,\ginvtof A,\gidof A}$ e
$\cal B = \sset B {\ast_B,\ginvtof B,\gidof B}$ grupos.
A função $\phi : A \to B$ é um \dterm{homomorfismo} do
$\cal A$ para o $\cal B$ sse ela respeita a operação,
os inversos, e a identidade:
$$
\alignat2
&\text{para todo $x,y\in A$},\quad & \phi(x \ast_A y)   &= (\phi x) \ast_B (\phi y) \\
&\text{para todo $x\in A$},\quad   & \phi(\ginvtof A x) &= \ginvtof B \funparen{\phi x} \\
&&\phi e_A       &= e_B.
\endalignat
$$
Às vezes escrevemos $\phi : \cal A \to \cal B$ (em vez de $\phi:A\to B$)
para enfatizar que o $\phi$ nos leva do \emph{grupo} $\cal A$ para o
\emph{grupo} $\cal B$; ou também $\phi : A \homto B$.
%%}}}

%%{{{ note: safe juxtaposition 
\note.
Quando pelo contexto podemos inferir qual é a operação envolvida,
optamos para denotá-la com juxtaposição como produto mesmo.
Por exemplo, escrevemos
$$
\phi(xy) = \phi(x)\phi(y)
$$
sem ambigüidade nenhuma:
o $xy$ que aparece no lado esquerdo,
só pode denotar o $x \ast_A y$, pois $x,y \in A$.
No outro lado, o $(\phi x) (\phi y)$ só pode denotar o $\phi(x) \ast_B \phi(y)$,
pois $\phi(x),\phi(y) \in B$.
A mesma coisa acontece com os inversos:
$\phi(\ginv x)$ só pode denotar ``a imagem do inverso (no $A$) de $x$'',
e $\ginvp{\phi(x)}$ só pode denotar ``o inverso (no $B$) de $\phi(x)$'',
pois, no primeiro caso o $\ginv{}$ é aplicado num membro de $A$,
e no segundo caso num membro de $B$.
%%}}}

%%{{{ criterion: criterion_for_morphism_in_groups
\criterion de homomorfismo.
\label{criterion_for_morphism_in_groups}%
Sejam grupos $\cal A = \sset A {\ast_A,\ginvtof A,\gidof A}$
e $\cal B = \sset B {\ast_B,\ginvtof B,\gidof B}$
e função $\phi : A \to B$ que preserva a operação, ou seja,
tal que
$$
\quad\text{para todo $x,y\in A$},\quad
\phi(x \ast_A y) = (\phi x) \ast_B (\phi y).
$$
Então $\phi$ é um homomorfismo.
\sketch.
Precisamos provar o que falta:
$$
\alignat2
&&\phi e_A       &= e_B              \tag{iii}  \\
&\text{para todo $x\in A$},\quad &
\phi(\ginv x)    &= \ginvp{\phi x}.  \tag{ii}
\endalignat
$$
Para o~(iii), calculamos $\phi(e_A) = \phi(e_A) \phi(e_A)$
para concluir que $e_B = \phi(e_A)$;
para o~(ii), mostramos que o $\phi(\ginv x)$ satisfaz a
propriedade característica de ser inverso de $\phi x$:
$$
\phi(\ginv x) \phi(x) \askeq e_B.
$$
\qes
%%}}}

%%{{{ df: group_morphisms 
\definition -morfismos.
\label{group_morphisms}%
\tdefined{morfismo}[grupo]%
\tdefined{homomorfismo}[(grupo)]%
\tdefined{epimorfismo}[(grupo)]%
\tdefined{monomorfismo}[(grupo)]%
\tdefined{epimorfismo}[split (grupo)]%
\tdefined{monomorfismo}[split (grupo)]%
\tdefined{isomorfismo}[(grupo)]%
\tdefined{endomorfismo}[(grupo)]%
\tdefined{automorfismo}[(grupo)]%
Sejam grupos $\cal A$ e $\cal B$, e $\phi : \cal A \to \cal B$ um homomorfismo.
Usamos os termos:
$$
\align
\text{$\phi$ monomorfismo}       &\defiff \text{$\phi$ L-cancelável}\\
\text{$\phi$ epimorfismo}        &\defiff \text{$\phi$ R-cancelável}\\
\text{$\phi$ split monomorfismo} &\defiff \text{$\phi$ L-invertível}\\
                                 &\intiff \lexists {\phi' : \cal B \to \cal A}
                                                   {\phi'\phi = \idof A}\\
\text{$\phi$ split epimorfismo}  &\defiff \text{$\phi$ R-invertível}\\
                                 &\intiff \lexists {\phi' : \cal B \to \cal A}
                                                   {\phi\phi' = \idof B}\\
\text{$\phi$ isomorfismo}        &\defiff \text{$\phi$ é invertível}\\
                                 &\intiff \lexists {\phi' : \cal B \to \cal A}
                                                   {\phi'\phi = \idof A \mland \phi\phi' = \idof B}\\
\text{$\phi$ endomorfismo}       &\defiff \text{$\dom\phi = \cod\phi$}\\
\text{$\phi$ automorfismo}       &\defiff \text{$\phi$ endomorfismo~\&~isomorfismo}
\endalign
$$
onde ``cancelável'' e ``invertível'' significam com respeito a
operação da composição $\fcom$.
%%}}}

%%{{{ x: mono_splitmono_inj_in_Group 
\exercise.
\label{mono_splitmono_inj_in_Group}%
Investigue:
$$
\text{$\phi$ mono}
\askiff \text{$\phi$ split mono}
\askiff \text{$\phi$ injectiva}
$$
Como a situação compara com os resultados de funções entre conjuntos
(veja~\refn{An_epic_trip})?

\endexercise
%%}}}

%%{{{ x: epi_splitepi_surj_in_Group 
\exercise.
\label{epi_splitepi_surj_in_Group}%
Investigue:
$$
\text{$\phi$ epí}
\askiff \text{$\phi$ split epí}
\askiff \text{$\phi$ sobrejectiva}
$$
Como a situação compara com os resultados de funções entre conjuntos?

\endexercise
%%}}}

%%{{{ x: iso_bim_bij_in_Group 
\exercise.
\label{iso_bim_bij_in_Group}%
Investigue:
$$
\text{$\phi$ iso}
\askiff \text{$\phi$ mono} + \text{$\phi$ epí}
\askiff \text{$\phi$ bijectiva}
$$
Como a situação compara com os resultados de funções entre conjuntos?

\endexercise
%%}}}

%%{{{ sketch_of_morphism_adjectives_in_Group 
\note Rascunho de morfismos de grupos.
\label{sketch_of_morphism_adjectives_in_Group}%
Temos então:
$$
\align
\text{mono} &\iff \text{injecção} \\
\text{epí}  &\iff \text{sobrejecção} \\
\text{iso}  &\iff \text{bijecção}.
\endalign
$$
%%}}}

%%{{{ x: id_is_an_auto 
\exercise.
\label{id_is_an_auto}%
Seja $G$ grupo.  Mostre que a $\id : G \to G$
é um homomorfismo (e logo automorfismo).

\solution
Sejam $x,y\in G$.
Calculamos
$$
\id(xy) = xy = \id(x)\id(y)
$$
e logo $\id$ é um homomorfismo,
e como $\id$ é bijetora e endomapa, $\id$ é um automorfismo.

\endexercise
%%}}}

%%{{{ x: conj_is_an_auto 
\exercise.
\label{conj_is_an_auto}%
Seja $G$ grupo.  Para todo $g\in G$, o $g$-conjugador
(\ref{conjugator}) é um automorfismo.

\endexercise
%%}}}

\blah.
Finalmente podemos definir o que significa que dois grupos são isómorfos!

%%{{{ df: isomorphic_groups 
\definition Grupos isomórficos.
\label{isomorphic_groups}%
\tdefined{grupo}[isomórficos]%
Sejam grupos $G$ e $G'$.
Chamamos o $G$ \dterm{isomórfico} (ou \dterm{isómorfo}) ao $G'$ sse
existe isomorfismo $\phi : G \to G'$.
Nesse caso chamamos o $\phi$ \dterm{isomorfismo de grupos}.
Como introduzimos na~\ref{isomorphic_sets}
escrevemos $G \iso G'$ para dizer que <<os $G,G'$ são isómorfos>>,
e também $\phi : G \isoto G'$ ou até $\phi : G \iso G'$ para
<<$\phi$~é um isomorfismo de $G$ para $G'$>>.
%%}}}

%%{{{ x: isomorphic_is_an_equivalence_relation 
\exercise.
\label{isomorphic_is_an_equivalence_relation}%
Mostre que $\isomorphic$ é uma relação de equivalência.

\endexercise
%%}}}

%%{{{ x: additive_ints_and_rats_are_not_isomorphic 
\exercise.
\label{additive_ints_and_rats_are_not_isomorphic}%
Mostre que os $\sset \ints +$ e $\sset \rats +$ não são
isómorfos.

\hint
Procure uma propriedade grupoteórica que um dos dois tem e o outro não.

\solution
Considere a propriedade seguinte:
$$
\text{Para todo $w$, existe $u$ tal que $u+u = w$.}
$$
Ela é uma propriedade grupoteórica, válida no $\sset \rats +$
e inválida no $\sset \ints +$.
Em outras palavras, suponha para chegar num absurdo que temos
um isomorfismo desses grupos $\phi : \ints \to \rats$.
Olhe para o $w \asseq \phi(1)$ (qualquer número ímpar serveria em vez do $1$).
Sendo racional, o $u \asseq \phi(1)/2$ também é racional e temos:
$$
w = u + u.
$$
Qual inteiro é o $\finv\phi$?
Deve ser um inteiro que satisfaz
$$
\finv\phi(u) + \finv\phi(u)
= \finv\phi(u+u)
= \finv\phi(w)
= 1
$$
mas tal inteiro não existe.
Logo, não pode existir nenhum isomorfismo entre os
$\sset \ints +$ e $\sset \rats +$.
\endgraf
Usando uma outra propriedade grupoteórica para diferenciar
os dois grupos seria observar que um é cíclico, mas o outro não é.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Kernel, Image 
\section Kernel, Image.
\label{Kernel_Image}%

%%{{{ df: kernel 
\definition kernel, image.
\label{kernel}%
\tdefined{kernel de homomorfismo}%
\tdefined{image de homomorfismo}%
\sdefined {\ker{\sholed \phi}} {o kernel do homomorfismo $\phi$}
\sdefined {\ima{\sholed \phi}} {a image do homomorfismo $\phi$}
Sejam $A,B$ grupos e $\phi:A\to B$ um homomorfismo.
Definimos
$$
\alignat2
\ker\phi
&\defeq \pre \phi {\set{e_B}} &
\quad\big(&= \setst {a \in A} {\phi(a) = e_B} \ \big)\\
\ima\phi
&\defeq \img \phi A &
\quad\big(&= \setst {b \in B} {\lexists {x\in A} {\phi(x) = b}} \ \big)
\endalignat
$$
Chamamos o $\ker \phi$ o \dterm{kernel} do $\phi$
e o $\ima \phi$ o \dterm{image} do $\phi$.
%%}}}

%%{{{ thm: group_homo_mono_iff_ker_singleton 
\theorem.
\label{group_homo_mono_iff_ker_singleton}%
Sejam $A,B$ grupos e $\phi : A \to B$ homomorfismo.
$$
\text{$\phi$ injetora}
\iff
\ker\phi = \set{e_A}.
$$
\sketch.
\proofpart{\lrdir}.
Como $e_A \in \ker\phi$,
basta provar que todos os membros de $\ker\phi$ são iguais:
suponha $x,y\in\ker\phi$ e mostre que $x = y$.
\crproofpart{\rldir}.
Sejam $x,y \in A$ tais que $\phi(x) = \phi(y)$.
Operando nessa igualdade e usando o fato que $\phi$ é homomorfismo,
chegamos no $x=y$, ou seja, $\phi$ é injetora.
\qes
\proof.
\proofpart{\lrdir}.
Como $e_A \in \ker\phi$,
basta provar que todos os membros de $\ker\phi$ são iguais.
Sejam $x,y\in\ker\phi$ então.
Logo $\phi(x) = e_B = \phi(y)$,
e como $\phi$ é injetora, concluimos o desejado $x=y$.
\crproofpart{\rldir}.
\stepproof
\proofsteptnb {Sejam $x,y \in A$ tais que $\phi(x) = \phi(y)$.}
\thereforetby {$\phi(x) \ginv{\phi(y)} = e_B$}          {$(\ast \ginv{\phi(y)})$}
\thereforetby {$\phi(x) \phi\funparen{\ginv y} = e_B$}  {$\phi$ homo (inv.)}
\thereforetby {$\phi(x \ginv y) = e_B$}                 {$\phi$ homo (op.)}
\thereforetby {$x\ginv y \in \ker\phi$}                 {def.~$\ker\phi$}
\thereforetby {$x\ginv y \in \set{e_A}$}                {hipótese}
\thereforetby {$x\ginv y = e_A$}                        {$\set{e_A}$ singleton}
\thereforetby {$x = y$}                                 {$(\ast y)$}
\endstepproof
\qed
%%}}}

%%{{{ x: kernel_subgroup 
\exercise.
\label{kernel_subgroup}%
Sejam $A$ e $B$ grupos e $\phi : A \to B$ homomorfismo.
Prove que $\ker\phi\subgrp A$.

\hint
Primeiramente verifique que $\ker\phi\neq\emptyset$.
Agora, graças ao~\ref{nonempty_subgroup_criterion}, precisas provar:
(i)~$\ker\phi$ é~$\ast$-fechado;
(ii)~$\ker\phi$ é~$\ginv{}$-fechado.

\hint
Para o (i), tome $x,y\in\ker\phi$ e mostre que $xy\in\ker\phi$,
ou seja, que $\phi(xy) = e_B$.

\hint
Para o (ii), tome $x\in\ker\phi$ e mostre que $\ginv x\in\ker\phi$,
ou seja, que $\phi\funparen{\ginv x} = e_B$.

\solution
Primeiramente observamos que $\ker\phi\neq\emptyset$:
$e_A \in \ker\phi$, pois $\phi$ é um homomorfismo
e logo leva a $e_A$ para a $e_B$.
Então graças ao~\ref{nonempty_subgroup_criterion}, basta provar:
\crproofpart{$\ker\phi$ é fechado pela operação:}
Sejam $x,y\in\ker\phi$.
Precisamos mostrar que $xy\in\ker\phi$, ou seja, que $\phi(xy) = e_B$.
Calculamos:
\compute
\phi(xy)
&= \phi(x) \phi(y)  \by {$\phi$ homo (oper.)}
&= e_B e_B          \by {$x,y\in\ker\phi$}
&= e_B.             \by {def.~$e_B$}
\endcompute
\proofpart{$\ker\phi$ é fechado pelos inversos:}
Seja $x\in\ker\phi$.
Precisamos mostrar que $\ginv x\in\ker\phi$, ou seja, que $\phi\funparen{\ginv x} = e_B$.
Calculamos:
\compute
\phi\funparen{\ginv x}
&= \ginvp{\phi(x)}  \by {$\phi$ homo (inv.)}
&= \ginv{e_B}       \by {$x\in\ker\phi$}
&= e_B.             \by {inverso da identidade~(\ref{inverse_of_identity_in_group})}
\endcompute

\endexercise
%%}}}

%%{{{ x: kernel_is_normal 
\exercise.
\label{kernel_is_normal}%
Sejam $A$ e $B$ grupos e $\phi : A \to B$ homomorfismo.
Prove que $\ker\phi\normal A$.

\hint
Acabamos de provar que $\ker\phi\subgrp \cal A$ no~\ref{kernel_subgroup}.
Basta provar que $\ker\phi$ é fechado pelos conjugados.
Seja $k\in\ker\phi$ e tome $a\in A$.
Precisamos provar que o $a$-conjugado de $k$ também está no $\ker\phi$:
$ak\ginv a \in \ker\phi$.
Ou seja, basta verificar que realmente $\phi(ak\ginv a) = e_B$.

\solution
Seja $k\in\ker\phi$ e tome $a\in A$.
Precisamos provar que o $a$-conjugado de $k$ também está no $\ker\phi$:
$ak\ginv a \in \ker\phi$.
Calculamos:
\compute
\phi\funparen{ak\ginv a}
&= \phi(a) \phi(k) \phi\funparen{\ginv a}   \by {$\phi$ homo}
&= \phi(a) e_B \phi\funparen{\ginv a}       \by {$n\in\ker\phi$}
&= \phi(a) \phi\funparen{\ginv a}           \by {def.~$e_B$}
&= \phi(a) \ginvp{\phi(a)}                  \by {$\phi$ homo}
&= e_B                                      \by {def.~$\ginvp{\phi(a)}$}
\endcompute
Logo $ak\ginv a\in\ker\phi$ como queremos provar.

\endexercise
%%}}}

%%{{{ x: kernel_is_normal_alt_proof 
\exercise.
\label{kernel_is_normal_alt_proof}%
Veja a prova completa do~\ref{kernel_is_normal}.
No seu cálculo, mostre como continuar num caminho diferente depois da terceira
igualdade para chegar no mesmo resultado desejado: $e_B$.

\hint
Aplicamos a propriedade que homomorfismos preservam os inversos.
Aplique outra propriedade de homomorfismos.

\solution
Calculamos:
\compute
\phi\funparen{ak\ginv a}
&= \phi(a) \phi(k) \phi\funparen{\ginv a}   \by {$\phi$ homo (oper.)}
&= \phi(a) e_B \phi\funparen{\ginv a}       \by {$k\in\ker\phi$}
&= \phi(a) \phi\funparen{\ginv a}           \by {def.~$e_B$}
&= \phi(a \ginv a)                          \by {$\phi$ homo (oper.)}
&= \phi(e_A)                                \by {def.~$\ginv a$}
&= e_B                                      \by {$\phi$ homo (iden.)}
\endcompute

\endexercise
%%}}}

%%{{{ x: image_subgroup 
\exercise.
\label{image_subgroup}%
Sejam $A$ e $B$ grupos e $\phi$ um homomorfismo de $A$ para $B$.
Prove que $\ima\phi\subgrp B$.

\hint
Precisas mostrar que $\ima\phi$ é fechado pela operação e pelos conjuntos.

\hint
\proofpart{$\ima\phi$ fechado pela operação:}
Tome $x', y' \in \ima\phi$ e ache um $w\in A$ tal que que $\phi(w) = x'y'$.
\crproofpart{$\ima\phi$ fechado pelos conjuntos:}
Tome $x' \in \ima\phi$ e ache um $x\in A$ tal que $\phi(x) = \ginvp{x'}$.

\solution
\proofpart{$\ima\phi$ fechado pela operação:}
Sejam $x', y' \in \ima\phi$.
Logo, sejam $x,y\in A$ tais que $\phi x = x'$, e $\phi y = y'$.
Calculamos:
\compute
\phi(xy)
&= \phi(x) \phi(y)  \by {$\phi$ homo (oper.)}
&= x' y'.           \by {pela escolha dos $x,y$}
\endcompute
Ou seja, $x'y' \in \ima\phi$.
\crproofpart{$\ima\phi$ fechado pelos conjuntos:}
Seja $x' \in \ima\phi$.
Logo, seja $x\in A$ tal que $\phi x = x'$.
Calculamos:
\compute
\phi\funparen{\ginv x}
&= \ginvp{\phi x}   \by {$\phi$ homo (inv.)}
&= \ginvp{x'}.      \by {pela escolha do $x$}
\endcompute
Ou seja, $x'\in\ima\phi$.

\endexercise
%%}}}

%%{{{ thm: first_isomorphism_theorem_groups 
\theorem Primeiro teorema de isomorfismo.
\label{first_isomorphism_theorem_groups}%
\iisee{grupo!teorema de isomorfismo}{teorema de isomorfismo}%
\ii{teorema de isomorfismo}[primeiro (de grupos)]%
\iiseealso{isomorfismo}{teorema de isomorfismo}%
Sejam $G$ e $G'$ grupos
e $\phi : G \to G'$ homomorfismo.
\beginil
\item{\rm (i)}   $\ker\phi\normal G$;
\item{\rm (ii)}  $\ima\phi\subgrp G'$;
\item{\rm (iii)} $\quogrp G {\ker\phi} \iso \ima\phi$.
\endilnoskip
\sketch.
Acabamos de provar as (i)~\&~(ii) nos~\refn{kernel_is_normal}~\&~\refn{image_subgroup}.
Para a (iii) precisamos definir uma função
$$
\Phi : \quogrp G {\ker\phi} \to \ima\phi
$$
tal que $\Phi$ é um isomorfismo.
Seja $K \asseq \ker\phi$.
Queremos definir a $\Phi$ pela
$$
\Phi(Kx) = \phi(x)
$$
para qualquer coclasse $Kx$ do $K$ (essas são as suas entradas).
\endgraf
O problema é que $\Phi$ não parece \emph{bem-definida}, pois seu valor
pode depender na escolha do representante $x$ da coclasse---veja
o~\ref{not_well_defined_function_danger_firstiso} caso que o problema
com essa definição não é claro.
Precisamos melhorar essa definição e provar que:
(a) realmente defina uma \emph{função} $\Phi$;
(b) $\Phi$ é bijetora;
(c) $\Phi$ é um homomorfismo (e logo isomorfismo).
\qes
%%}}}

%%{{{ beware: not_well_defined_function_danger_firstiso 
\beware.
\label{not_well_defined_function_danger_firstiso}%
Caso que o perigo descrito no esboço acima não é óbvio,
primeiramente volte re-estudar os
\ref{not_well_defined_function_danger_quogrp},
\ref{not_well_defined_function_danger_argument_name_dependence},
e~%
\ref{not_well_defined_function_danger_choice_dependence}.
\endgraf
Agora vamos pensar como um programador querendo definir essa
função $\Phi$.
Sua função, quando chamada, recebe uma coclasse, ou seja,
um conjunto com certos elementos membros.
Ela não sabe qual foi o nome que o chamador escolheu para essa coclasse
(\ref{not_well_defined_function_danger_argument_name_dependence}).
Até pior, e para corresponder ainda melhor com nosso caso, observe
que o $Kx$ é na verdade uma operação entre um subgrupo $K$ e um membro
$x$ que resulta num subconjunto de $G$.
Mas a $\Phi$ \emph{não tem acesso nesse $x$}
(\ref{not_well_defined_function_danger_choice_dependence}).
\endgraf
Mesmo se defini-la pela
$$
\Phi(C) = \phi(c),\quad
\text{onde $c$ é algum membro de $C$}
$$
temos uma tarefa para fazer:
\emph{precisamos provar que seu valor $\Phi(C)$ não depende da escolha de $c$}.
Até conseguir provar isso, não podemos considerar a $\Phi$ uma função
\ii{função}[bem-definida]\emph{bem-definida}.
Veja bem a prova do~\ref{first_isomorphism_theorem_groups}.
%%}}}

%%{{{ kernel <==> normal 
\note Dois lados da mesma moeda.
Já provamos algo (\ref{kernel_is_normal}) que,
informalmente falando, podemos escrever assim:
$$
\text{kernel} \implies \text{normal}.
$$
E o converso?
Será que também é verdade?
O que exatamente é esse converso?
Como formalizar?  Podemos provar?
\endgraf
Realmente o converso da implicação-informal também é válido:
$$
\text{normal} \implies \text{kernel}.
$$
Temos então o slogan
$$
\text{normal} \iff \text{kernel}.
$$
Ou seja, em teoria dos grupos os conceitos de ``kernel''
e de ``subgrupo normal'' são apenas dois lados da mesma moeda.
Deixo os \emph{detalhes importantes} pra ti,
no~\ref{normal_is_kernel}---não pule!
%%}}}

\endsection
%%}}}

%%{{{ Categories_and_groups 
\section Pouco de cats---categorias e grupos.
\label{Categories_and_groups}%

\secintro
Temos uns objetos que nos interessam: os grupos.
Temos umas setas interessantes entre esses objetos: os morfimos.
Será que temos uma categoria (\ref{category_first_def})?

%%{{{ df: GROUP 
\definition.
\label{GROUP}%
\sdefined {\GROUP} {a categoria dos grupos e seus homomorfismos}%
Denotamos por $\GROUP$ a categoria dos grupos:
\beginul
\li $\Obj \GROUP$: todos os grupos;
\li $\Arr \GROUP$: todos os homomorsfismos de grupos;
\endul
onde obviamente os $\src\phi$ e $\tgt\phi$ denotam os $\dom\phi$ e $\cod\phi$ respectivamente.
%%}}}

%%{{{ x: GROUP_is_a_cat 
\exercise.
\label{GROUP_is_a_cat}%
Demonstre que $\GROUP$ realmente é uma categoria.

\endexercise
%%}}}

%%{{{ eg: products_of_Group 
\example.
\label{products_of_Group}%
A categoria $\GROUP$ possui produtos?  (\ref{product_in_category}.)

\solution
Sim.
Dados dois objetos $G,H$ o
$\tupp{\outl, G \cross H, \outr}$ (\refn{direct_product_of_groups}) é um produto
dos $G,H$.
Primeiramente precisamos demonstrar que $G \cross H$ realmente é um objeto
da $\GROUP$, ou seja, um grupo;
tu demonstraste isso no~\ref{direct_product_of_groups_is_a_group}.
Agora falta verificar que dados $\tupp{f_1, F, f_2}$,%
\footnote{%
Sim, isso é uma frase completa, com seu verbo e tudo mais:
<<\dots dados $\tupp{f_1,F,f_2}$, existe única seta $! : F \to G \cross H$
que faz o diagrama seguinte comutar: \dots>>
Mais uma vez que percebemos a veracidade do ditado
$$
\text{1 diagrama comutativo} = \text{1{,}000 palavras}.
$$
}
$$
\cdopt{sep=1cm}
                                 \| \|                                  \| G \\
F
\ar[rr, dotted, "\unique"]
\ar[urrr, bend left=24,  "f_1"]
\ar[drrr, bend right=24, "f_2"'] \| \| G \cross H
                                       \ar[ur, bend left=15, "\outl"]
                                       \ar[dr, bend right=15, "\outr"'] \| \\
                                 \| \|                                  \| H
\endcd
$$
Defina a $!$ pela
$$
! = \fpair {f_1} {f_2}.
$$
Isso realmente é o único que faz o diagrama comutar---tu
já verificaste isso no~\ref{product_is_a_product},
certo?---então só basta demonstrar uma coisa pra terminar.
\endexample
%%}}}

%%{{{ x: what more is needed to prove? 
\exercise.
Qual?
Enuncie e demonstre!

\hint
Basta demonstrar que $! : F \to G \cross H$ é um homomorfismo mesmo.
Demonstre!

\endexercise
%%}}}

%%{{{ x: initial_and_terminal_of_Group 
\exercise.
\label{initial_and_terminal_of_Group}%
A categoria $\GROUP$ possui objetos iniciais?  Terminais?  Quais?
(\ref{initial_terminal_null_objects}.)
E, esqueci: a $\SET$ tem?

\endexercise
%%}}}

%%{{{ df: ABEL 
\definition.
\label{ABEL}%
\sdefined {\ABEL} {a categoria dos grupos abelianos e seus homomorfismos}%
Denotamos por $\ABEL$ a categoria dos grupos abelianos:
\beginul
\li $\Obj \ABEL$: todos os grupos abelianos;
\li $\Arr \ABEL$: todos os homomorsfismos de grupos abelianos;
\endul
onde novamente os $\src\phi$ e $\tgt\phi$ são as coisas óbvias.
%%}}}

%%{{{ x: ABEL_is_a_cat 
\exercise.
\label{ABEL_is_a_cat}%
Verifique que $\ABEL$ realmente é uma categoria.

\endexercise
%%}}}

\blah.
É fácil verificar que a $\ABEL$ também possui produtos:
essencialmente o mesmo argumento da $\GROUP$ passa aqui também.
Mas a situação é bastante diferente olhando para os \emph{coprodutos}
(\ref{coproduct_in_category}).

%%{{{ products_and_coproducts_in_Group_complicated
\note Coprodutos de grupos.
\label{products_and_coproducts_in_Group_complicated}%
Os coprodutos na~$\GROUP$\dots~meio complicado.
Vamos voltar nesse assunto no~\ref{Category_theory};
mas por enquanto observe que o conjunto $G \disjunion H$
que usamos para o coproduto $G \coprod H$ na $\SET$ não
possui uma estrutura de grupo óbvia para servir como coproduto
dos $G,H$.  Qual seria sua identidade, por exemplo, e, antes
de chegar em conseguir perguntar isso, qual seria sua operação?
No outro lado é fácil demonstrar que $\ABEL$ possui
coprodutos---e tu nem imagina quais são!
%%}}}

%%{{{ x: coproducts_in_Abel 
\exercise.
\label{coproducts_in_Abel}%
Dados objetos (grupos abelianos) $G,H$, ache um coproduto deles.
Tu ficarás surpreso.

\hint
Que tipo de coisa é o coproduto literalmente?

\hint
Na $\ABEL$, o $G\cross H$ serve como objeto tanto de produto,
quanto de coproduto!
Demonstre!

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Problems 
\problems.

%%{{{ prob: conjugates_look_alike 
\problem.
\label{conjugates_look_alike}%
Pode achar alguma propriedade grupoteórica tal que num grupo $G$,
dentro duma das suas classes de conjugação vai ter membros que
satisfazem e membros que não?

\endproblem
%%}}}

%%{{{ prob: hom_abel_with_pointwise_plus 
\problem.
\label{hom_abel_with_pointwise_plus}%
Sejam $G,G'$ grupos abelianos.
Prove que
$$
\Hom(G,G') \defeq \setstt {\phi : G \to G'} {$\phi$ homomorfismo}
$$
é um grupo abeliano com operação a $+$ definida pointwise (\ref{pointwise_operation}):
$$
(\phi + \psi)(x) = \phi(x) + \psi(x).
$$
com operação a $+$ pointwise é um grupo abeliano.
Precisas realmente saber que ambos os $G,G'$ são abelianos?

\solution
Primeiramente precisamos provar que $\Hom(G,G')$ é $+$-fechado.
Então sejam $\phi,\psi\in\Hom(G,G')$ e $x,y \in G$.
Calculamos:
\compute
(\phi + \psi)(x + y)
&= \phi(x + y) + \psi(x + y)                \by {pointwise~$+$}
&= \phi(x) + \phi(y) + \psi(x) + \psi(y)    \by {$\phi,\psi$ homo}
&= \phi(x) + \psi(x) + \phi(y) + \psi(y)    \by {$G'$ abeliano}
&= (\phi + \psi)(x) + (\phi+\psi)(y).       \by {def.~$\phi+\psi$}
\endcompute
Agora basta só confirmar que realmente é abeliano.
Fácil:
$$
(\phi + \psi)(x)
= \phi(x) + \psi(x)
= \psi(x) + \phi(x)
= (\psi + \phi)(x).
$$
Observe que precisamos a comutatividade apenas no $G'$,
ou seja, $\sset {\Hom(G,G')} +$ é abeliano se $G'$ é.

\endproblem
%%}}}

%%{{{ prob: aut_G_is_a_group 
\problem.
\label{aut_G_is_a_group}%
\sdefined {\Aut({\sholed G})} {o grupo de automorfismos no $G$}%
Mostre que dado um grupo $G$, o conjunto de todos os seus automorfismos
$$
\Aut G
\defeq
\set{
\phi : G\bijto G
\st
\text{$\phi$ é um automorfismo}
}
$$
com operação $\compose$ é um grupo.

\endproblem
%%}}}

%%{{{ prob: bij_G_subgrp_aut_G 
\problem.
\label{aut_G_subgrp_bij_G}%
Sabendo que $\namedop{Bij} G \defeq \sset {(G \bijto G)} {\compose}$ é um grupo,
mostre que
$$
\Aut G \subgroup \namedop{Bij} G.
$$

\hint
Se $F$ é injetora, então: $x=y \impliedby F(x) = F(y)$.

\solution
Como $\Aut G \subset \namedop{Bij} G$ precisamos verificar
apenas que $\Aut G$ é:
\crproofpart{Não vazio:}
$\id : G \to G$ é um automorfismo (\ref{id_is_an_auto})
e logo $\Aut G\neq\emptyset$.
\crproofpart{Fechado pela operação:}
Tome $\phi,\psi\in\Aut G$, e $x,y\in G$.  Calculamos:
\compute
(\phi\compose\psi)(x\cdot y)
&=\phi\paren{\psi(x\cdot y)}                                     \by {def.~$\compose$}
&=\phi\paren{\psi(x) \cdot \psi(y)}                              \by {$\psi$ homo}
&=\phi\paren{\psi(x)} \cdot \phi\paren{\psi(y)}                  \by {$\phi$ homo} 
&=\paren{\phi\compose\psi}(x) \cdot \paren{\phi\compose\psi}(y). \by {def.~$\compose$}
\endcompute
\proofpart{Fechado pelos inversos:}
Tome $\phi\in\Aut G$.
Precisamos verificar que a bijecção $\finv\phi$
é realmente um homomorfismo.
Ou seja, precisamos mostrar que
$$
\phi^{-1}(x\cdot y) = \phi^{-1}(x)\cdot \phi^{-1}(y)
$$
para todos os $x,y\in G$.
Seguindo a dica, basta provar que
$$
\phi\paren{\phi^{-1}(x\cdot y)} = \phi\paren{\phi^{-1}(x)\cdot \phi^{-1}(y)}
$$
O lado esquerdo é igual ao $x\cdot y$.
Calculamos o lado direito:
\compute
\phi\paren{\phi^{-1}(x) \cdot \phi^{-1}(y)}
&=\phi\paren{\phi^{-1}(x)} \cdot \phi\paren{\phi^{-1}(y)}   \by {$\phi$ homo}
&=x\cdot y.  \by {def.~$\phi^{-1}$}
\endcompute

\endproblem
%%}}}

%%{{{ df: inner_auto 
\definition Inner autos.
\label{inner_auto}%
\tdefined{automorfismo}[inner]%
\sdefined {\Inn({\sholed G})} {os inner automorfismos de $G$}%
\iisee{inner automorfismo}{automorfismo, inner}%
Seja $G$ grupo.
Definimos o conjunto dos seus \dterm{inner automorfismos}
$$
\Inn(G) \defeq \setst {\gconj g} {g \in G}
$$
onde $\gconj g$ é o $g$-conjugador (\ref{conjugator}).
%%}}}

%%{{{ prob: inn_normal_aut 
\problem.
\label{inn_normal_aut}%
$\Inn G \normal \Aut G$.

\hint
Enxergue bem todos os seus alvos:
(i) $\Inn G \subset \Aut G$;
(ii) $\Inn G \subgroup \Aut G$;
(iii) $\Inn G \normal \Aut G$.
O que precisas demonstrar para matar cada um deles?

\solution
Precisamos demonstrar:
$\Inn G \subset \Aut G$;
$\Inn G \subgroup \Aut G$;
$\Inn G \normal \Aut G$.
\crtabproofpart{$\Inn G \subset \Aut G$}.
Seja $f \in \Inn G$.
Logo seja $g \in G$ tal que $f = \actorS g {\ginv g}$.
Precisamos mostrar que $f$ é um automorfismo.
Já demonstramos que é bijetora (\ref{group_actors_are_bijective})
então basta provar que é um homomorfismo.
Pelo~\ref{criterion_for_morphism_in_groups}, é suficiente
mostrar que $f$ respeita a operação.
Calculamos:
$$
\align
f(x)f(y)
&= \paren{\actorS g {\ginv g} x}
   \paren{\actorS g {\ginv g} y} \\
&= \paren{gx\ginv g}
   \paren{gy\ginv g} \\
&= gx\ginv g g y \ginv g \\
&= gxey \ginv g \\
&= g(xy) \ginv g \\
&= f(xy).
\endalign
$$
\crtabproofpart{$\Inn G \subgroup \Aut G$}.
Vamos usar o~\ref{nonempty_subgroup_criterion}.
Primeiramente mostramos que $\Inn G \neq \emptyset$:
de fato, $\idof G \in \Inn G$, pois $\idof G$ é um inner:
$$
\idof G = \actorS e {\ginv e}.
$$
\crproofpart{$\Inn G$ $\fcom$-fechado}.
Agora sejam $f_1,f_2 \in \Inn G$.
Vou demonstrar que
$f_1\fcom f_2$ é um inner.
Como $f_1,f_2$ são inners, sejam $g_1,g_2$ tais que
$$
\xalignat2
f_1 & = \actorS {g_1} {\ginv {g_1}} &
f_2 & = \actorS {g_2} {\ginv {g_2}}.
\endxalignat
$$
Para um arbitrário $x \in G$ temos:
$$
\align
(f_1 \fcom f_2) x
&= f_1 ( f_2 x ) \\
&= f_1 ( g_2 x \ginv {g_2} ) \\
&= g_1 ( g_2 x \ginv {g_2} ) \ginv {g_1} \\
&= (g_1 g_2) x \paren{\ginv {g_2} \ginv {g_1}} \\
&= (g_1 g_2) x \ginvp{g_1 g_2}.
\endalign
$$
Ou seja, $f_1\fcom f_2\in\Inn G$.
\crproofpart{$\Inn G$ $\ginv{}$-fechado}.
Seja $f \in \Inn G$, e logo seja $g\in G$
tal que $f = \actorS g {\ginv g}$.
Observe que $\actorS {\ginv g} g$ é a inversa da $f$,
e que realmente é um inner, pois
$$
\actorS {\ginv g} g = \actorS {\ginv g} {\ginvp {\ginv g}},
$$
ou seja, $\ginv f \in \Inn G$.
\crtabproofpart{$\Inn G$ fechado pelos conjugados}.
Seja $f \in \Inn G$ e logo seja $g\in G$
tal que $f = \actorS g {\ginv g}$.
Vou mostrar que todos os conjugados de $f$ são inners.
Seja então $\alpha \in \Aut G$.
Basta provar que $\alpha f \ginv{\alpha} \in \Inn G$.
Ou seja, basta resolver o
$$
\alpha f \ginv{\alpha} = \actorS {\askbox} {\ginv{\askbox}}.
$$
Para um arbitrário $x \in G$ temos:
\compute
\paren{\alpha \fcom f \fcom \ginv{\alpha}} x
&= \alpha \funparen{ f \funparen { \finv{\alpha} x } }                               \by {def.~$\fcom$}
&= \alpha \funparen{ g \ast \paren { \finv \alpha x } \ast \ginv g }                 \by {pela escolha de $g$}
&= \alpha g \ast \alpha \funparen { \finv \alpha x } \ast \alpha \funparen {\ginv g} \by {$\alpha$ homo: resp.~op.}
&= \alpha g \ast \paren{\alpha \fcom \finv \alpha} x \ast \alpha \funparen {\ginv g} \by {def.~$\fcom$}
&= \alpha g \ast x \ast \alpha \funparen {\ginv g}                                   \by {def.~$\finv \alpha$}
&= \alpha g \ast x \ast \ginvp {\alpha g}                                            \by {$\alpha$ homo: resp.~inv.}
\endcompute
e logo $\alpha f \ginv{\alpha} \in \Inn G$.

\endproblem
%%}}}

%%{{{ prob: normal_is_not_an_order 
\problem.
\label{normal_is_not_an_order}%
A relação $\normal$ é uma ordem?

\hint
Não é!
Ela não é transitiva.
Demonstre!

\hint
Basta achar contraexemplo: grupo $G$ e subgrupos $A,B \subgrp G$
tais que $A \normal B \normal G$ mas $A \nnormal G$.

\hint
Procure teu contraexemplo no $G \asseq \sym 4$ e seus subgrupos
(considere o $A \asseq \gen{\permc{1 & 2}\permc{3 & 4}}$.
Alternativamente, procure no $\dih 4$ e seus subgrupos;
talvez olhando para o diagrama Hasse do $\dih 4$ ajuda.

\endproblem
%%}}}

%%{{{ prob: normal_is_kernel 
\problem kernel = normal.
\label{normal_is_kernel}%
Já provamos algo que informalmente falando podemos escrever assim:
$$
\text{kernel} \implies \text{normal}
$$
Formalize e prove o converso.

\hint
Formalização:
{\proclaimstyle
Seja $G$ grupo e $N \normal G$.
Logo existem grupo $G'$ e homomorfismo $\phi : G \to G'$
tal que $N$ é o kernel de $\phi$.}

\hint
O $G'$ é o $\quogrp G N$.

\solution
Formalização:
{\proclaimstyle Seja $G$ grupo e $N \normal G$.
Logo existem grupo $G'$ e homomorfismo $\phi : G \to G'$
tal que $N$ é o kernel de $\phi$.}
\crproofpart{\proofname.}
Considere o grupo $\quogrp G N$ e
defina a $\phi : G \to \quogrp G N$
pela
$$
\phi(x) = Nx.
$$
Basta provar que:
\beginil
\item{(i)}  $\phi$ é um homomorfismo;
\item{(ii)} $\ker\phi = N$.
\endil
(i) Basta verificar que $\phi$ respeita a operação.
Sejam $x,y \in G$.
Calculamos
$$
\phi (xy) = N(xy) = (Nx)(Ny) = \phi(x) \phi(y).
$$
(ii) Temos
\compute
x\in \ker\phi
&\iff \phi(x) = e_{\quogrp G N} \by {def.~$\ker\phi$}
&\iff \phi(x) = N    \by {$N$ é a identidade do $\quogrp G N$}
&\iff Nx = N         \by {def.~$\phi$}
&\iff x \in N.       \by {\ref{Ha_eq_H_iff_a_in_H}}
\endcompute
Ou seja, $\ker\phi = N$.
\endgraf
Com isso concluimos que na teoria dos grupos,
``subgrupo normal'' e ``kernel'' são dois lados da mesma moeda.

\endproblem
%%}}}

%%{{{ prob: cayley_theorem 
\problem Teorema de Cayley.
\label{cayley_theorem}%
\TODO Outline Cayley's theorem.

\endproblem
%%}}}

%%{{{ prob: cauchy_theorem 
\problem Teorema de Cauchy.
\label{cauchy_theorem_groups}%
\TODO Outline Cauchy's theorem.

\endproblem
%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

Para practicar com propriedades de operações vale a pena
resolver os primeiros 15 problemas do~\cite{halmoslapb}.

Livros introdutórios em álgebra abstrata tratam em geral
a teoria dos grupos mais profundamente que podemos tratar aqui.
\cite{pinteralgebra} é um desses livros, bastante acessível,
com exemplos de diversas áreas, mostrando várias aplicações.
Uma \emph{excelente} introdução em vários tópicos de álgebra é
o~\cite{hersteintopics}, famoso para sua exposição e didática.

A álgebra abstrata foi introduzida nos currículos de graduação
com o clássico~\cite{babybm}.  Os mesmos autores, no~\cite{papamb},
apresentam álgebra mais profundamente e com um cheiro
categórico (veja~\ref{Category_theory}).
O bem-legível \cite{aluffialgebra} começa já introduzindo a linguagem
e as idéias das categorias e trata assim todos os assuntos principais
de álgebra abstrata.

Depois de se acostumar com as idéias algébricas em geral,
dois livros focados especialmente em teoria dos grupos
são os~\cite{rosegroups} e~\cite{rotmangroups}.

O convex hull que encontramos \emph{en passant} nesse capítulo
gera um problema algorítmico muito interessante:
\emph{dado um conjunto $A$ de pontos dum espaço euclideano
calcule um óptimo $C \subset A$ tal que seus pontos
são as vértices do convex hull do $A$}.
Para mais sobre isso, veja por exemplo o~\cite{clrs}[\S33.3].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Algebraic structures 
\chapter Estruturas algébricas.
\label{Algebraic_structures}%

%%{{{ Monoids 
\section Monóides.
\label{Monoids}%

%%{{{ df: monoid 
\definition Monóide.
\label{monoid}%
\tdefined{monóide}%
Um conjunto estruturado $\cal M = \sset M {\cdot,\epsilon}$
é um \dterm{monóide} sse:
$$
\alignat2
\pforall {a,b\in M}    &\bracket{a\cdot b \in G}                       &\tag{G0}\\
\pforall {a,b,c\in M}  &\bracket{a\cdot(b\cdot c) = (a\cdot b)\cdot c} &\tag{G1}\\
\pforall {a\in M}      &\bracket{\epsilon\cdot a = a = a\cdot\epsilon} &\tag{G2}
\endalignat
$$
Naturalmente, se a $\cdot$ é comutativa chamamos $M$ de \dterm{monóide comutativo}.
%%}}}

%%{{{ eg: any group is a monoid 
\example.
A partir de qualquer exemplo de grupo
$\cal G = \sset G {\ast_G, \ginv{}, \gidof G}$
temos um exemplo de monóide também:
o~$\sset G {\ast_G, \gidof G}$.
\endexample
%%}}}

\blah.
Mais interessantes agora seriam exemplos de monóides
que não são grupos:

%%{{{ eg: nats with addition 
\example.
Os naturais com adição formam um monóide.
\endexample
%%}}}

%%{{{ eg: positive nats with multiplication 
\example.
O $\sset {\nats_{\neq0}} {\ntimes}$ é um monóide.
\endexample
%%}}}

%%{{{ eg: strings 
\example Strings.
Considere um alfabeto finito $\Sigma$ e seja $\kstar\Sigma$
o conjunto de todos os strings formados por letras do $\Sigma$.
O $\kstar \Sigma$ com a operação a concatenação de strings,
é um monóide.  Sua identidade é o string vazio.
\endexample
%%}}}

%%{{{ Q: How would you define the submonoid relation? 
\question.
Como tu definirias a relação de submonóide?
%%}}}
\spoiler.

%%{{{ df: submonoid 
\definition submonóide.
\label{submonoid}%
\tdefined{submonóide}%
Seja $\cal M = \sset M {\cdot_M,\epsilon_M}$ monóide
e $H \subset M$.
O $H$ é um submonóide de $M$ sse $\epsilon_M \in H$
e $H$ é $\cdot_M$-fechado.
%%}}}

%%{{{ remark: same abuses as always 
\remark abusamos como sempre.
Literalmente não é o conjunto $H$ que é submonóide,
mas o conjunto estruturado
$$
\cal H \asseq \text{$\sset H {{{\cdot_M} \restosub {N \times N}}, \epsilon_M}$}.
$$
Eu presumo que tu és acostumado com esses abusos depois que
os discutimos nos itens~\refn{notational_abuse_structured_sets}
e~\refn{notational_abuse_groups}.
%%}}}

%%{{{ Q: How would you define homomorphism between monoids? 
\question.
Como tu definirias o homomorfismo entre monóides?
%%}}}
\spoiler.

%%{{{ df: monoid_homomorphism 
\definition homomorfismo.
\label{monoid_homomorphism}%
\tdefined{homomorfismo}[de monóide]%
Sejam $\cal M = \sset M {\cdot_M,\epsilon_M}$
e $\cal N = \sset N {\cdot_N,\epsilon_N}$ monóides.
Uma função $\phi : M \to N$ é um \dterm{homomorfismo} sse:
\beginol
\li para todo $x,y\in M$,\quad $\phi(x \cdot_M y) = \phi(x) \cdot_N \phi(y)$.
\li $\phi(\epsilon_M) = \epsilon_N$;
\endol
%%}}}

%%{{{ eg 
\example.
Considere os monóides $\cal N = \sset \nats {0, +}$ e
$\cal B = \sset B {\concat,\epsilon}$, onde:
$B$ é o conjunto de todos os strings (finitos) binários,
ou seja, $B=\kstar{\set{\digit 0,\digit 1}}$;
$\epsilon$ é o string vazio ``$\,$'';
$\concat$ a concatenação.
A $\phi : \cal N \to \cal B$ definida recursivamente pelas
$$
\align
\phi(0)     &= \epsilon\\
\phi(n+1)   &= \phi(n) \concat \digit0
\endalign
$$
é um homomorfismo.
A $\namedfun{length} : \cal B \to \cal N$ que retorna o tamanho da sua entrada é um homomorfismo.
\endexample
%%}}}

%%{{{ noneg 
\nonexample.
Com o contexto do exemplo anterior, a $\psi : \cal N \to \cal B$
definida recursivamente pelas:
$$
\align
\psi(0)     &= \epsilon\\
\psi(n+1)   &=
\knuthcases{
\psi(n) \concat \digit0, & se $\psi(n)$ não termina com $\digit0$\cr
\psi(n) \concat \digit1, & caso contrário
}
\endalign
$$
não é um homomorfismo.
\endnonexample
%%}}}

%%{{{ x: why? 
\exercise.
Por quê?

\solution
Temos:
$$
\psi(1+1)
= \digit0\digit1
\neq \digit0\digit0
= \psi(1)\concat\psi(1).
$$

\endexercise
%%}}}

%%{{{ beware: not everything comes for free 
\beware.
No~\ref{Group_theory} assim que definimos o que significa homomorfismo
de grupos~(\refn{group_homomorphism}) demonstramos
o~\ref{criterion_for_morphism_in_groups} que nos permite concluir
que uma função entre grupos é homomorfismo assim que
souber que ela respeita a operação.
Isso quis dizer que temos esse critério nos monóides também?
Primeiramente olhamos para a demonstração
do~\ref{criterion_for_morphism_in_groups} para ver se
ela ``passa'' nos monóides também:
se ela usou apenas os (G0)--(G2), então passa.
Não é o caso: \emph{essa} demonstração necessitou o (G3)
pois usou os inversos.
Então isso quis dizer que perdemos esse critério nos monóides?
\emph{Não!}
O que perdemos foi a demonstração; mas talvez existe
outra que segura o mesmo teorema, e que não necessita os inversos.
Será?
%%}}}

%%{{{ x: in_monoids_preservation_of_oper_does_not_imply_preservation_of_identity 
\exercise.
\label{in_monoids_preservation_of_oper_does_not_imply_preservation_of_identity}%
Podemos provar um critérion parecido com
o~\ref{criterion_for_morphism_in_groups} para os monóides?
Ou seja, se $\phi$ preserva a operação do monóide,
ela necessariamente preserva a identidade também?

\hint
Não!
Mas como podemos demonstrar que não tem como demonstrar isso?

\hint
Procure um contraexemplo:
monóides $\cal M, \cal N$ e função $\phi : M \to N$ tais que
$\phi$ preserva a operação do monóide mas não a identidade.

\endexercise
%%}}}

%%{{{ criterion: monoid_morphism_criterion 
\criterion.
\label{monoid_morphism_criterion}%
Uma função sobrejetora $\phi : M \surto N$ tal que
$$
\text{para todo $x,y\in M$},\quad
\phi(x \cdot_M y) = \phi(x) \cdot_N \phi(y)
$$
é um homomorfismo.
\proof Demonstrarás agora no~\ref{monoid_morphism_criterion_proof}.
\qed
%%}}}

%%{{{ x: monoid_morphism_criterion_proof 
\exercise Critérion.
\label{monoid_morphism_criterion_proof}%
Demonstre o~\ref{monoid_morphism_criterion}.

\hint
Precisamos provar que $\phi(\epsilon_M) = \epsilon_N$.
Como podemos ler essa igualdade em lingua (mais) natural?

\hint
Queremos: <<o $\phi(\epsilon_M)$ é a identidade do $\cal N$>>.
O que significa <<ser a identidade dum monóide>>?
Ou seja, o que precisamos provar sobre esse objeto, $\phi(\epsilon_M)$
para mostrar que realmente ele é a identidade?

\hint
Precisamos provar que:
$$
\lforall {n \in N} {n \cdot_N \phi(\epsilon_M) = n = \phi(\epsilon_M) n}.
$$
Como começaria essa prova?

\hint
``Seja $n \in N$.''
Depois dessa frase, queremos provar que
$$
n \cdot_N \phi(\epsilon_M) = n = \phi(\epsilon_M) n.
$$

\hint
Já provamos no~\ref{in_monoids_preservation_of_oper_does_not_imply_preservation_of_identity} que não tem como ganhar a preservação da identidade como conseqüência da preservação da operação tendo uma função $\phi : M \to N$ qualquer.  Então com certeza precisamos usar nossa hipótese nova aqui, que a $\phi$ é sobrejetora.

\hint
Seja $n \in N$.
Como $\phi$ é sobrejetora, tome $m \in M$ tal que $\phi(m) = n$.

\solution
Vamos provar que $\phi(\epsilon_M) = \epsilon_N$, ou seja, que para todo $n\in N$, 
$$
n \cdot_N \phi(\epsilon_M) = n = \phi(\epsilon_M) \cdot_N n.
$$
Seja $n \in N$.
Logo $n = \phi(m)$ para algum $m \in M$ (pois $\phi$ sobre $N$).
Calculamos:
\compute
n\cdot_N \phi(\epsilon_M)
&= \phi(m) \cdot_N \phi(\epsilon_M) \by {pela escolha do $m$}
&= \phi(m \cdot_M \epsilon_M)       \by {$\phi$ homo: resp.~op.}
&= \phi(m)                          \by {pela (G2)}
&= n                                \by {pela escolha do $m$}
\endcompute
Similarmente, $n = \phi(\epsilon_M) \cdot_N n$.
\endgraf
Alternativamente, podemos começar assim:
seja $m \in M$ tal que $\phi(m) = e_N$; e agora
\compute
\phi(e_M)
&= \phi(e_M) e_N        \by {def.~$e_N$}
&= \phi(e_M) \phi(m)    \by {pela escolha de $m$}
&= \phi(e_M m)          \by {$\phi$ homo: resp.~op.}
&= \phi(m)              \by {def.~$e_M$}
&= e_N.                 \by {pela escolha de $m$}
\endcompute

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Rings 
\section Aneis.
\label{Rings}%

\blah.
Vamos estudar pouco a estrutura de \emph{anel},
cuja definição foi dada primeiramente por \Fraenkel{}Fraenkel.
Nossa inspiração e guia para os grupos, foram os mapeamentos e as permutações.
Para os anéis, nossa guia são os inteiros.

%%{{{ df: ring 
\definition Anel.
\label{ring}%
\tdefined{anel}%
\tdefined{anel}[comutativo]%
Seja $\cal R = \sset R {\plus,\,\ntimes,0,1}$ um conjunto estruturado,
onde $\plus,\ntimes$ são operações binárias
e $0,1$ são constantes.
$\cal R$ é um \dterm{anel} (ou \dterm{ring}) sse
$$
\alignat2
\pforall {a,b\in R}                 &\bracket{a\plus b \in R}                              &\tag{RA0} \\
\pforall {a,b,c\in R}               &\bracket{a\plus(b\plus c) = (a\plus b)\plus c}        &\tag{RA1} \\
\pforall {a \in R}                  &\bracket{0\plus a = a = a\plus 0}                     &\tag{RA2} \\
\pforall {a\in R} \pexists {y\in R} &\bracket{y\plus a = 0 = a \plus y}                    &\tag{RA3} \\
\pforall {a,b\in R}                 &\bracket{a\plus b = b \plus a}                        &\tag{RA4} \\
\pforall {a,b\in R}                 &\bracket{a\ntimes b \in R}                            &\tag{RM0} \\
\pforall {a,b,c\in R}               &\bracket{a\ntimes(b\ntimes c) = (a\ntimes b)\ntimes c}&\tag{RM1} \\
\pforall {a \in R}                  &\bracket{1\ntimes a = a = a\ntimes 1}                 &\tag{RM2} \\
\pforall {a,b,c \in R}              &\bracket{a\ntimes (b \plus c) = (a\ntimes b) \plus (a \ntimes c)}  &\tag{RDL}\\
\pforall {a,b,c \in R}              &\bracket{(b \plus c)\ntimes a = (b\ntimes a) \plus (c \ntimes a)}  &\tag{RDR}\\
\intertext{Caso que também é satisfeita a lei}
\pforall {a,b\in R}                 &\bracket{a\ntimes b = b \ntimes a}                    &\tag{RM4}
\endalignat
$$
chamamos o $\cal R$ \dterm{anel comutativo}.
%%}}}

%%{{{ x: rings_with_different_structures 
\exercise.
\label{rings_with_different_structures}%
Acima escolhemos a maneira ``intermediaria'' de estrutura.
Qual seria uma estrutura ``mais completa'' para definir o conceito de anel, e qual uma estrutura mais pobre?
Descreva as aridades dos símbolos usados (a assinatura da estrutura algébrica).

\solution
A estrutura mais completa:
$$
\sset R {+,\ntimes,-,0,1}
$$
onde seus símbolos têm as aridades $(2,2,1,0,0)$ respectivamente.
A estrutura mais pobre:
$$
\sset R {+,\ntimes}
$$
com assinatura $(2,2)$.

\endexercise
%%}}}

%%{{{ x: ring_definition_using_groups 
\exercise.
\label{ring_definition_using_groups}%
Como podemos definir o que é um anel usando definições de estruturas algébricas que já conhecemos?

\solution
Seja $\cal R = \sset R {\plus, \ntimes, -, 0, 1}$ um conjunto estruturado,
onde $0,1$ são constantes, $\plus,\ntimes$ são operações binárias, e $-$ unária.
O $\cal R$ é um \dterm{anel} sse:
\item{(i)} $\sset R {\plus, -, 0}$ é um grupo abeliano;
\item{(ii)} $\sset R {\ntimes, 1}$ é um monóide;
\item{(iii)} as seguintes leis são satisfeitas:
$$
\alignat2
\pforall {a,b,c \in R} &\bracket{a\ntimes (b \plus c) = (a\ntimes b) \plus (a \ntimes c)}  &\tag{RDL}\\
\pforall {a,b,c \in R} &\bracket{(b \plus c)\ntimes a = (b\ntimes a) \plus (c \ntimes a)}  &\tag{RDR}
\endalignat
$$

\endexercise
%%}}}

%%{{{ note: notation 
\note Notação.
\label{subtraction_in_rings}%
\label{multiples_in_rings}%
\label{powers_in_rings}%
Dado $x\in R$, denotamos com $(-x)$ o objeto garantido pela~(RA3).
Seguindo nossa experiência com adição e multiplicação de números,
adoptamos as mesmas convenções para os anéis: denotamos pela juxtaposição
a ``multiplicação'' do anel, e consideramos que ela tem precedência contra a ``adição''.
Note também que como não temos alguma operação binária $-$ de subtraição,
a expressão $x-y$ num anel não é definida.
Definimos a operação \emph{binária} $-$ num anel $R$ pela
$$
x - y \sugareq x + (-y).
$$
Pelo contexto sempre dará pra inferir a aridade do símbolo \sq{$-$};
então não tem como criar ambigüidade com a operação \emph{unária} $-$,
mesmo compartilhando o mesmo símbolo.
Continuando, se $n\in\nats$, usamos:
$$
\xalignat2
nx   &\sugareq \tubrace{x + x + \dotsb + x} {$n$ vezes} &
x^n  &\sugareq \tubrace{x x \dotsb x} {$n$ vezes}.
\intertext{Ou seja, lembrando da notação do~\ref{powers_in_group}:}
nx   &\sugareq x^{+n} &
x^n  &\sugareq x^{\ntimes n}.
\endxalignat
$$
%%}}}

%%{{{ eg: first_ring_examples 
\example.
\label{first_ring_examples}%
Todos os seguintes conjuntos são exemplos de anéis:
$$
\xalignat7
&\sset \ints                {+,\ntimes}&
&\sset \rats                {+,\ntimes}&
&\sset \reals               {+,\ntimes}&
&\sset \complex             {+,\ntimes}&
&\sset {\polys\reals x}     {+,\ntimes}&
&\sset {C[a,b]}             {+,\ntimes}&
&\sset {\reals^{n\times n}} {+,\ntimes}
\endxalignat
$$
onde lembramos que
$\polys\reals x$ é o conjunto de todos os polinómios numa variável $x$ com coeficientes
reais,
e $\reals^{n\times n}$ é o conjunto de todas as matrices reais $n\times n$.
Temos também
$$
C[a,b]
\defeq
\setstt {f : [a,b]\to\reals} {$f$ é contínua}
$$
para quaisquer $a,b\in\reals$ com $a\leq b$.
A adição e multiplicação no $C[a,b]$ são as
\emph{operações~\ii{pointwise}[operação]pointwise},
definidas pelas:
$$
\xalignat2
f + g       &= \lam x {f(x) + g(x)}         &
f \ntimes g &= \lam x {f(x) \ntimes g(x)}.
\endxalignat
$$
(Veja a~\ref{pointwise_operation}.)
\endexample
%%}}}

%%{{{ eg: End_G_is_a_ring_claim 
\example.
Fez o~\ref{hom_abel_with_pointwise_plus}?%
\footnote{Não?  Vá lá fazer agora e volte assim que resolver.}
Quem fez, sabe que se $G'$ é abeliano, então o
$\sset {\Hom(G,G)} +$ onde $+$ é a operação pointwise
baseada no $+_{G'}$.
Em particular, para qualquer grupo abeliano $G$ o conjunto
$$
\End(G) \defeq \Hom(G,G)
$$
vira um grupo abeliano $\sset {\End(G)} +$.
Mas no mesmo conjunto uma outra operação interessante é a composição.
O $\sset {\End(G)} {+,\com}$ é um anel.
\endexample
%%}}}

%%{{{ x: End_G_is_a_ring_proof 
\exercise.
Prove!

\endexercise
%%}}}

%%{{{ df: zero_ring 
\definition.
\label{zero_ring}%
Se num anel $R$ temos $0_R = 1_R$ chamamos o $R$ de \dterm{anel zero}.
Caso contrário \dterm{anel não-zero}.
%%}}}

%%{{{ lemma: ring_zero_absorbs 
\lemma Zero absorve.
\label{ring_zero_absorbs}%
Seja $R$ um anel.
Então:
$$
\text{para todo $x\in R$,}\quad
0x = 0 = x0.
$$
\proof.
Seja $x\in R$.
Calculamos:
\compute
0x
&= (0 + 0)x  \by {def.~$0$}
&= 0x + 0x   \by {pela~(RDR)}
\endcompute
Achamos então que $0x$ é uma resolução da $0x + \askbox = 0x$.
E como o $\sset R +$ é um grupo sabemos então que $0x = 0$
(\ref{cheaper_gid}) que foi o que queremos provar.
\qed
%%}}}

%%{{{ corollary: a zero ring is a singleton 
\corollary.
Se $R$ é um anel zero, $R$ é um singleton.
\proof.
Seja $r \in R$.  Calculamos:
$$
r = r1_R = r0_R = 0_R.
$$
\qed
%%}}}

%%{{{ x: ring_negation_of_difference 
\exercise.
\label{ring_negation_of_difference}%
Para todo $a,b\in R$,
$$
-(a - b) = b - a.
$$

\endexercise
%%}}}

%%{{{ lemma: ring_negation_of_product 
\lemma Negação de produto.
\label{ring_negation_of_product}%
Seja $R$ um anel.  Logo,
$$
\text{para todo $a,b\in R$,}\quad
(-a)b = -(ab) = a(-b).
$$
\sketch.
Para provar a primeira igualdade, basta enxergá-la como a afirmação seguinte:
\emph{o $(-a)b$ é o $+$-inverso do $ab$}.
Verificamos então que $ab + (-a)b = 0$.
A outra igualdade é similar.
\qes
\proof.
Verificamos que $(-a)b$ realmente é o inverso de $ab$:
\compute
ab + (-a)b
&= (a + (-a))b  \by {pela (RDR)}
&= 0b           \by {def.~$(-a)$}
&= 0            \by {\ref{ring_zero_absorbs} com $x\asseq b$}
\endcompute
e como a equação $ab + \askbox$ tem resolução única
(pois o $\sset R +$ é um grupo)
e o $-(ab)$ também a resolve,
concluimos que $(-a)b = -(ab)$.
A outra igualdade é similar.
\qed
%%}}}

%%{{{ corollary 
\corollary.
Em qualquer anel $\cal R$, para todos $x,y\in\cal R$ temos:
\item{\rm (i)}   $(-x)(-y) = xy$;
\item{\rm (ii)}  $(-1)x = -x$;
\item{\rm (iii)} $(-1)(-1) = 1$;
\item{\rm (iv)}  $-(x+y) = (-x) + (-y)$.
%%}}}

%%{{{ x: pset_with_setops_ring 
\exercise.
\label{pset_with_setops_ring}%
Seja $X$ conjunto.
Defina no $\pset X$ duas operações tais que $\pset X$ vira um anel.
Identifique quas são seus $0,1$ e prove que realmente é um anel.

\hint
Lembre o~\ref{pset_with_setops_group}?

\hint
Graças ao~\ref{pset_with_setops_group}, a adição do anel deve ser a $\symdiff$.

\hint
$\sset {\pset X} {\symdiff, \inter}$.

\endexercise
%%}}}

%%{{{ Q: How would you define subring and ring homomorphism? 
\question.
Como tu definirias o conceito de subanel?
Pode definir algum critérion parecido com os critéria~\refn{nonempty_subgroup_criterion}
ou~\refn{finite_subgroup_criterion} para decidir se algo é subanel dum dado anel?
E o homomorfismo de anel?  Como definirias isso?  E pode definir algum critérion
parecido com o~\refn{criterion_for_morphism_in_groups}?
\spoiler.
%%}}}

%%{{{ df: subring 
\definition Subanel.
\label{subring}%
\tdefined{subanel}%
Seja $\cal R$ um anel.
O $S\subset R$ é um \dterm{subanel} de $\cal R$ sse
$\sset S {+_R, \cdot_R,0_R, 1_R}$ é um anel.
%%}}}

%%{{{ criterion: subring_criterion 
\criterion de subanel.
\label{subring_criterion}%
Sejam $R$ anel e $S \subset R$.
O $S$ é um subanel de $R$ sse:
\item{\rm (i)}  $S$ tem a identidade do $R$: $1_R \in S$;
\item{\rm (ii)} $S$ é fechado pela adição: para todo $a,b \in S$, $a+b \in S$;
\item{\rm (iii)}$S$ é fechado pela multiplicação: para todo $a,b \in S$, $ab \in S$;
\item{\rm (iv)} $S$ é fechado pelos negativos: para todo $a \in S$, $-a\in S$.
%%}}}

%%{{{ df: ring_homomorphism 
\definition homomorfismo.
\label{ring_homomorphism}%
\tdefined{homomorfismo}[de anel]%
Sejam os anéis
$\cal R = \sset R {+_R, \cdot_R, 0_R, 1_R}$ e
$\cal S = \sset S {+_S, \cdot_S, 0_S, 1_S}$.
A~função $\phi : R \to S$ é um homomorfismo sse:
\item{\rm (i)}   $\phi(0_R) = 0_S$;
\item{\rm (ii)}  $\phi(1_R) = 1_R$;
\item{\rm (iii)} para todo $x,y\in R$, $\phi(x+_R y) = \phi(x) +_S \phi(y)$;
\item{\rm (iv)}  para todo $x,y\in R$, $\phi(x\cdot_R y) = \phi(x) \cdot_S \phi(y)$;
\item{\rm (v)}   para todo $x\in R$, $\phi(-x) = -(\phi(x))$.
%%}}}

%%{{{ criterion: ring_homomorphism_criterion 
\criterion de homomorfismo.
\label{ring_homomorphism_criterion}%
Se a função $\phi : \cal R \to \cal S$ satisfaz:
$$
\align
\phi(1_R)           &= 1_S\\
\phi(x +_R y)       &= \phi(x) +_S \phi(y)\quad\text{para todo $x,y\in R$}\\
\phi(x \cdot_R y)   &= \phi(x) \cdot_S \phi(y)\quad\text{para todo $x,y \in R$}
\endalign
$$
então ela é um homomorfismo.
(Ou seja, podemos apagar os itens (i) e (v) na~\ref{ring_homomorphism}.)
\proof.
Como $\sset R {+_R}$ e $\sset S {+_S}$ são grupos,
sabemos que se $\phi$ respeita a operação aditiva então
ela necessariamente respeita sua identidade e seus inversos
também~(\ref{criterion_for_morphism_in_groups}).
\qed
%%}}}

%%{{{ x: multiplicative_part_of_a_ring_not_a_group 
\exercise.
\label{multiplicative_part_of_a_ring_not_a_group}%
As leis de anel exigem que sua ``parte aditiva'' é um grupo abeliano,
e sobre sua ``parte multiplicative'' exigem apenas ser um monóide.
Pode ter anel $\cal R = \sset R {+,\ntimes,0,1}$ cuja parte multiplicative
realmente forma um grupo?
Ou seja, tal que $\sset R {\ntimes, 1}$ é um grupo?
Se sim, mostre um exemplo de tal anel;
se não, demonstre que não existe tal anel.

\hint
\ref{ring_zero_absorbs}.

\hint
Não pode.  Exceto se\dots

\solution
Se é pra ter tal anel $R$, qual seria o inverso de $0$?
Pelo~\ref{ring_zero_absorbs} temos que
$$
0 x = 0
$$
para todo $x\in R$, e logo para $x \asseq \ginv 0$ também:
$$
0 \ginv 0 = 0
$$
Mas $0 \ginv 0 = 1$ pela definição de $\ginv 0$, e logo
$$
0 = 0 \ginv 0 = 1.
$$
Necessariamente então, em tal ring temos $0=1$.
Pode ter mais membros alem do $0$?
Não!
Seja $r\in R$.
Temos então
\compute
r
&= 1r \by {def.~$1$}
&= 0r \by {pois 0=1}
&= 0  \by {pelo~\ref{ring_zero_absorbs}}
\endcompute
e logo $R = \set {0_R}$.

\endexercise
%%}}}

%%{{{ df: kernel_image_in_rings 
\definition kernel, image.
\label{kernel_image_in_rings}%
Seja $\phi : R \to S$ homomorfismo de aneis.
$$
\alignat2
\ker\phi
&\defeq \pre \phi {\set{0_S}} &
\quad\big(&= \setst {r \in R} {\phi(r) = 0_B} \ \big)\\
\ima\phi
&\defeq \img \phi R &
\quad\big(&= \setst {s \in S} {\lexists {r\in R} {\phi(r) = s}} \ \big)
\endalignat
$$
%%}}}

\blah.
Podemos já provar o equivalente do~\ref{image_subgroup} que encontramos
nos grupos, para os anéis:

%%{{{ lemma: image_subring 
\lemma.
\label{image_subring}%
Seja $\phi : R \to S$ um homomorfismo de anéis.
Sua imagem $\ima\phi$ é um subanel de $S$.
\sketch.
Usamos o~\ref{subring_criterion} e a definição de $\ima\phi$.
\qes
\proof.
Tome $a,b\in \ima\phi$.  Logo
$$
\alignat2
a &= \phi(a') &\quad&\text{para algum $a' \in R$}\\
b &= \phi(b') &\quad&\text{para algum $b' \in R$}.
\endalignat
$$
Calculamos:
\compute
1_S
&= \phi(1_R);           \by {$\phi$ homo ($1$)}
a + b
&= \phi(a') + \phi(b')  \by {pela escolha dos $a',b'$}
&= \phi(a'+b');         \by {$\phi$ homo ($+$)}
-a
&= -\phi(a')            \by {pela escolha do $a'$}
&= \phi(-a');           \by {$\phi$ homo ($-$)}
ab
&= \phi(a')\phi(b')     \by {pela escolha dos $a',b'$}
&= \phi(a'b').          \by {$\phi$ homo ($\cdot$)}
\endcompute
Ou seja:  $1_S, a+b, -a, ab \in \ima\phi$ e podemos usar
o~\ref{subring_criterion}.
\qed
%%}}}

%%{{{ Q: Is the kernel cooler than just a subring? 
\question.
Será que o kernel é algo mais-legal-que-subanel na mesma
forma que aconteceu nos grupos?
%%}}}
\spoiler.

%%{{{ x: 
\exercise.
Seja $\phi : R \homto S$.
O que consegues demonstrar entre o $\ker\phi$ e o $R$?

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Boolean rings 
\section Aneis booleanos.
\label{Boolean_rings}%

%%{{{ df: boolean_ring 
\definition Anel booleano.
\label{boolean_ring}%
\tdefined{anel}[booleano]%
Chamamos o anel $\cal R$ um \dterm{anel booleano} sse
sua multiplicação é \ii{idempotência}\emph{idempotente}, ou seja:
$$
\text{para todo $a\in \cal R$},\quad
a^2 = a.
$$
%%}}}

%%{{{ eg 
\example.
Dado conjunto $X$, o $\sset {\pset X} {\symdiff, \inter}$
é um anel booleano.
\endexample
%%}}}

%%{{{ x: boolean_rings_are_idempotent 
\exercise.
\label{boolean_rings_are_idempotent}%
Seja $\cal R$ um anel booleano.
Prove que:
$$
\text{para todo $p\in \cal R$},\quad
p = -p.
$$

\hint
$p + p = (p+p)^2 = \dotsc$

\solution
Seja $p \in R$.
Calculamos:
\compute
p + p
&= (p+p)^2               \by {$R$ booleano}
&= (p+p)(p+p)            \\
&= (p+p)p + (p+p)q       \\
&= pp + pp + pp + pp     \\
&= p^2 + p^2 + p^2 + p^2 \\
&= p + p + p + p         \by {$R$ booleano}
&= p + p + (p + p)
\endcompute
e logo $p + p = 0$, ou seja, $p = -p$.

\endexercise
%%}}}

%%{{{ x: boolean_rings_negative_of_product 
\exercise.
\label{boolean_rings_negative_of_product}%
Seja $\cal R$ um anel booleano.
Prove que:
$$
\text{para todo $p,q\in \cal R$},\quad
pq = -qp
$$
e mostre como isso gera mais uma prova
do~\ref{boolean_rings_are_idempotent}.

\hint
Calcule o $(p+q)^2$.

\solution
Sejam $p,q \in R$.
Calculamos:
\compute
(p+q)^2
&= (p+q)(p+q)           \\
&= (p+q)p + (p+q)q      \\
&= pp + qp + pq + qq    \\
&= p^2 + qp + pq + q^2  \\
&= p + qp + pq + q.     \by {$B$ booleano}
\endcompute
Mas como $B$ é booleano temos também $(p+q)^2 = p+q$.
Ou seja
\compute
p + q &= p + qp + pq + q \\
      &= p + q + (qp + pq) \\
\intertext{e logo (\ref{cheaper_gid})}
0     &= qp + pq    \tag{1}
\endcompute
ou seja, $pq = -qp$.
\endgraf
Para ganhar o~\ref{boolean_rings_are_idempotent} como
corolário, é so tomar $q \asseq 1$.

\endexercise
%%}}}

%%{{{ x: boolean_rings_are_commutative 
\exercise.
\label{boolean_rings_are_commutative}%
Todo anel booleano é comutativo.

\hint
Use os \ref{boolean_rings_are_idempotent}
e~\refn{boolean_rings_negative_of_product}.

\solution
Sejam $p,q$ membros dum anel booleano.
Temos
\compute
pq
&= -qp  \by {\ref{boolean_rings_negative_of_product}, com $p \asseq p$ e $q \asseq q$}
&= qp.  \by {\ref{boolean_rings_are_idempotent}, com $p \asseq qp$}
\endcompute

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Integral domains 
\section Domínios de integridade.
\label{Integral_domains}%

%%{{{ df: zerodivisors 
\definition Divisores de zero.
\label{zerodivisors}%
\tdefined{zerodivisor}%
\iisee{divisor de zero}{zerodivisor}%
Seja $R$ um anel, e $x,y\in R$.
Se $xy = 0_R$ e nem $x=0_R$ nem $y=0_R$, chamamos os $x,y$
\dterm{divisores de zero} (ou \dterm{zerodivisores}) no $R$.
%%}}}

%%{{{ eg: ints_6 
\example.
No anel $\ints_6$, temos $2\ntimes 3 = 0$.
Logo ambos os $2,3$ são divisores de zero nesse anel.
O $4$ também é, pois $3\ntimes 4 = 0$ também.
\endexample
%%}}}

%%{{{ eg: real_continuous_functions_zerodivisors 
\example.
\label{real_continuous_functions_zerodivisors}%
Considere o anel $C[-1,1]$ com as operações~\ii{pointwise}[operação]pointwise
(veja~\ref{first_ring_examples}).
Tome as funções $f,g$ definidas pelas
$$
\xalignat2
f(x) &= \knuthcases{
-x, & se $x\leq 0$\cr
0,  & se $x > 0$
}&
g(x) &= \knuthcases{
0,  & se $x\leq 0$\cr
x,  & se $x > 0$.
}
\endxalignat
$$
Calculando, achamos
$$
f\ntimes g = \lam x 0_{C[-1,1]}
$$
e logo os $f,g$ são divisores de zero no $C[-1,1]$.
\endexample
%%}}}

%%{{{ x: design_graphs_of_zerodevisor_real_continuous_functions 
\exercise.
\label{design_graphs_of_zerodevisor_real_continuous_functions}%
Desenhe os gráficos das funções $f,g$
do~\ref{real_continuous_functions_zerodivisors},
e com um cálculo explique porque $f\ntimes g = 0$.

\endexercise
%%}}}

%%{{{ df: integral_domain ; cancellation_domain 
\definition Domínio de integridade e de cancelamento.
\label{integral_domain}%
\label{cancellation_domain}%
\tdefined{domínio de integridade}%
\tdefined{domínio de cancelamento}%
Seja $\cal D$ um anel comutativo.
Chamamos o $\cal D$ \dterm{domínio de integridade}
sse ele não tem zerodivisores, ou seja, sse:
$$
\text{para todo $x,y \in D$,}\quad
\text{se $xy=0$ então $x=0$ ou $y=0$}.
\tag{NZD}
$$
Chamamos o $\cal D$ \dterm{domínio de cancelamento}
sse
$$
\text{para todo $a,x,y \in D$,}\quad
ax = ay \mland a \neq 0 \implies x=y.
\tag{RCL}
$$
que é equivalente à
$$
\text{para todo $a,x,y \in D$,}\quad
xa = ya \mland a \neq 0 \implies x=y.
\tag{RCR}
$$
pois esse anel é comutativo.
%%}}}

%%{{{ criterion: integral_domain_equiv_cancellation_domain 
\criterion.
\label{integral_domain_equiv_cancellation_domain}%
Os termos ``domínio de integridade'' e ``domínio de cancelamento''
são sinônimos, ou seja:
$$
\text{$D$ é um domínio de integridade} \iff \text{$D$ é um domínio de cancelamento}.
$$
\proof.
\proofpart{\lrdir:}
Sejam $a,x,y \in D$ tais que $a \neq 0$ e $ax = ay$.
Logo $ax - ay = 0$.
Logo $a(x-y) = 0$.
Pela hipótese (NZD) então $x-y = 0$, ou seja $x = y$.
\crproofpart{\rldir:}
Sejam $x,y \in D$ tais que $xy = 0$ e $x \neq 0$.
Queremos $y = 0$.
Temos $xy = 0 = x0$ (pois $0 = 0x$ em todo anel).
Ou seja $xy = x0$, e como $x\neq 0$, usando a (RCL) concluimos $y=0$.
\qed
%%}}}

\endsection
%%}}}

%%{{{ Fields 
\section Corpos.
\label{Fields}%

%%{{{ df: field 
\definition Corpo.
\label{field}%
\tdefined{corpo}%
Seja $\cal K$ um anel não-zero e comutativo.
Chamamos o $\cal K$ um \dterm{corpo} (ou \dterm{field})
sse todos os seus membros diferentes de $0$ são invertíveis,
ou seja sse:
$$
\text{para todo $a\in K_{\neq0}$,
existe $y \in K$, tal que $ay = 1 = ya$.}
\tag{FM3*}
$$
%%}}}

%%{{{ eg: rats and reals and complex 
\example.
Os racionais, os reais, e os complexos, com suas operações canônicas de adição
e multiplicação são todos corpos.
\endexample
%%}}}

%%{{{ noneg: ints and nats 
\nonexample.
Os inteiros e os naturais não!
\endnonexample
%%}}}

%%{{{ eg: integers_modulo_p_field_example 
\example.
\label{integers_modulo_p_field_example}%
O $\cal Z_p = \sset {\quogrp \ints {p\ints}} {+_p, \ntimes_p}$ onde $p$ primo é um corpo.
\endexample
%%}}}

%%{{{ noneg: integers_modulo_n_field_nonexample 
\nonexample.
\label{integers_modulo_n_field_nonexample}%
O $\cal Z_n$ onde $n>1$ e não primo, não é um corpo.
\endnonexample
%%}}}

%%{{{ criterion: finite_integral_domain_implies_field 
\criterion.
Se $D$ é um domínio de integridade finito então $D$ é um corpo.
\proof.
Suponha que $D$ é um domínio de integridade finito.
Precisamos mostrar que cada $d \neq 0$ no $D$ tem inverso.
Seja $d\in D$, $d\neq 0$.
Procuro $d' \in D$ tal que $dd' = 1$.
Sejam
$$
d_1, d_2, \dotsc, d_n
$$
todos os elementos distintos de $D\setminus\set{0}$.
Considere os
$$
dd_1, dd_2, \dotsc, dd_n.
$$
Observe que:
$$
dd_i = dd_j \impliesbecause{(RCL)} d_i = d_j \implies i = j.
$$
Ou seja,
$$
D\setminus\set{0} = \set{dd_1, dd_2, \dotsc, dd_n}.
$$
Ou seja, como $1\in D\setminus\set{0}$,
$$
1 = dd_u \quad\text{para algum $u\in\set{1,\dotsc,n}$}
$$
que é o que queremos provar.
\qed
%%}}}

%%{{{ x: integers_modulo_p_field_iff_p_prime
\exercise.
\label{integers_modulo_p_field_iff_p_prime}%
Prove que o~\ref{integers_modulo_p_field_example}
realmente é um exemplo de corpo
e que o~\ref{integers_modulo_n_field_nonexample}
realmente não é.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Lattices 
\section Reticulados.
\label{Lattices_as_algebras}%

%%{{{ Lattice laws 
\note Leis de reticulado.
Num reticulado temos duas operações binárias que chamamos
de \dterm{join} ($\join$) e \dterm{meet} ($\meet$).
Elas satisfazem as leis de reticulado:
$$
\xalignat2
\text{associatividade} &\ \leftbrace{
\aligned
a \join (b \join c) &= (a \join b) \join c \\
a \meet (b \meet c) &= (a \meet b) \meet c
\endaligned
} &
\rightbrace{
\aligned
a \join b &= b \join a \\
a \meet b &= b \meet a
\endaligned
}\ & \text{comutatividade}
\\
\text{idempotência} &\ \leftbrace{
\aligned
a \join a &= a \\
a \meet a &= a
\endaligned
} &
\rightbrace{
\aligned
a \join (a \meet b) &= a \\
a \meet (a \join b) &= a
\endaligned
}\ & \text{absorpção}
\endxalignat
$$
Observe que sem as leis de absorpção não temos uma estrutura interessante.
Essas leis nos dizem como as duas operações interagem e oferecem à teoria
de reticulados sua alma.
Formalmente, temos:
%%}}}

%%{{{ df: lattice_as_algebra 
\definition.
\label{lattice_as_algebra}%
\label{bounded_lattice_as_algebra}%
\tdefined{reticulado}[como álgebra]%
\tdefined{reticulado}[limitado, como álgebra]%
Seja $\cal L = \sset L {\join,\meet}$ um conjunto estruturado onde
$\join,\meet$ são operações binárias que chamamos de \dterm{join}
e \dterm{meet} respectivamente.
$\cal L$ é um \dterm{reticulado} (ou \dterm{láttice}) sse:
$$
\alignat2
\pforall {a,b\in L}   &\bracket{a\join b \in L}                         &\tag{LJ0} \\
\pforall {a,b,c\in L} &\bracket{a\join(b\join c) = (a\join b)\join c}   &\tag{LJ1} \\
\pforall {a,b\in L}   &\bracket{a\join b = b \join a}                   &\tag{LJ2} \\
\pforall {a\in L}     &\bracket{a\join a = a}                           &\tag{LJ3} \\
\pforall {a,b\in L}   &\bracket{a\meet b \in L}                         &\tag{LM0} \\
\pforall {a,b,c\in L} &\bracket{a\meet(b\meet c) = (a\meet b)\meet c}   &\tag{LM1} \\
\pforall {a,b\in L}   &\bracket{a\meet b = b \meet a}                   &\tag{LM2} \\
\pforall {a\in L}     &\bracket{a\meet a = a}                           &\tag{LM3} \\
\pforall {a,b \in L}  &\bracket{a\join (a \meet b) = a}                 &\tag{LAJ} \\
\pforall {a,b \in L}  &\bracket{a\meet (a \join b) = a}.                &\tag{LAM} \\
\intertext{%
Seja $\cal L = \sset L {\join,\meet,0,1}$ um conjunto estruturado onde
$\join,\meet$ são operações binárias e $0,1$ constantes, e tal que
$\cal L$ é um \dterm{reticulado limitado} (ou \dterm{bounded láttice}) sse
$\sset L {\join,\meet}$ é um reticulado e
}
\pforall {a \in L}    &\bracket{a\join 0 = a}                           &\tag{LJB} \\
\pforall {a \in L}    &\bracket{a\meet 1 = a}.                          &\tag{LJB}
\endalignat
$$
%%}}}

%%{{{ criterion: lattice_without_idem_criterion 
\criterion.
\label{lattice_without_idem_criterion}%
Seja $\cal L = \sset L {\join, \meet}$ conjunto estruturado
onde $\join$ e $\meet$ satisfazem as leis de:
associatividade, comutatividade, absorção.
Então $\cal L$ é um reticulado.
\proof.
\ref{abs_and_com_imply_idem}.
\qed
%%}}}

%%{{{ x: abs_and_com_imply_idem 
\exercise.
\label{abs_and_com_imply_idem}%
Prove o~\ref{lattice_without_idem_criterion}.

\hint
$a\join(a\meet(a\join a))$.

\solution
Seja $a \in L$.
Calculamos
\compute
a \join ( (a \join a) \meet a )
&= a \join a                         \by {$\meet$-abs.}
\intertext{e também}
a \join ( (a \join a) \meet a)
&=  ( (a \join a) \meet a) \join a   \by {$\join$-com.}
&=  ( a \meet (a \join a) ) \join a  \by {$\meet$-com.}
&=  a                                \by {$\join$-abs.}
\endcompute
Logo $a\join a = a$.

\endexercise
%%}}}

%%{{{ x: two_equiv_ways_to_define_an_order_on_an_algebraic_lattice_teaser 
\exercise.
\label{two_equiv_ways_to_define_an_order_on_an_algebraic_lattice_teaser}%
Seja $\cal L = \sset L {\join,\meet}$ um reticulado pela~\ref{lattice_as_algebra}.
Prove que:
$$
a\join b = b \iff a\meet b = a.
$$

\solution
\proofpart{\lrdir}.
Suponha $b = a \join b$.
Calculamos
\compute
a \meet b
&= a \meet (a \join b)  \by {hipótese}
&= (a \join b) \meet a  \by {$\meet$-com.}
&= a.                   \by {$\meet$-abs.}
\endcompute
\proofpart{\rldir:}
Similar.

\endexercise
%%}}}

%%{{{ df: semilattice 
\definition.
\label{semilattice}%
\label{bounded_semilattice}%
\tdefined{semirreticulado}%
\tdefined{semirreticulado}[limitado]%
Seja $\cal S = \sset S {\dmnd}$ um conjunto estruturado onde
$\dmnd$ é uma operação binária.
$\cal S$ é um \dterm{semirreticulado} (ou \dterm{semiláttice}) sse
sua operação é associativa, comutativa, e idempotente:
$$
\alignat2
\pforall {a,b\in S}   &\bracket{a\dmnd b \in S}                        &\tag{SL0} \\
\pforall {a,b,c\in S} &\bracket{a\dmnd(b\dmnd c) = (a\dmnd b)\dmnd c}  &\tag{SL1} \\
\pforall {a,b\in S}   &\bracket{a\dmnd b = b \dmnd a}                  &\tag{SL2} \\
\pforall {a\in S}     &\bracket{a\dmnd a = a}                          &\tag{SL3} \\
\intertext{%
Seja $\cal S = \sset S {\dmnd,\ell}$ um conjunto estruturado tal que
$\sset S {\dmnd}$ é um semirreticulado e $\ell$ é uma constante.
$\cal S$ é um \dterm{semirreticulado limitado} (ou \dterm{bounded semiláttice}) sse:
}
\pforall {a\in S}     &\bracket{a\dmnd \ell = a}                       &\tag{SLB}
\endalignat
$$
%%}}}

%%{{{ remark: shorter (bounded) lattice definitions using (bounded) semilattices
\remark Definições mais curtas.
Com as definições de semirreticulados podemos definir numa maneira mais simples
o que é um reticulado:
%%}}}

%%{{{ x: from_semilattice_to_lattice 
\exercise Definições mais curtas.
\label{from_semilattice_to_lattice}%
\tdefined{lattice}%
Defina os conceitos ``reticulado'' e ``reticulado limitado''
usando os conceitos ``semirreticulado'' e ``semirreticulado limitado''.

\solution
O conjunto estruturado $\cal L = \sset L {\join,\meet}$ é um
\dterm{lattice} sse os conjuntos estruturados
$\sset L {\join}$ e $\sset L {\meet}$ são semilattices,
e as leis de absorção são satisfeitas.
$\cal L = \sset L {\join,\meet}$ é um \dterm{reticulado} sse
$\sset L \join$ e $\sset L \meet$ são semirreticulados.
Similarmente $\sset L {\join,\meet,0,1}$ é um reticulado limitado sse
$\sset L {\join,0}$ e $\sset L {\meet,1}$ são semirreticulados limitados.

\endexercise
%%}}}

\blah.
Nosso objectivo aqui é brincar com várias estruturas algébricas, e não
aprofundar em nenhuma.
Mas se preocupe não: voltamos a estudar reticulados no~\ref{Lattices}.

\endsection
%%}}}

%%{{{ Problems 
\problems.

%%{{{ prob: N_00 
\problem.
Considere o conjunto $\cal N_{00}$ das seqüências infinitas de naturais
``eventualmente zero'', ou seja
$$
\cal N_{00}
\defeq
\setst {f : \nats\to\nats} {\pexists {N\in\nats} \lforall {n \geq N} {f(n) = 0}}.
$$
Consideramos a operação de \emph{adição~pointwise\ii{pointwise}[operação]} definida pela:
$$
(f + g)(x) = f(x) + g(x).
$$
Prove que $\cal N_{00}$ com essa operação forma um monóide
isómorfo com o monóide $\sset {\nats_{>0}} {\ntimes}$
(com operação a multiplicação usual).

\endproblem
%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite{pinteralgebra},
\cite{hersteintopics},
\cite{babybm},
\cite{papamb}.
\cite{sharperings}.

\cite{aluffialgebra}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: The real numbers 
\chapter Os números reais.
\label{Real_numbers}%

%%{{{ intro 
\chapintro
O $\sset \reals {+,\ntimes,0,1}$ é um \emph{corpo ordenado completo}.
Nesse capítulo vamos estudar o que isso significa e investigar as
primeiras conseqüências dos axiomas dos reais.
Alem disso, vamos definir e estudar os conceitos fundamentais
de limites e séries.
%%}}}

%%{{{ Ordered fields 
\section Corpos ordenados.
\label{Ordered_fields}%

\secintro
Nessa secção, $F$ vai denotar um arbitrário corpo ordenado:

%%{{{ df: ordered_field 
\definition Corpo ordenado.
\label{ordered_field}%
\tdefined{corpo}[ordenado]%
Seja $F$ um conjunto, $0,1\in F$, $+$ e $\ntimes$ duas operações
binárias no $F$, e $-$ uma operação unária.
Seja também $P$ uma relação unária no $F$, que identificamos com
seu gráfico: $P \subset F$.
Seu papel é representar os membros \emph{positivos}.
Chamamos o $\cal F = \sset F {+, \,\ntimes\,, -, 0, 1, P}$
um \dterm{corpo ordenado} sse as seguintes leis são satisfeitas:
$$
\align
                        &{0 \neq 1}                             \tag{FNZ}\\
\\
\pforall {a,b\in F}     &\bracket{a + b \in F}                  \tag{FA0}\\
\pforall {a,b,c\in F}   &\bracket{a + (b + c) = (a + b) + c}    \tag{FA1}\\
\pforall {a \in F}      &\bracket{a + 0 = a}                    \tag{FA2}\\
\pforall {a\in F}       &\bracket{a + (-a) = 0}                 \tag{FA3}\\
\pforall {a,b\in F}     &\bracket{a + b = b + a}                \tag{FA4}\\
\\
\pforall {a,b\in F}     &\bracket{a\ntimes b \in F}                                     \tag{FM0}\\
\pforall {a,b,c\in F}   &\bracket{a\ntimes(b\ntimes c) = (a\ntimes b)\ntimes c}         \tag{FM1}\\
\pforall {a \in F}      &\bracket{a\ntimes 1 = a}                                       \tag{FM2}\\
\pforall {a\in F}       &\bracket{a\neq 0 \implies \lexists {y\in F} {a \ntimes y = 1}} \tag{FM3*}\\
\pforall {a,b\in F}     &\bracket{a\ntimes b = b \ntimes a}                             \tag{FM4}\\
\\
\pforall {a,b,c \in F}  &\bracket{a\ntimes (b+c) = (a\ntimes b) + (a \ntimes c)}        \tag{FD}\\
\\
\pforall {a \in F}      &\bracket{\text{exatamente uma: $-a \in P$; $a = 0$; $a \in P$}}  \tag{FP3}\\
\pforall {a,b\in P}     &\bracket{a + b \in P}                  \tag{FPA}\\
\pforall {a,b\in P}     &\bracket{a\ntimes b \in P}             \tag{FPM}
\endalign
$$
%%}}}

%%{{{ eg: rats_and_reals_are_ordered_fields 
\example.
Os $\rats,\reals$ onde $P_\rats = \rats_{>0}$ e $P_\reals = \reals_{>0}$,
e as operações e os constantes são os usuais.
\endexample
%%}}}

%%{{{ noneg: compex_order_field_noneg 
\nonexample.
\label{complex_cannot_by_ordered}%
Os complexos não são (\ref{complex_cannot_by_ordered}).
\endnonexample
%%}}}

%%{{{ df: gt_in_ordered_fields 
\definition.
\label{gt_in_ordered_fields}%
Definimos a relação binária $<$ num corpo ordenado $F$ pela
$$
x < y \defiff y - x \in P.
$$
Naturalmente definimos as $>, \leq, \geq$ em termos das $<$ e $=$.
Lembre-se a definição da $-$ binária em qualquer anel (\ref{subtraction_in_rings}).
%%}}}

%%{{{ alternative_formalization_of_ordered_fields 
\note Formalização alternativa.
\label{alternative_formalization_of_ordered_fields}%
Em vez de adicionar a relação unária $P$ em nossa estrutura
para representar os membros positivos, podemos considerar a
$$
\cal F = \sset F {+, \,\ntimes\,, -, 0, 1, <}
$$
onde $<$ é uma relação \emph{binária}, cujo papel é representar
a ordem.
Nesse caso vamos precisar substituir as leis (FP$\_$) sobre
o $P$ com leis que afirmam que: $<$ é uma ordem estrita e total:
$$
\align
\pforall {x,y,z \in F}  &\bracket{x<y \mland y<z \implies x<z}  \tag {FOT}\\
\pforall {x,y \in F}    &\bracket{\text{exatamente uma: $x < y$; $x = y$; $x > y$}}  \tag {FO3}\\
\intertext{e que comporta bem com as operações:}
\pforall {a,b,c\in F}   &\bracket{a<b \implies a+c < b+c}  \tag{FOA}\\
\pforall {a,b\in F}     &\bracket{0<a \mland 0<b \implies 0 < a\ntimes b}.  \tag{FOM}
\endalign
$$
E podemos definir o conjunto $P$ (ou a relação unária $P$, dependente do ponto
de visto) em termos da ordem $<$, e vice versa, definir a $<$ em termos de $P$:
$$
\xalignat 2
&\gathered
\sset F {+, \,\ntimes\,, -, 0, 1, P} \\
x < y \defiff y-x \in P
\endgathered
&
&\gathered
\sset F {+, \,\ntimes\,, -, 0, 1, <} \\
x \in P \defiff 0 < x.
\endgathered
\endxalignat
$$
As duas abordagens são equivalentes.
%%}}}

%%{{{ remark: rats is an ordered field too 
\remark.
Os números racionais também formam um corpo ordenado.
Ou seja, todas essas leis que listamos até agora,
não são suficientes para determinar os reais, pois
nem conseguem diferencia-los dos racionais.
Falta só um axioma, o axioma da completude,
que realmente vai determinar o conjunto $\reals$.
Mas para entender esse axioma, precisamos primeiro
entender um outro conceito: o \emph{supremum},
e seu conceito dual, o \emph{infimum}.
Faremos essas coisas
nas~\refn{Infimum_and_supremum_on_reals}--\refn{Completeness_of_reals}.
%%}}}

\blah.
Vamos agora investigar umas conseqüências dessas leis de corpo ordenado.
Pronto para \emph{descobrir a teoria de corpos ordenados?}

%%{{{ x: ordered_field_trichotomy 
\exercise Tricotomia.
\label{ordered_field_trichotomy}%
Para todo $a,b\in F$, exatamente uma das
$$
a < b;\qquad
a = b;\qquad
a > b;
$$
é válida.

\endexercise
%%}}}

%%{{{ x: ordered_field_transitivity 
\exercise Transitividade.
\label{ordered_field_transitivity}%
A $<$ é uma relação transitiva:
$a < b \mland b < c \implies a < c$.

\endexercise
%%}}}

%%{{{ x: ordered_field_plus_c_monotone 
\exercise.
\label{ordered_field_plus_c_monotone}%
Se $a < b$ então $a + c < b + c$.

\endexercise
%%}}}

%%{{{ x: ordered_field_times_positive_c_monotone 
\exercise.
\label{ordered_field_times_positive_c_monotone}%
Se $a < b \mland c > 0$ então $ac < bc$.

\endexercise
%%}}}

%%{{{ x: ordered_field_product_of_negatives_is_positive 
\exercise.
\label{ordered_field_product_of_negatives_is_positive}%
Se $a,b < 0$ então $ab > 0$.

\endexercise
%%}}}

%%{{{ x: ordered_field_square_of_nonzero_is_positive 
\exercise.
\label{ordered_field_square_of_nonzero_is_positive}%
Se $a\neq 0$ então $a^2 > 0$.

\endexercise
%%}}}

%%{{{ x: ordered_field_one_is_greater_than_zero 
\exercise.
\label{ordered_field_one_is_greater_than_zero}%
$1 > 0$.

\endexercise
%%}}}

%%{{{ x: ordered_field_times_negative_c_antimonotone 
\exercise.
\label{ordered_field_times_negative_c_antimonotone}%
Se $a < b \mland c < 0$ então $ac > bc$.

\endexercise
%%}}}

%%{{{ x: ordered_field_negate_is_antimonotone 
\exercise.
\label{ordered_field_negate_is_antimonotone}%
Se $a < b$ então $-a > -b$.

\endexercise
%%}}}

%%{{{ x: ordered_field_negate_of_negative_is_positive 
\exercise.
\label{ordered_field_negate_of_negative_is_positive}%
Se $a < 0$ então $-a > 0$.

\endexercise
%%}}}

%%{{{ x: ordered_field_product_positive_means_samesign 
\exercise.
\label{ordered_field_product_positive_means_samesign}%
Se $ab > 0$ então $a,b$ são ou ambos positivos ou ambos negativos.

\endexercise
%%}}}

%%{{{ x: ordered_field_add_side_by_side 
\exercise.
\label{ordered_field_add_side_by_side}%
Se $a < c \mland b < d$ então $a + b < c + d$.

\endexercise
%%}}}

%%{{{ x: complex_cannot_be_ordered_in_disguise 
\exercise.
\label{complex_cannot_be_ordered_in_disguise}%
Não existe $x\in F$ com $x^2 + 1 = 0$.

\endexercise
%%}}}

%%{{{ x: sum_of_squares_in_ordered_field 
\exercise.
\label{sum_of_squares_in_ordered_field}%
Para todo $a,b\in F$, temos $a^2 + b^2 \geq 0$.
Ainda mais: $a^2 + b^2 = 0$ sse $a = b = 0$.

\endexercise
%%}}}

%%{{{ x: order_fields_are_unbounded 
\exercise.
\label{order_fields_are_unbounded}%
O $F$ não tem nem mínimo, nem máximo.

\endexercise
%%}}}

%%{{{ x: only_zero_is_leq_than_all_positives 
\exercise.
\label{only_zero_is_leq_than_all_positives}%
Se $x$ tem a propriedade que $0 \leq x < \epsilon$
para todo $\epsilon > 0$, então $x = 0$.

\endexercise
%%}}}

%%{{{ df: abs_in_ordered_fields 
\definition.
\label{abs_in_ordered_fields}%
Definimos a operação $\abs{\dhole} : F \to F$ num corpo ordenado $F$ pela
$$
\abs x \defeq
\knuthcases{
x,  & se $x\geq 0$ \cr
-x, & se não.
}
$$
%%}}}

%%{{{ x: ordered_field_abs_lemma 
\exercise.
\label{ordered_field_abs_lemma}%
Sejam $x,w\in F$.  Logo
$$
\abs x \leq w
\iff
-w \leq x \leq w.
$$

\endexercise
%%}}}

%%{{{ x: ordered_field_triangular_inequality 
\exercise Desigualdade triangular.
\label{ordered_field_triangular_inequality}%
Sejam $x,y,z\in F$.  Logo:
$$
\gather
\abs{x + y} \leq \abs x + \abs y \\
\bigabs{\abs x - \abs y} \leq \abs{x - y} \\
\abs{x - z} \leq \abs{x - y} + \abs{y - z}.
\endgather
$$

\endexercise
%%}}}

\TODO Corpos arquimedeanos.

%%{{{ Models 
\note Modelos.
\tdefined{modelo}%
Temos dois exemplos principais de corpos ordenados,
viz.~os reais e os racionais:
ámbos têm toda a estrutura exigida, e satisfazem todos os axiomas.
Em palavras mais formais, eles são o que a gente chama
de \dterm{modelos} de corpos ordenados.
%%}}}

%%{{{ Q: how_can_we_separate_reals_from_rats
\question.
\label{how_can_we_separate_reals_from_rats}%
Podemos adicionar alguma lei capaz de separar os reais dos racionais?
Ou seja, chegar numa estrutura com leis mais exigentes, tais que
os reais vão ser um modelo, mas os racionais não.
%%}}}
\spoiler.

\blah.
Responder nessa pergunta neste momento é um grande desafio.%
\footnote{Vai desistir de pensar em alguma resposta por causa disso?}
Mas já estamos prontos para encontrar o que falta para
a pergunta virar mais fácil~(\refn{Infimum_and_supremum_on_reals})
e finalmente chegar numa resposta (\refn{Completeness_of_reals}).

\endsection
%%}}}

%%{{{ Infimum and supremum 
\section Infimum e supremum.
\label{Infimum_and_supremum_on_reals}%

%%{{{ df: lower_and_upper_bounds_reals 
\definition Lower e upper bounds.
\label{lower_and_upper_bounds_reals}%
\tdefined{limitante}[por baixo]%
\tdefined{limitante}[por cima]%
\tdefined{bound}[lower]%
\tdefined{bound}[upper]%
\tdefined{limitado}[por baixo]%
\tdefined{limitado}[por cima]%
\tdefined{bounded}[below]%
\tdefined{bounded}[above]%
\sdefined {\sholed x \leq \sholed A} {$x$ é um lower bound de $A$}%
\sdefined {\sholed A \leq \sholed x} {$x$ é um upper bound de $A$}%
\sdefined {\lbs {\sholed A}} {o conjunto de todos os lower bounds de $A$}%
\sdefined {\ubs {\sholed A}} {o conjunto de todos os upper bounds de $A$}%
Seja $A\subset \reals$.
Chamamos o $x$ um \dterm{lower bound} de $A$ sse $x \leq a$ para todo $a \in A$,
e \emph{dualmente} $x$ é um \dterm{upper bound} de $A$ sse $x \geq a$ para todo $a \in A$:
$$
\align
\text{$x$ é um lower bound de $A$} &\defiff \lforall {a\in A} {x \leq a} \\
\text{$x$ é um upper bound de $A$} &\defiff \lforall {a\in A} {a \leq x}.
\endalign
$$
Abusando a notação escrevemos $x \leq A$ e $A \leq x$:
$$
\align
x \leq A &\defiff \lforall {a \in A} {x \leq a} \\
A \leq x &\defiff \lforall {a \in A} {a \leq x}.
\endalign
$$
Denotamos o conjunto de todos os lower bounds de $A$ por $\lbs A$,
e dualmente usamos $\ubs A$ para o conjunto de todos os seus upper bounds:
$$
\align
\lbs A &\defeq \setst {x \in \reals} {x \leq A} \\
\ubs A &\defeq \setst {x \in \reals} {A \leq x}.
\endalign
$$
Se um $A$ tem pelo menos um limitante por cima, dizemos que $A$
é \dterm{limitado por cima} (ou, \dterm{bounded above});
e se tem pelo menos um limitante por baixo, \dterm{limitado por baixo}
(ou, \dterm{bounded below}).
%%}}}

%%{{{ df: inf_sup_reals 
\definition infimum; supremum.
\label{inf_sup_reals}%
\tdefined{infimum}[reais]%
\tdefined{supremum}[reais]%
\tdefined{least upper bound}[reais]%
\tdefined{greatest lower bound}[reais]%
\tdefined{reais}[estendidos]%
\sdefined {\inf {\sholed A}} {o infimum de $A\subset\reals$}%
\sdefined {\sup {\sholed A}} {o supremum de $A\subset\reals$}%
\sdefined {\glb {\sholed A}} {o greatest lower bound de $A\subset\reals$}%
\sdefined {\lub {\sholed A}} {o least upper bound de $A\subset\reals$}%
\sdefined {\overline{\reals}} {os reais estendidos: $\reals\union\set{\minfty,\pinfty}$}%
Definimos os $\inf A$ e $\sup A$ pelas:
$$
\align
\text{$x$ é um infimum  de $A$} &\defiff x \leq A \mland \lforall {w \leq A} {w \leq x} \\
\text{$x$ é um supremum de $A$} &\defiff x \geq A \mland \lforall {w \geq A} {x \leq w}.
\endalign
$$
Mais curtamente:
$$
\xalignat 2
\inf A &\defeq \max {\lbs A} &
\sup A &\defeq \min {\ubs A}.
\intertext{Outros nomes (e notações correspondentes) desses dois conceitos
são muito comuns e vamos ficar os usando também:
o infimum é chamado também de \dterm{greatest lower bound} e o supremum
de \dterm{least upper bound}, e denotados por $\glb$ e $\lub$ respectivamente:}
\glb A &\defeq \inf A & 
\lub A &\defeq \sup A.
\endxalignat
$$
%%}}}

%%{{{ warning: later on we'll meet even more names and notations 
\warning.
No~\ref{Posets} encontramos ainda mais nomes e notações!
%%}}}

%%{{{ remark: inf and sup are partial 
\remark.
Observe que assim, $\inf$ e $\sup$ não são operações totais nos reais,
mas \emph{parciais:}
$$
\inf,\sup \eqtype \pset \reals \parto \reals.
$$
Ou seja, ninguém garanta que para qualquer
$A\subset\reals$ existe mesmo um real $x$ que satisfaz as
condições das definições acima.
Mas se existem, são únicos~(\ref{inf_and_sup_are_unique}):
%%}}}

%%{{{ thm: inf_and_sup_are_unique 
\theorem.
\label{inf_and_sup_are_unique}%
Seja $A \subset \reals$.
Se $A$ tem infimum, ele é único.
Dualmente, se $A$ tem supremum, ele é único.
\proof.
Por fight club: suponha $\ell, \ell'$ são infima, logo $\ell \leq \ell'$
pois $\ell'$ é maior que qualquer lower bound, e $\ell$ é um lower bound.
No outro lado $\ell' \leq \ell$ pois $\ell$ é maior que qualquer lowe bound,
e $\ell'$ é um lower bound.  Logo $\ell \leq \ell'$ e $\ell' \leq \ell$
e pela antisimetria da $\leq$ temos $\ell = \ell'$.
\qed
%%}}}

%%{{{ The extended reals 
\note Os reais estendidos.
\label{extended_reals}%
Agora, se $A$ não é bounded below e se $A$ não é bounded above escrevemos
$$
\xalignat 2
\inf A &= \minfty &
\sup A &= \pinfty
\endxalignat
$$
respectivamente.
Isso é bem justificável se pensar no $\reals$ apenas como um conjunto
(parcialmente) ordenado enriquecido por dois novos objetos:
o $\minfty$ e o $\pinfty$ chegando assim no conjunto
$$
\set{\minfty}\union\reals\union\set{\pinfty}
$$
que ordenamos assim:
$$
\minfty < x < \pinfty, \quad\text{para todo $x\in\reals$}.
$$
Chamamos os membros do $\reals\union\set{\minfty,\pinfty}$
de \dterm{reais estendidos} e denotamos esse conjunto por
$\overline{\reals}$ e $[\minfty,\pinfty]$ também.
Podemos considerar ambas as operações então como
$$
\inf,\sup \eqtype \pset \reals \parto [\minfty,\pinfty].
$$
%%}}}

%%{{{ x: inf_in_set_implies_min 
\exercise.
\label{inf_in_set_implies_min}%
Seja $A \subset \reals$.
Prove que:
(i) se $\inf A \in A$ então $\inf A = \min A$;
(ii) a dual da (i).

\endexercise
%%}}}

%%{{{ x: lbs_and_ubs_are_empty_or_infinite 
\exercise.
\label{lbs_and_ubs_are_empty_or_infinite}%
Seja $A \subset \reals$.
Prove que $\lbs A$ é vazio ou infinito, e a mesma coisa sobre o $\ubs A$.

\endexercise
%%}}}

%%{{{ x: a_set_with_nats_as_limit_points 
\exercise.
\label{a_set_with_nats_as_limit_points}%
Considere o conjunto
$$
A = \setlst {m + \frac 1 {2^n}} {m \in \nats, n \in \nats_{>0}}.
$$
(i) Visualize o $A$ na linha dos reais, e rascunhe seu desenho.
(ii) Ache o $\inf A$ e $\sup A$ se são definidos.

\endexercise
%%}}}

%%{{{ x: inf_sup_reals_extreme_cases 
\exercise.
\label{inf_sup_reals_extreme_cases}%
Pode acontecer que para algum $A\subset\reals$ temos\dots
\beginil
\item{(i)} $\inf A = \sup A$?
\item{(ii)} $\inf A > \sup A$?
\endil
Se sim, quando?
Se não, por que não?

\endexercise
%%}}}

\blah.
E agora\dots
Será que podes pensar numa resposta para
a~\ref{how_can_we_separate_reals_from_rats}?
\spoiler.

\endsection
%%}}}

%%{{{ Completude 
\section Completude.
\label{Completeness_of_reals}%

\blah.
Agora temos tudo que precisamos para responder
a~\ref{how_can_we_separate_reals_from_rats}.
Nossa resposta com palavras de rua é
\standout
\emph{os reais não têm ``buracos''}
\endstandout
mas precisamos formalizar essa afirmação.%
\footnote{No~\ref{Cantors_paradise} encontramos uma outra
resposta a~\ref{how_can_we_separate_reals_from_rats},
de natureza completamente diferente.  Paciência!}
A idéia é exigir que \emph{não falta nenhum supremum}---ou, dualmente,
nenhum infimum, pois é a mesma coisa:
uma afirmação acaba implicando a outra.
Mas o que quis dizer que não falta nenhum supremum?
E, nenhum mesmo?  Não.
Um conjunto que nem é bounded above não tem chances de ter supremum.
Vamos exigir suprema de todos os outros então:

%%{{{ df: complete_ordered_field 
\definition Corpo ordenado completo.
\label{complete_ordered_field}%
\tdefined{corpo}[ordenado, completo]%
Um corpo ordenado $R$ é \dterm{completo} sse
todos os seus subconjuntos bounded above possuem supremum no $R$
$$
\align
\pforall {A\subset R} &\bracket{\text{$A\neq\emptyset$} \mland \text{$A$ bounded above} \implies \text{$A$ tem supremum no $R$}}. \tag{FC}
\endalign
$$
%%}}}

%%{{{ eg: reals_is_a_complete_ordered_field 
\example.
\label{reals_is_a_complete_ordered_field}%
Os reais $\sset \reals {+, \,\ntimes\,, -, 0, 1, <}$.
\endexample
%%}}}

%%{{{ x: can_we_prove_that_reals_is_a_complete_ordered_field 
\exercise.
\label{can_we_prove_that_reals_is_a_complete_ordered_field}%
Tem como provar isso?
Se sim, o que seria uma prova disso?
Se não, por que não?

\endexercise
%%}}}

%%{{{ noneg: rats_is_not_a_complete_ordered_field 
\nonexample.
\label{rats_is_not_a_complete_ordered_field}%
Os racionais!
\endnonexample
%%}}}

%%{{{ x: rats_is_not_a_complete_ordered_field_proof 
\exercise.
\label{rats_is_not_a_complete_ordered_field_proof}%
Prove!
Ou seja, ache um $A$ bounded above sem supremum
no $\rats$.

\endexercise
%%}}}

%%{{{ remark: now inf and sup are total operations on extended reals 
\remark.
Assim as operações $\inf$ e $\sup$ virar totais nos reais estendidos:
$$
\inf,\sup \eqtype \pset\reals \to \reals\union\set{\minfty,\pinfty}.
$$
%%}}}

%%{{{ thm: bounded_below_subsets_have_infima 
\theorem.
\label{bounded_below_subsets_have_infima}%
Sejam $R$ um corpo ordenado completo e $A \subset R$
bounded below.  Logo $A$ possui infimum no $R$.
\proof Demontrado no~\ref{bounded_below_subsets_have_infima_proof}.
\qed
%%}}}

%%{{{ x: bounded_below_subsets_have_infima_proof 
\exercise.
\label{bounded_below_subsets_have_infima_proof}%
Demonstre o~\ref{bounded_below_subsets_have_infima}.

\hint
Tu vai precisar usar a lei de completude.

\hint
Procure definir um subconjunto de $\reals$
que será garantido ter um supremum, e use
esse supremum para definir o infimum de $A$.

\endexercise
%%}}}

%%{{{ Enough! 
\note Chega!.
Vamos revisar pouco a situação com as estruturas que estudamos até agora.
Como a gente escolha os axiomas (leis) que botamos nas nossas definições?
As mais leis que eu boto, as mais ferramentas que ganho para matar mais
teoremas.  Minha teoria vai acabar sendo capaz de provar mais coisas,
mas o preço que pago para isso são modelos!
\endgraf
Quantos monóides encontramos?  Demais!  Todos os grupos são monóides,
e a gente já encontrou ainda mais monóides que não são grupos (lembra?).
E grupos?
``Menos'', mas muitos também!
E grupos abelianos?
Provamos mais teoremas, mas temos menos exemplos de grupos abelianos.
E aneis?  E aneis comutativos?  E domínios de integridade?
Cada vez que adicionamos restricções (leis), a teoria correspondente
cresce, e a colecção de models diminui.
E corpos?
Ainda encontramos vários modelos: racionais, reais, complexos, inteiros
módulo primo $p$, \dots
\endgraf
E corpos ordenados?
Aqui ganhamos muita teoria graças a ordem, mas perdemos os complexos e os
inteiros módulo $p$, mas ainda temos os reais e os racionais e mais
uns modelos, mas já estamos percebendo que fica mais e mais difícil
achar modelos \emph{realmente} diferentes que satisfazem todas as leis!
\endgraf
E agora?
Adicionamos mais uma lei: o axioma da completude; e assim chegamos nos
\emph{corpos ordenados completos}.  E agora \emph{chega!}
Estamos num ponto onde adicionamos tantos axiomas que nosso conceito
foi tão exigente que perdemos todos os modelos exeto um: os reais!
Realmente não encontramos outro exemplo, mas isso não quis dizer que
não existem outros modelos.  Certo?  Certo, mas acontece que nessa
situação não é o caso: \emph{essencialmente existe apenas um
único corpo ordenado completo: os reais!}
%%}}}

%%{{{ Q: what does ``essentially'' mean above? 
\question.
O que significa a palavra ``essencialmente'' acima?
%%}}}
\spoiler.

%%{{{ thm: uniqueness_of_complete_ordered_field 
\theorem Unicidade.
\label{uniqueness_of_complete_ordered_field}%
Se $R,R'$ são corpos ordenados completos então $R,R'$ são isómorfos.
\sketch.
Sejam
$\sset R    {+, \;\ntimes\;, -, 0, 1, <}$ e
$\sset {R'} {+', \;\ntimes'\;, -', 0', 1', <'}$
corpos ordenados completos.
Precisamos definir um isomorfismo
$$
\phi
\eqtype
\sset R    {+, \;\ntimes\;, -, 0, 1, <}
\longtoby{\iso}
\sset {R'} {+', \;\ntimes'\;, -', 0', 1', <'}.
$$
Obviamente botamos
$$
\align
\phi0 &= 0' \\
\phi1 &= 1'
\intertext{Isso já determina a $\phi$ no resto dos
``naturais'' $N\subset R$:}
\phi2 &= \phi(1 + 1) = \phi1 + \phi1 = 1' + 1' = 2' \\
\phi3 &= \phi(2 + 1) = \phi2 + \phi1 = 2' + 1' = 3' \\
&\eqvdots \\
\phi(n+1) &= \phi n + \phi1 = n' + 1' \\
&\eqvdots
\endalign
$$
ou seja, a $\phi$ (restrita no $N$) necessariamente embute
isomorficamente o $N\subset R$ no $\img \phi N = N' \subset R'$:
$$
\phi \restosub N : N \isoto N'.
$$
Agora, como $\phi$ é homomorfismo, temos
$$
\phi(-x) = \mathord{-'}(\phi x)
\quad\text{para todo $x\in R$},
$$
e logo a $\phi$ necessariamente embute os ``inteiros''
$Z\subset R$ nos ``inteiros'' $Z' \subset R'$:
$$
\phi \restosub Z : Z \isoto Z'.
$$
Definimos a $\phi$ nos ``racionais'' $Q\subset R$ assim:
$$
\phi(m/n)
= \phi(m \ntimes \ginv n)
= \phi m \ntimes' \ginvp{\phi n}
= \phi m \ntimes' \phi (\ginv n)
= \phi m \mathbin{/'} \phi n
$$
e logo
$$
\phi \restosub Q : Q \isoto Q'.
$$
Estamos perto!
Basta só definir a $\phi$ nos ``buracos'' (nos ``irracionais'')
de $R$ e pronto!
\qes
%}}}

%%{{{ remark: we cannot finish this proof right now 
\remark.
Infelizmente, por enquanto não temos todo o armamento para matar
os detalhes e o que falta no esboço, mas é importante entender
pelo menos tudo que tá lá.  Voltamos nesse assunto
no~\ref{Axiomatic_set_theory}~(\refn{Constructing_more_numbers}).
%%}}}

%%{{{ warning: does_a_complete_ordered_field_exist_warning 
\warning.
\label{does_a_complete_ordered_field_exist_warning}%
Mesmo se aceitar que quaisquer corpos ordenados completos são
isomorfos (o~\ref{uniqueness_of_complete_ordered_field}), ainda
temos um ponto que roubamos: para existir único, precisamos duas
coisas: \emph{pelo menos} um; \emph{no máximo} um.
O~\refn{uniqueness_of_complete_ordered_field} realmente ofereceu
a segunda coisa; mas a primeira?
Qual foi tua resolução
do~\ref{can_we_prove_that_reals_is_a_complete_ordered_field}
mesmo?
Voltamos nesse assunto
no~\ref{Axiomatic_set_theory}~(\refn{Constructing_more_numbers}).
%%}}}

\endsection
%%}}}

%%{{{ The reals 
\section Os reais.
\label{The_reals}%

%%{{{ Calculus, the real deal 
\note Calculus, real e oficial.
Como começamos a teoria dos grupos no~\ref{Group_theory}?
Apresentamos os axiomas dos grupos e continumos investigando
suas conseqüências.  A colecção dessas conseqüências (teoremas)
é exatamente o que chamamos de \dterm{teoria}.
E a \emph{teoria dos aneis} é feita por todos os teoremas
que seguem pelos axiomas de aneis; etc.~etc.
E a \emph{teoria dos corpos ordenados completos?}
Ela não é muito famosa por esse nome, mas com certeza
tu já ouviste falar dela por seu apelido:
\dterm{Calculus}, \dterm{análise real}, etc.
Na abordagem axiomática, não nos importa \emph{definir}\/ ou
\emph{construir} os objetos que vamos chamar de \dterm{números reais}.
Começamos aceitando a existência dum certo conjunto que denotamos
por $\reals$, suas operações binárias de adição e multiplicação,
seu zero $0$ e seu um $1$, e seu subconjunto $P$ cujos membros
chamamos de \dterm{positivos}.
Estipulamos os axiomas seguintes.
%%}}}

%%{{{ ax: closedness 
\axiom Fechado.
O $\reals$ é fechado sobre $+$ e $\,\ntimes\,$.
%%}}}

%%{{{ ax: associativity 
\axiom Associatividade.
As $+$ e $\ntimes$ são associativas.
%%}}}

%%{{{ ax: identities 
\axiom Identidades.
As $+$ e $\ntimes$ têm os distintos $0$ e $1$ como
identidades respectivamente.
%%}}}

%%{{{ ax: inverses 
\axiom Inversos.
Todo $a\in \reals$ tem $+$-inverso (denotado por $-a$)
e todo $a\neq 0$ tem $\,\ntimes\,$-inverso (denotado por $a^{-1}$).
%%}}}

%%{{{ ax: commutativity 
\axiom Comutatividade.
As $+$ e $\ntimes$ são comutativas.
%%}}}

%%{{{ ax: distributivity 
\axiom Distributividade.
A $\ntimes$ é distributiva sobre a $+$.
%%}}}

%%{{{ ax: positive closedness 
\axiom Positivamente fechado.
O $P$ é fechado sobre $+$ e $\,\ntimes\,$.
%%}}}

%%{{{ ax: trichotomy 
\axiom Tricotomia.
Para todo $x \in \reals$ exatamente uma das afirmações seguintes é válida:
$-x$ é positivo; $x=0$; $x$ é positivo.
%%}}}

%%{{{ ax: completeness 
\axiom Completude.
Todo conjunto $A\neq\emptyset$ de reais que é limitado por cima,
tem um supremum, ou seja, existe real $b\in\reals$ tal que $b = \sup A$.
%%}}}

\blah.
Ou seja, estipulamos o seguinte:
\standout
\proclaimstyle $\reals$ é um corpo ordenado completo.
\endstandout
As conseqüências desses axiomas é o que estudamos em calculus e análise real.
O resto desse capítulo é um teaserzinho dessa teoria linda demais;
e, como sempre, no fim tenho ponteiros na literatura para mergulhar mais.
No~\ref{Metric_spaces} voltamos nessa investigação de análise real,
pois estudamos a teoria dos \emph{espaços métricos}:
conjuntos equiparados com uma noção de distância, ou seja,
uma função binária \emph{com valores reais}, satisfazendo certas leis.

\endsection
%%}}}

%%{{{ Geometric_representation_of_reals 
\section Representação geométrica e digital.
\label{Geometric_representation_of_reals}%

\TODO Expansão como instruções.

\endsection
%%}}}

%%{{{ Limits_of_reals 
\section Limites.
\label{Limits_of_reals}%

%%{{{ df: epsilon_close_ball_hood 
\definition epsilon: -perto, -bola, -vizinhança.
\label{epsilon_close_ball_hood}%
\tdefined{perto}[de real]%
\tdefined{bola}[de real]%
\tdefined{vizinhança}[de real]%
\sdefined {\ball {\sholed \epsilon} {\sholed {x_0}}} {a $\epsilon$-bola do $x_0$}%
A distância entre dois $x,y\in\reals$ é calculada por $\abs{x-y}$.
Sejam $x,y\in\reals$ e $\epsilon > 0$.
Dizemos que
$$
\text{$x$ é $\epsilon$-perto do $y$}
\defiff
\abs{x-y} < \epsilon.
$$
Observe que a relação é simétrica (\ref{epsilon_close_is_symmetric})
e logo podemos escrever também:
$$
\text{$x,y$ são $\epsilon$-perto}.
$$
Dado um ponto $x_0\in\reals$, o conjunto de todos os pontos que
são $\epsilon$-perto do $x_0$ é chamada \dterm{$\epsilon$-bola}
ou \dterm{$\epsilon$-vizinhança} do $x_0$:
$$
\ball \epsilon {x_0}
\defeq
\setstt {x \in \reals} {$x,x_0$ são $\epsilon$-perto}.
$$
Também chamamos de \dterm{bola com centro $x_0$ e raio $\epsilon$}.
%%}}}

%%{{{ eg 
\example.
Os $1$ e $2/3$ são $1/2$-perto;
a $1/3$-bola do $\sqrt 2$ é o intervalo $(\sqrt2 - 1/3, \sqrt2 + 1/3)$.
\endexample
%%}}}

%%{{{ x: epsilon_close_is_reflexive 
\exercise.
\label{epsilon_close_is_reflexive}%
Dado $\epsilon > 0$, seja $\sim_\epsilon$ a relação definida pela
$$
x \sim_\epsilon y
\defiff
\text{$x$ é $\epsilon$-perto do $y$}.
$$
Demonstre que $\sim_\epsilon$ é reflexiva.

\hint
$$
\abs{x - x} = 0
$$

\endexercise
%%}}}

%%{{{ x: epsilon_close_is_symmetric 
\exercise.
\label{epsilon_close_is_symmetric}%
Dado $\epsilon > 0$, a $\sim_\epsilon$
do~\ref{epsilon_close_is_reflexive} é simétrica,
e logo podemos escrever frases como
$$
\text{<<os $x,y$ são $\epsilon$-perto>>}.
$$

\hint
Olha:
$$
\abs{x - y}
= \abs{-(y - x)}
= \abs{y - x}
$$
Dá pra justificar ambas as $=$?

\endexercise
%%}}}

%%{{{ x: epsilon_close_is_not_an_equivalence_relation 
\exercise.
\label{epsilon_close_is_not_an_equivalence_relation}%
Seja $\epsilon > 0$.
A $\sim_\epsilon$ do~\ref{epsilon_close_is_reflexive}
é uma relação de equivalência?

\hint
Não!

\endexercise
%%}}}

%%{{{ df: for_sufficiently_large_values_of 
\definition <<para valores suficientemente grandes>>.
\label{for_sufficiently_large_values_of}%
Seja $R(n)$ uma afirmação que envolve o natural $n$.
Dizemos que $R(n)$ \dterm{para valores suficientemente grandes de} $n$
sse a partir dum natural $n_0$ todos os naturais satisfazem a $R$,
ou seja, sse
$$
\pexists {n_0\in\nats}
\lforall {i \geq n_0}
{R(i)}.
$$
%%}}}

%%{{{ df: limit_of_sequence_of_reals 
\definition limite.
\label{limit_of_sequence_of_reals}%
\tdefined{limite}[reais]%
\sdefined {{\sholed {\seqn a n}} \limto {\sholed \ell}} {a seqüência $\seqn a n$ tende ao $\ell$}%
Seja $\seqn a n$ uma seqüência de reais e seja $\ell\in\reals$.
Dizemos que $\seqn a n$ \dterm{tende ao limite} $\ell$
sse a partir dum membro $a_N$, todos os seus membros
ficam $\epsilon$-perto do $\ell$.
Ou seja:
$$
\seqn a n \limto \ell
\defiff
\pforall  {\epsilon > 0}
\pexists  {N \in \nats}
\lforallt {i \geq N}
{$a_i$ é $\epsilon$-perto de $\ell$}.
$$
Escrevemos
$$
\liml_n a_n = \ell
$$
como sinônimo de $\seqn a n \limto \ell$.
\mistake
%%}}}

%%{{{ remark: n nought 
\remark.
É muito comum usar o nome \sq{$n_0$}
onde usei o \sq{$N$} na~\ref{limit_of_sequence_of_reals}.
O \sq{$n_0$} é freqüêntemente lido ``$n$ nought'' em inglês.
%%}}}

%%{{{ Alternating quantifiers
\note Quantificadores alternantes.
Provavelmente essa foi a primeira definição que tu encontraste
que necessitou três alternações de quantificadores:
$$
\forall\dots\exists\dots\forall\dots
$$
Para cada alteração de quantificação que seja adicionada
numa afirmação, o processo de digeri-la naturalmente fica
mais complicado para nossa mente!
Com experiência, \dterm{matemalhando}, essas definições
com três quantificadores ficarão mais e mais digeríveis.
Mesmo com essa experiência, num momento vamos encontrar
uma afirmação com \emph{quatro} quantificações alternantes,
e a dificuldade vai voltar e te lembrar dessa dificuldade
que sentes agora.
Felizmente, temos as ferramentas formais de lógica matemática
que nos permitem trabalhar com proposições sem digeri-las
completamente!
%%}}}

%%{{{ x: limit_of_sequence_of_reals_uniqueness_needed 
\exercise.
\label{limit_of_sequence_of_reals_uniqueness_needed}%
Qual o problema com a~\ref{limit_of_sequence_of_reals}

\hint
O problema fica na
$$
\liml_n a_n = \ell.
$$
Qual é?

\solution
Precisamos demonstrar a unicidade dos limites para usar
o símbolo \sq{$=$} da \emph{igualdade}.  Pois, se uma
seqüência tende a dois limites
$$
\xalignat2
\seqn a n &\limto \ell &
\seqn a n &\limto \ell'
\endxalignat
$$
com $\ell = \ell'$, então escrevendo
$$
\xalignat2
\liml_n a_n &= \ell
\liml_n a_n &= \ell'
\endxalignat
$$
teriamos (pela simetria e transitividade da igualdade)
$\ell = \ell'$, contradizendo nossa hipótese.

\endexercise
%%}}}

%%{{{ eg: ones tends to one 
\example.
A seqüência $1, 1, 1, \dotsc$ tende ao limite $1$.

\solution
Seja $\epsilon>0$.
O desafio é achar $N \in \nats$ tal que a partir de $N$,
todos os membros da seqüência são $\epsilon$-perto de $1$.
Tome $N \asseq 0$, e seja $n \geq N$.
Obviamente o $n$-ésimo termo da seqüência é $\epsilon$-perto
do $1$ pois, ele é igual ao $1$ mesmo e logo a distância
deles é $0$, e logo menor que $\epsilon$.
Observe que qualquer escolha de $N$ aqui seria correta!
\endexample
%%}}}

\blah.
Como tu já resolveste
o~\ref{limit_of_sequence_of_reals_uniqueness_needed} (né?)
tu sabes que precisamos demonstrar a unicidade dos limites.
E a existência?
A existência não é garantida (vamos descobrir isso agora
no~\ref{alternating_zero_one_does_not_have_a_limit}),
então precisamos tomar cuidado com o símbolo $\lim$:
é um operador \emph{parcial}.

%%{{{ x: alternating_zero_one_does_not_have_a_limit 
\exercise.
\label{alternating_zero_one_does_not_have_a_limit}%
A seqüência $0,1,0,1,\dotsc$, formalmente definida pela
$$
a_n = \knuthcases{
0, & se $n$ par \cr
1, & caso contrário.
}
$$
tende a algum limite?
Se sim, ache e demonstre; se não, refute.

\hint
Não tende a limite nenhum!
Como podemos demonstrar isso?

\hint
Demonstre que para qualquer possível limite $\ell \in \reals$,
$$
\seqn a n \ntendsto \ell.
$$

\endexercise
%%}}}

%%{{{ thm: uniqueness_of_limits_of_reals 
\theorem unicidade de limites.
\label{uniqueness_of_limits_of_reals}%
Uma seqüência não pode ter mais que um limite.
Formalmente, seja $\seqn a n$ seqüência de reais tal que
$$
\xalignat 2
\seqn a n &\limto \ell_1 &
\seqn a n &\limto \ell_2.
\endxalignat
$$
Então $\ell_1 = \ell_2$.
\proof.
Graças ao~\ref{only_zero_is_leq_than_all_positives} basta provar
que $\abs{\ell_1 - \ell_2} < \epsilon$ para todo $\epsilon > 0$.
Seja $\epsilon > 0$ então, e agora observe que para quaisquer
$\epsilon_1,\epsilon_2>0$ podemos escolher $N_1,N_2$ tais que:
$$
\xalignat 2
\pforall {i \geq N_1} &\bracket{\abs{a_i - \ell_1} < \epsilon_1} &
\pforall {j \geq N_2} &\bracket{\abs{a_j - \ell_2} < \epsilon_2}.
\endxalignat
$$
Tome $N \asseq \max\set{N_1, N_2}$.
Logo
$$
\xalignat 2
\abs{a_N - \ell_1} &< \epsilon_1 &
\abs{a_N - \ell_2} &< \epsilon_2.
\endxalignat
$$
Observando que $\abs{a_N - \ell_1} = \abs{\ell_1 - a_N}$ e somando as desigualdades
por lados temos
$$
\abs{\ell_1 - a_N} + \abs{a_N - \ell_2} < \epsilon_1 + \epsilon_2.
$$
Mas
$$
\munderbrace {\abs{\ell_1 - a_N + a_N - \ell_2}} {\abs{\ell_1 - \ell_2}}
\leq \abs{\ell_1 - a_N} + \abs{a_N - \ell_2}
< \epsilon_1 + \epsilon_2.
$$
Lembre-se que isso é válido para quaisquer $\epsilon_1,\epsilon_2>0$, então
basta selecioná-los para satisfazer $\epsilon_1+\epsilon_2\leq\epsilon$
(tome pore exemplo ambos (menores ou) iguais ao $\epsilon/2$).
Assim provamos que para todo $\epsilon > 0$,
$$
0 \leq \abs{\ell_1 - \ell_2} < \epsilon,
$$
ou seja, $\abs{\ell_1 - \ell_2} = 0$, e logo $\ell_1 - \ell_2 = 0$,
e logo $\ell_1 = \ell_2$, que é o que queremos provar!
\qed
%%}}}

%%{{{ x: exp_over_factorial_limit 
\exercise.
\label{exp_over_factorial_limit}%
Demonstre que
$$
\lim_n \frac {2^n} {\fac n} = 0.
$$

\hint
$$
\frac
{2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes \dotsb}
{1 \ntimes 2 \ntimes 3 \ntimes 4 \ntimes 5 \ntimes 6 \ntimes 7 \ntimes \dotsb}
=
\frac
{2 \ntimes 2 \ntimes 2}
{1 \ntimes 2 \ntimes 3}
\ntimes
\dotsc
$$

\hint
$$
\frac
{2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes \dotsb}
{1 \ntimes 2 \ntimes 3 \ntimes 4 \ntimes 5 \ntimes 6 \ntimes 7 \ntimes \dotsb}
=
\frac
{2 \ntimes 2 \ntimes 2}
{1 \ntimes 2 \ntimes 3}
\ntimes
\frac
{2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes \dotsb}
{4 \ntimes 5 \ntimes 6 \ntimes 7 \ntimes \dotsb}
=
\frac 4 3
\ntimes
\frac
{2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes \dotsb}
{4 \ntimes 5 \ntimes 6 \ntimes 7 \ntimes \dotsb}
\leq
\frac
{2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes \dotsb}
{4 \ntimes 4 \ntimes 4 \ntimes 4 \ntimes \dotsb}
$$
e agora?

\endexercise
%%}}}

%%{{{ x: exp_over_factorial_limit_gen 
\exercise.
\label{exp_over_factorial_limit_gen}%
No~\ref{exp_over_factorial_limit}, podemos trocar o $2$
por quais números?

\endexercise
%%}}}

%%{{{ thm: convergent_implies_bounded_in_reals 
\theorem.
\label{convergent_implies_bounded_in_reals}%
Toda seqüência convergente $\seqn a n$ é bounded.
\sketch.
Seja $\seqn a n$ tal que $\seqn a n \limto \ell$.
Logo, usando $\epsilon \asseq 1$ seja $N\in\nats$
tal que a partir do $a_N$, todos os $a_n$'s são
$1$-perto de $\ell$.
Observe que o conjunto $\set{a_0, \dotsc, a_{N-1}}$
é finito, e logo possui mínimo $m$ e máximo $M$:
$$
m \leq a_0, \dotsc, a_{N-1} \leq M.
$$
Agora, observe que a seqüência é bounded below pelo
$\min \set{ m , \ell - 1 }$ e similarmente bounded above pelo
$\max \set{ M , \ell + 1 }$.
\qes
%%}}}

%%{{{ thm: monotone_and_bounded_implies_convergent 
\theorem.
\label{monotone_and_bounded_implies_convergent}%
Uma seqüência monótona e bounded é convergente.
%%}}}

\TODO sketch.

%%{{{ df: Cauchy_sequence_of_reals 
\definition seqüência Cauchy.
\label{Cauchy_sequence_of_reals}%
\tdefined{Cauchy}[reais]%
Seja $\seqn a n$ uma seqüência de reais.
Dizemos que $\seqn a n$ é \Cauchy[seqüência]\dterm{Cauchy}
sse para qualquer $\epsilon > 0$ existe um membro da
seqüência tal que a partir dele, todos os seus membros
são $\epsilon$-perto entre si (dois a dois).
Formalmente:
$$
\text{$\seqn a n$ é Cauchy}
\defiff
\pforall  {\epsilon > 0}
\pexists  {N \in \nats}
\lforallt {i,j \geq N}
{$a_i,a_j$ são $\epsilon$-perto}.
$$
%%}}}

%%{{{ thm: convergent_implies_Cauchy_in_reals 
\theorem.
\label{convergent_implies_Cauchy_in_reals}%
Se uma seqüência de reais é convergente, então ela é Cauchy.
%%}}}

%%{{{ thm: Cauchy_implies_bounded_in_reals 
\theorem.
\label{Cauchy_implies_bounded_in_reals}%
Se uma seqüência de reais é Cauchy, então é bounded.
%%}}}

%%{{{ thm: Cauchy_with_conv_subseq_implies_convergent_in_reals 
\theorem.
\label{Cauchy_with_conv_subseq_implies_convergent_in_reals}
Se uma seqüência de reais é Cauchy e possui subseqüência
convergente, então é convergente.
%%}}}

%%{{{ thm: Bolzano_Weierstrass_theorem 
\theorem Bolzano--Weierstrass.
\label{Bolzano_Weierstrass_theorem}%
Toda seqüência bounded de reais possui subseqüência convergente.
%%}}}

%%{{{ cor: Cauchy_implies_convergent_in_reals 
\corollary.
\label{Cauchy_implies_convergent_in_reals}
Uma seqüência de reais é Cauchy sse é convergente.
%%}}}

%%{{{ cor: bounded_implies_Cauchy_subseq_in_reals.
\corollary.
\label{bounded_implies_Cauchy_subseq_in_reals}%
Toda seqüência bounded possui subseqüência Cauchy.
%%}}}

\endsection
%%}}}

%%{{{ Continuity 
\section Continuidade.

\TODO Elaborar.

%%{{{ df: continuous_real_function 
\definition função real contínua.
\label{continuous_real_function}%
Sejam $X,Y\subset \reals$, $f : X \to Y$, e $x_0 \in X$.
Chamamos
$$
\multline
\text{$f$ contínua no $x_0$}
\defiff
\pforall {\epsilon > 0}
\pexists {\delta > 0} \\
\lforall {x \in X}
{
\text{$x,x_0$ são $\delta$-perto}
\implies
\text{$f x, f x_0$ são $\epsilon$-perto}
}.
\endmultline
$$
Dizemos que $f$ é \dterm{contínua} sse ela é contínua em
cada ponto do seu domínio.
%%}}}

%%{{{ Continuity as a game 
\note Continuidade como jogo.
\label{continuity_game}%
%%}}}

\TODO Escrever.

%%{{{ lemma: continuous_functions_preserve_sign 
\lemma preservação de sinal.
\label{continuous_functions_preserve_sign}%
Seja $f : A \to \reals$ contínua no $a$ com $fa \neq 0$.
Logo existe $\ball \delta a$ tal que f não muda sinal nela.
\sketch.
\proofpart{Caso $fa > 0$.}
Usamos a continuidade da $f$ no $a$ com $\epsilon \asseq (fa)/2$,
assim ganhando um $\delta > 0$ tal que
todos os $\delta$-perto de $a$ são mapeados $\epsilon$-perto
de $fa$.  Logo todos são positivos.
\crproofpart{Caso $fa < 0$:} similar.
\qes
%%}}}

%%{{{ thm: Bolzano_theorem 
\theorem Bolzano.
\label{Bolzano_theorem}%
{\Bolzano[teorema]}%
Seja $f : A \to \reals$ contínua em todo ponto dum intervalo
$[a,b]$ tal que $(fa),(fb)$ têm sinais opostos.
Logo existe $w \in (a,b)$ tal que $fw = 0$.
\sketch.
\proofpart{Caso $fa < 0 < fb$.}
Observe que podem exisir vários $w \in (a,b)$ com $fw = 0$;
a gente precisa achar um tal $w$.
Seja
$$
L = \setst {x \in [a,b]} {f x \leq 0}.
$$
Observe $L \neq \emptyset$ (pois $a \in L$) e ele é
bounded above (por $b$), e logo possui supremum:
seja $w \asseq \sup L$.
Basta demonstrar que (i) $fw = 0$; (ii) $a < w < b$.
(i) Pela tricotomía da ordem basta eliminar as possibilidades
$fw > 0$ e $fw < 0$.
Fazemos isso usando a continuidade da $f$ e
o~\ref{continuous_functions_preserve_sign}.
supondo a primeira chegamos na contradição de achar um
upper bound de $L$ menor que $w$;
supondo a segunda chegamos na contradição que o $w$
não é um upper bound.
(ii) Temos $w \in [a,b]$, basta eliminar as possibilidades
de $w = a$ e $w = b$: imediato pois $fw = 0$ e $fa,fb\neq 0$.
\crproofpart{Caso $fb < 0 < fa$:} similar.
\qes
%%}}}

%%{{{ df: preserves_limits_in_reals 
\definition preserva limites.
\label{preserves_limits_in_reals}%
Seja $f : A \to \reals$.
Dizemos que \dterm{$f$ preserva os límites} sse
para toda seqüência convergente $\seqn a n$
$$
f\funparen{ \liml_n x_n } = \liml_n (f x_n).
$$
%%}}}

%%{{{ criterion: continuous_iff_preserves_limits_in_reals 
\criterion.
\label{continuous_iff_preserves_limits_in_reals}%
Seja $f : A \to \reals$.
$$
\text{$f$ contínua}
\iff
\text{$f$ preserva os limítes}.
$$
%%}}}

\TODO Demonstrar.

\endsection
%%}}}

%%{{{ Series 
\section Séries.

\endsection
%%}}}

%%{{{ Pointwise convergence 
\section Convergência ponto a ponto.

\endsection
%%}}}

%%{{{ Problems 
\problems.

%%{{{ prob: alternative_formalization_of_ordered_fields_is_equivalent 
\problem.
\label{alternative_formalization_of_ordered_fields_is_equivalent}%
No~\ref{alternative_formalization_of_ordered_fields} afirmei que
as duas formalizações são equivalentes.
Afirme formalmente o que isso quis dizer e demonstre.

\endproblem
%%}}}

%%{{{ prob: complex_cannot_by_ordered 
\problem.
\label{complex_cannot_by_ordered}%
Demonstre que não tem como definir uma ordem no corpo dos
complexos em tal forma que ele vira um corpo ordenado.

\endproblem
%%}}}

%%{{{ prob: weird_convex_modulized 
\problem.
\label{weird_convex_modulized}%
O que muda no~\ref{weird_convex} se definir o $Q$ como
$Q = \Union_n \set{\tup{\cos n, \sin n}}$?

\endproblem
%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite{spivakcalculus},
\cite{apostol1},
\cite{hardypuremath}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Cantor's paradise 
\chapter O paraíso de Cantor.
\label{Cantors_paradise}%

%%{{{ A bit of historical context 
\history Um pouco de contexto histórico.

\TODO Terminar as duas histórias.

%%{{{ Wild_numbers 
\note Números selvágens.
\yearof{1682}:
\Leibniz{}Leibniz demonstra que $\sin$ não é uma
\ii{função}[algébrica]\dterm{função algébrica}.
\yearof{1700}:
\Euler{}Euler define os números \dterm{transcendentais};
mas não consegue provar se existem ou não.
\yearof{1768}:
\Lambert{}Lambert
prova que $\pi$ é \emph{irracional} e os $e^q$ também, para qualquer $q\in\rats_{\neq0}$.
\yearof{1844}:
\Liouville{}Liouville demonstra que existem números transcendentais.
Definiu o que hoje chamamos de \dterm{números Liouville},
mostrou que todos eles são transcendentais, e no 1851 construiu
um número Liouville específico, a \dterm{constante Liouville}
$$
\Sum_{n=1}^\infty 10^{-n!}
= 0.11000100000000000000000100\dots
$$
que foi (finalmente) um exemplo simples e concreto de um
número transcendental.
\yearof{1870}--\yearof{1872}:
\Cantor{}Cantor;
\yearof{1873}:
\Hermite{}Hermite provou que $e$ é transcendental.
Esse foi o primeiro número transcendental que conhecemos cujo
objectivo (cuja definição) não foi feita para ser um tal número.
Liouville \emph{definiu} seus números com objectivo de achar
transcendentais.  O $e$ já era definido e estudado muito,
e sua \emph{raison d'être} não tinha nada a ver com os
números transcendentais.
\yearof{1882}:
\vonLindemann{}von~Lindemann prova a transcendentalidade
dos $e^\alpha$ para $\alpha\neq0$ algébrico---e logo
do $\pi$ também (\ref{pi_is_transcendental})---e
\Weierstrass{}Weierstrass generaliza no \yearof{1885} para o
teorema conhecido como Lindemann--Weierstrass na teoria de
números transcendentais.
%%}}}

%%{{{ From Fourier series to the study of sets 
\note De series Fourier para o estudo de conjuntos.
\yearof{1870}:
\Cantor{}Cantor se interessou nas series \Fourier{}Fourier.
O que são as \dterm{series Fourier} não é importante nesse
momento;%
\footnote{%
Uma série Fourier tem a forma
$$
f(x)
= A
+ \Sum_{n=1}^{\infty} a_n \cos(nx)
+ \Sum_{n=1}^{\infty} b_n \sin(nx).
$$
}
basta saber que são determinadas por seus
\emph{coeficientes} que são duas seqüências de números reais
$$
\xalignat2
&a_1,a_2,a_3,\dotsc &
&b_1,b_2,b_3,\dotsc
\endxalignat
$$
Cantor demonstrou um teorema impressionante:

%%{{{ thm: Cantor_theorem_1870 
\theorem Cantor, 1870.
\label{Cantor_theorem_1870}%
Sejam $f,f'$ series Fourier que convergem (pointwise)
função $F$ no $[0,2\pi]$.
Então os coeficientes das $f,f'$ são iguais.
%%}}}

\blah.
Mas Cantor se perguntou:
<<E se elas convergem na mesma função em todo o $[0,2\pi]$
\emph{exceto um conjunto de possíveis excessões}
$E \subset [0,2\pi]$?  Será que se o $E$ não é grande
demais eu ainda consigo demonstrar o mesmo resultado,
que os coeficientes são iguais?>>
E realmente conseguiu, já no próximo ano:

%%{{{ thm: Cantor_theorem_1871 
\theorem Cantor, 1871.
\label{Cantor_theorem_1871}%
Sejam $f,f'$ series Fourier que convergem (pointwise)
na mesma função $F$ no $[0,2\pi] \setminus E$.
Se $E$ é finito, então os coeficientes das $f,f'$ são iguais.
%%}}}

\blah.
Observe que o teorema de 1870 é um caso especial do
teorema de 1871, tomando $E \asseq \emptyset$.
No próximo ano, Cantor conseguiu melhorar ainda mais seu
teorema:

%%{{{ thm: Cantor_theorem_1872 
\theorem Cantor, 1872.
\label{Cantor_theorem_1872}%
Sejam $f,f'$ series Fourier que convergem (pointwise)
na mesma função $F$ no $[0,2\pi] \setminus E$.
Se $E$ é \dterm{derivável até $\emptyset$},
então os coeficientes das $f,f'$ são iguais.
%%}}}

\blah.
O que significa \dterm{derivável até $\emptyset$} vamos
encontrar no~\ref{Metric_spaces};
por enquanto basta saber que essa condição é satisfeita
por muitos conjuntos \emph{infinitos}, e por todos os
conjuntos finitos, e logo o teorema de 1871 é um caso
especial do teorema de 1872.

\blah.
Essas aventuras fizeram Cantor se preocupar sobre os
conjuntos como objetos matemáticos próprios, como
``first-class cítizens'' e se preocupar sobre seus
tamanhos também.
E assim nasceu a \dterm{teoria (ingênua) dos conjuntos}.
Nesse capítulo estudamos as idéias de Cantor sobre conjuntos e
sobre infinidade(s); descobertas importantíssimas em matemática,
tanto que faz sentido de falar sobre matemática a.C.~e~d.C.~(antes
Cantor e depois Cantor).
%%}}}

\endhistory
%%}}}

%%{{{ What is counting and comparing of quantities? 
\section O que é contar e comparar quantidades?.

%%{{{ How we count 
\note.
Quando queremos \dterm{contar} a quantidade de membros
dum conjunto $A$, começamos apontando a cada um deles,
e usando \emph{números}, atribuimos um para cada membro.
No final das contas---ahem---acabamos com um certo número $n$
e digamos que $A$ tem $n$ membros.  A \dterm{cardinalidade}
de $A$, é o $n$.
Em símbolos,
$$
\card A = n.
$$
Essa análise tem varios pontos hipersimplificados e talvez
controversiais.
\endgraf
Primeiramente note que, se o conjunto $A$ é infinito, esse
processo nunca vai parar, e a gente não vai conseguir atribuir
um $n\in\nats$ para representar a cardinalidade $\card A$.
Alem disso, precisamos \emph{ter} os números.
Isso talvez parece um ponto bobo, mas vale a pena se perguntar
se os humanos sabiam sobre o conceito de \dterm{quantidade},
e equivalentemente de \dterm{cardinalidade de conjunto},
antes de \emph{ter} os números ou não!
%%}}}

%%{{{ Do we really need numbers? 
\note Precisamos mesmo de números?.
Sabemos como contar conjuntos finitos então.
E usamos o $\nats$ para representar as quantidades possíveis.
Agora não queremos contar, mas \emph{comparar} dois conjuntos
\emph{com relação à quantidade de elementos}.
A discussão sobre contagem acima presuponha a existência
dos números que usamos para contar:  1, 2, 3, etc.,
e dependende da época talvez o 0 também faz parte desses números.
Mas, bem antes de ter números para contar, os humanos poderiam
comparar quantidades.
Talvez um humano prehistórico sabia dizer que ele tem a mesma
quantidade de filhos que seu vizinho, sem saber dizer que
cada um tem \emph{cinqo} filhos.
Como ele sabia então comprarar essas cardinalidades?
%%}}}

\endsection
%%}}}

%%{{{ Equinumerosity 
\section Eqüinumerosidade.

%%{{{ df: finord 
\definition.
\label{finord}%
\sdefined {\finord {\sholed n}} {o conjunto $\set {0,\dotsc,n-1}$}%
Como usamos bastante o conjunto $\set{0,1,\dotsc,n-1}$,
vale a pena introduzir uma notação para denotá-lo:
$$
\finord n \pseudodefeq \set{0,\dotsc,n-1}.
$$
%%}}}

%%{{{ x: define \finord using set-builder 
\exercise.
Defina o $\finord n$ usando a notação set-builder.

\hint
Começa com o $\nats$ e filtre seus elementos usando suas relações de ordem.

\solution
Definimos
$$
\finord n \defeq \setst {i \in \nats} { 0 \leq i < n }.
$$

\endexercise
%%}}}

%%{{{ x: define \finord using recursion 
\exercise.
Defina o operador $\finord{\hole} : \nats \to \pset\nats$ recursivamente.

\hint
Cuidado com as operações e os ``tipos'' dos seus argumentos.

\solution
Qualquer uma das definições abaixo serve:
$$
\xalignat 2
\finord 0 &\defeq \emptyset                                     & \finord 0    &\defeq \emptyset\\
\finord n &\defeq \finord {n-1} \union \set{n-1}\qquad(n > 0)   & \finord {Sn} &\defeq \finord n \union \set n.
\endxalignat
$$

\endexercise
%%}}}

%%{{{ df: equinumerous 
\definition Eqüinúmeros.
\label{equinumerous}%
\tdefined {eqüinúmeros}%
\sdefined {\sholed A \eqc \sholed B} {os $A$ e $B$ são equinúmeros}%
Chamamos os conjuntos $A$ e $B$ \dterm{eqüinúmeros} sse
existe bijecção $f : A \bijto B$.
Escrevemos:
$$
A \eqc B \defiff \lexists f {f : A \bijto B}.
$$
%%}}}

Continuamos em definir mais relações para comparar os tamanhos de conjuntos:

%%{{{ df: leqc_and_ltc 
\definition.
\label{leqc_and_ltc}%
\sdefined {\sholed A \leqc \sholed B} {o $A$ é menor-ou-igual em cardinalidade que o $B$}
\sdefined {\sholed A \ltc \sholed B}  {o $A$ é menor em cardinalidade que o $B$}
Sejam $A$ e $B$ conjuntos.
Definimos
$$
\align
A \leqc B &\defiff \lexists {B_0\subset B} {A \eqc B_0}\\
A \ltc B  &\defiff A\leqc B \mland A\neqc B
\endalign
$$
Seguindo nossa práctica comum, usamos também $A\gtc B$ como sinónimo de $B\ltc A$,
$A \not\geqc B$ para significar que não é o caso que $B \leqc A$, etc.
%%}}}

%%{{{ x: A_subset_B_implies_A_leqc_B 
\exercise.
Verifique que
$$
A \subset B \implies A \leqc B.
$$
Mostre que, em geral,
$$
A \subsetneq B \nimplies A \ltc B.
$$

\endexercise
%%}}}

%%{{{ x: wrong_ltc_def 
\exercise.
\label{wrong_ltc_def}%
Prove ou disprove a afirmação que podemos usar a seguinte definição como alternativa:
$$
A \ltc B \askiff \lexists {B_0\subsetneq B} {A \eqc B_0}.
$$

\hint
$\nats\ltc\ints$?

\endexercise
%%}}}

%%{{{ x: fun_leqc_def_injto 
\exercise.
\label{fun_leqc_def_injto}%
Prove ou disprove a afirmação que podemos usar a seguinte definição como alternativa:
$$
A \leqc B \askiff \lexists f {f : A \injto B}.
$$

\hint
Realmente
$$
A \leqc B \iff \lexists f {f : A \injto B}.
$$
Prove!

\endexercise
%%}}}

%%{{{ x: fun_leqc_def_surto 
\exercise.
\label{fun_leqc_def_surto}%
Podemos usar a seguinte definição como alternativa?:
$$
A \leqc B \askiff \lexists f {f : B \surto A}.
$$

\endexercise
%%}}}

%%{{{ x: eqc_is_eqrel 
\exercise.
A $\eqc$ é uma relação de equivalência.  Ou seja:
$$
\align
\text{reflexiva:}\quad&  \text{para todo conjunto $A$,     $A \eqc A$};\\
\text{transitiva:}\quad& \text{para todo conjunto $A,B,C$, $A \eqc B \mland B \eqc C \implies A \eqc C$};\\
\text{simétrica:}\quad&  \text{para todo conjunto $A,B$,   $A \eqc B \implies B \eqc A$}.
\endalign
$$

\solution
Usamos as bijecções seguintes: identidade, composição, inversa.

\endexercise
%%}}}

%%{{{ lemma: leqc_is_equiorder 
\lemma.
\label{leqc_is_equiorder}%
A $\leqc$ é:
$$
\align
\text{reflexiva:}              \quad &A \leqc A;\\
\text{transitiva:}             \quad &A \leqc B \mland B \leqc C \implies A \leqc C;\\
\text{não antissimétrica:}     \quad &A \leqc B \mland B \leqc A \nimplies A = B;\\
\text{``equiantissimétrica'':} \quad &A \leqc B \mland B \leqc A \implies A \eqc B.
\endalign
$$
\sketch.
Para as duas primeiras usamos a identidade e a composição respectivamente.
Para a próxima tomando $A\asseq \nats$ e $B\asseq \ints$ serve.
Para ver que não é antissimétrica basta achar um contraexemplo: tente os $\set 0$ e $\set 1$.
A última é realmente difícil para provar:
é um corolário direto
do teorema Schröder--Bernstein (\ref{schroder_bernstein}).
\qes
%%}}}

%%{{{ x: times_respects_eqc 
\exercise.
\label{times_respects_eqc}%
$A \eqc A' \mland B \eqc B' \implies A\times B \eqc A'\times B'$.

\solution
Defina $F: A\times B \to A' \times B'$ pela
$
F(a,b) = (f(a), g(b)).
$
Ou seja, $F = f \cross g$.
\proofpart{Injectividade.}
Tome $\tup{a_1,b_1} \neq \tup{a_2,b_2}$ no $A\times B$.
Logo $a_1\neq a_2$ ou $b_1\neq b_2$ (pela definição de $=$ nas tuplas).
Logo
$$
F(a_1,b_2) = \tup{f(a_1), g(b_1)} \neq \tup{f(a_2), g(b_2)} = F(a_2,b_2).
$$
onde a $\neq$ segue pelas injectividades das $f,g$:
pois se $a_1\neq a_2$ então $f(a_1)\neq f(a_2)$,
e se $b_1\neq b_2$ então $g(b_1) \neq g(b_2)$.
\proofpart{Sobrejectividade.}
Tome $\tup{a',b'}\in A'\times B'$.
Logo $a'\in A'$ e $b'\in B'$, e como $f$ e $g$ são sobrejetoras,
sejam $a \in A$ e $b\in B$ tais que $f(a) = a'$ e $g(b) = b'$.
Observe que $F(a,b) = \tup{f(a), g(b)} = \tup{a',b'}$.

\endexercise
%%}}}

%%{{{ x: pset_respects_eqc 
\exercise.
\label{pset_respects_eqc}%
$A \eqc A' \implies \pset A \eqc \pset A'$.

\solution
Defina $F : \pset A \to \pset A'$ pela
$
F(X) = \img f X.
$
\proofpart{Injectividade.}
Tome $X,Y \in \pset A$ tais que $X\neq Y$.
Ou seja, existe $z\in X\symdiff Y$.
Tome tal $z$ e considere os $F(X)$ e $F(Y)$.
Como $f$ é injetora, o $f(z) \in F(X) \symdiff F(Y)$.
Ou seja: $F(X) \neq F(Y)$.
\proofpart{Sobrejectividade.}
Tome $X' \in \pset A'$.
Observe que o $\pre f {X'}$ é mapeado no $X'$ através da $F$,
graças ao~\ref{jection_iff_composition_with_inverse}.

\endexercise
%%}}}

%%{{{ x: to_respects_eqc 
\exercise.
\label{to_respects_eqc}%
$A \eqc A' \mland B \eqc B' \implies (A\to B) \eqc (A'\to B')$.

\solution
Defina $F : (A\to B) \to (A' \to B')$ pela
$F(t) = g \compose t \compose f^{-1}$.
\proofpart{Injectividade.}
Sejam $s,t \in (A\to B)$ com $s\neq t$.
Logo existe $a_0 \in A$ tal que $s(a_0) \neq t(a_0)$.
Calcule:
\compute
(F(s))(f(a_0))
&= (g \compose s \compose \finv f)(f(a_0))\\
&= (g \compose s \compose \finv f \compose f)(a_0)\\
&= (g \compose s)(a_0)\\
&= g(s(a_0))\\
&\neq g(t(a_0)) \by {$g$ injetora e $s(a_0) \neq t(a_0)$}
&= (g \compose t)(a_0)\\
&= (g \compose s \compose \finv f \compose f)(a_0)\\
&= (g \compose s \compose \finv f)(f(a_0))\\
&= (F(t))(f(a_0)).
\endcompute
\proofpart{Sobrejectividade.}
Seja $t' \in (A'\to B')$.
Defina a $t \in (A\to B)$ pela
$$
    t = \finv g \compose t' \compose f
$$
e observe que $F(t) = t'$.

\endexercise
%%}}}

%%{{{ x: which_setops_respect_cardinalities 
\exercise.
\label{which_setops_respect_cardinalities}%
Quais das operações $\Union$, $\Inter$, respeitam a eqüinumerosidade?

\hint
Nenhuma.
Ache contraexemplos.

\solution
Nenhuma!
Como contraexemplo, tome os
$$
A \asseq \set{ \set{0}, \set{1} }
\eqc
B \asseq \set{ \set{0,1}, \set{1,2} }
$$
e calcule
$$
\xalignat2
\Union \set{ \set{0}, \set{1} }     &= \set{0,1} &
\Inter\set{ \set{0}, \set{1} }      &= \emptyset \\
\Union \set{ \set{0,1}, \set{1,2} } &= \set{0,1,2} &
\Inter\set{ \set{0,1}, \set{1,2} }  &= \set{1}.
\endxalignat
$$
Ou seja, $\Union A \neqc \Union B$ e $\Inter A \neqc \Inter B$.

\endexercise
%%}}}

%%{{{ x: currying_eqc 
\exercise.
\label{currying_eqc}%
$((A \times B) \to C) \eqc (A \to (B\to C))$.

\hint
Curry!

\hint
Use lambdas (veja~\ref{A_touch_of_lambda}).

\solution
Defina $F : ((A\times B) \to C) \to (A \to (B\to C))$, pela
$$
F(t) = \lam a {\lam b {t(a,b)}}.
$$
\proofpart{Injectividade.}
Tome $s,t \in ((A\times B) \to C)$ tais que $s\neq t$.
Ou seja, para alguma entrada $\tup{a_0,b_0} \in (A\times B)$,
as saídas são diferentes elementos de $C$:
$$
s(a_0,b_0) \neq t(a_0,b_0).
$$
Observe então que $F(s) \neq F(t)$,
pois para a entrada $a_0$, elas retornam valores diferentes:
a $F(s)$ retorna a função
$\lam b {s(a_0, b)}$,
e a $F(t)$ retorna a função $\lam b {t(a_0, b)}$.
Para confirmar que realmente
$$
\lam b {s(a_0, b)}
\neq
\lam b {t(a_0, b)}
$$
basta observar que seus valores para a entrada $b\asseq b_0$
são diferentes.
\proofpart{Sobrejectividade.}
Toma um $f\in (A\to (B\to C))$.
Defina a $t : (A\times B) \to C$
pela
$$
t(a,b) = (f(a))(b)
$$
e observe que realmente $F(t) = f$.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ What is cardinality? 
\section O que é cardinalidade?.

%%{{{ The double abstraction of Cantor 
\note A dupla abstracção de Cantor.
\Cantor{}Cantor definiu a cardinalidade numa maneira informal,
mas sua descrição é bastante indicativa e serve como uma guia
para chegar numa definição formal.
A cardinalidade dum conjunto $A$ é o que fica, se
a gente mentalmente esquecer a ordem que pensamos os membros de $A$
e também os seus nómes.  Assim o $A$ parece uma colecção de pontinhos
abstratos e distintos.  Cantor denotou a cardinalidade de $A$
$$
\cantorcard A
$$
usando as duas barras para indicar essa ``dupla abstracção''.
%%}}}

%%{{{ But what is a cardinal number? 
\note Mas o que é um número cardinal?.
Vamos voltar pouco ao passado, e seguindo os passos do livro
clássico de \Hausdorff{}Hausdorff (\cite{hausdorffsettheory})
não vamos preocupar com a \emph{natureza} dos cardinais.
Vamos deixar isso ``para os filósofos'' como ele disse,
pois na época que ele escreveu seu texto ninguém tinha conseguido
dar uma definição satisfatória de \dterm{número cardinal}.
Uns anos depois, \vonNeumann{}von~Neumann conseguiu definir
formalmente os números cardinais, algo que vamos encontrar
no~\ref{Ordinal_arithmetic}.  Mas sem saber o que são,
já podemos usá-los deixando claro quais são as propriedades
que exigimos que eles satisfaçam.
Um operador de cardinalidade $\card{\dhole}$ deve satisfazer
pelo menos a:
$$
A \eqc B \iff \card{A} = \card{B}
$$
e possivelmente mais condições ainda.
Vamos voltar para estudar os detalhes no~\ref{Axiomatic_set_theory}.
%%}}}

\endsection
%%}}}

%%{{{ Finite and infinite; countable and uncountable 
\section Finitos e infinitos; contáveis e incontáveis; jogos para imortais.

%%{{{ df: finite_set ; infinite_set 
\definition.
\label{finite_set}%
\label{infinite_set}%
\tdefined{finito}%
\tdefined{infinito}%
O conjunto $A$ é \dterm{finito} sse existe $n\in\nats$ tal que $A \eqc \finord n$.
O conjunto $A$ é \dterm{infinito} sse $A$ não é finito.
%%}}}

%%{{{ df: countable_set ; uncountable_set 
\definition.
\label{countable_set}%
\label{uncountable_set}%
\tdefined{conjunto}[contável]%
\tdefined{conjunto}[incontável]%
O conjunto $A$ é \dterm{contável} sse $A$ é finito ou $\nats\eqc A$.
Usamos os termos \dterm{enumerável} e \dterm{denumerável} como sinónimos
de contável.
O conjunto $A$ é \dterm{incontável} sse $A$ não é contável.
%%}}}

%%{{{ countable vs enumerable 
\warning.
Em muitos textos as palavras ``contável'' e ``(d)enumerável'' não
são exatamente sinónimas: uma delas pode insistir que o conjunto seja
infinito, e a outra relaxar essa restricção para permitir os finitos
também.  As duas palavras, etimologicamente e semanticamente falando,
parecem ser sinônimos no mundo matemático, e por isso nesse texto
eu vou usar as duas como sinônimos mesmo.  Mas cuidado lendo
textos diferentes, pois podem significar coisas diferentes
no caso que o conjunto em questão é finito.
(Sobre conjuntos infinitos os dois termos sempre concordam.)
%%}}}

%%{{{ df: enumeration 
\definition.
\label{enumeração}%
\tdefined{enumeração}%
Uma \dterm{enumeração} dum conjunto $A$ é qualquer surjecção
$\pi : \nats\surjto A$.
Assim temos:
$$
A = \img \pi {\nats} = \set{\pi(0), \pi(1), \pi(2), \dotsc}
$$
%%}}}

%%{{{ The enumeration game of Smullyan 
\note O jogo de enumeração de Smullyan.
\label{Smullyan_game}%
\Smullyan{jogo} criou o seguinte jogo que ajuda em entender o conceito
de conjunto enumerável.  Seja $S$ um conjunto que chamaremos de
\dterm{conjunto-segredo}.  Tu, o jogador, e eu, o inimigo, começamos
o jogo e nos dois sabemos qual é o conjunto $S$ desse jogo.
Eu jogo primeiro, escolhendo um membro $w\in S$.
Teu objectivo é adivinhar o $w$.
Todo dia tu tens um palpite, e eu vou responder ``sim'' ou ``não''.
No dia $i$ então, tu escolhe um membro $s_i \in S$ como um
palpite fazer exatamente um palpite na forma equacional:
$$
w = s_i?
$$
onde $s_i$ é teu $i$-ésimo palpite, ou seja, o palpite do dia $i$.
Tu ganhas se um belo dia tu conseguir adivinhar a minha escolha:
o $w$ que selecionei no inicio do jogo.
Um exemplo de jogo então com $S=\nats$ parece assim:
\dialogue
\say Eu escolhi meu membro $w \in \nats$.
\say (Dia 0:) É o 42?
\say Não.
\say (Dia 1:) É o 28?
\say Não.
\say (Dia 2:) É o 8?
\say Não.
\say (Dia 3:) É o 1024?
\say Não.
\say (Dia 4:) É o 1024?
\say Não!
\say (Dia 5:) É o 12?
\say Sim.
\enddialogue
Quantas tentativas tu tens?
Um para cada dia, pra sempre!
Pois é, um detalhe pequeno: vamos supor que nós dois somos imortais.
E o inimigo não tem o direito de mudar seu palpite!
O jogo então é baseado no conjunto-segredo $S$.
O teu objectivo como jogador é adivinhar o $w$ que eu, teu inimigo, escolhi.
\endgraf
O teu objectivo como matemático é achar uma
\ii{estratégia}[vencedora]\emph{estratégia vencedora},
ou seja, \emph{uma estratégia que garanta vitória} para o jogador.
Se tal estratégia existe para esse jogo, chamamos o $S$ \dterm{enumerável}.
Observe que uma estratégia nesse jogo não é nada mais que uma
\emph{seqüência}
$$
s_0, s_1, s_2, s_3, s_4, \dotsc
$$
de membros de $S$, que o jogador vai seguir, jogando $s_i$ no $i$-ésimo dia.
Ela é vencedora sse
$$
\pforall {w \in S}
\lexists {i \in \nats}
{s_i = w}.
$$
Pensando em seqüências do $S$ como funções $s : \nats\to S$ isso quis
dizer que $s$ é sobrejetora.
%%}}}

%%{{{ Secret set
\note Conjunto-segredo: de easy para nightmare.
Vamos ver se (e como!) tu jogaria nesse jogo com uns $S$
variando em dificuldade:
$$
S = \set {12, -2, 0}.
$$
Espero que é óbvio como garantir vitória aqui:
$$
0, 12, -2;
$$
ou seja, no primeiro dia jogue o $0$; se não foi o escolhido,
jogue o $12$; se nem isso foi o escolhido, jogue o $-2$ que com
certeza será o certo pois não tem outros membros o~$S$.
$$
S = \nats.
$$
Aqui a situação é pouco mais complicada, mais ainda múito fácil:
$$
0, 1, 2, 3, 4, \dotsc;
$$
ou seja: no dia $i$, escolha o $i$!
Não importa quão grande foi o número segredo $w$ que escolhi,
um belo dia (no $w$-ésimo dia mesmo) tu acertás!
Próximo!
$$
S = \ints.
$$
Aqui eu vou adivinhar qualquer inteiro.  O que farás?
Observe que a última estratégia não funciona mais.
Se eu escolher qualquer número negativo, tu nunca adivinharás,
pois tu ``ficarás preso'' para a eternidade adicinhando apenas
os inteiros não-negativos.
\emph{O fato que uma estratégia não é vencedora, não quis dizer
que não existem vencedoras!}
Aqui realmente existe!
%%}}}

%%{{{ Q: Can we guarantee victory with S = ints ?
\question.
Tem como garantir vitória nesse jogo com $S = \ints$?
%%}}}
\spoiler.

%%{{{ x: binary_union_of_countable_is_countable 
\exercise.
\label{binary_union_of_countable_is_countable}%
A união $C\union D$ de dois conjuntos contáveis $C,D$ é contável.

\endexercise
%%}}}

%%{{{ Q: uncountable_or_uncountable_guess 
\question.
\label{countable_or_uncountable_guess}%
Para cada um dos conjuntos seguintes, tu jogaria nesse jogo?
Ou seja, tem estratégia vencedora?
$$
\rm
\align
I   &= \setst {x\in\reals}   {\text{$x$ é irracional}}\\
A   &= \setst {x\in\reals}   {\text{$x$ é algébrico}}\\
T   &= \setst {x\in\reals}   {\text{$x$ é transcendental}}\\
C   &= \setst {z\in\complex} {\modulus z = 1}\\
P_L &= \setstt {p} {$p$ é um programa da linguagem de programação $L$}\\
G   &= \graph(f), \quad \text{onde $f : \reals\to\reals$ definida pela $f(x) = x^2$}\\
D   &= (\nats \to \set{0,2})\\
S   &= (\nats \to \nats)\\
P   &= (\nats \bijto \nats)\\
Z   &= \setst {f:\nats\to\nats} {\pexists {n_0\in\nats} \lforall {n\geq n_0} {f(n)=0}}
\endalign
$$
%%}}}

%%{{{ And the answers? 
\blah E as respostas?.
Pense nisso agora, meio-adivinhando, e até o fim desse capítulo tu vai
saber a resposta para cada um deles!
%%}}}

%%{{{ lemma: A_is_countable_equiv_statements 
\lemma.
\label{A_is_countable_equiv_statements}%
Seja $A$ conjunto.
O.s.s.e.:
\item{\rm (1)} $A$ é contável
\item{\rm (2)} $A \leqc \nats$
\item{\rm (3)} $A=\emptyset$ ou $A$ possui enumeração.
\sketch.
As direcões $(1)\Rightarrow(2)\Rightarrow(3)$ são conseqüências fáceis
das definições.  Para ``fechar o round-robin'' ($(3)\Rightarrow(1)$),
precisamos definir uma \emph{bijecção} $f : \nats\bijto A$
ou $f : \finord n\bijto A$, dados uma \emph{surjecção} $\pi:\nats\surjto A$.
Usamos recursão e o princípio da boa ordem.
\qes
\proof.
Vamos provar o lemma ``round-robin'', provando as implicações
$(1)\Rightarrow(2)\Rightarrow(3)\Rightarrow(1)$.
As duas primeiras são conseqüências imediatas das definições---nada
interessante---mas para a $(3)\Rightarrow(1)$ precisamos mais cuidado.
\crproofpart{$(1)\Rightarrow(2)$.}
Caso $A$ finito, para algum $n\in\nats$ temos $A\eqc \finord n \subset \nats$
e logo $A \leqc \nats$.
Caso que $A$ infinito, temos $A\eqc\nats\subset\nats$ e logo $A \leqc \nats$.
\crproofpart{$(2)\Rightarrow(3)$.}
Suponha que $A\neq\emptyset$.
Vamos construir uma enumeração do $A$, ou seja, uma $\pi : \nats \surjto A$.
Pela hipótese, seja $N_0 \subset \nats$ tal que $A \eqc N_0$.
E logo temos uma bijecção $f : N_0 \bijto A$.
Seja $a_0 \in A$ ($A\neq\emptyset$) e defina a função $\pi : \nats \to A$ pela
$$
\pi(x) =
\knuthcases{
f(x), & se $x \in N_0$ \cr
a_0,  & se não.
}
$$
Basta verificar que $\pi$ é realmente sobrejetora, mas isso é fácil:
para cada $a\in A$, temos
$$
\pi(\finv{f}(a)) = a.
$$
\proofpart{$(3)\Rightarrow(1)$.}
Caso $A$ finito, $A$ é contável.
Suponha que $A$ infinito, e seja $\pi : \nats \surjto A$
uma enumeração de $A$.
Precisamos definir uma bijecção $f : \nats\bijto A$ ou $f : \finord n\bijto A$.
Defina a $f$ pela recursão
$$
\align
f(0)   &= \pi(0) \\
\text{e para $n>0$ defina}\qquad
f(n) &= \pi(m_n)
\phantom{\text{e para $n>0$ defina}\qquad}
\endalign
$$
onde $m_n$ é o menor natural $m$ tal que $\pi(m) \notin \set{f(0),\dotsc,f(n-1)}$.
Observe que tal $m_n$ existe graças ao \ii{PBO}Principio da boa ordem \refn{WOP}.
\qed
%%}}}

%%{{{ What do we gain? 
\note O que ganhamos?.
Suponha que um conjunto $A$ é contável.
O que ganhamos realmente com essa informação?
Como podemos usar essa hipótese?
Já sabemos, por exemplo, que o fato ``$C \neq \emptyset$'' nos permite escrever ``Seja $c\in C$.''.
O que o fato ``$A$ é contável'' nos permite fazer?
Bem, podemos escrever: ``seja $a_n$ uma \emph{enumeração} de $A$'', ou, escrever:
``Suponha $A = \set{a_0, a_1, a_2, \dotsc}$.''.
%%}}}

%%{{{ beware 
\beware.
É um erro comum escrever ``Suponha $A = \set{a_0, a_1, a_2, \dotsc}$.''~mesmo quando
não sabemos que $A$ é contável.  Talvez $A$ é \emph{grande demais} para poder ser
escrito nessa forma.  Como o $\reals$, por exemplo, que sabemos que não pode ser escrito
como $\reals = \set{r_0, r_1, r_2, \dotsc}$, pois é um conjunto incontável!%
%}}}

\endsection
%%}}}

%%{{{ Cantor's first diagonal argument 
\section O primeiro argumento diagonal de Cantor.
\label{Cantor_first_diagonal_argument}%

%%{{{ And the rationals? 
\note E os racionais?.
O fato que $\ints$ é contável não deixou ninguém muito surpreso.
Mas na maneira que contamos os membros do $\ints$, existe essa
idéia de ``próximo número'' meio incorporada no próprio conjunto
pela sua ordem.
\emph{<<Primeiramente tome o $0$.
Depois tome o próximo positívo,
e depois o próximo negativo, e por aí vai.>>}
Mas o $\rats$ com sua ordem padrão é um conjunto \dterm{denso}:
entre quaisquer racionais $x,y$ com $x<y$, existe racional $w$
tal que $x < w < y$.  Vamos dizer que começou no $0$.
Quem vai depois?  Não existe ``próximo'' para nenhuma direção!
Em vez de contar os membros de $\rats$, vamos contar
os membros de $\nats^2$.  E isso já vai resolver o problema
de enumerar o $\rats$ facilmente.
%%}}}

%%{{{ Counting the pairs of nats 
\note Contando os pares de naturais.
Naturalmente pensamos no $\nats^2$ numa forma bidimensional
(até pronunciando o conjunto usamos a palavra ``quadrado'').
Vamos arrumar então os naturais numa tabela bidimensional
e infinita assim:
$$
\tikzpicture
\tikzi pairs5x5nats;
\endtikzpicture
$$
Naturalmente, influenciados por nossos hábitos talvez gostariamos
de contar os membros linha por linha, ou coluna por coluna---só
que\dots
\endgraf\bigskip\noindent
\centerline{Expectativa:}\nobreak
$$
\xalignat 2
&\tikzpicture
\tikzi pairs5x5nats;
\foreach \y in {0,...,4} {
    \node at (-1,-\y) {$S_{\y}$};
    \draw[->] (-.5,-\y) -- (4.666,-\y);
}
\node at (-1, -4.666) {$\vdots$};
\endtikzpicture
&
&\tikzpicture
\tikzi pairs5x5nats;
\foreach \x in {0,...,4} {
    \node at (\x,1) {$S_{\x}$};
    \draw[->] (\x,.5) -- (\x,-4.5);
}
\node at (5, 1) {$\cdots$};
\endtikzpicture
\endxalignat
$$
\endgraf\bigskip\noindent
\centerline{Realidade:}\nobreak
$$
\xalignat 2
&\tikzpicture
\tikzi pairs5x5nats;
\foreach \y in {0,...,4} {
    \node at (-1,-\y) {$S_{\y}$};
}
\draw[->] (-.5,0) -- (4.666,0);
\node at (-1, -4.666) {$\vdots$};
\endtikzpicture
&
&\tikzpicture
\tikzi pairs5x5nats;
\foreach \x in {0,...,4} {
    \node at (\x,1) {$S_{\x}$};
}
\draw[->] (0,.5) -- (0,-4.5);
\node at (5, 1) {$\cdots$};
\endtikzpicture
\endxalignat
$$
O que aconteceu?
Stratificando nosso espaço nessa maneira, \emph{ficaremos presos}
no $S_0$ pra sempre!  Se o inimigo no jogo escolher qualquer um dos
membros fora do $S_0$ a gente nunca vai ganhar!
%%}}}

%%{{{ Finite strata 
\note Strata finita.
Stratificando nosso espaço precisamos tomar cuidado para qualquer
stratum ser um conjunto \emph{finito}.  Usando a analogia do jogo
isso garanta vitória, pois ficaremos no primeiro stratum para uma
quantidade finita de dias, e um belo momento depois de ter contado
todos os membros do primeiro stratum vamos começar o segundo,
que (sendo também finito) sabemos que um belo dia já vamos começar
contar o terceiro; etc., etc.
%%}}}

%%{{{ Cantor's first diagonal argument 
\note O primeiro argumento diagonal de Cantor.
\label{Cantor_stratification_of_pairs}%
\Cantor[diagonalização]Cantor conseguiu stratificar esse espaço
apenas virando sua cabeça num ángulo $\pi/4$:
$$
\tikzpicture
\tikzi pairs5x5nats;
\foreach \y in {0,...,4} {
    \node[rotate=45] at (-.8,-\y-.8) {$S_{\y}$};
    \draw[->] (-.5,-\y-.5) -- (\y+.5,.5);
}
\node at (-.8, -5.666) {$\vdots$};
\endtikzpicture
$$
Observe que na stratificação de Cantor, \emph{cada stratum é finito}.
Com sua método de diagonalização Cantor conseguiu algo maravilhoso:
contou todos dos \emph{racionais}, algo muito chocante, pois a maneira
que visualizamos esse conjunto é \emph{muito} mais populosa daquela
dos inteiros ou dos naturais.  Mas chega Cantor e nos ilumina:
\emph{o $\rats$ parece tão mais populoso porque tu não tá fazendo
essa dupla abstração, deixando a natureza e ordem te confundir!}
%%}}}

%%{{{ Gödel's stratification 
\note A stratificação de Gödel.
\label{Godel_stratification_of_pairs}%
\Godel[diagonalização]Gödel muitos anos depois preferiu uma
stratificação diferente:
$$
\tikzpicture
\tikzi pairs5x5nats;
\foreach \i in {0,...,4} {
    \node at (-1,-\i) {$S_{\i}$};
    \draw[rounded corners=2ex,->] (-.5,-\i) -- (\i,-\i) -- (\i,.5);
}
\node at (-1, -4.666) {$\vdots$};
\endtikzpicture
$$
Observe que aqui também cada stratum é finito, e logo serve para
contar todos os membros do conjunto.
%%}}}

%%{{{ x: define_both_stratifications_of_pairs 
\exercise.
\label{define_both_stratifications_of_pairs}%
Defina formalmante as stratificações de
Cantor~(\refn{Cantor_stratification_of_pairs}) e de
Gödel~(\refn{Godel_stratification_of_pairs}).
Observe que cada stratum, sendo finito, pode ser representado por um
conjunto (e não uma tupla) sem problema nenhum.
Defina curtamente então, usando a notação set-builder,
os $S_n$'s de ambas as stratificações.

\hint
$S_n = \setst {(x,y)} {\asklhole}$.

\endexercise
%%}}}

%%{{{ no_repetitions_implies_bijection 
\remark.
\label{no_repetitions_implies_bijection}%
Para corresponder numa bijecção mesmo, o jogo do~\refn{Smullyan_game}
tem que ser modificado, para proibir repetições do mesmo palpite.
Observamos que se o jogador tem uma estratégia para ganhar num jogo que
permite repetições de palpites, ele já pode adaptá-la para ganhar no
jogo com a restricção: ele apenas segue a estratégia do jogo ``livre''
e quando aparecem palpites que ele já adivinhou, ele pula para o próximo,
até chegar num palpite que ele não tentou ainda, para tentá-lo.
Por exemplo, para enumerar os racionais sabendo uma enumeração dos pares
de inteiros, copiamos a estratégia do $\ints^2$, pulando pares que ou não
correspondem em racionais (como o $(0,0)$ por exemplo), ou que são iguais
com palpites anteriores (como o $(2,4)$ que pulamos por causa do $(1,2)$
que já adivinhamos).
%%}}}

%%{{{ thm: countable_union_of_countables_is_countable 
\theorem.
Seja $\cal C$ uma colecção contável de conjuntos contáveis.
Logo $\Union \cal C$ é contável.
Em outras palavras: união contável de contáveis é contavel.
\sketch.
Seja $\seqn C n$ uma enumeração dos membros do $\cal C$:
$$
\align
\cal C &= \set{ C_0, C_1, C_2, \dotsc }.
\intertext{Sabemos que todos os $C_n$'s são contáveis; logo seja
$\sequence {c_n^i} i$ uma enumeração do $C_n$:}
C_0 &= \set {c_0^0, c_0^1, c_0^2, c_0^3, \dotsc } \\
C_1 &= \set {c_1^0, c_1^1, c_1^2, c_1^3, \dotsc } \\
C_2 &= \set {c_2^0, c_2^1, c_2^2, c_2^3, \dotsc } \\
    &\eqvdots 
\endalign
$$
e agora é óbvio como usar o primeiro argumento diagonal de Cantor
e obtenir uma enumeração do $\Union \cal C = \Union_{n=0}^{\infty} C_n$.
\qes
%%}}}

%%{{{ Are there uncountable sets? 
\note Tem incontáveis?.
Até este momento podemos sentir uns dos sentimentos de \Cantor{}Cantor
investigando essas infinidades.  Até talvez uma frustração, pois,
por enquanto, todos os conjuntos infinitos que testamos acabaram sendo
contáveis.  Será que todos são?  Os reais estão resistindo ainda,
mas antes de pensar no primeiro argumento diagonal, os racionais
também estavam!
Agora tu provaras que muitos mais conjuntos são realmente contáveis.
%%}}}

%%{{{ x: strings_from_finite_alphabet_countable 
\exercise.
\label{strings_from_finite_alphabet_countable}%

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Hacking intermission 
\problems Intervalo para hackear.

%%{{{ codeit: EnumPairs 
\codeit EnumPairs.
\label{program_enumpairs}%
Implemente uma estratégia para ganhar no jogo sem repetições com
conjunto-segredos o $\nats^2$.
Ou seja, escreva um programa que imprime (pra sempre) os palpites
do jogador na sua ordem.
\endcodeit
%%}}}

%%{{{ codeit: EnumRatsReps 
\codeit EnumRatsReps.
\label{program_enumrats}%
Modifique o EnumPairs para o caso com conjunto-segredos
o conjunto de racionais não-negativos, mas permitindo repetições.
Represente cada palpite como fracção,
imprimindo por exemplo o racional $\frac 1 3$ como o string
``{\tt 1/3}''.
\endcodeit
%%}}}

%%{{{ codeit: EnumRats 
\codeit EnumRats.
\label{program_enumratsnoreps}%
Modifique o EnumRats para o caso que o jogo proibe
repetições (mas para o mesmo conjunto $\rats_{\geq0}$).
Use teu código para responder na pergunta:
\emph{dada a escolha do inimigo, em qual dia o jogador vai adivinhá-la?}
\endcodeit
%%}}}

%%{{{ x: amnesiac_player 
\exercise Jogador amnésico.
\label{amnesiac_player}%
Ache uma estratégia para ganhar no jogo com conjunto-segredos o
conjunto dos racionais não-negativos, se o jogador tem memória que o
permite lembrar apenas seu último palpite!

\endexercise
%%}}}

%%{{{ x: nextPair 
\exercise.
\label{nextPair}%
Defina uma função 
$\namedop{nextPair} : \nats^2 \to \nats^2$
tal que para cada entrada $(n,m)$ ela retorna o próximo palpite do jogador
que acabou de tentar o $(n,m)$, no jogo com conjunto-segredos o $\nats^2$.
Considera que sua estratégia começa com o palpite $(0,0)$.
Assim, a enumeração representada por a estratégia do jogador seria a:
$$
(0,0), f(0,0), f^2(0,0), f^3(0,0), \dotsc,
$$
ou seja, a seqüência $\set{ f^n (0,0) }_{n}$.

\endexercise
%%}}}

%%{{{ codeit: NextPair 
\codeit NextPair.
\label{NextPair}%
Implemente função do~\ref{nextPair}.
\endcodeit
%%}}}

\endproblems
%%}}}

%%{{{ Cantor's second diagonal argument 
\section O segundo argumento diagonal de Cantor.

\blah.
Vamos finalmente atacar a cardinalidade dos reais, começando com seu
subconjunto $[0,1]\subset\reals$.
Vamos ver que realmente isso é um conjunto \dterm{incontável}.
Não tem como enumerar seus membros!
Como podemos provar isso?
Lembrando a definição, basta demonstrar que não existe enumeração
$$
[0,1] = \set{a_0, a_1, a_2, \dots}.
$$

%%{{{ A slightly wrong sketch 
\note Um esboço pouco errado.
Suponha que alguém chegou feliz pra ti, afirmando que conseguiu enumerar
todos os reais no $[0,1]$, a apresenta sua enumeração pra ti:
$$
a_0, a_1, a_2, a_3, \dots
$$
Tu pega sua lista e escreva a expansão decimal de cada número,
um número por linha; por exemplo:
$$
\def\u{\underline}
\def\b{\phantom0}
\matrix
\format
\r  &~~\c~~&     &\c    &\c     &\c     &\c     &\c     &\c     &\c   &\c \\
a_0 &=     &0\b. &\b 3  &\b 6   &\b 4   &\b 8   &\b 8   &\b 5   &\b 0 &\b \dots \\
a_1 &=     &0\b. &\b 2  &\b 1   &\b 8   &\b 9   &\b 8   &\b 0   &\b 5 &\b \dots \\
a_2 &=     &0\b. &\b 0  &\b 8   &\b 9   &\b 8   &\b 5   &\b 8   &\b 8 &\b \dots \\
a_3 &=     &0\b. &\b 9  &\b 2   &\b 6   &\b 6   &\b 8   &\b 6   &\b 6 &\b \dots \\
a_4 &=     &0\b. &\b 2  &\b 3   &\b 4   &\b 6   &\b 0   &\b 5   &\b 7 &\b \dots \\
    &\eqvdots&
\endmatrix
$$
Nosso objectivo é mostrar um certo número $w \in [0,1]$ que não está nessa lista.
Vamos definir esse $w$ construindo sua expansão decimal:
$$
\def\f{\faded}%
\def\b{\phantom0}%
\matrix
\format
\r  &~~\c~~ &     &\c    &\c    &\c    &\c    &\c    &\c    &\c    &\c \\
  w &\defeq &0\b. &\b\f? &\b\f? &\b\f? &\b\f? &\b\f? &\b\f? &\b\f? &\b\dots
\endmatrix
$$
E a idéia é a seguinte:
traversa a tabela acima diagonalmente, mudando o dígito,
construindo assim um novo número.
Os primeiros três passos aqui podem ser os seguintes:
$$
\def\n{}%
\def\u{\underline}%
\def\a{\alert}%
\def\f{\faded}%
\def\b{\phantom0}%
\xalignat3
&\matrix
\format
\r  &~~\c~~ &     &\c    &\c    &\c    &\c    &\c    &\c    &\c \\
  w &\defeq &0\b. &\b\a4 &\b\f? &\b\f? &\b\f? &\b\f? &\b\f? &\b\dots \\
a_0 &=      &0\b. &\b\a3 &\b\f6 &\b\f4 &\b\f8 &\b\f8 &\b\f5 &\b\dots \\
a_1 &=      &0\b. &\b\f2 &\b\u1 &\b\f8 &\b\f9 &\b\f8 &\b\f0 &\b\dots \\
a_2 &=      &0\b. &\b\f0 &\b\f8 &\b\u9 &\b\f8 &\b\f5 &\b\f8 &\b\dots \\
a_3 &=      &0\b. &\b\f9 &\b\f2 &\b\f6 &\b\u6 &\b\f8 &\b\f6 &\b\dots \\
a_4 &=      &0\b. &\b\f2 &\b\f3 &\b\f4 &\b\f6 &\b\u8 &\b\f5 &\b\dots \\
    &\eqvdots
\endmatrix
&
&\matrix
\format
\r  &~~\c~~ &     &\c    &\c    &\c    &\c    &\c    &\c    &\c\\
  w &\defeq &0\b. &\b\n4 &\b\a2 &\b\f? &\b\f? &\b\f? &\b\f? &\b\dots \\
a_0 &=      &0\b. &\b\u3 &\b\f6 &\b\f4 &\b\f8 &\b\f8 &\b\f5 &\b\dots \\
a_1 &=      &0\b. &\b\f2 &\b\a1 &\b\f8 &\b\f9 &\b\f8 &\b\f0 &\b\dots \\
a_2 &=      &0\b. &\b\f0 &\b\f8 &\b\u9 &\b\f8 &\b\f5 &\b\f8 &\b\dots \\
a_3 &=      &0\b. &\b\f9 &\b\f2 &\b\f6 &\b\u6 &\b\f8 &\b\f6 &\b\dots \\
a_4 &=      &0\b. &\b\f2 &\b\f3 &\b\f4 &\b\f6 &\b\u8 &\b\f5 &\b\dots \\
    &\eqvdots
\endmatrix
&
&\matrix
\format
\r  &~~\c~~ &     &\c    &\c    &\c    &\c    &\c    &\c    &\c\\
  w &\defeq &0\b. &\b\n4 &\b\n2 &\b\a0 &\b\f? &\b\f? &\b\f? &\b\dots \\
a_0 &=      &0\b. &\b\u3 &\b\f6 &\b\f4 &\b\f8 &\b\f8 &\b\f5 &\b\dots \\
a_1 &=      &0\b. &\b\f2 &\b\u1 &\b\f8 &\b\f9 &\b\f8 &\b\f0 &\b\dots \\
a_2 &=      &0\b. &\b\f0 &\b\f8 &\b\a9 &\b\f8 &\b\f5 &\b\f8 &\b\dots \\
a_3 &=      &0\b. &\b\f9 &\b\f2 &\b\f6 &\b\u6 &\b\f8 &\b\f6 &\b\dots \\
a_4 &=      &0\b. &\b\f2 &\b\f3 &\b\f4 &\b\f6 &\b\u8 &\b\f5 &\b\dots \\
    &\eqvdots
\endmatrix
\endxalignat
$$
onde para mudar cada dígito, eu fui para o ``próximo''.
Foi construido assim o
$$
\def\b{\phantom0}%
\matrix
\format
\r  &~~\c~~ &     &\c  &\c  &\c  &\c  &\c  &\c \\
  w &\defeq &0\b. &\b4 &\b2 &\b0 &\b7 &\b9 &\b\dots
\endmatrix
$$
que não está na lista $a_0, a_1, a_2, \dots$.
%%}}}

%%{{{ Q: why is w not in the list? 
\question.
Por que $w$ não está na lista?
%%}}}
\spoiler.

%%{{{ A 
\blah Resposta.
Realmente $w$ não pode ser nenhum dos $a_0,a_1,a_2,\dots$, ou seja,
vamos demonstrar que
$$
\text{para todo $i\in\nats$,}\quad
w \neq a_i.
$$
Seja $i\in \nats$ então.
Agora observe que o $w \neq a_i$ pois pela sua construção,
ele discorda com o $a_i$ no $i$-ésimo dígito.
Ele discorda com o $a_0$ na primeira posição, com o $a_1$
na segunda, etc.
%%}}}

%%{{{ x: why_cant_we_prove_that_rats_is_uncountable 
\exercise.
Por que não podemos usar o mesmo argumento para concluir que o $\setst{q \in \rats}{0\leq q\leq 1}$ também é incontável?

\hint
Como tu vai provar que o número construido pela método de Cantor realmente é um elemento de $\rats\inter[0,1]$?

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Cantor set 
\section O conjunto de Cantor.
\label{Cantor_set}%

%%{{{ Cantor set 
\note O conjunto de Cantor.
$$
\tikzpicture
\tikzi cantorset;
\endtikzpicture
$$
%%}}}

\endsection
%%}}}

%%{{{ Some important applications 
\section Umas aplicações importantes da teoria de Cantor.

%%{{{ corollary: irrats_uncountable 
\corollary.
\label{irrats_uncountable}%
Os irracionais são incontáveis.
\proof.
Os racionais são contáveis.  Os reais incontáveis.
Logo, os irracionais são incontáveis, pois
$\reals = \rats \union \paren{\reals\setminus\rats}$
e logo se $\reals\setminus\rats$ fosse contável teriamos
a contradição do $\reals$ ser contável também
(\ref{binary_union_of_countable_is_countable}).
\qed
%%}}}

%%{{{ And the transcendentals? 
\note E os transcendentais?.
Os transcendentais parecem ainda mais selvagens que os irracionais.
E neste momento temos poquíssimos exemplos: os números de \Liouville{}Liouville
que foram contruidos exatamente com esse propósito;
o $e$ que \Hermite{}Hermite acabou de provar que é
transcendental~(\yearof{1873}) e a transcendentalidade do $\pi$ demorou uns anos.
Como encontramos transcendentais tão raramente em comparação com os algébricos
faz sentido pensar que eles são contáveis.%
\footnote
{Na verdade, a única razão que temos nesse momento de acreditar
que o conjunto de transcendentais é infinito são os números Liouville:
ele realmente conseguiu contruir uma infinidade (incontável) de transcendentais.}
%%}}}

%%{{{ lemma: algebraics_are_countable 
\lemma.
\label{algebraics_are_countable}%
Os algébricos são contáveis.
\sketch.
Basta observar que $\polys\rats x \eqc \kstar\rats$, com a correspondência
$$
a_0 + a_1 x + a_2 x^2 + \dotsb + a_{n-1} x^{n-1} + a_n x^n
\leftrightarrow
\tupp{a_0, a_1, a_2, \dotsc, a_{n-1}, a_n}.
$$
Seja $f_0, f_1, f_2, \dotsc$ uma enumeração do $\polys\rats x$.
Stratificamos então os números algébricos onde o $i$-ésimo stratum é o
conjunto de todas as raízes reais de $f_i$:
$$
S_i = \setst {\alpha\in\reals} {f_i(\alpha) = 0}.
$$
Pelo teorema fundamental da Álgebra agora, sabemos que cada $f_i$
tem no máximo $\deg(f_i)$ raízes, ou seja, todos os strata
são finitos e pronto!
\qes
%%}}}

%%{{{ corollary: transcends_uncountable 
\corollary.
\label{transcends_uncountable}%
Os transcendentais são incontáveis.
\proof.
Como os algébricos são contáveis (\ref{algebraics_are_countable}),
os transcendentais são incontáveis com o mesmo argumento da demonstração
do~\ref{irrats_uncountable}.
\qed
%%}}}

%%{{{ Sky and stars 
\note Céu de estrelas.
Sem as descobertas de Cantor, alguém pensaria que isso
é uma coincidência muito grande e bizarra:
como aconteceu que a gente definiu um número bem importante
como o $\pi$ ou o $e$ e aconteceu que ele tem essa propriedade
estranha de ser transcendental?
Mas, graças ao Cantor, sabemos melhor:
\emph{de fato, seria bizarro se fosse o contrário!}
Pois sabemos agora que, na verdade, as excessões são os
algébricos e não os transcendentais.
O estranho seria descobrir que $e$ aconteceu que é racional!
Como piada considere o princípio seguinte:
%%}}}

%%{{{ joke: transcendentality_principle 
\joke Princípio de transcendentalidade.
Seja $x\in\reals$ com $x\neq0,1$.
Se $x$ é profundamente interessante em matemática,
então $x$ é transcendental.
%%}}}

%%{{{ Liouville vs Cantor 
\note Liouville vs Cantor.
\label{Liouville_vs_Cantor}%
É comum encontrar argumentos favorecendo o teorema de Liouville
contra o teorema de Cantor, sobre a existência de transcendentais.
Normalmente escutamos algo do tipo <<Liouville construiu e mostrou
transcendentais, Cantor apenas demonstrou que existem sem constriur
ou mostrar nenhum>>.
Essa afirmação é completamente errada!
%%}}}

%%{{{ x: cantor_proof_is_constructive 
\exercise.
\label{cantor_proof_is_constructive}%
Explique o porquê.

\endexercise
%%}}}

%%{{{ codeit: CantorCon 
\codeit CantorCon.
\label{CantorCon}%
Escreva um programa que compute irracionais e transcendentais.
Considere que teu usuário vai querer determinar quantos
números construir, e também até que precisão (quantos dígitos).
\endcodeit
%%}}}

\endsection
%%}}}

%%{{{ Looking for bijections 
\section Procurando bijecções.

\note.
Vamos ver como as transformações de esticar/encolher
(stretch/shrink) e de deslocar (shift) nos intervalos de reais,
sendo bijecções levam suas entradas para saídas equinúmeras.

%%{{{ x: (0,1) =c (0,2) 
\exercise.
Mostre as seguintes eqüinumerosidades entre os seguintes intervalos de reais:
\beginol
\li $(0,1) \eqc (0,2)$;
\li $(0,2) \eqc (3,5)$;
\li $[0,1) \eqc (0,1]$;
\li $(a,b) \eqc (c,d)$;
\li $[a,b) \eqc (c,d]$;
\li $[a,b) \eqc (c,d]$;
(onde $a < b$ e $c < d$);
\endol

\hint
Tente aproveitar que composição de bijecções é bijecção, quebrando assim cada
tarefa em tarefas menores e mais fáceis para resolver, tais que a composição
das resoluções delas, resultará na resolução da tua tarefa inicial.

\endexercise
%%}}}

%%{{{ x: (α,β) =c (0,1) 
\exercise.
Mostre as seguintes eqüinumerosidades entre os seguintes intervalos de reais,
$$
(\alpha,\beta) \eqc (0,1)
$$
onde $\alpha,\beta \in \reals\union\set{\minfty,\pinfty}$ com $\alpha < \beta$.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ The Cantor--Schröder--Bernstein theorem 
\section O teorema Cantor--Schröder--Bernstein.
\label{The_CSB_theorem}%

\blah.
Esse teorema que provamos aqui é conhecido como
``\Cantor{}Cantor--\Schroder{}Schröder--\Bernstein{}Bernstein''
ou ``Schröder--Bernstein'', mas vamos referir a ele nessas notas
apenas com o nome de Bernstein, pois foi o primeiro que demonstrou
sua veracidade numa forma correta.%
\footnote{E sua prova não precisou o
\emph{axioma da escolha}~(\refn{Axioms_of_choice}),
algo que vamos apreciar mais no~\ref{Axiomatic_set_theory}.}
Vamos começar atacando esse problema com uma abordagem amorosa,
de \Smullyan{}Smullyan (veja~\cite{smullyanbeginners}).

%%{{{ x: lovely approach 
\exercise Abordagem amorosa.
\label{schroder_bernstein_by_smullyan}%
Suponha que num universo seus habitantes são divididos em dois conjuntos \emph{infinitos}:
o conjunto $A$ de homens e $B$ de mulheres.
Suponha também que os seguintes são fatos sobre esse universo:
\beginol
\li Cada homem ama exatamente uma mulher.
\li Nenhuma mulher é amada por dois homens.
\li Cada mulher ama exatamente um homem.
\li Nenhum homem é amado por duas mulheres.
\endol
(Essas condições já deixam esse universo bem bizarro.)
Mostre que tem como casar todos os habitantes desse universo em casamentos monogâmicos e heterosexuais,
em tal modo que em cada casal é garantido amor (mas não necessariamente reciprocal), ou seja:
se $a\in A$ é casado com $b\in B$, \emph{pelo menos uma} das duas condições acontece:
$a$~ama~$b$; $b$~ama~$a$.

\hint
Escolhe uma pessoa $x \in A \union B$.  Independente se ela é homem ou mulher,
podemos a perguntar: \emph{<<quem te ama?>>}.
Duas possibilidades existem: ou ela é amada por algum $x_1 \in A \union B$,
ou ninguém ama $x$.  No primeiro caso perguntamos $x_1$ a mesma pergunta,
definindo assim o $x_2$, se $x_1$ é uma pessoa amada, etc.
Observerve que cada $x \in A \union B$ defina assim um \dterm{caminho amoroso}
$x, x_1, x_2, \dots$.  Esse caminho ou é infinito, ou termina num certo membro $x_n \in A\union B$.
Vamos agora separar todas as pessoas do $A\union B$ em três grupos:
$$
\align
G_A         &= \setstt {x \in A\union B} {o caminho amoroso de $x$ termina num membro de $A$}\\
G_B         &= \setstt {x \in A\union B} {o caminho amoroso de $x$ termina num membro de $B$}\\
G_\infty    &= \setstt {x \in A\union B} {o caminho amoroso de $x$ é infinito}
\endalign
$$
Tente casar todos os membros de cada um desse grupo entre si!

\endexercise
%%}}}

\blah.
Voltando dessa versão antropomórfica do problema, observe que
a condição (1) garanta a existência duma função $f : A \to B$,
que graças à (2) é injetora.
Similarmente, a condição (3) garanta a existência duma função
$g : B \to A$, que graças à (4) é injetora também.
Essas são as hipotéses do~\ref{schroder_bernstein}.
Observe também que se resolver o problema amoroso do~\ref{schroder_bernstein_by_smullyan}
tu já forneceu uma função \emph{bijetora} $F : A \to B$, definida pela
$$
F(x) = \text{a pessoa casada com $x$}.
$$
Vamos ver isso agora sem amor.

%%{{{ thm: schroder_bernstein 
\theorem Bernstein.
\Bernstein{}%
\label{schroder_bernstein}%
\ii{teorema}[Schröder--Bernstein]%
Sejam conjuntos $A$ e $B$ e funções injetoras
$f : A \injto B$ e $g : B \injto A$.
Então existe bijecção $\phi : A \bijto B$.
%%}}}

\endsection
%%}}}

%%{{{ Looking for injections 
\section Procurando injecções.

\blah.
Agora é \emph{bem} mais fácil provar o seguinte
e ganhar o corolário embaixo.
Sem \Bernstein{}Bernstein, precisamos resolver o~\ref{change_of_ends_of_intervals_without_bernstein}.

%%{{{ x: (a,b) \eqc (a,b] with Bernstein
\exercise.
\label{change_of_ends_of_intervals_with_bernstein}%
Usando o teorema de Schröder--Bernstein~\refn{schroder_bernstein}
prove que $(a,b) \eqc (a,b] \eqc [a,b]$.

\endexercise
%%}}}

\corollary.
Qualquer intervalo não-trivial (vazio ou singleton) de reais,
tem a mesma cardinalidade com o próprio $\reals$.

%%{{{ x: \reals \eqc \pset\nats with Bernstein
\exercise.
Usando o teorema de Schröder--Bernstein~\refn{schroder_bernstein}
prove que $\reals \eqc \pset\nats$.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Encodings 
\section Codificações.
\label{Encodings}%

%%{{{ Encodings 
\note Encodings.
Uma maneira de pensamento para construir injecções seria através
de codificações (ou \dterm{encodings}).
Uma \dterm{codificação} de $A$ no $B$ é qualquer injecção
de $A$ para $B$.
%%}}}

%%{{{ eg: rats_leqc_nats_encoding 
\example.
\label{rats_leqc_nats_encoding}%
Para provar que $\rats\leqc\nats$ basta achar uma maneira de
codificar cada racional como um natural.  Aqui um jeito fácil:
dado um racional $q\in \rats$ sejam $m,n$ tais que $q = m/n$
e $m/n$ irredutível; codificamos
$$
\align
m/n  &\mapsto 1\tunderbrace{00\cdots0}{$m$ vezes}1\tunderbrace{00\cdots0}{$n$ vezes}1.
\intertext{Assim,}
1/2  &\mapsto 101001 \\
10/6 = 5/3 &\mapsto 10000010001 \\
22/7 &\mapsto 10000000000000000000000100000001
\endalign
$$
etc.
Observe que para qualquer $n\in\nats$, existem dois casos:
ou ele serve como codificação para algum $q\in\rats$
(como o $101001$ acima) ou não (como o $1$, o $2$, o $1011$, etc.).
Caso que sim, podemos facilmente extrair a informação codificada
no $n$, voltando para o racional $q$:
$$
10001001 \leadsto 3/2.
$$
A mesma idéia serve para codificar o $\kstar\nats$:
\endexample
%%}}}

%%{{{ x: kstar_nats_leqc_nats_encoding 
\exercise.
\label{kstar_nats_leqc_nats_encoding}%
Prove usando codificação que $\kstar\nats \leqc \nats$.

\endexercise
%%}}}

%%{{{ x: pset_nats_leqc_zeroone_encoding 
\exercise.
\label{pset_nats_leqc_zeroone_encoding}%
Prove usando codificação que $\pset\nats \leqc [0,1)$.

\endexercise
%%}}}

%%{{{ x: zeroone_eqc_nats_to_nats_encoding 
\exercise.
\label{zeroone_eqc_nats_to_nats_encoding}%
Prove demonstrando duas codificações que $[0,1) \eqc (\nats\to\nats)$.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Cantor's theorem and its consequences 
\section O teorema de Cantor e suas conseqüências.
\label{Cantors_theorem_and_its_consequences}%

\blah.
Até agora temos encontrado apenas duas quantidades infinitas diferentes:
aquela do $\nats$, e aquela do $\reals$.
Essa situação está prestes a mudar drasticamente..

%%{{{ Cantor's theorem: what it says and first steps 
\note O teorema de Cantor.
Cantor provou que para todo conjunto $A$, seu powerset $\pset A$
tem cardinalidade estritamente maior que do $A$:
$$
A \ltc \pset A.
$$
Primeiramente observe que para conjuntos finitos já sabemos disso,
e é fácil provar:
$$
\card {\pset A} = 2^{\card A} > \card A
$$
pois para todo $n\in\nats$, realmente temos $2^n > n$.
Cantor conseguiu provar que $A \ltc \pset A$ para qualquer $A$.
Lembrando a definição de $\ltc$, precisamos provar duas coisas:
$$
A \leqc \pset A
\qqqquad
A \neqc \pset A.
$$
A primeira é fácil: faça agora!
%%}}}

%%{{{ x: A_leqc_pset_A 
\exercise.
\label{A_leqc_pset_A}%
Para todo conjunto $A$, $A \leqc \pset A$.

\hint
Seja $A$ conjunto e defina a $f : A \to \pset A$ pela
$$
f(x) = \set x.
$$
Prove que é injetora.

\solution
Seja $A$ conjunto.
Definimos a $f : a \injto \pset a$ pela
$$
f(x) = \set x.
$$
Facilmente ela é injetora (\ref{the_singletonizer_is_injective}).

\endexercise
%%}}}

%%{{{ proof idea with depressive members 
\note A linda idéia da sua prova.
Suponha que temos um conjunto $A$, e uma função $A \toby \pi \pset A$.
Vamos provar que a $\pi$ não pode ser sobrejetora---e logo, nem bijetora.
Para entender a idéia melhor, vamos desenhar um exemplo.
Imagina então que o $A$ parece como no desenho abaixo,
e seu powerset tá no seu lado, onde eu desenhei apenas uns dos
seus membros, pois o desenho ficaria bagunçado demais se eu tivesse
desenhado todos.  Mas todos estão lá mesmo: o $\pset A$, pela sua definição,
é o conjunto de \emph{todos} os subconjuntos de $A$.
$$
\tikzpicture
\draw (0,0) to[out=180,in=90] (-1,-1) to[out=270,in=270] (1,-1) to[out=90,in=0] cycle;
\node at (0,-.2) {$\bullet$};
\node at (-.9,-.9) {$\ast$};
\node at (.9,-.9) {$\star$};
\endtikzpicture
$$
A $\pi$ então mapeia cada membro de $A$ com um membro de $\pset A$.
Por exemplo, pode ser assim:
$$
\mathrm{desenho com $\pi$ aqui}
$$
Vamos dar um toque antropomórfico agora:
vamos considerar os membros de $A$ como pessoas, e a $\pi$
como uma função de \emph{amor}, que mapeia cada $x\in A$
para o conjunto de todas as pessoas que $x$ ama:
$$
\pi (x) = \setstt {y \in A} {$x$ ama $y$}.
$$
Lembre-se que nosso objectivo é achar um membro de $\pset A$
que não pertence na imagem da $\pi$.
Chame \dterm{depressivo} um $x \in A$ sse $x$ não se ama.
Ou seja,
$$
\text{$x$ é depressivo}
\defiff
x \notin \pi(x)
$$
pois $\pi(x)$ são todas as pessoas que $x$ ama.%
\footnote{Outros exemplos de definições razoáveis nessa interpretação
seriam chamar o $x$ \dterm{misántropo} se $\pi(x) = \emptyset$,
\dterm{egoista} se $\pi(x) = \set x$, etc.,
mas aqui só vamos precisar dos depressivos mesmo.}
Assim, cada $x\in A$ ou é depressivo, ou não.
Condiseramos o conjunto $D$ de todos os depressivos membros de $A$:
$$
D
\defeq \setstt {x \in A} {$x$ é depressivo}
= \setst {x \in A} {x \notin \pi(x)}.
$$
Observe que $D \subset A$, ou seja, $D$ é um membro do $\pset A$.
Esse $D$ é o testemunha que estamos procurando:
um membro do codomínio da $\pi$, garantido para não pertencer
na imagem $\img \pi A$.
Por quê?
Para chegar num abdurdo, suponha o contrário:
que para algum $d \in A$, temos $\pi(d) = D$.
Faz sentido agora perguntar:
\emph{esse $d$ é depressivo?}
Dois casos existem, e os dois chegam em absurdo:
\compute
\text{$d$ depressivo}
&\implies d \notin \pi(d)           \by {def.~depressivo}
&\implies d \notin D                \by {pela escolha de $d$}
&\implies \text{$d$ não depressivo} \by {def.~$D$}
&\implies \text{absurdo!}
\intertext{e no outro lado,}
\text{$d$ não depressivo}
&\implies d \in \pi(d)              \by {def.~depressivo}
&\implies d \in D                   \by {pela escolha de $d$}
&\implies \text{$d$ depressivo}     \by {def.~$D$}
&\implies \text{absurdo!}
\endcompute
Logo, para nenhum $d \in A$ temos $\pi(d) = D$,
ou seja, $D \notin \img \pi A$ e logo $\pi$ não é sobrejetora.
Em palavras antropomórficas, com essas definições
ninguém pode amar \emph{somente todos} os depressivos.
Note bem que em lugar nenhum usamos os desenhos do $A$
e da $\pi$ nessa prova.  Desenhei apenas para ilustrar.
Podemos então provar formalmente o teorema de Cantor,
sem nada depressivo!
%%}}}

%%{{{ thm: cantor_theorem 
\theorem Cantor.
\label{cantor_theorem}%
\Cantor[teorema]%
\ii{teorema}[Cantor]%
Seja $A$ conjunto.
Então $A\ltc \pset A$.
\proof.
Seguindo a definição de $\ltc$, precisamos provar duas coisas:
\crproofpart{{\proofname} de $A\leqc \pset A$.}
\ref{A_leqc_pset_A}.
\crproofpart{{\proofname} de $A\neqc \pset A$.}
Basta provar que não existe função sobrejetora de $A$ para $\pset A$.
Seja $\pi : A \to \pset A$.
Queremos provar que a $\pi$ não pode ser sobrejetora, ou seja,
mostrar um elemento $C$ do seu codomínio que não pertence na imagem da $\pi$
(ou seja: tal que $C \notin \img \pi A$).
Observe que para qualquer $x\in A$, temos $\pi(x)\in\pset A$,
ou seja $\pi(x) \subset A$.
Considere o conjunto
$$
D = \setst {x\in A} {x \notin \pi(x)}.
$$
Pela definição de $D$, temos $D \subset A$.
Ou seja, $D \in \pset A$, que é o codomínio da $\pi$.
Precisamos provar que para todo $x \in A$, $\pi(x) \neq D$.
Para chegar num absurdo, seja $d\in A$ tal que $\pi(d) = D$.
Agora nos perguntamos: $d\in\pi(d)$?
Como $\pi(d)=D$, a pergunta reduza em: $d\in D$?
Ambas as alternativas (\emph{sim} e \emph{não}) são impossíveis:
$$
d \in D
\iff
d \notin D
$$
pela definição de $D$ e pela escolha de $d$.
Absurdo!
Logo $\pi$ não mapeia nenhum membro de $A$ para o $D\in\pset A$,
ou seja, $\pi$ não é sobrejetora.
\qed
%%}}}

%%{{{ x: the_singletonizer_is_injective 
\exercise.
\label{the_singletonizer_is_injective}%
Prove em detalhe que a função $f$ definida na prova de~\ref{cantor_theorem}
realmente é injetora.

\endexercise
%%}}}

%%{{{ cor: infinitely_many_infinities 
\corollary.
\label{infinitely_many_infinities}%
Existe uma infinidade (contável) de cardinalidades infinitas:
$$
\nats
\ltc \pset\nats
\ltc \pset\pset\nats
\ltc \pset\pset\pset\nats
\ltc \pset\pset\pset\pset\nats
\ltc \dotsc
$$
%%}}}

%%{{{ cor: no_maximum_cardinality 
\corollary.
Não existe cardinalidade máxima:
para qualquer conjunto $M$, o conjunto $\pset M$ tem cardinalidade maior.
%%}}}

%%{{{ df: aleph_and_continuum 
\definition.
\label{aleph_and_continuum}%
\sdefined {\aleph_0} {a cardinalidade do $\nats$}%
\sdefined {\continuum} {a cardinalidade do $\pset\nats$ e do $\reals$}%
\tdefined{aleph 0}%
\tdefined{continuum}%
Denotamos a cardinalidade de $\nats$ por $\aleph_0$ (\dterm{aleph 0}),
e a cardinalidade de $\pset\nats\eqc\reals$ por $\continuum$.
Chamamos o $\continuum$ o \dterm{continuum}.
%%}}}

%%{{{ note: holes in the chain of cardinalities of powersets 
\note.
Considere os conjuntos
$$
\emptyset
\ltc \pset\emptyset
\ltc \pset\pset\emptyset
\ltc \pset\pset\pset\emptyset
\ltc \pset\pset\pset\pset\emptyset
\ltc \dotsb
$$
Observe que cada conjunto nessa seqüência (infinita) de conjuntos é finito.
Mas, quais são suas cardinalidades?
Calculamos:
$$
\align
\card{\emptyset}                     &= 0\\
\card{\pset\emptyset}                &= 1\\
\card{\pset\pset\emptyset}           &= 2\\
\card{\pset\pset\pset\emptyset}      &= 4\\
\card{\pset\pset\pset\pset\emptyset} &= 16\\
                                     &\eqvdots\\
\endalign
$$
Observamos que a seqüência dessas cardinalidades ``tem burácos''.
Por exemplo, nenhum desses conjuntos tem cardinalidade $3$,
mesmo que realmente tem conjuntos com essa cardinalidade
(por exemplo o $\finord 3=\set{0,1,2}$).
Ou seja, existe conjunto $C$ com
$$
\pset\pset\emptyset\ltc C\ltc \pset\pset\pset\emptyset.
$$
Similarmente achamos conjuntos ``estritamente entre'' os conjuntos que aparecem
depois nessa seqüência.
%%}}}

%%{{{ note: some questions arise 
\note.
Umas questões aparecem imediatamente:
\beginol
\li Será que tem conjuntos ``estritamente entre'' alguns dos conjuntos
infinitos da seqüência anterior?
\li Será que tem algum conjunto com cardinalidade maior que qualquer uma dessas
cardinalidades?
\li Será que tem algum conjunto incomparável com todos eles?
\li Até pior: tem conjuntos incomparáveis em cardinalidade?)
\endol
%%}}}

\endsection
%%}}}

%%{{{ The smallest infinities 
\section As menores infinidades.

\blah.
Então.  Já sabemos que tem uma quantidade infinita de infinidades
diferentes graças ao teorema de Cantor.
Já encontramos as cardinalidades dos primeiros beths
$$
\beth_0 < \beth_1 < \beth_2 < \beth_3 < \dotsb
$$
que são os nomes das cardinalidades dos conjuntos
$$
\nats \ltc \pset\nats \ltc \pset\pset\nats \ltc \pset\pset\pset\nats \ltc \dotsb
$$

%%{{{ The equinumerosities so far 
\note As eqüinumerosidades até agora.
Temos então provado as:
$$
\nats 
\eqc \ints
\eqc \rats
\eqc \algs
\eqc C\union C'
\eqc \Union_{n=0}^\infty {C_n}
\eqc C^n
\eqc \kstar C
$$
onde $C,C'$, etc.~denotam conjuntos contáveis.
E tambem temos:
$$
\gather
\Delta \eqc \cantorset \eqc \pset\nats \\
(\alpha,\beta) \eqc [\alpha,\beta) \eqc (\alpha,\beta] \eqc [\alpha,\beta] \eqc \reals.
\endgather
$$
onde $\alpha,\beta\in\reals\union\set{\minfty,\pinfty}$ tais que $\alpha<\beta$.
Como $\cantorset \subset [0,1]$ concluimos que
$$
\Delta \eqc \cantorset \eqc \pset\nats \leqc
(a,b) \eqc [a,b) \eqc (a,b] \eqc [a,b] \eqc (0,1) \eqc \reals.
$$
%%}}}

\endsection
%%}}}

%%{{{ Two big hypotheses 
\section Duas grandes hipoteses.
\label{Two_big_hypotheses}%

%%{{{ Cardinal comparability hypothesis 
\note A hipótese da comparabilidade de cardinais.
%%}}}

%%{{{ CCH 
\hypothesis.
\label{CCH}%
Para todo conjunto $A,B$, $A \leqc B$ ou $B \leqc A$.
%%}}}

%%{{{ The continuum hypothesis 
\note A hipótese do continuum.
%%}}}

%%{{{ CH 
\hypothesis CH.
\label{CH}%
Não existe subconjunto de reais com cardinalidade estritamente
entre as cardinalidades de $\nats$ e de $\reals$:
$$
\lforall {X \subset \reals} {X \leqc \nats \lor X \eqc \reals}.
$$
%%}}}

%%{{{ GCH 
\hypothesis GCH.
\label{GHC}%
Para todo conjunto infinito $A$, não existe conjunto com cardinalidade
estritamente entre as cardinalidades de $A$ e de $\pset A$.
$$
\lforall {A} {\text{$A$ infinite} \implies \lforall {X \subset \pset A} {X \leqc A \lor X \eqc \pset A}}.
$$
%%}}}

\endsection
%%}}}

%%{{{ Transfinite_numbers 
\section Os números transfinitos.
\label{Transfinite_numbers}%

%%{{{ ordinals_vs_cardinals 
\note Ordinais vs{.} cardinais.
\label{ordinals_vs_cardinals}%
Na língua natural temos os números \dterm{cardinais}
\quotepar
um, dois, três, quatro, cinco, \dots
\endquote
e os números \dterm{ordinais}
\quotepar
primeiro, segundo, terceiro, quarto, quinto, \dots
\endquote
\Cantor{}Cantor generalizou esses números finitos para os casos finitos,
que chamou de \dterm{números transfinitos} (veja \cite{cantortransfinite}).
Os cardinais representam \emph{quantidades} e os ordinais \emph{ordens}.
Abusando pouco a lingua, podemos dizer que o cardinal dum conjuno $A$
mostra \emph{quantos membros ele tem}, e o ordinal dum conjunto ordenado
$\ssetfont B$ \emph{mostra quão longo ele é}.
%%}}}

%%{{{ Transfinite arithmetic 
\note Aritmética transfinita.
Bem mais que isso, Cantor conseguiu definir e elaborar uma
\dterm{aritmética transfinita:}
definiu operações de adição, multiplicação, e exponenciação
nesses números e sua aritmética realmente---alem de ser
linda---é muito útil e interessante.
Nesse capítulo não vamos nos preocupar com isso---paciência até
o~\ref{Axiomatic_set_theory} (\refn{Cardinal_arithmetic})
e o~\ref{Ordinal_arithmetic} (todo!).
%%}}}

\endsection
%%}}}

%%{{{ A taste of measure theory 
\section Um toque de teoria de medida.

%%{{{ from sets to new theories 
\note.
Assim que \Cantor{}Cantor, \Dedekind{}Dedekind, e seus seguidores
desenvolveram essa primeira teoria de conjuntos, os matemáticos
da época ganharam uma ferramenta poderosa e útil que nos liberou
e guiou para desenvolvemento de bem mais teorias interessantes, como:
\emph{teoria de espaços métricos}, \emph{topologia geral},
e \emph{teoria da medida}.
Nesse texto vamos dedicar um capítulo para a primeira (\ref{Metric_spaces})
e um para a segunda (\ref{General_topology}),
e apenas uma secção (essa!)~para a terceira.
%%}}}

%%{{{ measure theory 
\note.
Vários matemáticos, principalmente \Borel{}Borel, \Baire{}Baire,
\Lebesgue{}Lebesgue, \Frechet{}Frechét, \Hausdorff{}Hausdorff,
desenvolveram a teoria de medida.
Podemos pensar em medida como uma generalização do comprimento dum intervalo
$(a,b)$ de reais, em tal jeito que podemos atribuir um ``comprimento''
(ou seja, \dterm{medir}) conjuntos bem mais complicados que intervalos,
e equivalentemente para dimensões maiores, generalizando assim as idéias
de área, volúme, etc.
Isso nos leva para uma \emph{teoria de integração} bem mais poderosa que
a primeira que encontramos (integral \Riemann{}Riemann), e também serve
como base para fundar a \emph{teoria de probabilidade}, graças ao
\Kolmogorov{}Kolmogorov (\yearof{1933}, \cite{kolmogorovprob}).
Nosso interesse aquí tem a ver com probabilidade mesmo, pois queremos
responder na pergunta seguinte.
%%}}}

%%{{{ Q: pick a random number from [0,1]; what is the probablity that... 
\question.
Escolhemos \emph{aleatoriamente} um número real $a\in[0,1]$.
Qual a probabilidade de $a$ ser\dots
(i) o número $1/2$?
(ii) um número real no $(a,b)$ com $0\leq a<b \leq 1$?
(iii) um número racional?
(iv) um número algébrico?
%%}}}

%%{{{ warning: tends_to_warning 
\warning <<Tende ao>>.
\label{tends_to_warning}%
É um erro comum afirmar certas coisas sobre probabilidades,
números, funções, limites, etc., especialmente usando frases
como a \emph{<<tende ao>>}, então vou deixar certas coisas claras
aqui antes de começar nosso pequeno estudo.
\endgraf
{(1)}
A probabilidade dum evento especifico acontecer, se é definida, é um
número real no $[0,1]$.
E números não mexem.
Números não tendem a lugar nenhum.
Números ficam quetinhos nos seus lugares.
\endgraf
{(2)}
O limite duma função também não tende a lugar nenhum.
Se é definido, é apenas um número real;
talvez \emph{estendido} para incluir os $\pminfty$~(\ref{extended_reals}).
Por exemplo, temos
$$
\lim_{x\to\pinfty} 1/x = 0.
$$
Tá vendo essa igualdade aí?
Esse limite é o número zero.
O limite \emph{não tende ao} zero.
O limite \emph{é o próprio} zero!
Podemos sim dizer (corretamente) que
\emph{a expressão $1/x$ tende ao 0 quando $x$ tende ao $\pinfty$}.
%%}}}

\endsection
%%}}}

%%{{{ Consequences in computability and definability 
\section Conseqüências em computabilidade e definabilidade.

%%{{{ Aristos vs Blammenos 
\note Áristos vs Blammenos.
\label{Aristos_vs_Blammenos}%
\endgraf\noindent
\centerline{\scshape Cena 1.}
\centerline{\it Segunda-feira, madrugada.}
\centerline{\it Dois amigos, Áristos e Blammenos,}
\centerline{\it estão estudando para a prova de Fundamentos Matemáticos.}
\centerline{\it Eles estão tentando resolver o problema seguinte:}
\standout
\emph{<<O conjunto $P$ de todos os programas de tipo
$\Nat\to\Nat$ é contável?>>}
\endstandout
\dialogue
\who {Áristos}
O conjunto $P$ é contável, e aqui minha prova:
o conjunto $S$ de todos os strings feitos por um alfabeto finíto
é contável, e todos os programas possíveis correspondem em apenas
um subconjunto próprio de $S$ (pois todo programa é um string,
mas tem strings que não são programas).
Logo, o $P$ é contável.
\who {Blammenos}
Então tu tá afirmando que existe enumeração do $P$?
Eu vou chegar num absurdo com essa hipótese.
Suponha $p_0, p_1, p_2, \dotsc$ uma enumeração de $P$.
Eu defino o programa $p_*$ com o algoritmo bem simples:
$$
p_*(n) = p_n(n) + 1.
$$
Agora temos $p_* \notin P$, pois para todo $n\in\nats$, $p_* \neq p_n$.
\who {Á}
Por quê?
\who {B}
Seja $n\in\nats$.
Eu vou lhe mostrar que $p_* \neq p_n$.
Calculamos
\compute
p_*(n)
&= p_n(n) + 1   \by {pela def.~$p_*$}
&\neq p_n(n)
\endcompute
que mostra que $p_* \neq p_n$.
Ou seja, $p_*$ não é nenhum dos $p_0, p_1, \dotsc$
que a gente supôs que esses são todos os membros do $P$.
Cheguei assim num absurdo, logo $P$ é incontáv---
\who {Á}
Peraí, tu tá roubando!
Como teu programa usou essa enumeração $p_0, p_1, \dotsc$?
Se tu tivesse um algoritmo (programa) que gera essa
seqüência, tu teria razão.
\who {B}
Hmmm\dots\ \ 
Mas é fácil programar esse algoritmo!
Concordas que podemos gerar facilmente todos os strings no $S$?
\who {Á}
Sim, esse programa que gera os strings, a gente já encontrou na aula.
\who {B}
Bem, então meu algoritmo é o seguinte:
gere todos os strings $s_0, s_1, s_2, \dotsc \in S$,
mas para cada string que não é um programa, pula para o próximo.
Esse programa gera sim a seqüência $p_0, p_1, p_2, \dotsc$
de todos os programas!
\who {Á}
Pqp, faz sentido!
Não consigo achar um erro na tua prova, mas nem na minha!
\who {B}
Eu também não consigo achar um erro na tua prova!
\enddialogue
%%}}}

%%{{{ Q: Who is right? 
\question.
Um conjunto não pode ser contável e incontável,
então pelo menos um dos dois alunos tá errado.
Quais são o(s) erro(s)?
Seguindo as suas idéias o que podemos concluir mesmo?
%%}}}
\spoiler.

%%{{{ A 
\blah Resposta.
O Blammenos tá errado.
O problema é que seu programa em algum momento tem que decidir se um string aleatório é um programa válido, e ainda mais, se termina ou não para alguma dada entrada.
Também não podemos chamar a
$$
p_*(n) \neq p_n(n)
$$
verdadeira para todo $n \oftype \Nat$,
pois existe a possibilidade de algum programa não terminar.
Nesse caso os dois lados são $\bot$ (``bottom'').
Podemos então concluir que é impossível criar tal programa!
%%}}}

\TODO Quantos programas?. 

\TODO Quantas funções?.

\TODO Gödel numbers e lista de todos os programas.

\endsection
%%}}}

%%{{{ Problems 
\problems.

%%{{{ prob: a_letter_from_cantor_to_dedekind 
\problem Uma carta de Cantor para Dedekind.
\label{a_letter_from_cantor_to_dedekind}%
\Cantor{}Cantor definiu a função $f : (0,1)^2 \to (0,1)$ pela
$$
f(a, b)
= 0.a_1b_1a_2b_2a_3b_3\dotsc
\qtext{onde}
\leftbrace{
\aligned
a &\eqass 0.a_1a_2a_3\dotsc\\
b &\eqass 0.b_1b_2b_3\dotsc
\endaligned
}
$$
são as expansões decimais \emph{que não terminam em 9's repetidos}.
Afirmando que ela é bijetora, mandou sua idéia para Dedekind,
como uma prova de $(0,1)^2 \eqc (0,1)$.
\Dedekind{}Dedekind percebeu um erro na carta de Cantor.
(1) Por que Cantor botou a restricção <<que não terminam em $9$'s repetidos>>?
(2) Qual o erro de Cantor?

\hint
(1) Precisamos disso para que $f$ seja bem-definida (por quê?).
(2) A $f$ não é bijetora!  (Por quê?)

\solution
(1) Precisamos disso para que $f$ seja bem-definida.
Sem essa restricção, para onde $f$ manda o $\tup{1/2,1/3}$?
O $1/3$ realmente \emph{determina} os $b_j$'s, mas o $1/2$
não determina os $a_i$'s pois:
$$
0.4999\dots = 1/2 = 0.5000\dots
$$
e logo a $f$ não seria bem-definida sem essa restricção.
\endgraf\noindent
(2) A $f$ não é bijetora!
Basta só criar um exemplo que sua preimagem seria um número que
termina em $999\dots$:
$$
f( ? ) = 0.4393939393\dots
$$
Nenhuma entrada $(a,b)$ pode ser mapeada nesse número, pois pela
definição da $f$ o $b$ só pode ser o $0.333\dots = 1/3$
(e nenhum problema com isso), mas o $a$ deve ser o $0.4999\dots$.
Ou seja $a=1/2$.  Mas
$$
f(\frac 1 2,\frac 1 3) = 0.53030303 \neq 0.439393\dots
$$
e logo $f$ não é sobrejetora!

\endproblem
%%}}}

%%{{{ prob: change_of_ends_of_intervals_without_bernstein 
\problem Sem Bernstein.
\label{change_of_ends_of_intervals_without_bernstein}%
Mostre pela definição a eqüinumerosidade
$$
(a,b) \eqc [a,b) \eqc [a,b];
$$
onde $a,b \in \reals$ e tais que os intervalos não são
nem vazios nem singletons.

\hint
Aqui duas maneiras diferentes para o $(a,b) \eqc [a,b)$:
(i) demonstre $[0,\pinfty) \eqc (\minfty,\pinfty)$;
(ii) demonstre $(0,1] \eqc (0,1)$.

\hint
Seguindo a idéia (i) da primeira dica:
lembre como provamos que $\nats\eqc\ints$;
e seguindo a idéia (ii):
faz sentido mandar o $1$ para o $1/2$; e o $1/2$?

\hint
Seguindo a idéia (i):
$\reals = \Union_n [n,n+1)$.
Seguindo a idéia (ii):
defina uma função $f : (0,1] \eqc (0,1)$ por casos:
$$
f(x) =
\knuthcases{
\askhole & se \asklhole \cr
\askhole & caso contrário
}
$$
tal que
$$
\align
1    &\mapstoby f 1/2 \\
1/2  &\mapstoby f \askhole \\
     &\eqvdots \\
\askhole  &\mapstoby f \askhole
\endalign
$$

\endproblem
%%}}}

%%{{{ prob: sime_simo_eqclass_card 
\problem.
\label{sime_simo_eqclass_card}%
\def\sime{\rel{\stackrel{{}_{\mathrmsmall e}}=}}%
\def\simo{\rel{\stackrel{{}_{\mathrmsmall o}}=}}%
No $(\nats\to\nats)$ sejam as relações $\sime$ e $\simo$ como no~\ref{simz_sime_simo_simi}:
$$
\align
f\sime g&\defiff f(2n)   = g(2n)  \ \text{para todo $n\in\nats$}\\
f\simo g&\defiff f(2k+1) = g(2k+1)\ \text{para todo $k\in\nats$}.
\endalign
$$
Qual é a cardinalidade do $\eqclass f {\sime} \inter \eqclass f {\simo}$?

\endproblem
%%}}}

%%{{{ prob: define three eqrels such that quosets have certain cards 
\problem.
No conjunto dos reais $\reals$, defina três relações de equivalência
$\sim_1$, $\sim_2$, $\sim_3$, diferentes da igualdade $\eqof \reals$,
da vazia, e da trivial $\mathsf{True}$, tais que:
$$
\xalignat3
\quoset \reals {\sim_1} &\ltc \nats &
\quoset \reals {\sim_2} &\eqc \nats &
\quoset \reals {\sim_3} &\gtc \nats.
\endxalignat
$$
Para cada uma, descreva seu conjunto quociente.

\hint
Cada relação de equivalência corresponde numa partição e vice-versa,
então basta definir três partições.

\solution
Cada relação de equivalência corresponde numa partição e vice-versa,
então descrevemos as três partições diretamente:
$$
\align
\scr C_1 &= \set   {(\minfty,0), \set{0}, (0,\pinfty)} \\
\scr C_2 &= \setst {[n,n+1)} {n\in\ints} \\
\scr C_3 &= \setst {\set{a}} {a\in\reals\setminus\rats} \union \set{\rats}.
\endalign
$$
Sem usar partições poderiamos definir as relações diretamente assim:
$$
\align
x \sim_1 y &\defiff \text{$x=y$ ou $xy>0$} \\
x \sim_2 y &\defiff \floor x = \floor y \\
x \sim_3 y &\defiff \text{$x = y$ ou $x,y\in\rats$}.
\endalign
$$

\endproblem
%%}}}

%%{{{ codeit: RatApprox 
\codeit RatApprox.
\label{RatApprox}%
Usando uma implementação de enumeração $\set{q_n}_n$ do $\rats$
(com ou sem repetições), implemente uma função
$a : \reals\times\reals \to \nats$ que, dados $x\in\reals$ e $\epsilon>0$
retorna o primeiro $n\in\nats$ com a propriedade $\abs{q_n - x} < \epsilon$:
$$
a(x,\epsilon) = \min\setst{n\in\nats}{\abs{q_n-x}<\epsilon}.
$$
\endgraf
Se tua linguagem de programação suporta funções de ordem superior,
considere que seu primeiro argumento deve ser a própria enumeração $q$:
$$
\align
\namedfun{ratApprox} &\eqtype (\nats\to\rats) \to \reals \to \reals \to \nats\\
\namedfun{ratApprox}\ q\ x\ \epsilon &= \min\setst{n\in\nats}{\abs{q_n-x}<\epsilon}
\endalign 
$$
Alternativamente, pode representar uma enumeração de racionais
como uma lista (infinita) de racionais.  Considere retornar o
primeiro racional suficientemente próximo alem de apenas seu
índice.  Improvise e teste sua função, vendo quanto ``demora''
uma enumeração para chegar suficientemente perto de um número
pre-determinado, sendo racional ou não.
Por exemplo, use $x=\sqrt 2$ ou $e$ ou $\pi$,
e
$\epsilon=1, 1/2, 1/4, \dotsc$.
Assim, para qualquer real $x$, tu pode
\emph{construir}---mesmo não muito ``eficientemente''---uma
seqüência de racionais que converge em $x$, apenas aplicando a função
$\lambda \epsilon. \namedfun{ratApprox}\ q\ x\ \epsilon$
em argumentos que formam qualquer seqüência que convirja no zero!
\endcodeit
%%}}}

%%{{{ df: terminating_game 
\definition Jogo terminante.
\label{terminating_game}%
\tdefined{jogo}[terminante]%
Consideramos jogos entre 2 jogadores.
Chamamos um jogo \dterm{terminante} sse não tem partidas infinitas.
Ou seja, seguindo suas regras cada partida termina depois um finíto número de turnos.
%%}}}

%%{{{ df: hypergame 
\definition Hypergame (Zwicker).
\label{hypergame}%
\tdefined{hypergame}%
{\Zwicker[hypergame]}%
Considere o jogo seguinte $\cal H$, chamado \dterm{hypergame}:
O $\cal H$ começa com o {\scshape Player~I} que escolha um jogo terminante $G$.
O {\scshape Player~II} começa jogar o jogo $G$ contra o {\scshape Player~I}.
Quem ganha nesse jogo $G$ é o vencedor do jogo $\cal H$.
%%}}}

%%{{{ eg: hypergame_plays 
\example.
\label{hypergame_plays}%
Por exemplo, sendo um bom jogador de ``jogo da velha'' e um pessimo jogador
de xadrez, se eu for o {\scshape Player~I} num hypergame, meu primeiro
movimento seria escolher o jogo terminante ``jogo da velha'' para jogar.
Meu oponente, se for o {\scshape Player~I} duma partida de hypergame,
seu primeiro movimento seria escolher o jogo terminante ``xadrez''.
Depois desse movimento eu viro o {\scshape Player~I} no xadrez.
Quem vai ganhar nesse xadrez, vai ser o vencidor dessa partida de hypergame.
\endexample
%%}}}

%%{{{ hypergame_paradox 
\note O paradoxo de hypergame.
\label{hypergame_paradox}%
{\def\P{\text{\tt P}}
\def\O{\text{\tt O}}
Zwicker\Zwicker[hypergame]{} percebeu o seguinte paradoxo, se perguntando
se o próprio Hypergame é um jogo terminante ou não.
Claramente tem que ser, pois a primeira regra do jogo obriga o {\scshape Player~I}
escolher um jogo terminante.  Logo, depois de $n\in\nats$ turnos, esse jogo
termina, e junto com ele termina a partida do hypergame (em $n+1$ turnos).
Então hypergame é terminante.
Logo, numa partida de hypergame, o {\scshape Player~I} pode escolher o próprio
hypergame.  Assim começamos uma sub-partida de hypergame, onde o
{\scshape Player~II} toma o papel de {\scshape Player~I}.
Se ele escolher, por exemplo, ``jogo de velha'', a partida parece assim:
$$
\def\drawTTTboard{%
\draw (-1, 3)     -- (-1,-3);
\draw ( 1, 3)     -- ( 1,-3);
\draw (-3, 1)     -- ( 3, 1);
\draw (-3,-1)     -- ( 3,-1);
}
\align
\P:\quad& \hbox{Escolho ``Hypergame''}\\
\O:\quad& \hbox{Escolho ``Jogo de velha''}\\
\P:\quad&
\gathered
\tikzpicture[scale=0.15]
\drawTTTboard
\draw (-0.7,-0.7) -- (0.7, 0.7);
\draw (-0.7, 0.7) -- (0.7,-0.7);
\endtikzpicture
\endgathered\\
\phantom{\P}\vdots\quad&\vdots\\
\O:\quad&
\gathered
\tikzpicture[scale=0.15]
\drawTTTboard
\draw (-0.7,-0.7) -- ( 0.7, 0.7);
\draw (-0.7, 0.7) -- ( 0.7,-0.7);
\draw (-2.7,-0.7) -- (-1.3, 0.7);
\draw (-2.7, 0.7) -- (-1.3,-0.7);
\draw (2,2)  circle (0.7);
\draw (0,-2) circle (0.7);
\endtikzpicture
\endgathered\\
\P:\quad&
\gathered
\tikzpicture[scale=0.15]
\drawTTTboard
% X-moves
\draw (-0.7,-0.7) -- ( 0.7, 0.7);
\draw (-0.7, 0.7) -- ( 0.7,-0.7);
\draw (-2.7,-0.7) -- (-1.3, 0.7);
\draw (-2.7, 0.7) -- (-1.3,-0.7);
\draw ( 1.3,-0.7) -- ( 2.7, 0.7);
\draw ( 1.3, 0.7) -- ( 2.7,-0.7);
% O-moves
\draw (2,2)  circle (0.7);
\draw (0,-2) circle (0.7);
% draw winning line
\draw (-2.7, 0.0) -- ( 2.7, 0.0);
\endtikzpicture
\endgathered\\
\endalign
$$
Onde denotamos os dois jogadores com $\P$ e $\O$ (de ``Player'' e ``Opponent'').
Mas, agora a partida seguinte é possível:
$$
\align
\P:\quad& \hbox{Escolho ``Hypergame''}\\
\O:\quad& \hbox{Escolho ``Hypergame''}\\
\P:\quad& \hbox{Escolho ``Hypergame''}\\
\O:\quad& \hbox{Escolho ``Hypergame''}\\
\phantom{\P}\vdots\quad&\vdots
\endalign
$$
e achamos uma partida infinita do hypergame!
Logo o hypergame não é terminante.
}
%%}}}

%%{{{ prob: from_hypergame_to_cantors_theorem 
\problem.
\label{from_hypergame_to_cantors_theorem}%
Seja conjunto $A$ e suponha que existe injecção $\phi : A \injto \pset A$.
Para todo $x\in A$, denota com $A_x$ o $\phi(x)$, ou seja, $A_x$
é o subconjunto de $A$ associado com o $x$.
Seja $a\in A$.  Chame um \dterm{caminho} de $a$ qualquer seqüência
finita ou infinita $\set{a_i}_i$ de elementos de $A$ que satisfaz:
$$
\align
a_0     &= a\\
a_{n+1} &\in A_{a_n}.
\endalign
$$
Finalmente, chame um $a\in A$ \dterm{terminante} se todos os caminhos
de $a$ são finítos.  Use o paradoxo do Hypergame para provar que
a $\phi$ não pode ser sobrejetora, achando assim uma nova prova
do teorema de Cantor~\refn{cantor_theorem}.

\hint
Seja $T \subset A$ o conjunto de todos os terminantes elementos de $A$.
Basta provar que $T\notin \img \phi A$, ou seja, que para todo $x\in A$,
$A_x \neq T$, provando assim que $\phi$ não é bijetora.

\hint
Suponha para chegar num absurdo que $T=A_a$ para algum $a\in A$.

\hint
$T = \emptyset$?

\solution
Seja $T \subset A$ o conjunto de todos os terminantes elementos de $A$.
Basta provar que $T\notin \img \phi A$, ou seja, que para todo $x\in A$,
$A_x \neq T$, provando assim que $\phi$ não é bijetora.
Suponha para chegar num absurdo que $T\in \img\phi A$ e logo seja
$a \in A$ tal que $T=A_a$\fact1.
Observe que $T\neq\emptyset$, pois se fosse vazio o $a$ seria terminante
e logo pertenceria ao $T$; absurdo.
Vamos provar que qualquer caminho de $a$ é terminante.
Seja $\alpha$ um caminho de $a$:
$$
\alpha = \paren{\alpha_0, \alpha_1, \alpha_2, \dotsc}
$$
Logo $\alpha_1 \in A_{\alpha_0} = A_a = T$,
ou seja $\alpha_1$ é terminante,
e logo o caminho $\paren{\alpha_1, \alpha_2, \dotsc}$ é finito!
Logo o $\paren{\alpha_0,\alpha_1,\alpha_2,\dotsc}$ também é.
Mostramos então que o arbitrário caminho de $a$ é finito;
ou seja, todos são; ou seja, $a$ é terminante\fact2~e logo
$a \in T$\fact3.
Mas aqui um caminho infinito de $a$:
$$
\align
a_0 &\asseq a \\
a_1 &\asseq a \\
a_2 &\asseq a \\
a_3 &\asseq a \\
    &\eqvdots
\endalign
$$
ou seja, o caminho seguinte:
$$
\paren{a,a,a,\dotsc}
$$
Isso realmente é um caminho de $a$ pois pelos~\byfact1~e~\byfact3,
$a \in A_a$ e logo substituindo iguais por iguais,
$$
\mubrace {a_{n+1}} {a} \in A_{\mubrace {a_n} {a}}.
$$
Concluimos então que $a$ não é terminante, contradizendo o~\byfact2.
Chegamos assim num absurdo, e logo nossa hipótese que
$T \in \img \phi A$ não é válida, ou seja, $T \notin \img \phi A$
e logo $\phi$ não é sobrejetora.

\endproblem
%%}}}

%%{{{ prob: weird_convex_now_easy 
\problem Agora é fácil.
\label{weird_convex_now_easy}%
Para resolver o~\ref{weird_convex_hard} demonstramos um certo
``buraco'' que o $Q_1$ tem: o $(0,0)$.
Tem outro(s)?  Quantos?

\hint
Considere a diámetro horizontal $\setst {(x,0)} {-1 < x < 1}$.

\endproblem
%%}}}

%%{{{ thm: von_Lindemann_theorem 
\theorem von Lindemann.
\label{von_Lindemann_theorem}%
Para todo $\alpha\neq0$ algébrico, $e^\alpha$ é transcendental.
%%}}}

%%{{{ prob: pi_is_transcendental 
\problem.
\label{pi_is_transcendental}%
Dado o teorema de~\vonLindemann{}von~Lindemann~\refn{von_Lindemann_theorem}
demonstre que $\pi$ é transcendental.

\hint
Se $\pi$ fosse algébrico, $i\pi$ também seria.

\endproblem
%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\blah Sobre a teoria de conjuntos de Cantor.
\cite{kleeneIM},
\cite{ynmnst}.
Um livro muito divertido que trata bem essas idéias de infinito
que encontramos aqui é o \cite[Part~VI]{satancantorinfinity}.

\blah Sobre teoria da medida.
\cite{bartlemeasure},
\cite{halmosmeasure},
\cite{taylorintegration}.

\blah Sobre os passos que levaram Cantor nas suas descobertas.
\cite{srivastavacantor}.
Mais sobre a construtividade e os ataques injustos contra a
demonstração de Cantor no~\cite{grayaboutcantor}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Posets; Lattices; Boolean algebras 
\chapter Posets; Reticulados; Álgebras booleanas.
\label{Posets}%
\label{Lattices}%
\label{Boolean_algebras}%

%%{{{ Concept, notation, properties 
\section Conceito, notação, propriedades.

\TODO Conceito.

%%{{{ df: poset 
\definition poset.
\label{poset}%
\tdefined{poset}%
Chamamos o conjunto estruturado $\cal P = \sset P \leq$
um \dterm{poset} (ou conjunto parcialmente ordenado),
sse $\leq$ é uma relação de ordem parcial:
$$
\gather
x \leq x\\
x \leq y \mland y \leq z \implies x \leq z\\
x \leq y \mland y \leq x \implies x = y
\endgather
$$
%%}}}

%%{{{ Notational abuse 
\note Abusos notacionais.
Extendemos o ``tipo'' do predicado $\dhole\leq\dhole$ de elementos de $P$
para elementos e/ou subconjuntos de $P$, definindo:
$$
\align
a \leq Y &\defiff a \leq y, \quad\text{para todo $y\in Y$};\\
X \leq b &\defiff x \leq b, \quad\text{para todo $x\in X$};\\
X \leq Y &\defiff x \leq y, \quad\text{para todo $x\in X$ e $y\in Y$}.
\endalign
$$
%%}}}

\blah.
Nas definições seguintes nosso contexto é um poset $\sset P \leq$.

%%{{{ df: incomparable 
\definition.
\label{incomparable}%
\tdefined{incomparável}%
Se $x \nleq y$ e $y \nleq x$ chamamos $x$ e $y$ \dterm{incomparáveis}.
Denotamos assim:
$$
x \incomp y \defiff x \nleq y \mland y \nleq x.
$$
%%}}}

%%{{{ df: chain_antichain 
\definition.
\label{chain_antichain}%
\tdefined{cadeia}%
\tdefined{anticadeia}%
Seja $X\subset P$.
Chamamos o $X$ uma \dterm{cadeia} sse todos os seus elementos são comparáveis.
No caso oposto, onde todos são comparáveis apenas com eles mesmo,
chamamos o $X$ \dterm{anticadeia}.  Simbolicamente:
$$
\align
\text{cadeia:}\quad&       x, y \in X  \implies  x \leq y \mlor y\leq x;\\
\text{anticadeia:}\quad&   x, y \in X  \mland x \leq y \implies x = y.
\endalign
$$
%%}}}

%%{{{ df: covby 
\definition.
\label{covby}%
\tdefined{cobertura}%
\sdefined {\sholed x \covby \sholed y} {o $x$ é coberto por o $y$}%
Se $x\leq y$ e não existe nenhum $z$ estritamente entre os $x$ e $y$
falamos que $y$ \dterm{cobre} o $x$.  Simbolicamente:
$$
x\covby y \defiff x \leq y \mland \lnot\exists z (x < z < y).
$$
%%}}}

%%{{{ Diagramas Hasse 
\note Diagramas Hasse.
\tdefined{Hasse}[diagrama]%
Já encontramos diagramas \Hasse{}Hasse no \ref{Group_theory}
(\refn{hasse_diagrams_first_encounter},
\refn{hasse_dih_3}, \refn{hasse_dih_4})
onde desenhamos os Hasse duns posets de subgrupos.
%%}}}

\beware.
Diagramas Hasse podem aparecer bastante diferentes mesmo
sendo do mesmo poset.

%%{{{ eg: cube_and_not_so_cube 
\example.
\label{cube_and_not_so_cube}%
Aqui duas formas de desenhar diagramas Hasse para o
$\sset{\pset\set{0,1,2}}{\subset}$:
$$
\xalignat2
&\tikzpicture
\node (max) at (0,4)  {$\set{0,1,2}$};
\node (a)   at (-2,2) {$\set{0,1}$};
\node (b)   at (0,2)  {$\set{0,2}$};
\node (c)   at (2,2)  {$\set{1,2}$};
\node (d)   at (-2,0) {$\set 0$};
\node (e)   at (0,0)  {$\set 1$};
\node (f)   at (2,0)  {$\set 2$};
\node (min) at (0,-2) {$\emptyset$};
\draw (min) -- (d) -- (a) -- (max) -- (b) -- (f)
(e) -- (min) -- (f) -- (c) -- (max)
(d) -- (b);
\draw[preaction={draw=white, -,line width=6pt}] (a) -- (e) -- (c);
\endtikzpicture
&
&\tikzpicture
\node (max) at (0,4)       {$\set{0,1,2}$};
\node (a)   at (-2,2.666)  {$\set{1,2}$};
\node (b)   at (0,2.666)   {$\set{0,2}$};
\node (c)   at (2,2.666)   {$\set{0,1}$};
\node (d)   at (-2,-0.666) {$\set 0$};
\node (e)   at (0,-0.666)  {$\set 1$};
\node (f)   at (2,-0.666)  {$\set 2$};
\node (min) at (0,-2)      {$\emptyset$};
\draw (min) -- (d) -- (c) -- (max) -- (a) -- (f) -- (min);
\draw (min) -- (e);
\draw (max) -- (b);
\draw (a) -- (e) -- (c);
\draw (d) -- (b) -- (f);
\endtikzpicture
\endxalignat
$$
Esse poset é chamado cubo por motivos óbvios se olhar
na seu primeiro diagrama, e não-tão-óbvios olhando para o segundo!
\endexample
%%}}}

%%{{{ df: min_max 
\definition.
\label{min_max}%
\tdefined{mínimo}%
\tdefined{máximo}%
\sdefined {\min {\sholed A}} {o mínimo de $A$}%
\sdefined {\max {\sholed A}} {o máximo de $A$}%
Seja $A\subset P$.
Chamamos o $m$ o \dterm{mínimo} de $A$ sse $m\leq a$ para todo $a\in A$.
\emph{Dualmente} chamamos o $m\in A$ o \dterm{máximo} de $A$ sse $a\leq m$ para todo $a\in A$.
Denotamos o mínimo de $A$, se existe, por $\min A$ e seu máximo, se existe, por $\max A$.
\mistake
%%}}}

%%{{{ x: uniqueness_of_min_max 
\exercise.
\label{uniqueness_of_min_max}%
Qual o erro na definição acima?
Ache-o e corrija-o.

\endexercise
%%}}}

%%{{{ df: bottom_top 
\definition.
\label{bottom_top}%
\label{zero_one_in_poset}%
\label{zero_one}%
\label{bounded_poset}%
\tdefined{bottom}%
\tdefined{top}%
\tdefined{zero}[dum poset]%
\tdefined{one}[dum poset]%
\tdefined{bounded}[por cima]%
\tdefined{bounded}[por baixo]%
\sdefined {\bot_{\sholed P}} {o bottom (o mínimo elemento dum poset)}%
\sdefined {\top_{\sholed P}} {o top (o máximo elemento dum poset)}%
\sdefined {0_{\sholed P}} {o zero (o mínimo elemento dum poset)}%
\sdefined {1_{\sholed P}} {o um (o máximo elemento dum poset)}%
Se o próprio $P\subset P$ possui elemento
mínimo, chamamos-o o \dterm{bottom} de $P$,
e se possui
máximo, chamamos-o o \dterm{top} de $P$.
Usamos as notações $\bot_P$ e $\top_P$ respectivamente,
esquecendo o $_P$ quando é implícito pelo contexto.
Sinônimos de bottom e top são os \dterm{zero} e \dterm{um} respectivamente,
usando as notações $0_P$ e $1_P$.
Se um poset possui bottom, ele é chamado \dterm{bounded por baixo},
e se ele possui top, ele é chamado \dterm{bounded por cima}.
Caso que seja bounded por cima e por baixo, chamamos-o apenas
\dterm{bounded}.
%%}}}

%%{{{ df: minimal_maximal 
\definition.
\label{minimal_maximal}%
\tdefined{minimal}%
\tdefined{maximal}%
Chamamos o $x$ um elemento \dterm{minimal} de $P$
sse nenhum elemento está embaixo dele, e, \emph{dualmente}
chamamos o $x$ \dterm{maximal} de $P$ sse nenhum elemento
está acima dele.  Simbolicamente:
$$
\align
\text{$x$ minimal de $P$}&\defiff  \lforall {y \in P} {y \leq x \implies x = y};\\
\text{$x$ maximal de $P$}&\defiff  \lforall {y \in P} {x \leq y \implies x = y}.
\endalign
$$
%%}}}

%%{{{ df: ubs_lbs 
\definition.
\label{ubs_lbs}%
\tdefined{upper bound}%
\tdefined{lower bound}%
\sdefined {\ubs {\sholed A}} {o conjunto dos upper bounds de $A$}%
\sdefined {\lbs {\sholed A}} {o conjunto dos lower bounds de $A$}%
Sejam $A\subset P$ e $m\in P$.
O $m$ é um \dterm{upper bound} de $A$ sse $x \leq m$ para todo $x\in A$.
Dualmente, o $m$ é um \dterm{lower bound} de $A$ sse $m \leq x$ para todo $x \in A$.
Usamos a notação
$$
\align
\ubs A &\defeq \setstt {m\in P} {$m$ é um upper bound de $A$}\\
\lbs A &\defeq \setstt {m\in P} {$m$ é um lower bound de $A$}.
\endalign
$$
%%}}}

%%{{{ eg: ubs_lbs_in_reals_example 
\example.
\label{ubs_lbs_in_reals_example}%
No $\reals$, considere seu subconjunto $(1,2]$.
Uns upper bounds dele são os reais $2, 5, \sqrt{12}, 8000$.
No outro ladom uns lower bounds dele são os $-400, -\pi, 0, 1/2, 0.8, 1$.
\endexample
%%}}}

%%{{{ df: lub_glb 
\definition.
\label{lub_glb}%
\tdefined{greatest lower bound}%
\tdefined{least upper bound}%
\tdefined{supremum}%
\tdefined{infimum}%
\sdefined {\sup{\sholed A}} {o supremum de $A$}%
\sdefined {\inf{\sholed A}} {o infimum de $A$}%
\sdefined {\lub{\sholed A}} {o least upper bound de $A$}%
\sdefined {\glb{\sholed A}} {o greatest lower bound de $A$}%
\sdefined {\Join{\sholed A}} {o join de $A$}%
\sdefined {\Meet{\sholed A}} {o meet de $A$}%
Se os $\ubs A$ e $\lbs A$ tem elemento mínimo e máximo respectivamente,
definimos
$$
\align
\lub A &\defeq \min\ubs A\\
\glb A &\defeq \max\lbs A.
\endalign
$$
Naturalmente chamamos o $\lub A$ o \dterm{least upper bound} de $A$,
e o $\glb A$ o \dterm{greatest lower bound} de $A$.
Usamos \emph{muitos} sinônimos, resumidos aqui:
$$
\xalignat3
\sup A &\ \text{(supremum)}   & \lub A &\ \text{(least upper bound)}    & \Join A &\ \text{(join)}\\
\inf A &\ \text{(infimum)}    & \glb A &\ \text{(greatest lower bound)} & \Meet A &\ \text{(meet)}
\endxalignat
$$
%%}}}

%%{{{ eg: inf_and_sup_of_openclosed_interval 
\example.
\label{inf_and_sup_of_openclosed_interval}%
O $A=(1,2]$ do~\ref{ubs_lbs_in_reals_example} tem
$\inf A = 1$ e $\sup A = 2$.
Observe que $\sup A \in A$ mas $\inf A \notin A$.
\endexample
%%}}}

%%{{{ x: when_glb_and_lub_is_min_and_max 
\exercise.
\label{when_glb_and_lub_is_min_and_max}%
O que podemos concluir quando $\glb A \in A$ e quando $\lub A \in A$?

\endexercise
%%}}}

%%{{{ df: downset_upset_downs  
\definition.
\label{downset_upset_downs}%
\tdefined{downset}%
\tdefined{upset}%
\sdefined {\downs{\sholed P}} {o conjunto de downsets de $P$}%
Chamamos o $A\subset P$ um \dterm{downset} no $P$
sse o $A$ é ``fechado para baixo'', e \emph{dualmente},
o chamamos \dterm{upset} sse ele é ``fechado para cima''.
Formalmente,
$$
\align
\text{$A$ downset} &\defiff {a \in A \mland x \leq a \implies x\in A};\\
\text{$A$ upset}   &\defiff {a \in A \mland a \leq x \implies x\in A}.
\endalign
$$
Dado um poset $P$, usamos $\downs P$ para denotar o conjunto de todos os seus
downsets.  Simbolicamente,
$$
\downs P \defeq \set{ D \subset P \st \text{$D$ é um downset de $P$} }.
$$
%%}}}

%%{{{ df: down_up 
\definition.
\label{down_up}%
\sdefined {\down {\sholed a}} {o down de $a$}%
\sdefined {\up {\sholed a}} {o up de $a$}%
Definimos para qualquer $a\in P$ os conjuntos
$$
\align
\down a &\defeq \setst {x \in P} {x \leq a}\\
\up a   &\defeq \setst {x \in P} {a \leq x}
\intertext{e generalizamos essas operações de elementos $a\in P$ para subconjuntos $A\subset P$ assim:}
\down A &\defeq \setstt {x \in P} {$x \leq a$ para algum $a \in A$}\\
\up A   &\defeq \setstt {x \in P} {$a \leq x$ para algum $a \in A$}.
\endalign
$$
Observe que $\down x = \down{\set x}$ e $\up x = \up{\set x}$.
Diretamente pelas definições também temos:
$$
\xalignat2
\down A &= \Union_{a\in A} {\down a}&
\up A &= \Union_{a\in A} {\up a}
\endxalignat
$$
%%}}}

%%{{{ x: down_is_downset_up_is_upset 
\exercise.
\label{down_is_downset_up_is_upset}%
Sejam $P$ poset e $A \in P$.
Prove que $\down A$ é um downset e $\up A$ um upset.

\endexercise
%%}}}

%%{{{ x: equivalent_statements_to_x_leq_y 
\exercise.
\label{equivalent_statements_to_x_leq_y}%
Sejam $P$ um poset, $x,y\in P$.
Prove que as afirmações
\beginil
\item{(i)}   $x \leq y$;
\item{(ii)}  $\down x \subset \down y$;
\item{(iii)} para todo downset $D$ de $P$ com $y \in D$, temos $x\in D$.
\endil
são equivalentes.

\solution
Vamos provar usando um caminho ``round-robin'':
\crtabproofpart{$\textrm{(i)}\Rightarrow\textrm{(ii)}$.}
Seja $a \in \down x$.  Logo $a \leq x$, e como $x\leq y$ (hipótese),
pela transitividade da $\leq$ temos $a \leq y$.  Logo $a\in \down y$.
Ou seja, $\down x \subset \down y$.
\crtabproofpart{$\textrm{(ii)}\Rightarrow\textrm{(iii)}$.}
Seja $D$ downset de $P$ com $y \in D$.
Logo $\down y \subset D$.
Pela hipótese $\down x \subset \down y$ e logo $\down x \subset D$.
Como $x \in \down x$, então $x \in D$.
\crtabproofpart{$\textrm{(iii)}\Rightarrow\textrm{(i)}$.}
Observe que $\down y$ é um downset tal que $y$ pertence nele.
Logo $x \in \down y$ (pela hipótese).
Logo $x \leq y$ (pela def.~de $\down y$).

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Operations and constructions 
\section Operações e construções.

%TODO (Construções de conjutos ordenados)
%TODO (Dualidade)
%TODO (Ordens canônicas, ordens lexicográficas)

\endsection
%%}}}

%%{{{ Mappings 
\section Mapeamentos.

%%{{{ df: monotone_embedding_isomorphism 
\definition.
\label{monotone_embedding_isomorphism}%
\tdefined{monótona}%
\tdefined{order-embedding}%
\tdefined{order-isomorfismo}%
\tdefined{isomorfismo}[de ordem]%
Sejam $\sset P {\leq_P}$ e $\sset Q {\leq_Q}$ posets
e $\phi : P \to Q$.
Definimos
$$
\align
\text{$\phi$ monótona}
&\defiff x\leq_P y \implies \phi(x) \leq_Q \phi(y)\\
\text{$\phi$ order-embedding}
&\defiff \text{$\phi$ injetora} \mland x\leq_P y \iff \phi(x) \leq_Q \phi(y)\\
\text{$\phi$ order-isomorfismo}
&\defiff \text{$\phi$ bijetora} \mland x\leq_P y \iff \phi(x) \leq_Q \phi(y)
\endalign
$$
%%}}}

%%{{{ criterion: order_embedding_criterion 
\criterion.
\label{order_embedding_criterion}%
Se $\phi : P \to Q$ tal que
$$
x \leq_P y \iff \phi(x) \leq_Q \phi(y)
$$
então $\phi$ é um order-embedding.
Segue que se $\phi$ é sobrejetora, ela é um order-isomorfismo.
\proof.
Basta provar que $\phi$ é injetora.
Tome $x,y \in P$.
Temos
\compute
\phi(x) = \phi(y)
&\implies \phi(x) \leq_Q \phi(y) \mland \phi(y) \leq_Q \phi(x)  \by {\ref{converse_of_antisymmetry}}
&\implies x \leq_P y \mland y \leq_P x                          \by {pela hipótese}
&\implies x = y.                                                \by {transitividade}
\endcompute
\qed
%%}}}

%%{{{ x: converse_of_antisymmetry 
\exercise Converso de antisimetria.
\label{converse_of_antisymmetry}%
Justifique o primeiro passo (a primeira implicação) na prova do~\ref{order_embedding_criterion}.

\endexercise
%%}}}

%%{{{ x: downsets_of_poset_iso_downsets_of_dual 
\exercise.
\label{downsets_of_poset_iso_downsets_of_dual}%
Defina um $\phi : \downsets P \iso \downsets { \dual P }$.

\solution
$\phi(X) = P\setminus X$

\endexercise
%%}}}

%%{{{ x: downsets_of_disjunion_iso_product_of_downsets 
\exercise.
\label{downsets_of_disjunion_iso_product_of_downsets}%
Defina um
$\psi : \downsets { P_1 \disjunion P_2 } \iso \downsets {P_1} \times \downsets {P_2}$.

\solution
$\psi(D) = \tup{ D \inter P_1, D \inter P_2 }$

\endexercise
%%}}}

%%{{{ x: posets_of_divisors 
\exercise.
\label{posets_of_divisors}%
Para $n\in\nats$, definimos o poset
${\cal D}_n \defeq \sset {D_n} {\divides}$
onde $D_n \defeq \set{ d \in \nats \st d \divides n }$.
\item{(i)}
Desenha o diagrama Hasse de ${\cal D}_{30}$.
\item{(ii)}
Ache conjunto $A$ tal que ${\cal D}_{30} \iso \sset {\pset A} {\subset}$
e defina um isomorfismo $\phi : D_{30} \to \pset A$.
\item{(iii)}
Existe conjunto $B$ tal que ${\cal D}_0 \iso \sset {\pset B} {\subset}$?
Se sim, ache o $B$ e defina um isomorfismo
$\phi : D_0 \to {\pset B}$;
se não, prove que é impossível.

\solution%%{{{
\noindent (i)
Primeiramente calculamos: $D_{30} = \set{1, 2, 3, 5, 6, 10, 15, 30}$.
$$
\tikzpicture
\node (max) at (0,4)  {$30$};
\node (a)   at (-2,2) {$6$};
\node (b)   at (0,2)  {$10$};
\node (c)   at (2,2)  {$15$};
\node (d)   at (-2,0) {$2$};
\node (e)   at (0,0)  {$3$};
\node (f)   at (2,0)  {$5$};
\node (min) at (0,-2) {$1$};
\draw (min) -- (d) -- (a) -- (max) -- (b) -- (f)
(e) -- (min) -- (f) -- (c) -- (max)
(d) -- (b);
\draw[preaction={draw=white, -,line width=6pt}] (a) -- (e) -- (c);
\endtikzpicture
$$
\endgraf
\noindent (ii)
Tome o $A = \set{2,3,5}$ e defina a função $\phi : \pset A \to D_{30}$
pelas equações:
$$
\align
\phi(30) &= A\\
\phi(15) &= \set{3,5}\\
\phi(10) &= \set{2,5}\\
\phi(6)  &= \set{2,3}\\
\phi(2)  &= \set{2}\\
\phi(3)  &= \set{3}\\
\phi(5)  &= \set{5}\\
\phi(1)  &= \emptyset
\endalign
$$
Seu diagrama Hasse parece assim:
$$
\tikzpicture
\node (max) at (0,4)  {$\set{2,3,5}$};
\node (a)   at (-2,2) {$\set{2,3}$};
\node (b)   at (0,2)  {$\set{2,5}$};
\node (c)   at (2,2)  {$\set{3,5}$};
\node (d)   at (-2,0) {$\set 2$};
\node (e)   at (0,0)  {$\set 3$};
\node (f)   at (2,0)  {$\set 5$};
\node (min) at (0,-2) {$\emptyset$};
\draw (min) -- (d) -- (a) -- (max) -- (b) -- (f)
(e) -- (min) -- (f) -- (c) -- (max)
(d) -- (b);
\draw[preaction={draw=white, -,line width=6pt}] (a) -- (e) -- (c);
\endtikzpicture
$$
\noindent
Obs: qualquer conjunto $A$ com $|A|=3$ serve!
Uma avantagem desse é que podemos bem elegantemente definir a bijecção
inversa, mandando cada subconjunto de $\set{2,3,5}$ para seu produtório!
\endgraf
\noindent (iii)
Não existe, pois $D_0 = \nats$ (contável)
e logo não pode ser equinúmero com o powerset de nenhum conjunto $B$.
\endgraf
\noindent (iv)
Verdade, a função $\phi : D_0 \to \set{D_n \st n\in \nats}$ definida pela
$$
\phi(n) = D_n
$$
é um isomorfismo, pois:
$$
n \divides m \iff D_n \subset D_m.
$$
%%}}}

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Lattices as posets 
\section Reticulados como posets.

%%{{{ df: lattice_as_poset 
\definition.
\label{lattice_as_poset}%
\tdefined{lattice}[como poset]%
\iisee{lattice}{reticulado}
Um poset $\cal L = \sset L {\leq}$
é um \dterm{lattice} (ou \dterm{reticulado}) sse 
para todo $x,y \in L$, os $\sup\set{x,y}$ e $\inf\set{x,y}$
existem.
%%}}}

\endsection
%%}}}

%%{{{ Lattices as algebraic structures 
\section Reticulados como estruturas algébricas.

\blah.
No~\ref{Algebraic_structures} introduzimos reticulados
como uma estrutura algébrica.%
\footnote{Leia a~\ref{Lattices_as_algebras} se não tá ligado.}
Aqui a definição novamente:

%%{{{ df: lattice_as_algebra_human 
\definition.
\label{lattice_as_algebra_human}%
\tdefined{lattice}[como algebra]%
Seja $\cal L = \sset L {\join, \meet}$ conjunto estruturado
onde $\join,\meet$ são operadores binários no $L$.
Chamamos o $L$ um \dterm{lattice} (ou \dterm{reticulado}) sse
as operações $\join,\meet$ são associativas, comutativas,
e idempotentes, e satisfazem as leis seguintes \emph{de absorção}:
$$
\align
a \join (b \meet a) &= a\\
a \meet (b \join a) &= a
\endalign
$$
%%}}}

\endsection
%%}}}

%%{{{ Complete lattices 
\section Reticulados completos.

%%{{{ df: complete_lattice 
\definition.
\label{complete_lattice}%
Um reticulado $L$ é um \dterm{reticulado completo} sse
para todo $S\subset L$ ambos os $\Join S$ e $\Meet S$ são definidos.
%%}}}

%%{{{ x: every_complete_lattice_is_bounded 
\exercise.
\label{every_complete_lattice_is_bounded}%
Todo reticulado completo é bounded.

\endexercise
%%}}}

%%{{{ remark: what do we gain in a complete lattice 
\remark.
Já provamos que num reticulado $L$ os joins e meets existem para qualquer
subconjunto \emph{não vazio e finito} dele.
Então num reticulado \emph{completo}, sabemos disso para o vazio
e para os subconjuntos infinitos também.
%%}}}

\TODO generalize o~\ref{set_limits} para qualquer reticulado completo.

\endsection
%%}}}

%%{{{ Fixpoints 
\section Fixpoints.

%%{{{ df: fixpoint 
\definition fixpoint.
\tdefined{fixpoint}%
\tdefined{fixpoint}[least]%
\tdefined{fixpoint}[greatest]%
\sdefined {\fixpoints {\sholed f}} {o conjunto dos fixpoints de $f$}%
\sdefined {\lfp {\sholed f}} {o menor fixpoint de $f$}%
\sdefined {\gfp {\sholed f}} {o maior fixpoint de $f$}%
Seja $f : X \to X$.
Chamamos o $x_0\in X$ um \dterm{fixpoint} de $f$ sse
$f(x_0) = x_0$.
Usamos a notação
$$
\fixpoints f
\defeq
\setstt { x \in \dom f } {$x$ é um fixpoint de $f$}
$$
e se $X$ é um poset e $\fixpoints F$ tem mínimo e máximo botamos
$$
\alignat2
\lfp f &\defeq \min(\fixpoints f)  \called {o \dterm{menor fixpoint} de $f$}
\gfp f &\defeq \max(\fixpoints f). \called {o \dterm{maior fixpoint} de $f$}
\endalignat
$$
%%}}}

%%{{{ df: prefixpoint_postfixpoint 
\definition prefixpoints, postfixpoints.
\label{prefixpoint_postfixpoint}%
\tdefined{prefixpoint}%
\tdefined{postfixpoint}%
Sejam $P$ poset e $F : P \to P$ e seja $p \in P$.
Chamamos o $p$ de \dterm{prefixpoint da $F$}
sse $Fp \leq p$.  Dualmente $p$ é um \dterm{postfixpoint da $F$}
sse $p \leq Fp$.
%%}}}

%%{{{ thm: knaster_tarski_fixpoint 
\theorem Knaster--Tarski.
\label{knaster_tarski_fixpoint}%
\Knaster{}\Tarski{}%
\ii{teorema}[Knaster--Tarski fixpoint]%
Seja $L$ reticulado completo e $F : L \to L$ monótona.
Então $F$ tem um fixpoint.
\sketch.
Sejam
$$
\xalignat2
D &\asseq \setst { x \in L } { x \leq Fx } &
U &\asseq \setst { x \in L } { Fx \leq x }.
\endxalignat
$$
os conjuntos de todos os postfixpoints e prefixpoints
da $F$ respecitivamente.
Considere o conjunto $\fixpoints F$.
Observe que $\fixpoints F = D \inter U$.
Vamos provar que o $\Join D$ é um fixpoint de $F$.
(O $\Meet U$ é similar.)
Precisamos $\Join D = F(\Join D)$.
Vamos provar $\Join D \leq F(\Join D)$ primeiro
e depois $F(\Join D) \leq \Join D$.
\proofpart{$\Join D \leq F(\Join D)$:}
Como $\Join D$ é o least upper bound de $D$,
basta provar $F(\Join D)$ é um upper bound de $D$.
\proofpart{$F(\Join D) \leq \Join D$:}
Aqui como $\Join D$ é um upper bound de $D$,
basta mostrar que $F(\Join D)$ é um membro de $D$.
(Nessa parte podemos e vamos usar a $\Join D \leq F(\Join D)$
que acabamos de provar!)
\qes
\proof.
Seja
$D \asseq \setst { x \in L } { x \leq Fx }$.
Vamos provar que $\Join D$ é um fixpoint de $F$,
ou seja $F(\Join D) = \Join D$.
Quebramos a prova em duas partes:
\proofpart{$\Join D \leq F(\Join D)$:}
Basta mostrar que $F(\Join D)$ é um upper bound de $D$.
Tome $d \in D$.
Logo $d \leq Fd$\fact1~(pela definição de $D$)
e também $d \leq \Join D$\fact2,
pois $\Join D$ é um upper bound de $D$.
Como $F$ é monótona, da \byfact2~ganhamos
$Fd \leq F(\Join D)$\fact3.
Juntando (transitividade) as \byfact1~e~\byfact3:
$$
d \leq Fd \leq F(\Join D)
$$
ou seja, $d \leq F(\Join D)$ e como $d$ foi arbitrário elemento de $D$,
concluimos que $F(\Join D)$ é um upper bound de $D$.
Logo $\Join D \leq F(\Join D)$.
\proofpart{$F(\Join D) \leq \Join D$:}
Basta provar que $F(\Join D) \in D$, pois $\Join D$ é um upper bound de $D$.
Como já provamos que $\Join D \leq F(\Join D)$, ganhamos a
$F(\Join D) \leq F(F(\Join D))$ (pela monotonicidade da $F$).
Ou seja, o $F(\Join D)$ satisfaz a definição de $D$, e logo pertence nele:
$F(\Join D) \in D$.
Como $\Join D$ é um upper bound de $D$, temos $F(\Join D) \leq \Join D$.
\qed
%%}}}

%%{{{ remark: the full Knaster--Tarski theorem 
\remark.
O teorema Knaster--Tarski fala que ainda mais é verdade:
o $\fixpoints F\subset L$ é um reticulado completo
(\ref{knaster_tarski_fixpoint_full}).
%%}}}

\TODO explicar e desenhar.

%%{{{ cor: real_f_monotone_on_closed_interval_has_lfp_and_gfp 
\corollary.
\label{real_f_monotone_on_closed_interval_has_lfp_and_gfp}%
Sejam $a,b\in\reals$ com $a\leq b$,
e função $f : [a,b] \to [a,b]$ monótona.
Logo $f$ tem um máximo e um mínimo fixpoint.
%%}}}

%%{{{ remark: we do not need f to be continuous 
\remark.
Observe que no~\ref{real_f_monotone_on_closed_interval_has_lfp_and_gfp}
não precisamos da $f$ ser continua.
%%}}}

%%{{{ note: a new proof of Schröder--Bernstein 
\note Uma nova prova de Schröder--Bernstein.
Ganhamos também como corolário o teorema Schröder--Bernstein
(\refn{schroder_bernstein})!
Os detalhes estão no~\ref{schroder_bernstein_lattice_proof}.
%%}}}

\endsection
%%}}}

%%{{{ Irreducible elements 
\section Elementos irredutíveis.

\endsection
%%}}}

%%{{{ Boolean algebras 
\section Álgebras booleanas.

\Boole{}

\endsection
%%}}}

%%{{{ Heyting algebras 
\section Álgebras Heyting.

\Heyting{}

\endsection
%%}}}

%%{{{ Categories_and_posets 
\section Pouco de cats---categorias e posets.
\label{Categories_and_posets}%

\endsection
%%}}}

%%{{{ Problems 
\problems.

%%{{{ x: rats_is_dense 
\problem.
\label{rats_is_dense}%
Prove que o $\rats$ com sua ordem padrão é denso.

\endproblem
%%}}}

%%{{{ df: cofinito_em_nats 
\definition.
\label{cofinito_em_nats}%
\tdefined{cofinito}%
Chamamos um $A\subset \nats$ \dterm{cofinito} sse
seu complemento $\nats\setminus A$ é finito.
%%}}}

%%{{{ prob: family_of_cofinite_lattice 
\problem.
\label{family_of_cofinite_lattice}%
\tdefined{reticulado}[de conjuntos]%
Mostre que as famílias
$$
\align
\scr L_1 &\asseq \set{ A \subset \nats \st \text{$A$ é cofinito} }\\
\scr L_2 &\asseq \set{ A \subset \nats \st \text{$A$ é finito ou cofinito} }
\endalign
$$
são \dterm{reticulados de conjuntos}, ou seja,
reticulados com relação de ordem $\subset$.

\solution
\proofpartstyle{Sobre o $\scr L_1$.}
Sejam $A, B \in \scr L_1$.
Pela definição então $\nats\setminus A$ e $\nats\setminus B$ são finitos.
Vou mostrar que $A\union B$ e $A\inter B$ são cofinitos, e logo pertencem ao
$\scr L_1$ também.
Calculamos 
$$
\align
\nats\setminus(A\union B) &=\paren{\nats\setminus A} \inter \paren{\nats\setminus B}\\
\nats\setminus(A\inter B) &=\paren{\nats\setminus A} \union \paren{\nats\setminus B},
\endalign
$$
logo os dois conjuntos no lado esquerdo são finitos como intersecção e união de
finitos respectivamente.
\endgraf
\proofpartstyle{Sobre o $\scr L_2$.}
Sejam $A, B \in \scr L_2$.
Separamos em casos:
\endgraf
\case{Caso ambos finitos:}
Facilmente $A\union B$ e $A \inter B$ são finitos também,
como intersecção e união de conjuntos finitos.
Logo ambos pertencem ao $\scr L_2$.
\endgraf
\case{Caso ambos cofinitos:}
Provamos isso na demonstração sobre o $\scr L_1$.
\endgraf
\case{Caso contrário:}
Temos um dos $A,B$ finito e o outro cofinito.
Sem perda de generalidade, suponha que $A$ finito, $B$ cofinito.
O $A\inter B$ é trivialmente finito como intersecção de finito com qualquer conjunto.
Logo $A\inter B \in \scr L_2$.
O $A\union B$ é cofinito, pois
$$
\nats\setminus(A \union B) = \paren{\nats\setminus A} \inter \paren{\nats\setminus B}
$$
que é finito para o mesmo motivo (intersecção com o $\nats\setminus B$ que é finito).
Logo $A\union B \in \scr L_2$.

\endproblem
%%}}}

%%{{{ prob: family_of_cofinite_not_complete_lattice 
\problem.
\label{family_of_cofinite_not_complete_lattice}%
Mostre que nenhum dos $\scr L_1,\scr L_2$ do~\ref{family_of_cofinite_lattice}
é completo.

\hint
Seja $A_n \asseq \nats\setminus\set{0,2,\dotsc, 2n - 2}$ o $\nats$ sem os
primeiros $n$ números pares.
Mostre que:
\emph{se $B \subset A_n$ para todo $n\in \nats$, então $B$ não é cofinito}.

\solution
Vamos provar primeiramente a afirmação seguinte:
\emph{se $B \subset A_n$ para todo $n\in \nats$, então $B$ não é cofinito}.
\endgraf
\proofstyle{{\proofname} da afirmação:}
Suponha que para todo $n\in\nats$, $B \subset A_n$.
Logo
$$
\align
    B &\subset \Inter_{i=0}^\infty A_i\\
\intertext{e complementando os dois lado,}
\nats\setminus B
    &\supset \nats\setminus\Inter_{i=0}^\infty A_i\\
    &= \Union_{i=0}^\infty(\nats\setminus A_i)\\
    &= \Union_{i=0}^\infty(\set{0,2,\dotsc, 2n-2})\\
    &= 2\nats.
\endalign
$$
Como $2\nats$ é infinito, o $B$ não é cofinito.
\endgraf
Agora voltamos a provar que nenhum dos $\scr L_1, \scr L_2$ é completo.
Considere o conjunto
$$
\cal S \asseq \set { A_0, A_1, A_2, \dotsc }
$$
Observe que
$\cal S \subset \scr L_1, \scr L_2$
pois todos os seus elementos são claramente cofinitos.
Mesmo assim, o $\Inter \cal S$ não é cofinito
$\Inter \cal S$ é o conjunto de todos os ímpares)
e logo não pertence em nenhum dos $\scr L_1, L_2$.

\endproblem
%%}}}

%%{{{ prob: knaster_tarski_fixpoint_full 
\problem Teorema Knaster--Tarski completo.
\label{knaster_tarski_fixpoint_full}%
No contexto do~\ref{knaster_tarski_fixpoint}, prove que
o subconjunto $\fixpoints F \subset L$ é um reticulado completo.

\endproblem
%%}}}

%%{{{ prob: banach_decomposition_theorem 
\problem Teorema de decomposição de Banach.
\label{banach_decomposition_theorem}%

\endproblem
%%}}}

%%{{{ prob: schroder_bernstein_lattice_proof 
\problem Teorema de Schröder--Bernstein.
\label{schroder_bernstein_lattice_proof}%
Sejam $f : A \injto B$ e $g : B \injto A$ funções injetoras.
Usando o teorema fixpoint de Knaster--Tarski~\refn{knaster_tarski_fixpoint}
prove que existe função bijetora $h : A \bijto B$.

\hint
O $\sset{\pset A}{\subset}$ é um reticulado completo.

\hint
Considere a função $F : \pset A \to \pset A$ definida pela
$$
F(X) = A \setminus \paren{ \img g {B \setminus {\img f X}} }.
$$
Mostre que ela é monótona.

\hint
Pelo teorema Knaster--Tarski~\refn{knaster_tarski_fixpoint}
a $F$ tem um fixpoint $C \subset A$, e
$$
C = F(C)
\iff
C = A \setminus \paren{ \img g {B \setminus {\img f C}} }
\iff
A \setminus C = \img g {B \setminus {\img f C}}.
$$

\hint
Defina a desejada $h : A \bijto B$ por casos:
$$
h(x) = \knuthcases{
\dots, & se $x \in C$ \cr
\dots, & se $x \in A\setminus C$.
}
$$

\endproblem
%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite{DaveyPriestley},
\cite{gratzerlatticefirst},
\cite{gratzerlatticefoundation}.

\cite[Cap.~6]{ynmnst}.

\cite[Cap.~2]{corilascar1},
\cite[Cap.~4]{bellmachover},
\cite{halmosboolean}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Metric spaces 
\chapter Espaços métricos.
\label{Metric_spaces}%

%%{{{ intro 
\chapintro
Logo depois do desenvolvemento da teoria de conjuntos de
\Cantor{}Cantor, no ano \yearof{1906} \Frechet{}Fréchet introduziu
os \dterm{espaços métricos} na sua tese de doutorado~\cite{frechetthesis}.
Nesse capítulo estudamos as primeiras idéias básicas.
%%}}}

%%{{{ Distances 
\section Distáncias.
\label{Distances}%

\endsection
%%}}}

%%{{{ Open_sets_and_neighborhoods_in_metric_spaces 
\section Conjuntos abertos.
\label{Open_sets_and_neighborhoods_in_metric_spaces}%

\endsection
%%}}}

%%{{{ Categories_and_metric_spaces 
\section Pouco de cats---categorias e espaços métricos.
\label{Categories_and_metric_spaces}%

\endsection
%%}}}

%%{{{ Problems 
\problems.

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite{simmonstopology},
\cite{kolmogorovfomin},
\cite{carothersreal}.

``Baby Rudin''~\cite{babyrudin}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: General topology 
\chapter Topologia geral.
\label{General_topology}%

%%{{{ What is a topology? 
\section O que é uma topologia.

\endsection
%%}}}

%%{{{ Topology constructions 
\section Construções de topologias.

\endsection
%%}}}

%%{{{ Bases and subbases 
\section Bases e subbases.

\endsection
%%}}}

%%{{{ Continuity 
\section Continuidade.

\endsection
%%}}}

%%{{{ Connectedness 
\section Conectividade.

\endsection
%%}}}

%%{{{ Compactness 
\section Compactividade.

\endsection
%%}}}

%%{{{ Hausdorff and separation axioms 
\section Hausdorff e axiomas de separação.

\endsection
%%}}}

%%{{{ Categories_and_topological_spaces 
\section Pouco de cats---categorias e espaços topológicos.
\label{Categories_and_topological_spaces}%

\endsection
%%}}}

%%{{{ Problems 
\problems.

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite{janichtopology},
\cite{simmonstopology},
\cite{munkrestopology},
\cite{willardtopology}.

\cite{vickerstopology},
\cite{escardosynthetic}.

\cite{johnstonestone}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Graph theory 
\chapter Teoria de grafos.

%%{{{ Problems 
\problems.

\endproblems
%%}}}

%%{{{ Further reading 
\further.

Umas introduções extensas são
o clássico~\cite{bondymurty1976}
e o mais novo~\cite{ChartrandZhang}.
Depois continua com~\cite{diestelgraph}
e~\cite{bondymurty2011}.
Finalmente, um nível ainda mais avançado, \cite{bollobasmodern}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Lambda calculus 
\chapter Lambda calculus.
\label{Lambda_calculus}%

%%{{{ The untyped lambda calculus 
\section O $\lambda$-calculus não-tipado.

\endsection
%%}}}

%%{{{ Faithfully representing mathematics 
\section Representando matemática fielmente.

\endsection
%%}}}

%%{{{ Programming 
\section Programmando.

\endsection
%%}}}

%%{{{ Recursion and fixpoints 
\section Recursão e fixpoints.

\endsection
%%}}}

%%{{{ Functional programming revisited 
\section Programação funcional revisitada.

\endsection
%%}}}

%%{{{ Problems 
\problems.

%%{{{ prob: what_does_this_lambda_term_with_minus_do 
\problem.
\label{what_does_this_lambda_term_with_minus_do}%
Suponha que já temos definido um $\lambda$-term $\Lmac{minus}$,
que comporta corretamente, no sentido que:
$$
\align
\Lmac{minus}\ {\Lnum n}\ {\Lnum m}
&\Lfinto \knuthcases{
  \Lnum {n - m},   &se $n \geq m$\cr
  \Lnum {0},       &se $n < m$.
}
\endalign
$$
Explique o comportamento do termo
$$
\Lmac f  \asseq  \Llam n {n\ (\Lmac{minus}\ {\Lnum 1})\ {\Lnum 0}}
$$
quando for aplicado para um numeral de \Church[numeral]{}Church $\Lnum k$:
qual é a função $f : \nats\to\nats$ que o termo $\Lmac f$ computa?

\hint
Cuidado com \Curry[currificação]{}Curry.

\endproblem
%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite{nederpeltgeuvers},
\cite{lecturesch}.
\cite{hindleyseldinlambdacl},
\cite{krivinelambda}.
\cite{barendregtlambda}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Combinatory logic 
\chapter Lógica combinatória.
\label{Combinatory_logic}%

%%{{{ Our first combinators 
\section Nossos primeiros combinadores.

%%{{{ df: first_combinators 
\definition.
\label{first_combinators}%
$$
\xalignat4
    \cI\,x    &\Cto x     &   \cB\,x\,y\,z &\Cto x\,(y\,z) &   \cS\,x\,y\,z &\Cto x\,z\,(y\,z)&\cR\,x\,y\,z &\Cto y\,z\,x\\\\
    \cK\,x\,y &\Cto x     &   \cBp\,x\,y\,z&\Cto y\,(x\,z) &   \cW\,x\,y    &\Cto x\,y\,y     &\cV\,x\,y\,z &\Cto z\,x\,y\\\\
    \cM\,x    &\Cto x\,x  &   \cC\,x\,y\,z &\Cto x\,z\,y   &                                
\endxalignat
$$
%%}}}

%%{{{ x: some_equiv_to_I 
\exercise.
\label{some_equiv_to_I}%
Mostre que o combinador
$\C S\ \C K\ (\C W\ (\C I\ \C B))$ comporta como o $\C I$.

\endexercise
%%}}}

%%{{{ x: another_equiv_to_I 
\exercise.
\label{another_equiv_to_I}%
Mostre que o combinator
$\C C\ (\C W\ \C K)\ \C K\ \C W$ comporta como o $\C I$.

\endexercise
%%}}}

%%{{{ x: CL_define_Bp 
\exercise.
\label{CL_define_Bp}%
Defina o $\cBp$ dos $\cI$, $\cM$, $\cB$, $\cC$.

\endexercise
%%}}}

%%{{{ x: CL_define_R 
\exercise.
\label{CL_define_R}%
Defina o $\cR$ dos $\cI$, $\cK$, $\cM$, $\cB$, $\cBp$, $\cC$, $\cS$, $\cW$.

\endexercise
%%}}}

%%{{{ x: CL_define_V 
\exercise.
\label{CL_define_V}%
Defina o $\cV$ dos $\cI$, $\cK$, $\cM$, $\cB$, $\cBp$, $\cC$, $\cS$, $\cW$, $\cR$.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Problems 
\problems.

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite{mockingbird},
\cite{bimbocl},
\cite{hindleyseldinlambdacl}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Mathematical logic 
\chapter Lógica matemática.
\label{Mathematical_logic}%

%%{{{ Semantics: worlds and models 
\section Semântica: mundos e modelos.

\note Mundos em $\zolang$: valuação e sua extenção recursiva.

\note Tautologias na $\zolang$.

\note Mundos em $\folang$: estruturas, e valuação de variáveis.

\note Tautologias na $\folang$.

\note Emulando constantes por funções.

\note Emulando funções por relações.

\note Modelos.

\note Como provar que duas formulas da $\folang$ (não) são equivalentes.

\note Independência de axiomas: o 5o axioma de Euclides.

\endsection
%%}}}

%%{{{ Complete sets of connectives 
\section Conjuntos de conectivos completos.

\endsection
%%}}}

%%{{{ Classical and intuitionistic logic 
\section Lógica clássica e intuicionista.

\endsection
%%}}}

%%{{{ Problems 
\problems.

\endproblems
%%}}}

%%{{{ Further reading 
\further.

Sobre lógica matemática:
\cite{kleeneIM},
\cite{curryfoundations};
\cite{kleenelogic},
\cite{smullyanfol};
\cite{corilascar1}~\&~\cite{corilascar2},
\cite{shoenfieldlogic},
\cite{bellmachover}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Structural_recursion_and_induction 
\chapter Recursão e indução estrutural.
\label{Structural_recursion_and_induction}%

%%{{{ Recursing over formulas 
\section Recursando nas fórmulas.

%%{{{ eg: bincon_count 
\example.
\label{bincon_count}%
Defina uma função $f : \zolang \to \nats$ que calcula o número
de conectivos binários que aparecem na sua entrada.
Use-lá para calcular os conectivos binários da expressão
$$
\lnot(P_4 \limplies (P_9 \land \lnot P_9)).
$$

\solution
Seguindo a definição de $\zolang$, cada um dos seus elementos
é formado por uma de certas regras.  Basta escrever então como
calcular o número desejado para cada um desses casos:
$$
\alignat2
f(p)                &= 0,          &\quad&\text{($p\in \mathrm{Pvar}$)} \tag{BC$_{P}$}\\
f(\lnot A)          &= f(A),            &&\text{($A\in \zolang$)}       \tag{BC$_{\lnot}$}\\
f((A \limplies B))  &= f(A) + 1 + f(B), &&\text{($A,B\in \zolang$)}     \tag{BC$_{\limplies}$}\\
f((A \land B))      &= f(A) + 1 + f(B), &&\text{($A,B\in \zolang$)}     \tag{BC$_{\land}$}\\
f((A \lor B))       &= f(A) + 1 + f(B), &&\text{($A,B\in \zolang$)}     \tag{BC$_{\lor}$}\\
\intertext{Preguiçosamente, podemos condensar as três últimas equações em úma só, assim:}
f((A \heartop B)) &= f(A) + 1 + f(B), &&\text{($A,B\in \zolang$, e $\heartop \in \set{\limplies,\land,\lor}$)}
\endalignat
$$
Aplicando nossa função na fórmula dada calculamos:
\compute
f( \lnot(P_4 \limplies (P_9 \land \lnot P_9)) )
&= f( (P_4 \limplies (P_9 \land \lnot P_9)) )   \by {por BC$_{\lnot}$}
&= f( P_4 ) + 1 + f( (P_9 \land \lnot P_9) )    \by {por BC$_{\limplies}$}
&= 0 + 1 + f( (P_9 \land \lnot P_9) )           \by {por BC$_{P}$}
&= 0 + 1 + ( f( P_9 ) + 1 + f ( \lnot P_9 ) )   \by {por BC$_{\land}$}
&= 0 + 1 + ( 0 + 1 + f ( \lnot P_9 ) )          \by {por BC$_{P}$}
&= 0 + 1 + ( 0 + 1 + f ( P_9 ) )                \by {por BC$_{\lnot}$}
&= 0 + 1 + ( 0 + 1 + 0 )                        \by {por BC$_{P}$}
&= 2
\endcompute

\endexample
%%}}}

\endsection
%%}}}

%%{{{ Problems 
\problems.

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite{aczelinductive},
\cite{ynminduction}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Computability_and_complexity 
\chapter Computabilidade e complexidade.
\label{Computability_and_complexity}%

%%{{{ A surprisingly difficult question 
\section Uma questão surpresamente difícil.

\endsection
%%}}}

%%{{{ Models of computation 
\section Modelos de computação.

\endsection
%%}}}

%%{{{ Decision problems 
\section Problemas de decisão.

\endsection
%%}}}

%%{{{ The halting problem 
\section O problema da parada.

\endsection
%%}}}

%%{{{ Asymptotic notation 
\section A notação assintótica.

\endsection
%%}}}

%%{{{ Analysis of algorithms 
\section Análise de algorítmos.

\endsection
%%}}}

%%{{{ Computational complexity 
\section Complexidade computacional.

\endsection
%%}}}

%%{{{ Problems 
\problems.

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite{cutlandcomputability},
\cite{kleeneIM},
\cite{rogersrecursive}.

\cite{kozenac}, \cite{kozentc}.

\cite{daviscu}, \cite{davisccl}, \cite{alicebook}.

\cite[Cap.~7]{bellmachover}.

\cite{dpv},
\cite{jonescomputability}.
\cite{gareyjohnson}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Theory_of_recursive_functions 
\chapter Teoria de funções recursivas.
\label{Theory_of_recursive_functions}%

%%{{{ Problems 
\problems.

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[Part~III]{kleeneIM},
\cite{shoenfieldrecursion},
\cite{ynmrandc},
\cite{rogersrecursive}.

\cite[Cap.~6--8]{bellmachover}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Formal languages 
\chapter Linguagens formais.

%%{{{ Problems 
\problems.

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite{alicebook},
\cite{kozenac},
\cite[Part~2]{davisccl}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Axiomatic set theory 
\chapter Teoria axiomática dos conjuntos.
\label{Axiomatic_set_theory}%

%%{{{ chapintro: sets like assembly 
\chapintro
Quando ``protoencontramos'' conjuntos no~\ref{Sets},
prometi que eles têm um papel importante para a \emph{fundação de matemática}.
Chegou a hora para ver o porquê!
Podemos traduzir todas as definições e relações matemáticas nessa
linguagem.  Nesse sentido, parece como uma ``assembly'', uma linguagem
``low-level'' onde podemos ``compilar'' toda a matemática, em tal modo
que cada definição, cada afirmação, cada teorema que provamos,
no final das contas, todos podem ser traduzidos para definições,
afirmações, teoremas e provas, que envolvem apenas conjuntos
e a relação primitiva de \emph{pertencer}.
E \emph{nada} mais!
%%}}}

%%{{{ Problems in Cantor's paradise: Russell's paradox 
\section Problemas no paraíso de Cantor: o paradoxo de Russell.

%%{{{ Russell's paradox 
\note O paradoxo de Russell (\yearof{1902}).
\label{russells_paradox}%
\tdefined{paradoxo}[de Russell]%
Russell\Russell[paradoxo]~observou que o conjunto
$$
\Univ \defeq \set{ x \st \text{$x$ é conjunto} }
$$
tem uma peculiaridade, uma propriedade estranha:
\emph{ele pertence nele mesmo}, ou seja, $\Univ\in \Univ$.
Os conjuntos que encontramos em matemática normalmente não têm essa
propriedade: $\alertR\nats\notin\alertB\nats$,
pois o $\alertR\nats$ não é um número natural!
Similarmente $\set{0,1,\set{1,2}}\notin\set{0,1,\set{1,2}}$, pois
$\set{0,1,\set{1,2}} \neq 0$,
$\set{0,1,\set{1,2}} \neq 1$, e
$\set{0,1,\set{1,2}} \neq \set{1,2}$.
Também $\emptyset \notin \emptyset$ pois nada pertence ao $\emptyset$.
Tudo bem, nenhum problema com isso, mas faz sentido definir o conjunto de
todos os conjuntos ``tranqüilos'', ou seja, aqueles que não têm essa
propriedade estranha de pertencer neles mesmo.
Russell definiu então o conjunto seguinte:
$$
\align
R &\defeq \setstt x {$x$ é conjunto~\andword~$x$ é tranqüilo} \\
  &=      \setstt x {$x$ é conjunto~\andword~$x\notin x$}.
\endalign
$$
E se perguntou:
\emph{o conjunto $R$ é tranqüilo, ou tem essa propriedade estranha?}
Consideramos os dois casos:
Se $\alertR R\in \alertB R$ então pela definição de $\alertB R$
temos que $\alertR R$ é tranquilo, ou seja, $\alertR R \notin \alertR R$,
então esse caso é impossível.
Se $\alertR R\notin \alertB R$ então $\alertR R$ não pertence nele mesmo
(ou seja, $\alertR R$ é tranqüilo) e logo pela definição de $\alertB R$
temos $\alertR R \in \alertB R$;
e assim esse caso também é impossível!
Sem muitas palavras:
\compute
\alertR R\in {\alertB R}
&\implies \text{$\alertR R$ tranqüilo}     \by {def.~$\alertB R$}
&\implies \alertR R \notin \alertR R       \by {def.~$\alertR R$ tranqüilo}
\alertR R\notin \alertB R
&\implies \text{$\alertR R$ não tranqüilo} \by {def.~$\alertB R$}
&\implies \alertR R \in \alertR R          \by {def.~$\alertR R$ tranqüilo}
\endcompute
Ou seja, concluimos que:
$$
R \in R \iff R \notin R
$$
e naturalmente queremos escrever um grande \emph{``absurdo''} neste momento,
mas\dots{}
De onde chegamos nesse absurdo?
Todas as vezes que chegamos num absurdo até agora, foi tentando provar algo:
\emph{supondo uma hipótese $H$}, chegamos num absurdo, então concluimos que
sua negação $\lnot H$ é verdade, ou vice-versa, usando o ``reductio ad absurdum'',
querendo provar que a $H$ é verdade supomos sua negação $\lnot H$,
achamos um absurdo e concluimos que nossa suposição não pode ser correta,
logo $H$.
Mas aqui não começamos supondo algo aleatoriamente.
Qual vai ser nossa conclusão agora?
Parece que chegamos num absurdo apenas com lógica sem supor nada ``extra''.
Será que lógica ou matemática é quebrada?
%%}}}

%%{{{ General Comprehension Principle 
\principle Comprehensão geral.
\label{general_comprehension_principle}%
Seja $P(\dhole)$ uma condição definitiva.
Existe um conjunto
$$
\set { x \st P(x) }
$$
cujos membros são exatamente todos os objetos $x$
que satisfazem a condição: $P(x)$.
%%}}}

%%{{{ cor: The general comprehension principle is invalid 
\corollary Russell.
O princípio da comprehensão geral não é válido.
\proof.
Supondo que é, chegamos no absurdo que achamos no~\refn{russells_paradox}.
\qed
%%}}}

%%{{{ the general Russell paradox 
\note O paradoxo de Russell geral.
Russell falou de conjuntos e de pertencer, mas facilmente identificamos
que seu paradoxo é apenas um caso de uma verdade mais geral.
Considere $R$ qualquer relação.
A formula
$$
\lnot
\exists x
\forall y
\paren{ R(x,y) \liff \lnot R(y,y) }
$$
é um tautologia; um teorema da FOL.
Suponha que tal $x$ existe (chame-o $x_0$).
Como $R(x_0, y) \liff \lnot R(y,y)$ para todos os $y$, então
tomando $y \asseq x_0$ chegamos na contradição
$$
R(x_0,x_0) \liff \lnot R(x_0,x_0).
$$
Observe que tomando como $R$ a relação $\in$ e como universo
o universo matemático comum, chegamos no paradoxo de Russell.
%%}}}

\endsection
%%}}}

%%{{{ Russell's and Zermelo's solutions 
\section As soluções de Russell e de Zermelo.

\note Teoria de tipos (Russell).
\Russell[teoria de tipos]{}

\note Teoria axiomática de conjuntos (Zermelo).
\Zermelo[teoria axiomática de conjuntos]{}

\note Créditos.
A teoria axiomática de conjuntos que estudamos nesse capítulo é conhecida
como ``Zermelo\Zermelo{}--\Fraenkel{}Fraenkel set theory''.
Mesmo assim, mais foram envolvidos na sua evolução, sua definição, e seu
amadurecimento, como os \Mirimanoff{}Mirimanoff, \Skolem{}Skolem,
e \vonNeumann{}von~Neumann, entre outros.

\endsection
%%}}}

%%{{{ Translations to and from the FOL of set theory 
\section Traduções de e para a FOL de conjuntos.
\label{FOL_translations_for_sets}%

%%{{{ The FOL of set theory 
\note A FOL da teoria de conjuntos.
Nessa linguagem de primeira ordem temos apenas um predicado não-constante:
o $\in$, de aridade 2, cuja interpretação canônica é ``\thole\ pertence ao \thole''.
Nosso universo aqui consiste (apenas) em conjuntos.
%%}}}

%%{{{ ex: FOL_translations_for_sets_exercise 
\exercise.
\label{FOL_translations_for_sets_exercise}%
Traduza as frases seguintes para a FOL da teoria de conjuntos.
\beginol
\li Existe conjunto sem membros.
\li O conjunto $x$ não tem membros.
\li O conjunto $y$ tem membros.
\li Existe conjunto com membros.
\li O $x$ é um singleton.
\li Existe conjunto com exatamente um membro.
\li Existe conjunto com pelo menos dois membros.
\li Os $x$ e $y$ têm exatamente um membro em comum.
\li Todos os conjuntos tem o $x$ como membro.
\li Existe conjunto que pertence nele mesmo.
\li O $y$ consiste em todos os subconjuntos de $x$ com exatamente 2 elementos.
\li Existe conjunto com exatamente dois membros.
\li Para todos conjuntos $a$ e $b$ sua intersecção é conjunto.
\li A união de $a$ e $b$ é um conjunto.
\li O $x$ não pertence em nenhum conjunto.
\li Existem conjuntos tais que cada um pertence no outro.
\li Existe conjunto que não é igual com ele mesmo.
\endol

\endexercise
%%}}}

%%{{{ Merely saying something doesn't make it true 
\note Apenas escrever algo não o torna verdade.
O fato que podemos expressar uma afirmação numa linguagem não quer dizer
que essa afirmação é válida.  Isso não é nada profundo: em português
também podemos escrever a frase ``a lua não é feita de queijo'', mas isso
não quis dizer que realmente não é---todos sabemos que é, certo?
Infelizmente existe um hábito de confundir as duas noções e usar como
``prova de veracidade de algo'' o fato que apenas esse algo foi escrito,
ou dito.%
\footnote{Veja por exemplo argumentações de várias igrejas de várias religiões.}
A afirmação da fórmula que tu achou para a última frase
do~\ref{FOL_translations_for_sets_exercise} por exemplo é falsa em nosso
mundo de conjuntos e ainda mais: é falsa em cada mundo possível, com qualquer
interpretação do símbolo $\in$!
%%}}}

%%{{{ A useful pattern 
\note Um padrão útil.
Muitas vezes queremos dizer que
existe um certo conjunto \emph{determinado por uma propriedade
característica}, ou seja, um conjunto $s$ que consiste em exatamente
todos os objetos que satisfazem um certo critério.
\endgraf
\emph{Como podemos dizer isso na FOL da teoria de conjuntos?}
Fácil!  Assim:
$$
\phantom{
\forall a
\forall b
\forall c
\dotsb
}
{\color{alert}
\exists s
\forall x
\bigparen{
x\in s \liff
{}
{\color{normal}
\tunderbrace{
\text{\vphantom|\xlthole}
}{critério}
}}}.
$$
Na maioria das vezes queremos afirmar a existência dum certo conjunto
dados conjuntos $a,b,c,\dotsc$.
Nesse caso usamos apenas o
$$
\forall a
\forall b
\forall c
\dotsb
{\color{alert}
\exists s
\forall x
\bigparen{
x\in s \liff
{}
{\color{normal}
\text{\xlthole}
}}}.
$$
Esse padrão vai aparecer em muitos dos axiomas abaixo.
%%}}}

%%{{{ Abbreviations and syntactic sugar 
\note Abreviações e açúcar sintáctico.
Assim que conseguirmos descrever um conceito interessante com uma fórmula,
faz sentido introduzir uma notação, um novo predicado.
Por exemplo, nas (2) e (5) de~\ref{FOL_translations_for_sets_exercise},
tu achou fórmulas que afirmam que $x$ é vazio, e que $x$ é um singleton.
Faz sentido definir como abreviações então os predicados seguintes:
$$
\align
\Empty(x)
&\sugareq
\lnot \exists w \paren{ w \in x }\\
\Singleton(x)
&\sugareq
\exists w \bigparen{
w \in x
\land
\forall u \paren{ u \in x \limplies u = w }
}
\intertext{e os símbolos:}
a \subset b
&\sugareq \forall x \paren{ x \in a \limplies x \in b }\\
a \subsetneq b
&\sugareq a \subset b \land a \neq b.
\intertext{Lembre-se também nossa práctica onde usamos}
x \neq y
&\sugareq \lnot\, x = y,\\
x \notin y
&\sugareq \lnot\, x \in y,
\endalign
$$
etc.
%%}}}

\endsection
%%}}}

%%{{{ Classes vs. Sets (I) 
\section Classes vs{.}~Conjuntos (I).

%%{{{ What is a class? 
\note O que é uma classe?.
Sem dúvida, a notação $\set{ x \st \text{\lthole} }$
que temos usado até agora é natural e útil.
Ela denota a colecção de todos os objetos $x$ que satisfazem
a condição (ou ``passam o filtro'') que escrevemos no \lthole.
Dada uma condição definitiva $P$ então consideramos a colecção
$$
\set {x \st P(x)}
$$
de todos os objetos que a satisfazem.
Provavelmente vocé já percebeu que eu evitei usar a palavra
\emph{conjunto}, pois reservamos essa palavra para
apenas os conjuntos-objetos do nosso universo.
%%}}}

%%{{{ df: class 
\definition Classe.
\tdefined{classe}%
\tdefined{classe}[própria]%
\iisee{própria}[classe]{classe própria}%
Dada uma condição definitiva $P(\dhole)$ definimos a \dterm{classe}
$$
\class x {P(x)}
$$
como um sinónimo da própria condição $P$!
Chamamos a classe $P$ \dterm{própria} sse não existe \emph{conjunto}
$S$ que satisfaz a propriedade:
$$
x \in S \iff P(x).
$$
%%}}}

%%{{{ eg: sets and proper classes 
\example.
Dados conjuntos $a$ e $b$,
das classes
$$
\munderbrace{\class x {x = a}} {\set a}
\qqquad
\munderbrace{\class x {x \in a \land x\in b}} {a\inter b}
\qqquad
\munderbrace{\class x {x \neq x}} {\emptyset}
\qqquad
\class x {x = x}
$$
apenas a última é própria.
As outras são conjuntos mesmo!
\endexample
%%}}}

%%{{{ warning: Abuso notacional 
\warning Abuso notacional.
É muito comum abusar o símbolo $\in$, escrevendo
$$
x \in C
$$
mesmo quando $C$ é uma classe própria!
Nesse caso consideramos o ``$x \in C$'' apenas como uma
abreviação do $C(x)$.
Em outras palavras, esse $\in$ não é um símbolo de relação da nossa FOL de
teoria de conjuntos, mas sim uma abreviação em nossa \emph{metalinguagem},
no mesmo jeito que $\iff$ também não é, mas o $\liff$ é.
Quando precisamos enfatizar essa diferença vamos usar um símbolo diferente:
%%}}}

%%{{{ Notation: inclass 
\note Notação.
\label{inclass}%
\sdefined {\sholed x\inclass\sholed C} {o objeto $x$ está na classe $C$}%
Usamos o símbolo $\inclass$ na metalinguagem como ``pertence''
quando possivelmente o lado direito é uma classe própria.%
\footnote{Seguimos aqui o exemplo dos símbolos de equivalência na metalinguágem
($\Longleftrightarrow$) e na linguagem-objeto de lógica ($\leftrightarrow$).}
Com essa notação:
$$
x\inclass P
\defiff
\knuthcases{
P(x)    & se $P$ é uma classe própria\cr
x\in P  & se $P$ é um conjunto.
}
$$
%%}}}

\endsection
%%}}}

%%{{{ The first axioms of Zermelo 
\section Os primeiros axiomas de Zermelo.

%%{{{ ax: Extensionality 
\axiom Extensionalidade.
\tdefined{axioma}[Extensionality]%
\label{extensionality}%
Todo conjunto é determinado por seus membros.
$$
\forall a \forall b
\paren{
\forall x
\paren{
x \in a
\liff
x \in b
}
\limplies
a = b
}
\axtaglabel{ZF1}{extensionality}
$$
%%}}}

\note.
Qual o efeito disso em nosso mundo?
Ainda nem podemos garantir a existência de nada,
mas pelo menos sabemos dizer se duas coisas são iguais ou não.
Vamos logo garantir a existência dum conjunto familiar:

%%{{{ ax: Emptyset 
\axiom Emptyset.
\tdefined{axioma}[Emptyset]%
\label{emptyset}%
Existe conjunto sem membros.
$$
\exists s \forall x
\paren{
x \notin s
}
\axtaglabel{ZF2}{emptyset}
$$
%%}}}

\blah.
E já nosso mundo mudou completamente:
ganhamos nossa primeira peça, uma coisa para brincar:
\emph{um conjunto sem membros!}
E já estamos em posição de provar nosso primeiro teorema,
seguido pela nossa primeira definição:

%%{{{ thm: uniqueness_of_emptyset 
\theorem Unicidade do conjunto vazio.
\label{uniqueness_of_emptyset}%
\ii{unicidade!do $\emptyset$}%
O conjunto sem membros garantido pelo axioma~\axref{emptyset} é único.
\proof.
Suponha que $e, o$ são conjuntos ambós satisfazendo a propriedade:
$$
\forall x\paren{x \notin e}
\qqqquad
\forall x\paren{x \notin o}.
$$
Então a equivaléncia
$$
x\in e \iff x \in o
$$
é válida para todo $x$, pois ambos lados são falsos.
Logo, pelo axioma~\axref{extensionality}, $e=o$.
\qed
%%}}}

%%{{{ df: emptyset_def 
\definition Conjunto vazio.
\label{emptyset_def}%
\tdefined{conjunto}[vazio]%
\sdefined {\emptyset} {o conjunto vazio}%
Denotamos com $\emptyset$ o \dterm{conjunto vazio} com a propriedade característica
$$
\forall x\paren{x\notin \emptyset}.
$$
%%}}}

\blah.
\dots e agora parece que não podemos fazer muita coisa mais.
Precisamos novos axiomas:

%%{{{ ax: Pairset 
\axiom Pairset.
\tdefined{axioma}[Pairset]%
\label{pairset}%
Dado um par de conjuntos, existe conjunto que consiste
em exatamente os conjuntos do par.
$$
\forall a
\forall b
\exists s
\forall x
\bigparen{
x\in s
\liff
\paren{
x = a
\lor
x = b
}
}
\axtaglabel{ZF3}{pairset}
$$
%%}}}

%%{{{ df: doubleton 
\definition Doubleton.
\tdefined {doubleton}%
\sdefined {\set{\sholed a, \sholed b}} {o conjunto doubleton de $a$ e $b$}%
Dados $a$ e $b$ quaisquer, o conjunto que consiste nos $a$ e $b$
é chamado o \dterm{doubleton} de $a$ e $b$, e denotado por $\set {a, b}$.
Definimos assim o operador $\set{\dhole, \dhole}$.
%%}}}

%%{{{ Effects 
\note Efeitos.
Como isso muda nosso mundo?
Quais novas peças ganhamos em nosso xadrez?
Para ganhar a existência de algo usando o Pairset
precisamos dar a ele dois objetos,
pois começa com dois quantificadores universais ($\forall$)
antes de chegar no seu primeiro existencial ($\exists$):
``$\forall a\forall b \exists \dots$''.
Quais objetos vamos escolher para dá-lo?
Nosso mundo está tão pobre que é fácil responder nessa pergunta:
\emph{vamos usar como $a$ e como $b$ a única peça que temos: o $\emptyset$}.
Ganhamos então que:
$$
\exists s \forall x\bigparen { x \in s \liff \paren{ x = \emptyset \lor x = \emptyset }}
$$
ou seja, $\exists s \forall x \bigparen { x \in s \liff x = \emptyset }$,
ou seja, existe o conjunto
$$
\set { x \st x = \emptyset }
$$
que acostumamos a denotá-lo por $\set \emptyset$.
Uma nova peça!  E teoremas?
%%}}}

%%{{{ thm: singleton_thm 
\theorem Singleton.
\label{singleton_thm}%
Dado conjunto $a$, existe um único conjunto cujo membro único é o $a$.
Formalmente,
$$
\forall a
\exists s
\forall x
\bigparen{
x\in s
\liff
x = a
}.
$$
\proof.
Bote $a\asseq a$ e $b\asseq a$ no Pairset~(\axref{pairset}):
$$
\phantom{\forall a}
\exists s
\forall x
\bigparen{
x \in s
\liff
x = a
}.
$$
O conjunto cuja existência está sendo afirmada tem como membro único o $a$,
e graças ao~\axref{extensionality}, ele é o único conjunto com essa propriedade.
\qed
%%}}}

%%{{{ df: singleton 
\definition.
\label{singleton}%
\sdefined {\set{\sholed a}} {o conjunto singleton de $a$, com membro único o $a$}%
Dado qualquer conjunto $a$, o conjunto cujo único membro é o $a$
é chamado o \dterm{singleton} de $a$, e denotado por $\set a$.
Definimos assim o operador $\set{\dhole}$.
%%}}}

%%{{{ x: infinitely_many_sets 
\exercise.
Ache uma infinidade de peças novas usando apenas os axiomas \axref{extensionality}, \axref{emptyset}, e \axref{pairset}.

\hint
Agora temos duas opções para cada $\forall$ do Pairset: $\emptyset$, $\set\emptyset$.

\endexercise
%%}}}

\blah.
Mesmo que nosso mundo mudou drasticamente---sim, ganhamos uma infinidade de
objetos---ele ainda tá bem limitado.

%%{{{ x: infinitely_many_singletons 
\exercise.
Mostre como construir uma infinidade de singletons e uma infinidade de doubletons.

\hint
\axref{emptyset}~\&~\ref{singleton_thm}.

\hint
Comece com o $\emptyset$ e aplique iterativamente o operador $\set{\dhole}$.

\solution
Graças ao Emptyset~(\axref{emptyset}) temos o $\emptyset$.
Aplicamos iterativamente o operador $\set{\dhole}$ e assim construimos
a seqüência infinita de singletons
$$
\emptyset,
\set{\emptyset},
\set{\set{\emptyset}},
\set{\set{\set{\emptyset}}},
\set{\set{\set{\set{\emptyset}}}},
\dotsc
$$
Para os doubletons, uma abordagem seria aplicar o $\set{\emptyset,\dhole}$
em todos os membros da seqüência acima começando com o segundo.
Construimos assim a seqüência seguinte de doubletons:
$$
\set{\emptyset, \set{\emptyset}},
\set{\emptyset, \set{\set{\emptyset}}},
\set{\emptyset, \set{\set{\set{\emptyset}}}},
\set{\emptyset, \set{\set{\set{\set{\emptyset}}}}},
\dotsc
$$

\endexercise
%%}}}

%%{{{ x: only_sets_with_up_to_two_elements 
\exercise.
\label{only_sets_with_up_to_two_elements}%
Podemos garantir a existência de conjuntos com qualquer cardinalidade finita que desejamos?

\hint
No exercício anterior construimos uns conjuntos com cardinalidade até 2.
Tente construir conjunto com cardinalidade 3.

\hint
Não tem como.  Por quê?

\solution
A construção dum conjunto com cardinalidade finita $n$ só pode ter sido garantida
ou pelo Emptyset, se $n=0$ (nesse caso o conjunto construido é o próprio $\emptyset$),
ou pelo Pairset, se $n>0$.  Mas o Pairset só construe
conjuntos de cardinalidade $1$ ou $2$, dependendo se o aplicamos em conjuntos
iguais ou não (respectivamente).
Para concluir: nossos axiomas não são suficientemente poderosos para garantir
a existência de conjuntos com cardinalidades maiores que $2$.

\endexercise
%%}}}

\note.
O próximo axioma não vai nos permitir---por enquanto---definir novos conjuntos.
Mas é a versão ``bug-free'' do princípio da comprehensão geral.
Com isso, o paradoxo de Russell se torna teorema!

%%{{{ ax: Separation 
\axiom Separation (schema).
\tdefined{axioma}[Separation (schema)]%
\label{separation}%
{\rm Para cada propriedade $\phi(\dhole)$, o seguinte:}
para todo conjunto, a colecção de todos os seus membros que têm a propriedade $\phi$ é um conjunto.
$$
\forall w
\exists s
\forall x
\bigparen{
x\in s
\liff
\paren{
x\in w 
\land
\phi(x)
}
}
\axtaglabel{ZF4}{separation}
$$
%%}}}

%%{{{ x: how many axioms? 
\exercise.
Quantos axiomas temos listado até este momento?

\hint
Não são 4.

\hint
Não é um número finito de axiomas!

\solution
Veja a discução no~\refn{axioms_vs_axiomatic_schemata}.

\endexercise
%%}}}

%%{{{ Axioms vs. axiomatic schemata 
\note Axiomas vs{.}~esquemas axiomáticos.
\label{axioms_vs_axiomatic_schemata}%
Usamos o termo ``esquema axiomático'', pois para cada fórmula $\phi(\dhole)$,
ganhamos um novo axioma pelo~\axref{separation}.
Para enfatizar isso podemos até citá-lo como~\axref{separation}$_{\phi}$.
Antes de usá-lo então precisamos primeiramente escolher nossa fórmula $\phi$,
assim passando do \emph{esquema}~\axref{separation}
para o \emph{axioma}~\axref{separation}$_{\phi}$.
Agora como o axioma começa com ``$\forall w \exists \dots$'',
precisamos escolher em qual conjunto $w$ nós vamos aplicá-lo,
para ganhar finalmente um novo conjunto.
%%}}}

%%{{{ df: set_builder_separation 
\definition.
Denotamos com
$$
\setst {x \in W} {\phi(x)}
$$
o conjunto único (pelo~\axref{extensionality}) garantido pelo~\axref{separation} quando o aplicamos com uma fórmula $\phi(x)$ para um conjunto $W$.
%%}}}

%%{{{ x: separation_yields_no_new_sets_yet 
\exercise.
\label{separation_yields_no_new_sets_yet}%
Mostre que os conjuntos garantidos pelos~\axref{extensionality}--\axref{pairset}
são os mesmos com os conjuntos garantidos pelos~\axref{extensionality}--\axref{separation}.

\hint
Usando o~\axref{separation}, criamos subconjunto de um conjunto dado.

\hint
Quais são todas as cardinalidades possíveis para o conjunto em qual
usamos o~\axref{separation}?

\endexercise
%%}}}

%%{{{ How to use the Separation 
\note Como usar o~\axref{separation}.
Queremos mostrar que uma certa classe $C$ de objetos realmente é um conjunto.
Para conseguir isso com o~\axref{separation},
precisamos construir (pelos axiomas!) um \emph{conjunto}
$W$ que contem todos os objetos da nossa classe $C$.
Em geral o $W$ vai ter mais elementos, um certo ``lixo'', que precisamos nos livrar.
E é exatamente com o~\axref{separation} que jogamos fora esse lixo,
usando uma apropriada fórmula $\phi$ como ``tesoura'' para cortar o $W$ e ficar só com o $C$,
garantido agora de ser conjunto.
Vamos ver uns exemplos desse uso,
enriquecendo nosso mundo com uns operadores conhecidos.
%%}}}

%%{{{ eg: define inters 
\example.
Defina o operador $\dhole\inter\dhole$.

\solution
Dados conjuntos $a$ e $b$,
precisamos achar um conjunto $W$ que contenha todos os membros
da intersecção desejada.  Assim vamos conseguir definir o $a \inter b$
usando o~\axref{separation} com filtro a fórmula
$$
\phi(x)\asseq {x \in a \land x \in b}
$$
Observe que todos os elementos da $a \inter b$ são elementos tanto de $a$,
quanto de $b$.
Temos então duas opções.  Vamos escolher a primeira e construir o
$$
\setst {x \in a} {x \in a \land x \in b}
$$
Observamos que com essa escolha nem precisamos a parte ``$x \in a$'' em nosso filtro.
Chegamos assim em duas soluções para nosso problema:
$$
\setst {x \in a} {x \in b}
\qqqquad
\setst {x \in b} {x \in a}
$$

\endexample
%%}}}

%%{{{ df: inters 
\definition Intersecção binária.
\label{inters_constructed}%
Sejam conjuntos $a,b$.
Usando o~\axref{separation} definimos
$$
a\inter b \defeq \setst {x\in a} {x\in b}.
$$
%%}}}

%%{{{ x: define setminus 
\exercise.
Defina o operador $\dhole\setminus\dhole$.

\hint
Começa considerando dados conjuntos $a$ e $b$.
Procure um \emph{conjunto} que contenha todos os membros
da classe $a\setminus a$ que tu queres construir como conjunto.
Cuidado: nesse caso não temos as duas opções que tivemos
na~\ref{inters_constructed}.

\solution
Usando o~\axref{separation} definimos:
$$
a\setminus b\defeq \setst {x \in a} {x \notin b}.
$$

\endexercise
%%}}}

%%{{{ x: cannot_define_union_yet 
\exercise.
\label{cannot_define_union_yet}%
Tente definir os operadores $\dhole\union\dhole$ e $\dhole\symdiff\dhole$.

\hint
Dados conjuntos $a$ e $b$,
precisas achar um \emph{conjunto} $W$
que contenha todos os membros de $a\union b$,
para depois filtarar apenas os certos usando
como filtro a fórmula
$$
\phi(x) \asseq
x \in a \lor x \in b
$$
para a operação $\dhole\union\dhole$;
e similarmente para a $\dhole\symdiff\dhole$ só que
para essa o filtro vai ser a fórmula
$$
\phi(x)\asseq
\paren{x \in a \land x \notin b}
\lor
\paren{x \notin a \land x \in b}.
$$

\hint
Não tem como!

\solution
Não tem como!
Os axiomas que temos por enquanto não são suficientemente poderosos para
definir nenhuma dessas operações!

\endexercise
%%}}}

%%{{{ Blammenos_strikes_back 
\note Blammenos strikes back.
\label{Blammenos_strikes_back}%
Estudamos o parádoxo de Russell, e a resolução do problema por Zermelo:
\emph{o princípio de comprehensão geral não é valido;
usando o separation axiom evitamos cair no parádoxo}.
Mas o aluno Blammenos pensou:
\dialogue
\who {Blammenos}
Ok, eu vou trabalhar na teoria de Zermelo então.
Seja $A$ um conjunto.
Defino o
$$
r(A) \defeq \setst {x \in A} {x \notin x}
$$
que realmente é um conjunto, graças ao Separation
(que o usei com a fórmula $\phi(x) \asseq x\notin x$).
Mas agora faço a mesma pergunta que Russell fez: $r(A) \in r(A)$?
Assim consigo cair no mesmo parádoxo:
$$
r(A) \in r(A) \iff r(A) \notin r(A).
$$
Então Zermelo não resolveu o problema não!
\enddialogue
%%}}}

%%{{{ x: Blammenos_strikes_back_spot_the_mistake 
\exercise.
\label{Blammenos_strikes_back_spot_the_mistake}%
Qual o erro do Blammenos essa vez?

\endexercise
%%}}}

\blah.
Com o axioma da separação no lugar do princípio da comprehensão geral,
o paradoxo de \Russell{}\ii{paradoxo!de Russell!vira teorema}Russell
vira-se um teorema muito útil que nos permite definir o operador
$\russell\dhole$ que
``escolhe definitivamente um objeto fora da sua entrada''.
Vamos?

%%{{{ thm: russells_paradox_to_theorem 
\theorem.
\label{russells_paradox_to_theorem}%
Dado qualquer conjunto existe algo que não pertence nele.
Ainda mais, pelo menos um dos seus subconjuntos não pertence nele.
\sketch.
Tome um conjunto $A$.
Usamos a mesma idéia do paradoxo de Russell\Russell[de paradoxo para teorema],
só que essa vez não consideramos \emph{todos} os conjuntos que não
pertencem neles mesmo, mas apenas aqueles que pertencem ao $A$.
Concluimos que $\russell A \notin A$ pois o caso $\russell A \in A$ chega 
no mesmo absurdo de Russell.
\qes
%%}}}

%%{{{ Univ is not a set 
\corollary.
\label{Univ_is_not_a_set}%
O universo $\Univ$ não é um conjunto.
\proof.
Se $\Univ$ fosse um conjunto, aplicando o teorema teriamos um conjunto $\russell \Univ$
com $\russell\Univ \notin \Univ$, absurdo pela definição do $\Univ$.
\qed
%%}}}

%%{{{ ax: Powerset 
\axiom Powerset.
\tdefined{axioma}[Powerset]%
\label{powerset}%
Para cada conjunto a colecção de todos os seus subconjuntos é um conjunto.
$$
\forall a
\exists s
\forall x
\paren{
x\in s
\liff
x \subset a
}
\axtaglabel{ZF5}{powerset}
$$
%%}}}

%%{{{ df: pset 
\definition.
\tdefined{powerset}%
\sdefined {\pset {\sholed a}} {o conjunto de partes (powerset) de $a$}%
\iisee{conjunto!de partes}{powerset}%
\iisee{conjunto!potência}{powerset}%
Dado conjunto $a$, escrevemos
$\pset a$
para o conjunto garantido pelo Powerset~(\axref{powerset}),
que é único graças ao~Extensionality(\axref{extensionality}).
Definimos assim o operador $\pset\dhole$.
%%}}}

%%{{{ x: powersingleton 
\exercise.
\label{powersingleton}%
Seja $a$ conjunto.  Mostre que a classe
$$
\class { \set x } { x \in a }
$$
de todos os singletons de elementos de $a$ é conjunto.

\solution
Queremos mostrar que dado conjunto $a$, a classe
$$
\class { \set x } { x \in a }
$$
é conjunto.
Basta só achar um conjunto $W$ tal que todos os $\set x \in W$.
Botamos apenas o $W\asseq\pset a$ que sabemos que é conjunto
pelo~Powerset~(\axref{powerset}), assim ganhando o conjunto
$$
\setst { z\in \pset a } { \lexists {x \in a} {z = \set x} }.
$$
pelo~Separation~(\axref{separation}).

\endexercise
%%}}}

%%{{{ x: arbitrarily_large_finite_sets 
\exercise.
\label{arbitrarily_large_finite_sets}%
Usando
os~\axref{extensionality}+\axref{emptyset}+\axref{pairset}+\axref{powerset},
podemos construir conjunto com cardinalidade finita, arbitrariamente grande?

\solution
Sim.
Seja $n\in\nats$.
Precisamos construir um conjunto $A$ com $\card A \geq n$.
Se $n=0$, graças ao Emptyset~(\axref{emptyset}) tomamos $A\asseq\emptyset$.
Se $n>0$, iteramos o operador $\pset\dhole$ até chegar num conjunto
cuja cardinalidade supera o $n$.

\endexercise
%%}}}

%%{{{ x: still_missing_some_finite_cardinalities 
\exercise.
\label{still_missing_some_finite_cardinalities}%
Usando os~\axref{extensionality}+\axref{emptyset}+\axref{pairset}+\axref{powerset}, podemos construir conjunto com cardinalidade finita qualquer?

\hint
Não.  Por quê?

\hint
Como vimos no~\ref{only_sets_with_up_to_two_elements},
usando os \axref{extensionality}+\axref{emptyset}+\axref{pairset}
podemos consturir apenas conjuntos com cardinalidades $0$, $1$, e $2$.
Se aplicar o Powerset~(\axref{powerset}) num conjunto $A$ com cardinalidade
finita $n$, qual será a cardinalidade do $\pset A$?

\solution
Não.
Por exemplo, não temos como construir conjunto com cardinalidade $3$,
pois uma tal construção deveria ``terminar'' com uma aplicação do Powerset
(o Emptyset construe conjuntos com cardinalidade $0$, e o Pairset com $1$ ou $2$).
Mas aplicando o Powerset para conjunto com cardinalidade finita $n$,
construimos conjunto com cardinalidade $2^n$, e $3$ não é uma potência de $2$.

\endexercise
%%}}}

%%{{{ Games 
\note Jogos.
Como descobrimos no~\ref{still_missing_some_finite_cardinalities}
não existe estratégia\ii{estratégia}[vencedora]\ vencedora num jogo
onde nosso oponente joga primeiro escolhendo um número $n\in\nats$,
e nosso objectivo é construir pelos axiomas um conjunto
com cardinalidade $n$.
Se ele escolher como $n$ um dos
$$
0, 1, 2, 2^2, 2^{2^2}, 2^{2^{2^2}}, \dotsc
$$
temos como ganhar, mas caso contrário, não.
\endgraf
No outro lado, num jogo onde  nosso objectivo é construir pelos
axiomas um conjunto com cardinalidade \emph{pelo menos} $n$,
como vimos no~\ref{arbitrarily_large_finite_sets},
temos uma estratégia vencedora sim:
comece com uma aplicação do Emptyset~(\axref{emptyset})
para ganhar o $\emptyset$ e aplique iterativamente o
Powerset~(\axref{powerset}) construindo assim conjuntos de
cardinalidades $0$ (do próprio $\emptyset$),
$1$, $2$, $2^2$, $2^{2^2}$, etc.,
até chegar num conjunto com cardinalidade maior-ou-igual
ao~$n$ escolhido por nosso oponente.
%%}}}

%%{{{ x: how many iterations of powerset do we need to win? 
\exercise.
Quantas iterações precisamos para conseguir conjunto com cardinalidade $n\in\nats$?

\endexercise
%%}}}

%%{{{ x: all_finite_cardinalities 
\exercise.
\label{all_finite_cardinalities}%
Usando os~\axref{extensionality}+\axref{emptyset}+\axref{separation}+\axref{powerset}, podemos construir conjunto com cardinalidade finita qualquer?

\hint
Dado $n\in\nats$ construa primeiramente um conjunto com cardinalidade
maior-ou-igual, e aplica o Separation~(\axref{separation}) para
ficar com apenas $n$ elementos.
Formalmente, use indução!

\endexercise
%%}}}

%%{{{ ax: Unionset 
\axiom Unionset.
\tdefined{axioma}[Unionset]%
\label{unionset}%
Para cada conjunto, sua união (a colecção de todos os membros dos seus membros) é um conjunto.
$$
\forall a
\exists s
\forall x
\bigparen{
x\in s
\liff
\exists w
\paren{
x \in w
\land
w \in a
}
}
\axtaglabel{ZF6}{unionset}
$$
%%}}}

%%{{{ df: unionset 
\definition.
\tdefined{unionset}%
\sdefined {\Union {\sholed a}} {a união de $a$ (operação unária)}
Dado conjunto $a$, escrevemos
$\Union a$
para o conjunto garantido pelo Unionset~(\axref{unionset}),
que é único graças ao~Extensionality~(\axref{extensionality}).
Definimos assim o operador da \dterm{união arbitrária} $\Union\dhole$.
%%}}}

%%{{{ x: union_and_symdiff_constructed 
\exercise.
\label{union_and_symdiff_constructed}%
Defina os operadores binários $\union$ e $\symdiff$.

\hint
(Sobre o operador $\union$.)
Combine os operadores $\Union\dhole$ e $\set{\dhole,\dhole}$!

\hint
(Sobre o operador $\symdiff$.)
Suponha $a,b$ conjuntos.  Temos
$a\symdiff b\subset a\union b$.

\solution
Sejam conjuntos $a,b$.
Definimos:
$$
\align
a \union b   &\defeq \Union\set{a,b}\\
a \symdiff b &\defeq \setst {x \in a\union b} {x \notin a\inter b}
\endalign
$$

\endexercise
%%}}}

%%{{{ x: complement_impossible 
\exercise.
\label{complement_impossible}%
Como podemos definir o operador unitário $\complement{\cdot}$ de \emph{complemento},
tal que $\complement a$ é o conjunto de todos os objetos que não pertencem ao $a$?

\hint
De jeito nenhum!  Por quê?

\solution
Não podemos.
Dado conjunto $a$, se seu complemento $\complement a$ também fosse conjunto,
poderiamos aplicar o $\union$ para construir o $a\union\complement a$.
Mas pela definição dos $\union$ e $\complement a$, temos agora
$$
x\in a\union \complement a
\iff
x\in a \lor x \notin a
$$
ou seja, todos os objetos $x$ satisfazem a condição na direita!
Em outras palavras $a \union \complement a$ seria o próprio universo $\Univ$
que sabemos que não é um conjunto.

\endexercise
%%}}}

%%{{{ x: Inter_constructed 
\exercise.
\label{Inter_constructed}%
Defina o operador unário $\Inter$,
aplicável em qualquer conjunto não vazio.
Precisamos o Unionset~(\axref{unionset})?

\solution
Dado conjunto $A\neq\emptyset$, definimos
$$
\Inter A
\defeq
\setst {x \in \Union A} {\lforall {a \in A} {x \in a}}.
$$

\endexercise
%%}}}

%%{{{ thm: finite_set_constructor 
\theorem.
\label{finite_set_constructor}%
Dados $a_1, a_2, \dotsc, a_n$ (onde $n\in\nats$) existe conjunto único
cujos membros são exatamente os $a_1$, $a_2$, \dots, $a_n$.
\proof Provarás no~\ref{finite_set_constructor_proof}.
\qed
%%}}}

%%{{{ remark: finite_set_constructor_notation 
\remark.
Pelo~\ref{finite_set_constructor} ganhamos para qualquer $n\in\nats$
o operador $n$-ário
$$
\set{\dhole,\dhole,\dotsc,\dhole}.
$$
%%}}}

\endsection
%%}}}

%%{{{ Construction trees 
\section Arvores de construção.

\blah.
Um jeito bem econômico e claro para descrever uma construção
e usando árvores.
Os exemplos seguintes servem para explicar essa idéia.

%%{{{ eg: Tree explanation 
\example.
Queremos provar que $\set{ \emptyset, \set{\emptyset, \set{\emptyset}}}$
é um conjunto.
Escrevemos:
{Pelo Emptyset~(\axref{emptyset}), $\emptyset$ é um conjunto.
Pelo Pairset~(\axref{pairset}) aplicado com $a,b\asseq\emptyset$ temos
que $\set{\emptyset,\emptyset}$ também é conjunto.
Mas, pelo Extensionality~(\axref{extensionality}),
$\set{\emptyset,\emptyset}=\set{\emptyset}$.
Agora, novamente pelo Pairset~(\axref{pairset}) essa vez
aplicado com $a\asseq\emptyset$ e $b\asseq\set{\emptyset}$
temos que $\set{\emptyset, \set{\emptyset}}$ é um conjunto.
Aplicando uma última vez o Pairset~(\axref{pairset}) com
$a\asseq\emptyset$ e $b\asseq \set{\emptyset, \set{\emptyset}}$,
conseguimos construir o conjunto
$\set{ \emptyset, \set{\emptyset, \set{\emptyset}}}$.
}
Podemos representar essa construção em forma de árvore:
$$
\AxiomC{}
\RightLabel{\axref{emptyset}}
\UnaryInfC{$\emptyset$}
\AxiomC{}
\RightLabel{\axref{emptyset}}
\UnaryInfC{$\emptyset$}
\AxiomC{}
\RightLabel{\axref{emptyset}}
\UnaryInfC{$\emptyset$}
\AxiomC{}
\RightLabel{\axref{emptyset}}
\UnaryInfC{$\emptyset$}
\doubleLine
\RightLabel{\axref{pairset}}
\BinaryInfC{$\set{\emptyset}$}
\RightLabel{\axref{pairset}}
\BinaryInfC{$\set{\emptyset, \set{\emptyset}}$}
\RightLabel{\axref{pairset}}
\BinaryInfC{$\set{\emptyset, \set{\emptyset, \set{\emptyset}}}$}
\DisplayProof
$$
onde a dupla linha indica que pulamos alguns passos implícitios,
como o uso de Extensionality~(\axref{extensionality}) nesse caso.
Usamos agora essa construção para construir um conjunto de cardinalidade $3$:
$$
\AxiomC{}
\RightLabel{\axref{emptyset}}
\UnaryInfC{$\emptyset$}
\AxiomC{}
\RightLabel{\axref{emptyset}}
\UnaryInfC{$\emptyset$}
\AxiomC{}
\RightLabel{\axref{emptyset}}
\UnaryInfC{$\emptyset$}
\AxiomC{}
\RightLabel{\axref{emptyset}}
\UnaryInfC{$\emptyset$}
\doubleLine
\RightLabel{\axref{pairset}}
\BinaryInfC{$\set{\emptyset}$}
\RightLabel{\axref{pairset}}
\BinaryInfC{$\set{\emptyset, \set{\emptyset}}$}
\RightLabel{\axref{pairset}}
\BinaryInfC{$\set{\emptyset, \set{\emptyset, \set{\emptyset}}}$}
\RightLabel{\axref{powerset}}
\UnaryInfC{$\set{\emptyset, \set{\emptyset}, \set{\set{\emptyset, \set{\emptyset}}}, \set{\emptyset, \set{\emptyset, \set{\emptyset}}}}$}
\RightLabel{\axref{separation},\ $\phi(x)\asseq \exists w(w\in x)$}
\UnaryInfC{$\set{\set{\emptyset}, \set{\set{\emptyset, \set{\emptyset}}}, \set{\emptyset, \set{\emptyset, \set{\emptyset}}}}$}
\DisplayProof
$$
Observe que para usar o \axref{separation} precisamos especificar qual é a fórmula--filtro.
\endexample
%%}}}

%%{{{ eg: tree_construction_with_open_leaves 
\example.
\label{tree_construction_with_open_leaves}%
Seja $a,b$ conjuntos.
Mostre que $\set{b, \set{\emptyset, \set{a}}}$ é conjunto.

\solution
$$
\AxiomC{$b$}
\AxiomC{}
\RightLabel{Empty}
\UnaryInfC{$\emptyset$}
\AxiomC{$a$}
\doubleLine
\RightLabel{Singleton}
\UnaryInfC{$\set{a}$}
\RightLabel{Pair}
\BinaryInfC{$\set{\emptyset, \set{a}}$}
\RightLabel{Pair}
\BinaryInfC{$\set{b, \set{\emptyset, \set{a}}}$}
\DisplayProof
$$
Onde deixamos as ``folhas'' da árvore $a,b$ ``sem fechar'', pois
correspondem realmente em nossas hipotéses: os conjuntos $a,b$ são dados!
Observe também que ``Singleton'' se-refere no~\ref{singleton_thm}.

\endexample
%%}}}

%%{{{ x: tree_construction_practice 
\exercise.
\label{tree_construction_practice}%
Sejam $a,b,c,d$ conjuntos.
Mostre pelos axiomas que os seguintes também são:
$$
\align
A &= \set{a,b,c,d}\\
B &= \set{a,b, \set{c,d}}\\
C &= \setstt x {$x \subset a\union b\union c\union d$\ \;\&\;\ $x$ tem exatamente 2 membros}
\endalign
$$
Use a método de árvores para umas construções e outras faça escrevendo em texto mesmo.
É bom practicar os dois jeitos.

\solution
Como $a,b$ são conjuntos, pelo Pairset o $\set{a,b}$ também é.
Similarmente o $\set{c,d}$ é conjunto, e aplicando mais uma vez o Pairset neles
temos que o $\set{\set{a,b},\set{c,d}}$ é conjunto.
Agora aplicando o Union nele o ganhamos o $A$.
\endgraf
\bigskip
\noindent
Aqui uma construção do $B$ pelos axiomas, em forma de árvore:
$$
\AxiomC{$a$}
\AxiomC{$b$}
\RightLabel{Pair}
\BinaryInfC{$\set{a,b}$}
\AxiomC{$c$}
\AxiomC{$d$}
\RightLabel{Pair}
\BinaryInfC{$\set{c,d}$}
\RightLabel{Singleton}
\doubleLine
\UnaryInfC{$\set{\set{c,d}}$}
\RightLabel{Pair}
\BinaryInfC{$\set{\set{a,b},\set{\set{c,d}}}$}
\RightLabel{Union}
\UnaryInfC{$\set{a,b,\set{c,d}}$}
\DisplayProof
$$
\endgraf
\bigskip
\noindent
Para o $C$, usamos o Separation~(\axref{separation})
no $\pset \paren{\Union A}$, que é conjunto graças aos Union (\axref{unionset})
\& Powerset (\axref{powerset}):
$$
\AxiomC{$A$}
\RightLabel{ZF6}
\UnaryInfC{$\Union A$}
\RightLabel{ZF5}
\UnaryInfC{$\pset\Union A$}
\RightLabel{ZF4}
\UnaryInfC{$C$}
\DisplayProof
$$
onde na aplicação de ZF4 usamos a fórmula
$
\exists u \exists v
\paren{ u \neq v \land \forall w(w \in x \liff w = u \lor w = v ) }
$.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Foundations of mathematics 
\section Fundações de matemática.

%%{{{ A low-level language for mathematics 
\note Uma linguagem ``low-level'' para matemática.
Fazendo uma analogia entre matemática e programação,
dizemos que a teoria de conjuntos pode servir como uma certa low-level linguagem
em qual podemos ``compilar'' (traduzir, representar, \dots)~todos os high-level
conceitos que nos interessam em matemática!
As ``definições'' (assim entre aspas) que temos usado até agora para os vários
tipos e conceitos que encontramos não foram formais.
Nossa tarefa então aqui é tirar essas aspas.
Dar uma definição formal dum conceito significa defini-lo dentro da
teoria de conjuntos.
No final das contas, tudo vai ser representado dentro da FOL da teoria de conjuntos,
pegando como noções primitívas \emph{apenas} os ``$\Set(\dhole)$'' de ``ser conjunto''
e o ``$\dhole\in\dhole$'' de ``pertencer''.
Já temos uma primeira biblioteca construida até agora,
um certo \emph{açúcar\ii{açúcar sintáctico}\ sintáctico}.
E cada vez que conseguimos compilar algo dentro da teoria de conjuntos,
ganhamos não apenas o próprio algo para seus usos e suas aplicações,
mas também algo mais para usar para nossas próximas compilações.
%%}}}

%%{{{ Our inventory so far 
\note Nosso inventório até agora.
Vamos resumir todos os operadores e predicados que temos já definido
dentro da teoria de conjuntos, usando apenas os axiomas que encontramos
até agora.
Temos:
$$
\gather
\emptyset \;;\\
\set \dhole \;;\quad
\set{\dhole,\dhole} \;;\quad
\set{\dhole,\dotsc,\dhole} \;;\quad
\set{x \in \dhole \st \phi(x)} \;;\\
\dhole \inter \dhole \;;\quad
\dhole \union \dhole \;;\quad
\dhole \setminus \dhole \;;\quad
\dhole\symdiff \dhole \;;\quad
\Union \dhole \;;\quad
\pset \dhole
\endgather
$$
{e com o proviso de $a$ conjunto com $a\neq\emptyset$ também o}
$$
\dsize\Inter a\,.
$$
Observe-se então que de todos esses operadores, o $\Inter\dhole$ é
o único operador \emph{parcial}.
Mas isso não é nada novo como conceito:
no final das contas, estamos usando operadores parciais o tempo todo
trabalhando com números reais: o $\dhole / \dhole$ por exemplo
não é definido quando seu segundo argumento é o $0$, e a mesma coisa
sobre a operação (unária) de inverso: o $0^{-1}$ também não é definido.
%%}}}

%%{{{ From specification to implementation 
\note De especificação para implementação.
Quando queremos representar algum \emph{tipo} de coisa
dentro do nosso mundo de conjuntos,
precisamos esclarecer qual é a \emph{especificação} desse tipo.
Quais propriedades desejamos dos objetos desse tipo?
O que precisamos para construir um objeto desse tipo?
Quando identificamos dois objetos desse tipo e os consideramos iguais?
Como podemos usar os objetos desse tipo?
Qual é a ``interface'' deles?
Talvez ajuda pensar que nossa tarefa é similhante de um ``vendedor
de implementações matemáticas''.
Nossos ``clientes'' são os próprios matemáticos que desejam usar certos
tipos de objetos matemáticos, e nos seus pedidos eles estão esclarecendo
quais são as propriedades que eles precisam.
Nosso trabalho então será:
\emph{implementar} essa especificação, ou seja,
\emph{representar fielmente} esses tipos e conceitos como conjuntos.
Para conseguir isto:
(1) \emph{definimos} os conceitos e objetos como conjuntos;
(2) \emph{provamos} que nossa implementação realmente atende as especificações.
Muitas vezes vamos até oferecer uma \emph{garantia de unicidade}
para mostrar para nosso cliente-matemático que ele não precisa
procurar outras implementações alternativas da nossa concorrência,
pois \emph{essencialmente} nem tem!
%%}}}

\blah.
Nosso próximo trabalho será representar as tuplas,
e por isso vamos analizar em muito detalhe essa especificação.
Depois relaxamos um pouco deixando uns detalhes tediosos como
``óbvios''.

\endsection
%%}}}

%%{{{ Constructing the tuples 
\section Construindo as tuplas.

%%{{{ Specification 
\note Especificação.
\label{tup_specification}%
Vamos começar com o trabalho de implementar tuplas de tamanho 2,
ou seja \emph{pares ordenados}.
Precisamos então definir \emph{um} operador
$\tup{\dhole,\dhole}$ que atende as especificações.
Primeiramente:
$$
\tup{x, y} = \tup{x', y'} \implies x = x' \mland y=y'.
\taglabel{TUP1}{spec_tup1}
$$
Mas precisamos mais que isso.
Dados conjuntos $A$ e $B$ queremos que
$$
\text{a \emph{classe}}
\quad
A\times B = \class z {
\pexists {x \in A}
\lexists {y \in B}
{z = \tup {x,y}}
}
\quad
\text{é um \emph{conjunto}}.
\taglabel{TUP2}{spec_tup2}
$$
Lembrando a idéia de tupla como black\ii{black box}[de tupla]\ box,
a interface que desejamos consiste em duas operações,
as \emph{projecções}
$\first$ e $\second$ tais que
$$
\first \tup{x,y} = x
\qqqquad
\text e
\qqqquad
\second \tup{x,y} = y.
$$
Queremos definir também um predicado $\Pair(\dhole)$
para afirmar que um certo objeto representa um par ordenado.
Isso é facil:
$$
\Pair(z) \defiff
\exists x
\exists y
\paren{
z = \tup {x,y}
}
$$
Finalmente, precisamos e confirmamos:
$$
\Pair(z) \iff z = \tup{ \first(z), \second(z) }.
$$
Anotamos também que assim que definir \emph{funções} dentro
da teoria de conjuntos, vamos mostrar a existência das funções
$$
\xalignat2
\pi_0 &\eqtype A\times B \to A &  \pi_1&\eqtype A\times B \to B\\
\pi_0\tup{x,y} &= x            &  \pi_1\tup{x,y} &= y
\endxalignat
$$
para todos os conjuntos $A$ e $B$.
%%}}}

%%{{{ x: op1_converse_direction_by_logic 
\exercise.
\label{op1_converse_direction_by_logic}%
No \ref{spec_tup1} botamos ``$\Longrightarrow$'' em vez de ``$\Longleftrightarrow$''.
Por quê?  O que acontece com a ``$\Longleftarrow$''?

\hint
Como a direção ``$\Longleftarrow$'' poderia ser inválida?

\solution
A direção ``$\Longleftarrow$'' é garantida pela nossa lógica:
a propriedade da igualdade $=$,
que nos permite substituir iguais por iguais em qualquer expressão.

\endexercise
%%}}}

%%{{{ x: first_attempt_pair 
\exercise.
\label{first_attempt_pair}%
Prove que a operação
$$
\tup{x,y} \defeq \set{x,y}
$$
satisfaz uma das \ref{spec_tup1}~\&~\ref{spec_tup2}
mas não a outra, então essa
\emph{não} é uma implementação de par ordenado

\endexercise
%%}}}

\blah.
Nossa primeira tentativa não deu certo.
Mesmo assim é realmente possível implementar pares ordenados
como conjuntos!  Como?
\spoiler.

%%{{{ df: kuratowski_pair 
\definition par de Kuratowski.
\label{kuratowski_pair}%
\Kuratowski[par]%
Sejam $x,y$ objetos.
Definimos
$$
\tup{x,y} \defeq \kurpair x y.
$$
%%}}}

%%{{{ x: kurpair_satisfies_tup0 
\exercise.
\label{kurpair_satisfies_tup0}%
Mostre pelos axiomas que o operador $\tup{\dhole, \dhole}$ de Kuratowski
é bem-definido, ou seja: dados objetos $x,y$, o $\tup{x,y}$ é conjunto.

\endexercise
%%}}}

%%{{{ prop: kurpair_satisfies_tup1 
\proposition.
\label{kurpair_satisfies_tup1}%
O operador $\tup{\dhole, \dhole}$ de Kuratowski satisfaz a~\ref{spec_tup1}.
\sketch.
Suponha $\tup{x,y} = \tup{x',y'}$.
Logo
$$
\kurpair x y = \kurpair {x'} {y'}.
$$
Precisamos deduzir que $x=x'$ e $y=y'$ mas ainda não é claro.
O que temos é apenas igualdade desses dois conjuntos, que não
garanta o que queremos imediatamente.
Não podemos concluir nem que
$$
\alignat3
\set {x} &= \set {x'}
&\qquad&\mland\qquad&
\set {x,y} &= \set {x',y'},\\
\intertext{%
pois pela definição de igualdade de conjuntos (\axref{extensionality})
sabemos apenas que cada membro do conjunto no lado esquerdo
é algum membro do conjunto no lado direito e vice-versa.
Então, talvez
}
\set {x} &= \set { x',y'}
&\qquad&\mland\qquad &
\set {x,y} &= \set {x'}.
\endalignat
$$
Precisamos então separar em casos:
$x = y$ ou não.
Em cada caso argumentamos usando o (\axref{extensionality}) e a
cardinalidade dos conjuntos para progressar até chegar nos desejados
$x=x'$ e $y=y'$.
\qes
%%}}}

%%{{{ prop: kurpair_satisfies_tup2 
\proposition.
\label{kurpair_satisfies_tup2}%
O operador $\tup{\dhole, \dhole}$ de Kuratowski satisfaz a~\ref{spec_tup2}.
\proof.
Sejam $A,B$ conjuntos.
Precisamos mosrar que a classe
$$
A\times B = \class z {
\pexists {x \in A}
\lexists {y \in B}
{z = \tup {x,y}}
}
$$
é um conjunto.
Como já temos escrita a classe nessa forma, basta achar um conjunto $W$
que contem todos os pares que queremos, e aplicar esse mesmo filtro
para ficar apenas com eles mesmo.
Como parece o aleatório $\tup{a,b} \in A\times B$?
$$
a\in A
\mland
b\in B
\implies
\tup{a,b} = \kurpair a b \in \mathord{?}
$$
Vamos ver:
\stepproof
\proofsteptnb {Suponha $a\in A$ e $b\in B$.}
\thereforetby {$a,b \in A\union B$}                               {def.~$\union$}
\thereforetby {$\set {a}, \set{a,b} \subset A \union B$}          {def.~$\subset$}
\thereforetby {$\set {a}, \set{a,b} \in \pset\paren{A \union B}$} {def.~$\pset$}
\thereforetby {$\kurpair a b \subset \pset\paren{A \union B}$}    {def.~$\subset$}
\thereforetby {$\kurpair a b \in \pset\pset\paren{A \union B}$}   {def.~$\pset$}
\thereforetby {$\tup {a, b} \in \pset\pset\paren{A \union B}$}    {def.~$\tup{a,b}$}
\endstepproof
Tome então $W\asseq \pset\pset\paren{A \union B}$
e defina
$$
A \times B \defeq \setst { z \in \pset\pset\paren{A\union B} } {
\pexists {x \in A}
\lexists {y \in B}
{z = \tup {x,y}}
}
$$
que é conjunto graças ao Separation~(\axref{separation}).
\qed
%%}}}

%%{{{ Being agnostic 
\note Sendo agnósticos.
\tdefined{agnóstico}%
Acabamos de encontrar \emph{um} operador de par ordenado:
do Kuratowski\Kuratowski{}.
Ele não é o único possível, mas para continuar com nossa teoria,
precisamos apenas mostrar que existe um.
Vamos usar o símbolo $\tup{\dhole,\dhole}$ sem esclarecer se realmente é
a implementação de Kuratowski que usamos, ou alguma outra implementação.
Tomando cuidado, sobre esse operador nos permitimos usar
\emph{apenas as propriedades da sua especificação e nada mais}:
as \ref{spec_tup1}~\&~\ref{spec_tup2} do \refn{tup_specification}.
Falamos então que estamos sendo $\tup{\,}$-\dterm{agnósticos}.
Por exemplo, não podemos afirmar que $\set {x} \in \tup {x,y}$.
Sim, isso é valido com a implementação de Kuratowski, mas é uma
\emph{coincidência} e não uma \emph{conseqüência} da especificação
de par ordenado.
Talvez outra implementação não tem essa propriedade,
como tu vai descobrir agora provando que o $\tup{\dhole,\dhole}$
do~Wiener\Wiener{} também é uma implementação de par ordenado.
%%}}}

%%{{{ x: wiener_pair 
\exercise par de Wiener.
\label{wiener_pair}%
\Wiener[par]%
Mostre pelos axiomas que a operação $\tup{\dhole,\dhole}$ definida pela
$$
\tup{x,y} \defeq \bigset{ \set{ \emptyset, \set{x} }, \set{ \set{ y } } }
$$
é uma implementação bem-definida de par ordenado
(ou seja, dados $x,y$ o $\tup{x,y}$ é um conjunto sim)
que satisfaz as~\ref{spec_tup1}~\&~\ref{spec_tup2}.%
\footnote{Wiener definiu essa operação uns anos \emph{antes} da definição de Kuratowski.}

\hint
Trabalhe como fizemos para o par ordenado de Kuratowski
no~\ref{kurpair_satisfies_tup0} e nas
proposições~\refn{kurpair_satisfies_tup1}--\refn{kurpair_satisfies_tup2}.

\solution
Primeiramente verificamos que dados objetos $x,y$, o $\tup{x,y}$
realmente é um conjunto:
$$
\AxiomC{}
\RightLabel{Empty}
\UnaryInfC{$\emptyset$}
\AxiomC{$x$}
\RightLabel{Singleton}
\doubleLine
\UnaryInfC{$\set{x}$}
\RightLabel{Pair}
\BinaryInfC{$\set{\emptyset, \set{x}}$}
\AxiomC{$y$}
\RightLabel{Singleton}
\doubleLine
\UnaryInfC{$\set{y}$}
\RightLabel{Singleton}
\doubleLine
\UnaryInfC{$\set{\set{y}}$}
\RightLabel{Pair}
\BinaryInfC{$\set{\set{\emptyset,\set{x}}, \set{\set{y}}}$}
\DisplayProof
$$
\proofpart{\ref{spec_tup2}:}
Sejam $A,B$ conjuntos.
Queremos mosrar que a classe
$$
A\times B = \class {\tup{x,y}} {
x\in A
\mland
y\in B
}
$$
é um conjunto.
Como na prova da~\ref{kurpair_satisfies_tup2},
Basta achar um conjunto $W$ que contem o arbitrário $\tup{a,b}\in A\times B$,
pois depois aplicamos o Separation~(\axref{separation}) com a mesma
fórmula da~\ref{kurpair_satisfies_tup2} para ganhar o $A\times B$.
Um conjunto que serve como $W$ é o $\pset\pset\pset(A\union B)$,
como verificamos aqui, escrevendo a derivação em forma de árvore:
$$
\AxiomC{}
\UnaryInfC{$\emptyset\in\pset(A\union B)$}
\AxiomC{$a \in A$}
\UnaryInfC{$a \in A\union B$}
\UnaryInfC{$\set{a} \in \psetp{A\union B}$}
\BinaryInfC{$\set{\emptyset,\set{a}} \in \pset\psetp{A\union B}$}
\AxiomC{$b \in B$}
\UnaryInfC{$b \in A\union B$}
\UnaryInfC{$\set{b} \in \psetp{A\union B}$}
\UnaryInfC{$\set{\set{b}} \in \pset\psetp{A\union B}$}
\BinaryInfC{$\set{\set{\emptyset,\set{a}}, \set{\set{b}}}\in\pset\pset\psetp{A\union B}$}
\DisplayProof
$$

\endexercise
%%}}}

%%{{{ x: hausdorff_pair 
\exercise par de Hausdorff.
\label{hausdorff_pair}%
\Hausdorff[par]%
Considere $0$ e $1$ dois objetos distintos (algo que nossos axiomas garantam).
Para ser especifico, tome $0\asseq\emptyset$ e $1\asseq\set\emptyset$.
Prove que a operação
$$
\tup{x,y} \defeq \bigset{ \set{0, x}, \set{1, y} }
$$
também é uma implementação de par ordenado.

\hint
Calcule os $\tup {0,0}$, $\tup {0,1}$, $\tup {1,0}$, $\tup {1,1}$.

\hint
Separe em casos: $x=y$ ou não.

\endexercise
%%}}}

%%{{{ x: bad_pair 
\exercise Bad pair.
\label{bad_pair}%
Prove que não podemos usar a operação
$$
\tup{x,y} \defeq \bigset{ x, \set{y} }
$$
como uma implementação de par ordenado.

\hint
O $\tup{x,y}$ não satisfaz a~\ref{spec_tup1}.
Mostre um contraexemplo, ou seja, ache objetos $x,y,x',y'$ tais que:
$$
\tup{x,y} = \tup{x',y'}
$$
e mesmo assim não temos $x=x'$ e $y=y'$.

\solution
Seja $o$ qualquer conjunto (tome $o \asseq \emptyset$ por exemplo).
Considere o $\set{\set{o}, \set{\set{o}}}$.
Ele representa algum par ordenado?
Calculamos:
$$
\align
\tup{ \set{o}, \set{o} } &= \set{\set{o}, \set{\set{o}}} \\
\tup{ \set{\set{o}}, o } &= \set{\set{\set{o}}, \set{o}}
\endalign
$$
Observe que os conjuntos nos lados direitos são iguais:
$$
\set{\set{o}, \set{\set{o}}}
=
\set{\set{\set{o}}, \set{o}}
$$
e logo
$$
\tup{ \set{o}, \set{o} }
=
\tup{ \set{\set{o}}, o }.
$$
Isso já mostra que a~\ref{spec_tup1} não é satisfeita, pois
$\set{o} \neq \set{\set{o}}$.
(E nem $\set{o}=o$ mas só precisamos uma das duas ser falsa
para concluir que a propriedade não é satisfeita.)
\hfill\mistakesymbol
\endgraf
A prova que acabamos de escrever tem um roubo sutil,
que é muito fácil corrigir, mas difícil identificar!
Para corrigi-lo, basta tomar o conjunto $\emptyset$
onde tomamos um arbitrário conjunto $o$, e a prova
vira correta!
O \ref{find_the_crime_of_foundation} pede identificar
o problema.

\endexercise
%%}}}

%%{{{ x: spooky_pair 
\exercise Spooky pair.
\label{spooky_pair}%
Considere a operação
$$
\tup{x,y} \defeq \bigset{ x, \set{x,y} }
$$
como uma implementação de par ordenado.
Prove que ela satisfaz a~\ref{spec_tup2}.
Sobre a~\ref{spec_tup1}, a situação é mais complicada.
Nesse momento não podemos provar que ela é satisfeita,
mas nem construir um contraexemplo!
Mesmo assim, vale a pena pensar:
que conjunto (spooky!) serviria?
Deixo isso para o~\ref{spooky_pair_problem}.

\hint
Para provar a~\ref{spec_tup2}, dados conjuntos $a,b$,
tome $x\in a$ e $y \in b$ e ache um conjunto $w$ tal que
$\tup{x,y} \in w$.
(Exatamente como a gente fez no~\ref{kurpair_satisfies_tup2}.)

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Constructing the disjoint union 
\section Construindo a união disjunta.

%%{{{ Specification 
\note Especificação.
\label{disjunion_specification}%
Queremos definir a operação binária da \emph{união\ii{união!disjunta}\ disjunta}.
%%}}}

\TODO Especificação: mention coproduct.

%%{{{ df: disjoint_union 
\definition União disjunta.
\label{disjoint_union}%
\tdefined{união}[disjunta]%
\sdefined {\sholed A \disjunion \sholed B} {a união disjunta de $A$ com $B$}%
Fixamos dois objetos distintos como os $\mathrm L\asseq \emptyset$ e $\mathrm R\asseq \set\emptyset$
e definimos:
$$
A \disjunion B
\defeq
\paren{\set{\mathrm L} \times A}
\union
\paren{\set{\mathrm R} \times B}.
$$
%%}}}

%%{{{ x: why_not_use_A_and_B_as_tags 
\exercise.
\label{why_not_use_A_and_B_as_tags}%
Uma escolha de ``tags'' para os membros dos conjuntos $A$ e $B$ seria
os próprios conjuntos $A$ e $B$ em vez dos $\emptyset$ e $\set\emptyset$
que usamos.  Qual é o problema com essa idéia?

\endexercise
%%}}}

%%{{{ x: generalize_disjunion_to_indexed_Disjunion 
\exercise.
\label{generalize_disjunion_to_indexed_Disjunion}%
Generalize a construção de união disjunta binária para
o operador ``grande'' de união disjunta indexada por algum conjunto
de índices $I$.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Constructing the relations 
\section Construindo as relações.

%%{{{ Specification 
\note Especificação.
O que precisamos de algum objeto $R$ que merece o nome de
\emph{implementação de relação de $A$ para $B$}?
Bem, primeiramente, dados $a\in A$ e $b\in B$ queremos ter
como ``perguntar'' esse objeto $R$ se o $a$ está relacionado
com o $b$.
Dados quaisquer conjuntos $c$ e $d$ queremos também que
a classe de todas as relações de $c$ para $d$ seja um conjunto.
Nossa definição tem que ser feita em tal jeito que facilita
as demais definições de operações em relações, por exemplo
a composição, os vários fechos que encontramos, etc.
\endgraf
Praticamente, \emph{nossa especificação é o~\ref{Relations}!}
%%}}}

%%{{{ df: relation_formal_def 
\definition Relação.
\label{relation_formal_def}%
Sejam $A,B$ conjuntos.
Qualquer subconjunto $R \subset A \times B$
é uma relação de $A$ para $B$.
Em outras palavras:
$$
\text{$R$ relação de $A$ para $B$}
\defiff
R \subset A \times B.
$$
Introduzimos as notações
$$
\align
x \rel R y
&\sugdefiff \tup{x,y} \in R\\
R(x,y)
&\sugdefiff \tup{x,y} \in R.
\endalign
$$
Formalmente definimos o predicado
$$
\Relation(r,a,b)
\abbrdefeq
r \subset (a \times b).
$$
%%}}}

%%{{{ remark: remember the graph of a relation? 
\remark.
No final das contas, já tivemos definido esse conceito.
Seu nome foi \emph{o gráfico da $R$}.  Lembra?
Se não, veja o~\ref{relation_graph}.
Em outras palavras, dentro da teoria de conjuntos,
com nossa~\ref{relation_formal_def},
\emph{identificamos as relações com seus gráficos: $R = \graph R$.}
%%}}}

%%{{{ warning: faithful representation 
\warning.
Enfatisamos mais uma vez que isso não quis dizer que
uma relação \emph{é} o seu gráfico (que é um conjunto)!
Mas que isso é apenas um jeito de \emph{representar fielmente}
o conceito de \emph{relação} dentro da teoria de conjuntos, ou seja:
``\emph{como se fosse} conjunto''.
%%}}}

%%{{{ Q: must we define more terminology from relations? 
\question.
Precisamos definir as demais noções e termos que encontramos no~\ref{Relations}?
Por exemplo: precisamos definir os termos ``transitiva'', ``reflexiva'', etc.?
%%}}}
\spoiler.

%%{{{ A: No! 
\blah Resposta.
Não!
Voltando no~\ref{Relations} podes verificar que todas as outras definições
dependem apenas na noção de relação mesmo
(que acabamos de definir formalmente na~\ref{relation_formal_def}).
%%}}}

%%{{{ eg: equality in A 
\example.
Seja $A$ um conjunto.
O conjunto
$$
\setst {\tup{x,x}\in A^2} {x \in A}
$$
é uma relação, pois realmente é um subconjunto de $A\times A$.
Qual relação é essa?
Ela merece seu próprio nome e sua própria notação.
\endexample
%%}}}

%%{{{ df: eqin 
\definition.
\label{eqin}%
Dado conjunto $A$, a relação de \dterm{igualdade no $A$}
é a relação
$$
{\eqin A} \defeq \setst {\tup{x,x}\in A^2} {x \in A}.
$$
Logo temos
$$
x \eqin A y \iff x = y \mland x,y \in A.
$$
%%}}}

%%{{{ prop: a_relto_b_is_a_set 
\proposition.
\label{a_relto_b_is_a_set}%
Dados conjuntos $a,b$, a classe
$$
(a \relto b)
\defeq
\classt R {$R$ é uma relação de $a$ para $b$}
$$
é um conjunto.
\proof.
Basta achar um conjunto onde todas as relações de $a$ para $b$
pertencem.
Pela definição de relação, todas pertencem ao $\pset(a\times b)$.
De fato, ainda mais é verdade:
$$
(a \relto b)
=
\pset(a\times b)
$$
e logo é um conjunto graças aos operadores (totais) $\pset$ e $\times$.
\qed
%%}}}

%%{{{ eg: reflexive_and_irreflexive_formally 
\example.
Seja $R\subset A\times A$.
Então temos
$$
\align
\text{$R$ reflexive}
&\iff {\eqin A} \subset R\\
\text{$R$ irreflexive}
&\iff {\eqin A} \inter R = \emptyset
\endalign
$$
etc.
\endexample
%%}}}

%%{{{ x: rcompose_formal_def 
\exercise.
\label{rcompose_formal_def}%
Mostre que podemos definir o operador de composição de relações
$\dhole\rcom\dhole$ em tal modo quando é aplicado em conjuntos
$a,b$ que são relações (compatíveis), o conjunto
$a\rcom b$ também é uma relação, e a correta:
a composição de $a$ com $b$.
(Lembre-se a~\ref{rcompose}.)

\endexercise
%%}}}

%%{{{ x: closures_formal_def 
\exercise.
\label{closures_formal_def}%
Defina formalmente e diretamente como conjuntos os fechos que encontramos
no~\ref{Relations}:
reflexivo (\refn{rclosure}),
simétrico (\refn{sclosure}),
transitivo (\refn{tclosure}).
Tente dar a definição mais curta, elegante, e flexível possível!

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Constructing the functions 
\section Construindo as funções.
\label{Constructing_the_functions}%

%%{{{ Specification 
\note Especificação.
Como nas relações, aqui também nossa especificação deve ser clara:
\emph{traduzir todo o~\ref{Functions} na teoria de conjuntos!}
%%}}}

%%{{{ df: function_formal_def 
\definition Função.
\label{function_formal_def}%
Sejam $A,B$ conjuntos.
Uma relação $f$ de $A$ para $B$ é chamada \dterm{função de $A$ para $B$}
sse
$$
\pforall {a \in A}
\lunique {b \in B}
{\tup{a,b} \in f}.
$$
Equivalentemente
(e para ficar mais perto das Condições~\refn{functionhood_conditions}
do~\ref{Functions}) podemos separar essa condição em duas:
$$
\gather
\pforall {a \in A}
\lexists {b \in B}
{\tup{a,b} \in f}
\tag{TOT}\\
\pforall {a \in A}
\lforall {b,b' \in B}
{\tup{a,b},\tup{a,b'} \in f \implies b = b'}.
\tag{DET}
\endgather
$$
Escrevemos
$$
f(a) = b
\defiff
\tup{a,b} \in f
$$
e também usamos
$$
f(a)
\defeq
\text{aquele único $b\in B$ tal que $\tup{a,b}\in f$.}
$$
Lembre-se que escrevemos
$f : A \to B$ ou $A \toby f B$ para dizer que
$f$ é uma função de $A$ para $B$, etc.
(Veja~\ref{function_notation}.)
Formalmente definimos o predicado
$$
\Function(f,a,b)
\sugareq
\Relation(f,a,b)
\land
\pforall {x \in a}
\lunique {y \in b}
{\tup{x,y}\in f}.
$$
%%}}}

%%{{{ prop: a_to_b_is_a_set 
\property.
\label{a_to_b_is_a_set}%
Dados conjuntos $a,b$, a classe
$$
(a \to b)
\defeq
\class f {f : A \to B}
$$
é um conjunto.
\proof.
Fácil:
$$
(a \to b)
=
\setst {f \in (a \relto b)} {f : A \to B}
$$
que é conjunto graças ao operador $(\dhole\relto\dhole)$
(\ref{a_relto_b_is_a_set}) e ao axioma da separação~\axref{separation}.
\qed
%%}}}

%%{{{ We get inj surj bij for free 
\remark.
Como as definições de ``injetora'', ``sobrejetora'', e ``bijetora''
do~\ref{Functions} dependem apenas da definição de ``função''
(que acabamos de definir), já temos essas definições na teoria de conjuntos!
Simlarmente os operadores $(\dhole\injto\dhole)$, $(\dhole\surjto\dhole)$,
e $(\dhole\bijto\dhole)$ são facilmente definidos graças
à~\ref{a_to_b_is_a_set}
e o axioma da separação~\axref{separation}.
%%}}}

%%{{{ eg: eqc_formally_defined 
\example.
\label{eqc_formally_defined}%
Uma definição alternativa e formal do $\eqc$ é a seguinte:
$$
a \eqc b \defiff (a \bijto b) \neq \emptyset.
$$
\endexample
%%}}}

%%{{{ x: fcompose_fresto_fcross
\exercise.
\label{fcompose_fresto_fcross}%
Defina formalmente as operações e construções de funções que encontramos
no~\ref{Functions}:
composição (\refn{fcompose});
restricção (\refn{fresto});
produto (\refn{fcross}).

\endexercise
%%}}}

%%{{{ x: id_char_const_as_sets 
\exercise.
Descreva curtamente as funções identidades, características, e constantes como
conjuntos.
Esses conjuntos representam outras coisas (de outros tipos)?

\endexercise
%%}}}

%%{{{ beware: we do note get partial functions for free! 
\beware.
Tem um conceito do~\ref{Functions} que \emph{não} definimos
em termos de ``função'', e logo precisamos defini-lo formalmente
aqui: a \emph{função parcial}.
%%}}}

%%{{{ df: partial_function 
\definition Função parcial.
\label{partial_function_formally_defined}%
Uma relação $f$ de $A$ para $B$ é uma \dterm{função parcial} sse
$$
\pforall {a \in A}
\lforall {b,b' \in B}
{\tup{a,b},\tup{a,b'} \in f \implies b = b'}.
\tag{DET}
$$
%%}}}

%%{{{ x: a_parto_b_is_a_set 
\exercise.
\label{a_parto_b_is_a_set}%
Dados conjuntos $a,b$, a classe
$$
(a \parto b)
\defeq
\class f {f : A \parto B}
$$
é um conjunto.

\solution
Fácil, como na prova da~\ref{a_to_b_is_a_set}:
$$
(a \parto b)
=
\setst {f \in (a \relto b)} {f : A \parto B}
$$
que é conjunto.

\endexercise
%%}}}

%%{{{ x: parto_formally_defined 
\exercise.
\label{partial_function_formally_defined_as_function}%
Ache um outro jeito para definir funções parciais como funções.
(Talvez tu já pensou nisso no~\ref{implement_partial_functions}.)
Verifique que dados conjuntos $a,b$ a classe
$(a \parto b)$ também é um conjunto.

\hint
(Resolva primeiro o~\ref{implement_partial_functions}.)
Cada função parcial $f : A \parto B$ pode ser representada
como uma função total $f : A \to B'$ onde $B'$ é um outro
conjunto.
Qual $B'$ serve?

\hint
Duas idéias razoáveis:
\endgraf\noindent
\proofstyle{Idéia 1:}
Dados conjuntos $A,B$, escolha (como?)\ um objeto fora do $B$
para representar a ``diverjão'', ou valor ``não-definido''.
Lembra-se que $\russell B \notin B$, algo que
temos graças ao \ref{russells_paradox_to_theorem}.
Então tome $B' \asseq B \union \russell B$.
\endgraf\noindent
\proofstyle{Idéia 2:}
Tome
$$
B'
\asseq
\setstt {Y \subset B} {$\Singleton(Y)$ ou $Y = \emptyset$}.
$$

\endexercise
%%}}}

%%{{{ df: parfun_compatibility 
\definition Compatibilidade.
\label{parfun_compatibility}%
\tdefined{função}[parcial!conflito]%
\tdefined{função}[parcial!compatibilidade]%
Sejam $A,B$ conjuntos e $\scr F$ uma família de funções parciais de $A$ para $B$:
$\scr F \subset (A\parto B)$.
Chamamos a $\scr F$ \dterm{compatível} sse $\Union {\scr F} \in (A\parto B)$.
Digamos que $\scr F$ tem \dterm{conflito} no $a\in A$ sse
existem $y,y'\in B$ com $y\neq y'$ e $\tup{a,y}, tup{a,y'}\in \scr F$;
equivalentemente
$$
\card{ \set{ \tup{a,y} \st y\in B } } > 1.
$$
%%}}}

%%{{{ df: approximation 
\definition Aproximação.
\label{parfun_approx}%
\tdefined{função}[parcial!aproximação]%
Seja $F : A \to B$.
Chamamos qualquer $f\subset F$ uma aproximação (parcial) da $F$.
Ela é \dterm{própria} se $f\subsetneq F$.
%%}}}

%%{{{ x: fun_approxes_is_set 
\exercise.
\label{fun_approxes_is_set}%
Seja $F : A \to B$.
Prove que a classe
$$
\class f { \text{$f$ é uma aproximação da $F$} }
$$
é um conjunto.

\solution
Usando o Separation~(\axref{separation}) escrevemos
$$
\set {f \in (A\parto B)} {f \subset F}.
$$

\endexercise
%%}}}

%%{{{ x: fun_with_approxes 
\def\Approxes{{\scr F}}
\def\FinApproxes{\Approxes_{\textrm{f}}}
\exercise.
\label{fun_with_approxes}%
Seja $F : A \to B$.
(i) Prove que:
$$
F = \Union \Approxes
$$
onde $\scr F$ é o conjunto de todas as aproximações da $F$.
(ii) É verdade também que
$$
F = \Union \FinApproxes
$$
onde $\FinApproxes$ é o conjunto de todas as aproximações finitas da $F$?

\solution
{%
\def\Approxes{{\scr F}}
\def\FinApproxes{\Approxes_{\textrm{f}}}
(i)
Tome $\tup{x,y} \in F$.
Para concluir que $\tup{x,y} \in \Union \Approxes$
precisamos achar uma aproximação $f\in\Approxes$ tal que $\tup{x,y} \in f$.
Aqui uma: a aproximação $\set{\tup{x,y}} \subset F$.
Conversamente, tome $\tup{x,y}$ in $\Union\Approxes$.
Pela definição de $\Union$ então temos que $\tup{x,y}\in f$ para alguma aproximação
$f\in\Approxes$.  Pela definição de aproximação agora, $f\subset F$, ou seja:
$\tup{x,y}\in f \subset F$.
\endgraf
(ii) Sim.  A direção $\Union \FinApproxes \subset F$ é trivial graças ao (i),
e a direção oposta também provamos no (i) pois a aproximação $\set{\tup{x,y}}$
que escolhemos nessa direção é realmente finita.
}

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Constructing_the_sequences_and_indexed_families 
\section Construindo as seqüências e famílias indexadas.
\label{Constructing_the_sequences_and_indexed_families}%

\endsection
%%}}}

%%{{{ Constructing_the_structured_sets 
\section Construindo os conjuntos estruturados.
\label{Constructing_the_structured_sets}%

\endsection
%%}}}

%%{{{ Cardinal arithmetic 
\section Aritmética cardinal.
\label{Cardinal_arithmetic}%

\endsection
%%}}}

%%{{{ Classes vs. Sets (II) 
\section Classes vs{.}~Conjuntos (II).

\note Relações e funções ``grandes demais''.
\tdefined{predicado}%
\tdefined{class-relação}%

\TODO Explicar.

%%{{{ df: functionlike 
\definition.
\label{functionlike}%
Uma fórmula $\Phi(x,y)$ é \dterm{function-like}, sse:
$$
\forall x
\unique y
\Phi(x,y)
\qquad
\text{ou seja,}
\qquad
\forall x
\exists y
\bigparen{
\Phi(x,y)
\land
\forall y'
\paren{\Phi(x,y') \limplies y = y'}}.
$$
Nesse caso, também usamos os termo \dterm{função-classe}, \dterm{operador},
e a notação comum
$$
\Phi(x) = y
\qqqtext{como sinónimo de}
\Phi(x,y).
$$
Seguindo essa linha denotamos por $\Phi(x)$ o único objeto $y$ tal que
$\Phi(x,y)$.
Assim o $\Phi(x)$ denota um \emph{objeto}, mas o $\Phi(x,y)$ uma \emph{afirmação}.
%%}}}

\endsection
%%}}}

%%{{{ Problems intermission 
\problems Intervalo de problemas.

%%{{{ someset_problem 
\problem Someset is the new Emptyset.
\label{someset_problem}%
Considere o axioma seguinte:
\endgraf
\noindent
{\bf Someset.}
{\proclaimstyle Existe algo.}
$$
\exists s \paren{ s = s }
\axtaglabel{ZF2*}{someset}
$$
Mostre que no sistema axiomático
\axref{extensionality}%
+\axref{someset}%
+\axref{pairset}%
+\axref{separation}%
+\axref{powerset}%
+\axref{unionset},
existe o $\emptyset$.%
\footnote{Dependendo do uso e do contexto, podemos considerar como parte da lógica
que o universo não é vazio, ou seja, existe algo.  Nesse caso nem precisamos
o Someset~(\axref{someset}), pois seria implícito.}

\endproblem
%%}}}

%%{{{ triset_problem 
\problem Triset is the new Pairset.
\label{triset_problem}%
Considere o axioma seguinte:
\endgraf\noindent
{\bf Triset.}
{\proclaimstyle
Dados tres objetos distintos existe conjunto com exatamente
esses membros.
}
$$
\forall a
\forall b
\forall c
\lparen{
\bigparen{
a\neq b \land b \neq c \land c \neq a
}
\limplies
\exists s
\forall x
\bigparen{x\in s \liff x = a \lor x = b \lor x = c}
}
\axtaglabel{ZF3*}{triset}
$$
%\beginil
\item{(0)}
No sistema
\axref{extensionality}%
+\axref{emptyset}%
+\axref{pairset}%
+\axref{separation}%
+\axref{powerset}%
+\axref{unionset}
construa conjunto de cardinalidade~$3$.
\item{(1)}
Prove que no mesmo sistema
podemos substituir o axioma Pairset~(\axref{pairset}) pelo axioma
Triset~(\axref{triset}) ``sem perder nada''.
Em outras palavras, prove que no sistema
\axref{extensionality}%
+\axref{emptyset}%
+\axref{triset}%
+\axref{separation}%
+\axref{powerset}%
+\axref{unionset}
\emph{para todos os $a,b$ existe o conjunto $\set{a,b}$}.
\item{(2)}
Podemos provar a mesma coisa no sistema
\axref{extensionality}%
+\axref{emptyset}%
+\axref{triset}%
+\axref{separation}%
+\axref{unionset}%
?
%\endil

\hint
Para o (1), veja o (2); para o (2), veja o (1)!

\endproblem
%%}}}

%%{{{ conset_problem 
\problem.
\label{conset_problem}%
Considere o axioma seguinte:
$$
\forall h
\forall t
\exists s
\forall x
\bigparen{
x \in s
\liff
x = h
\lor
x \in t
}.
\axtaglabel{CONS}{conset}
$$
(1)
No sistema
{\axref{extensionality}%
+\axref{emptyset}%
+\axref{conset}}
prove o \axref{pairset} como teorema.
\endgraf\noindent
(2)
Mostre que não tem como provar o \axref{conset}
no sistema
{\axref{extensionality}%
+\axref{emptyset}%
+\axref{pairset}}.
\endgraf\noindent
(3)
No sistema
{\axref{extensionality}%
+\axref{emptyset}%
+\axref{pairset}%
+\axref{separation}%
+\axref{powerset}%
+\axref{unionset}}
prove o \axref{conset} como teorema.

\solution
(1)
Dados os objetos $a,b$, queremos construir o $\set{a,b}$.
Aplicando o \axref{conset} com $h \asseq b$ e $t \asseq \emptyset$
ganhamos o $\set{b}$, e agora aplicando novamente o mesmo axioma
com $h \asseq a$ e $t \asseq \set{b}$ ganhamos o desejado $\set{a,b}$.
\endgraf\noindent
(2)
Observe que com os axiomas
\axref{extensionality}%
+\axref{emptyset}%
+\axref{conset}\ 
conseguimos construir conjuntos de qualquer cardinalidade finita,
mas com os
\axref{extensionality}%
+\axref{emptyset}%
+\axref{pairset}\ 
conseguimos construir apenas conjuntos com cardinalidades $0$, $1$, ou $2$.
Basta realmente construir um conjunto com cardinalidade maior que $2$ então.
Aplique o \axref{conset} com $h,t \asseq \emptyset$ ganhando assim
o $\set{\emptyset}$.
Agora com $h \asseq \set\emptyset$ e $t \asseq \emptyset$ ganhando
o $\set{\set{\emptyset}}$.
Com $h \asseq \emptyset$ e $t \asseq \set{\set{\emptyset}}$
ganhamos o $\set{\emptyset, \set{\emptyset}}$.
E finalmente, com $h,t \asseq \set{\emptyset, \set{\emptyset}}$
construimos o $\set{\emptyset, \set{\emptyset}, \set{\emptyset, \set{\emptyset}}}$,
que tem cardinalidade $3$.
\endgraf\noindent
(3)
Sejam $h, t$ conjuntos.
Pelo singleton (\ref{singleton_thm}) ganhamos o $\set h$,
e usando a união binária (\ref{union_and_symdiff_constructed})
nos $\set h$ e $t$ ganhamos o desejado conjunto.

\endproblem
%%}}}

%%{{{ one_class_set_the_other_proper_problem 
\problem.
\label{one_class_set_the_other_proper_problem}%
Sejam $a,b$ conjuntos.
Mostre pelos axiomas \axref{extensionality}--\axref{unionset} que:
\item{(i)}  a classe $\class {\set{x,\set y}} {x \in a \land y \in b}$ é conjunto;
\item{(ii)} a classe $\classt {\set{x,y}} {$x,y$ conjuntos com $x\neq y$}$ é própria.

\hint
(ii) Absurdo.

\endproblem
%%}}}

%%{{{ two_sets_and_one_proper_class_problem 
\problem.
\label{two_sets_and_one_proper_class_problem}%
Sejam $a,b$ conjuntos.
Mostre pelos axiomas \axref{extensionality}--\axref{unionset} que as classes
$$
\align
C &= \class {\set{x, \set{x,y}}} {x \in a \land y \in b} \\
D &= \class {\set{x,y}} {
          \paren{ x \in a \lor x \in \Union a }
          \land
          \paren{y \in b \lor y \subset b}
    } \\
\intertext{são conjuntos, mas não a classe}
Z &= \class {\Inter\Inter z} {z \neq \emptyset \land \Inter z \neq \emptyset}.
\endalign
$$

\endproblem
%%}}}

%%{{{ finite_set_constructor_proof 
\problem.
\label{finite_set_constructor_proof}%
Demonstre o~\ref{finite_set_constructor}.

\hint
Indução!

\endproblem
%%}}}

%%{{{ construct_pfset 
\problem.
\label{construct_pfset}%
Demonstre que para todo conjunto $a$, o $\pfset a$ também é conjunto.
Ganhamos assim mais um construtor (unário) de conjuntos: $\pfset\dhole$.

\hint
O desafio aqui é conseguir escrever a afirmação
``o $x$ é um conjunto finito'' com uma fórmula.

\endproblem
%%}}}

\endproblems
%%}}}

%%{{{ The axiom of infinity 
\section O axioma da infinidade.

%%{{{ No infinite sets but Infinite(-) predicate 
\note.
Com todos os nossos axiomas até agora, mesmo tendo conseguido
representar tanta matemática fielmente dentro da teoria de conjuntos,
ainda \emph{não é garantida} a existência de nenhum conjunto infinito.
Mesmo assim, a noção de ``ser infinito'' pode sim ser expressada
em nossa dicionário, num jeito genial graças ao Dedekind\Dedekind{},
que deu a primeira definição de infinito que não presupõe
a definição dos números naturais.  Como?
\spoiler.
%%}}}

%%{{{ df: Dedekind-infinite 
\definition Dedekind-infinito.
\tdefined{Dedekind-infinito}
\sdefined {\Infinite(\sholed a)} {o conjunto $a$ é Dedekind-infinito}
Seja $A$ conjunto.  Chamamos o $A$ \Dedekind[infinito]\dterm{Dedekind-infinito} sse
ele pode ser ``injetado'' para um subconjunto próprio dele, ou seja,
sse existem $X\subsetneq A$ e $f : A \bijto X$.
Definimos então o predicado
$$
\Infinite(a) \defiff \exists x
\paren{
x\subsetneq a \land (a \eqc x)
}.
$$
%%}}}

%%{{{ Set successor 
\note Conjunto-sucessor.
\ii{conjunto-sucessor}
%%}}}

%%{{{ df: setsucc 
\definition Zermelo, von Neumann.
\tdefined {conjunto-sucessor}%
\sdefined {\setsucc {\sholed x}} {o conjunto-sucessor de $x$}%
Definimos
\vonNeumann[conjunto-sucessor]%
\Zermelo[conjunto-sucessor]%
o \dterm{conjunto-sucessor} dum conjunto $x$ ser o
$$
\align
\setsucc x &\defeq \set x           \tag{Zermelo}\\
\setsucc x &\defeq x \union \set x. \tag{von Neumann}
\endalign
$$
Como não existe ambigüidade, omitimos parenteses escrevendo por exemplo
$\setsucc{\setsucc{\setsucc x}}$ em vez de
$\setsucc{(\setsucc{(\setsucc x)})}$.
%%}}}

%%{{{ ax: Infinity 
\axiom Infinity.
\tdefined{axioma}[Infinity]%
\label{infinity}%
Existe um conjunto que tem o $\emptyset$ como membro e é fechado pela
operação $\lam x {\setsucc x}$.
$$
\exists s
\bigparen{
\emptyset \in s
\land
\forall x
\paren{
x \in s
\limplies
\setsucc x \in s
}
}
\axtaglabel{ZF7}{infinity}
$$
%%}}}

%%{{{ x: infinity_axiom_guarantees_natlike_object 
\exercise.
Verdade ou falso?
Com o axioma Infinity~(\axref{infinity}) é garantida a existéncia \emph{do} conjunto
$$
\set {
\emptyset,
\setsucc\emptyset,
\setsucc{\setsucc{\emptyset}},
\setsucc{\setsucc{\setsucc{\emptyset}}},
\dotsc
}.
$$
(Escrevemos ``do'' em vez de ``dum'' pois o axioma
Extensionality~(\axref{extensionality}) garanta que se existe, existe único.)

\hint
\emph{Não é} uma conseqüência imediata do~Infinity~(\axref{infinity}).
Por que não?

\endexercise
%%}}}

%%{{{ df: wrong_definition_of_I 
\definition.
\label{wrong_definition_of_I}%
Seja $I$ o conjunto cuja existência é garantida pelo axioma Infinity~(\axref{infinity}).
Ou seja, o conjunto que satisfaz a condição:
$$
\emptyset \in I \land \forall x \paren{x \in I \limplies \setsucc x \in I}.
$$
\mistake
%%}}}

%%{{{ x: def_of_I_used_definite_articile 
\exercise.
\label{def_of_I_used_definite_articile}%
Qual o problema com a \ref{wrong_definition_of_I}?

\hint
O artigo.

\solution
Para definir $I$ como \emph{o} conjunto que satisfaz tal propriedade
precisamos: \emph{existência \& unicidade}.
Existéncia é o que~\axref{infinity} garanta;
mas não temos---e nem podemos provar---unicidade.
Então precisamos definir o $I$ como \emph{um} conjunto
que satisfaz aquela condição.

\endexercise
%%}}}

%%{{{ Effects and side-effects 
\note Efeitos e efeitos colaterais.
O axioma Infinity~(\axref{infinity}) é o segundo dos nossos axiomas
que garanta diretamente a existência dum certo objeto;
o primeiro foi o Emptyset~(\axref{emptyset}).%
\footnote{Pois todos os outros começam com quantificadores universais.}
Assim que aceitamos o Emptyset, nos definimos o símbolo $\emptyset$
para ser \emph{o} conjunto vazio.
Para poder fazer isso precisamos \emph{provar} a unicidade
do conjunto vazio~(\ref{uniqueness_of_emptyset}).
Mas a condição que aparece no~\axref{infinity} não é
suficientemente forte para ganhar unicidade pelo~\axref{extensionality}!
Possivelmente (e realmente, como nos vamos ver) nosso mundo tem muitos
conjuntos com essa propriedade!
%%}}}

%%{{{ x: def_of_I_used_definite_articile 
\exercise.
\label{infinitely_many_infinite_sets}%
Mostre que já é garantida uma infinidade de conjuntos infinitos.

\hint
Olha para os subconjuntos de $I$.

\solution
Tome
$$
\align
I_0 &\asseq I\\
I_1 &\asseq I \setminus \set{ \emptyset }\\
I_2 &\asseq I \setminus \set{ \emptyset, \setsucc\emptyset }\\
I_3 &\asseq I \setminus \set{ \emptyset, \setsucc\emptyset, \setsucc\emptyset }\\
    &\eqvdots
\endalign
$$

\endexercise
%%}}}

%%{{{ How does this infinite set look like? 
\note Como parece esse conjunto infinito?.
Bem; sabemos que $I$ é infinito e tal, mas quais são os elementos dele?
É tentador pensar que $I$ é o conjunto
$$
I_* \pseudodefeq \set { \emptyset, \setsucc\emptyset, \setsucc{\setsucc\emptyset}, \setsucc{\setsucc{\setsucc{\emptyset}}},\dotsc}.
$$
No final das contas, vendo o~\axref{infinity},
\emph{o que mais poderia estar no $I$?}
Nada.  Certo?
Não.  Bem o oposto!
\emph{Absolutamente tudo} pode pertencer nesse $I$, pois a única informação
que temos sobre ele não tira nenhum objeto como possível membro dele!
Realmente, os únicos elementos \emph{garantidos} no $I$ são aqueles que escrevemos
acima como membros do $I_*$, mas o $I$ pode ter mais: pode ter ``lixo'', como esse:
$$
I_{\spade,\heart} \pseudodefeq \set {
\emptyset,
\spade,
\heart,
\setsucc\emptyset,
\setsucc{\setsucc\emptyset},
\setsucc{\setsucc{\setsucc{\emptyset}}},
\dotsc
}.
$$
Aqui os $\spade$ e $\heart$ denotam dois objetos do nosso universo,
talvez nem são conjuntos, talvez denotam os próprios símbolos
``$\spade$'' e ``$\heart$'', talvez somos nos, eu e tu, etc.
Para a gente, é o lixo.%
\footnote{Sem ofensa.}
\endgraf
Na verdade, esse último conjunto não pode ser o nosso $I$, pois ele não
satisfaz a condição do~(\axref{infinity}) pois
$$
\spade \in I
\qqtext{mas}
\setsucc\spade \notin I.
$$
Podemos então entender melhor nosso $I$.
Ele é um superconjunto do $I_*$---isto é garantido pelo~(\axref{infinity}) mesmo.
O que mais ele tem?  Não sabemos dizer, mas sabemos que \emph{se tem} outros objetos,
ele obrigatoriamente tem uma infinidade de conjuntos para cada um deles:
$$
\set {
\emptyset,
\spade,
\heart,
\setsucc{\emptyset},
\setsucc{\spade},
\setsucc{\heart},
\setsucc{\setsucc\emptyset},
\setsucc{\setsucc{\spade}},
\setsucc{\setsucc{\heart}},
\setsucc{\setsucc{\setsucc{\emptyset}}},
\setsucc{\setsucc{\setsucc{\spade}}},
\setsucc{\setsucc{\setsucc{\heart}}},
\dotsc
}.
$$
Vamos revisar esse $I$ então.
{\def\noise{\mathord{\;\vdots\;}}
Sabemos que ele parece assim:
$$
I = \set {
\emptyset,
\noise,
\setsucc{\emptyset},
\noise,
\setsucc{\setsucc{\emptyset}},
\noise,
\setsucc{\setsucc{\setsucc{\emptyset}}},
\noise,
\setsucc{\setsucc{\setsucc{\setsucc{\emptyset}}}},
\noise,
\dotsc
}
$$
onde os $\noise$ representam o lixo,
e nosso próximo trabalho será achar um jeito para nos livrar desse lixo!
}
%%}}}

\endsection
%%}}}

%%{{{ Constructing the natural numbers 
\section Construindo os números naturais.

%%{{{ Specification 
\note Especificação.
Primeiramente precisamos esclarecer o que precisamos implementar.
Qual é o ``pedido'' do cliente que queremos atender?
Quais são as leis (suficientes e necessárias) que os números naturais devem
respeitar?
\spoiler.
%%}}}

%%{{{ Peano system 
\definition Sistema Peano.
\tdefined{sistema Peano}%
\tdefined{princípio}[da indução, Peano]%
\label{Peano_system}%
Um \dterm{sistema Peano}\Peano[sistema]~é um conjunto estruturado
$\cal N = \sset \Nats {\Zero,\Succ}$ que satisfaz as leis:
$$
\alignat2
&\text{Zero é um número natural:}&\qquad&\Zero \in \Nats                                 \tag{P1}\\
&\text{O sucessor é uma operação unária nos naturais:}&&\Succ \eqtype \Nats \to \Nats    \tag{P2}\\
&\text{Naturais diferentes tem sucessores diferentes:}&&\Succ \eqtype \Nats \injto \Nats \tag{P3}\\
&\text{Zero não é o sucessor de nenhum natural:}&&\Zero \notin \img \Succ \Nats          \tag{P4}\\
&\text{Os naturais satisfazem o princípio da indução:}                                   \tag{P5}
\endalignat
$$
\dterm{Princípio da indução}\/:
\emph{para todo $X\subset \Nats$,}
$$
\bigparen{
\Zero\in X
\land
\forall n
\paren{
n \in X \limplies \Succ n \in X
}
} \limplies X = \Nats.
$$
Observe que graças às (P3) e (P4) temos
$$
\gather
\Succ n = \Succ m \implies n = m \\
\Succ n \neq \Zero
\endgather
$$
para todos os $n,m\in \Nats$.
%%}}}

%%{{{ Defining a Peano system 
\note Definindo um sistema Peano.
Então o que precisamos implementar é um conjunto estruturado
$\cal N = \sset \Nats {\Zero, \Succ}$.
Isso é fácil: nosso $\cal N$ vai ser uma tripla $\tup {\Nats, \Zero, \Succ}$,
onde seus membros $\Nats$, $\Zero$, e $\Succ$ são tais objetos que as leis
(P1)--(P5) são satisfeitas.
Sabemos que o $\Nats$ precisa ser infinito, então temos que o procurar
entre os conjuntos infinitos da nossa teoria.
Uma primeira idéia seria botar $\Nats \defeq I$, mas essa não parece
uma idéia boa---será difícil ``vender'' uma implementação com lixo!
O que realmente queremos botar como $\Nats$ é o $I_*$
(que não consiguimos ainda defini-lo).
Mas vamos supor que o $I_*$ realmente é um conjunto;
ele vai representar os números naturais,
mas quais serão nossos $\Zero$ e $\Succ$?
Pela especificação dos naturais, $\Zero$ tem que ser um dos membros do $I_*$,
e bem naturalmente escolhemos o $\emptyset$ como o zero.
E o $\Succ$?  Obviamente queremos botar $\Succ = \lam x {\setsucc x}$,
mas para realmente definir o $\Succ$ como função, lembramos que em nosso
dicionário ``função'' é um certo tipo de conjunto de pares.
Botamos então
$$
\align
\Succ &\pseudodefeq \class {\tup{n,m}} { m = \setsucc n }
\intertext{e agora só basta achar um conjunto que tem todos esses pares
como membros.  Fácil:}
\Succ &\defeq \setst {\tup{n,m}\in \Nats\times \Nats} { m = \setsucc n }.
\endalign
$$
Então falta só definir esse $I_*$.
%%}}}

%%{{{ Getting rid of noise 
\note Jogando fora o lixo.
Queremos definir o $I_*$ como conjunto; construí-lo pelos axiomas.
Uma primeira tentativa seria começar com o próprio $I$,
e usar o Separation~(\axref{separation}) para filtrar
seus elementos, separando os quais queremos do lixo,
assim botando
$$
I_* = \setst {x\in I} {\phi(x)}.
$$
para algum certo filtro $\phi(\dhole)$.
Qual fórmula vamos usar?
\spoiler.
%%}}}

%%{{{ A top-down approach 
\note Uma abordagem top-down.
Não podemos descrever um filtro em nossa linguagem de lógica
(FOL de teoria de conjuntos)!  (Lembra-se, uma fórmula não pode
ter tamanho infinito.)
Precisamos então alguma outra idéia para nos livrar dos elementos ``extra'' do $I$.
\emph{Vamos definir o conjunto $I_*$ com a abordagem top-down!}
Sabemos que nosso $I_*$ desejado é um subconjunto de $I$.
Então vamos começar com a colecção de todos os subconjuntos de $I$
que satisfazem a condição do Infinity:
$$
\scr I
\defeq
\setst {i \in \pset I} {\emptyset \in i \land \forall x\paren{x\in i \limplies \setsucc x \in i}
}.
$$
Queremos agora selecionar o ``menor'' elemento dessa família $\scr I$.
Menor no sentido de ``aquele que está contido em todos''.
Sim, nosso $I_*$ é o $\subset$-menor elemento do $\scr I$!
Para defini-lo basta tomar a intersecção da família $\scr I$,
que podemos pois
$\scr I \neq \emptyset$~(\ref{why_is_scrI_nonempty}):
$$
I_* \defeq \Inter {\scr I}.
$$
%%}}}

%%{{{ x: why_is_scrI_nonempty 
\exercise.
\label{why_is_scrI_nonempty}%
Por que $\scr I \neq \emptyset$?

\solution
Pois $I\in\scr I$.

\endexercise
%%}}}

%%{{{ thm: existence_of_nats 
\theorem Existência dos naturais.
\label{existence_of_nats}%
Existe pelo menos um sistema Peano $\cal N = \sset \Nats {\Zero, \Succ}$.
\sketch.
Definimos
$$
\cal N \defeq \tup{\Nats, \Zero, \Succ},
$$
onde:
$$
\align
\Nats &\defeq \Inter \setst {i \in \pset I} {\emptyset \in i \land \forall x \paren{x\in i \limplies \setsucc x \in i}}\\
\Zero &\defeq \emptyset\\
\Succ &\defeq \setst {\tup{m,n}\in \Nats\times\Nats} { n = \setsucc m }.
\endalign
$$
Temos já justificado que cada objeto que aparece nessa definição
é conjunto pelos axiomas.  Basta só verificar que as (P1)--(P5)
são satisfeitas.
\qes
\proof.
A única coisa que deixamos para completar a prova foi
verificar os (P1)--(P5), que é feito nos
exercícios \refn{zero_is_a_nat}--\refn{nat_has_induction}.
\qed
%%}}}

%%{{{ x: P1 zero_is_a_nat 
\exercise P1.
\label{zero_is_a_nat}%
Prove que $\Zero\in\Nats$.

\endexercise
%%}}}

%%{{{ x: P2 succ_is_a_function 
\exercise P2.
\label{succ_is_a_function}%
Prove que $\Succ$ é uma função.

\endexercise
%%}}}

%%{{{ x: P3 succ_is_injective 
\exercise P3.
\label{succ_is_injective}%
Prove que $\Succ : \Nats \injto \Nats$.

\endexercise
%%}}}

%%{{{ x: P4 zero_is_not_a_succ 
\exercise P4.
\label{zero_is_not_a_succ}%
Prove que $\Zero\notin \img \Succ \Nats$.

\endexercise
%%}}}

%%{{{ x: P5 nat_has_induction 
\exercise P5.
\label{nat_has_induction}%
Seja $X\subset \Nats$ tal que:
\beginil
\item{(1)} $\Zero \in X$;
\item{(2)} para todo $k\in \Nats$, se $k\in X$ então $\Succ k \in X$.
\endil
Prove que $X=\Nats$.

\endexercise
%%}}}

%%{{{ thm: uniqueness_of_nats 
\theorem Unicidade dos naturais.
\ii{unicidade!dos naturais}%
\label{uniqueness_of_nats}%
Se  $\cal N_1 = \sset {\Nats_1} {\Zero_1, \Succ_1}$
e   $\cal N_2 = \sset {\Nats_2} {\Zero_2, \Succ_2}$
são sistemas Peano, então são isomorfos: $\cal N_1 \iso \cal N_2$.
\wrongproof.
Precisamos definir um isomorfismo
$\phi : \cal N_1 \iso \cal N_2$.
Definimos a função $\phi : \Nats_1 \to \Nats_2$ usando recursão:
$$
\align
\phi(\Zero_1) &= \Zero_2\\
\phi(\Succ_1n) &= \Succ_2\phi(n).
\endalign
$$
Pela sua definição, a $\phi$ é um homomorfismo.
Basta só verificar que a $\phi$ é bijetora,
algo que tu vai fazer agora nos exercícios
\refn{homomorphism_of_nats_is_mono}~\&~\refn{homomorphism_of_nats_is_epi}.
\mistaqed
%%}}}

%%{{{ x: homomorphism_of_nats_is_mono 
\exercise.
\label{homomorphism_of_nats_is_mono}%
Prove que a $\phi : \Nats_1 \to \Nats_2$ definida
no~\ref{uniqueness_of_nats} é um monomorfismo.

\endexercise
%%}}}

%%{{{ x: homomorphism_of_nats_is_epi 
\exercise.
\label{homomorphism_of_nats_is_epi}%
Prove que a $\phi : \Nats_1 \to \Nats_2$ definida
no~\ref{uniqueness_of_nats} é um epimorfismo.

\hint
Pela definição de sobrejetora e de imagem,
basta provar que
$\img \phi {\Nats_1} = \Nats_2$.

\hint
Já sabemos que $\img\phi{\Nats_1} \subset \Nats2$.
Para provar a igualdade mesmo, use o princípio da indução.

\hint
Precisas provar duas coisas então:
(1) $\Zero_2 \in \img\phi{\Nats_1}$;
(2) para todo $n \in \Nats_2$, se $n \in \img\phi{\Nats_1}$ então $\Succ_2 n \in \img\phi{\Nats_1}$.

\solution
Como $\img \phi {\Nats_1} \subset \Nats_2$,
provamos a igualdade usando o princípio da indução~(P5).
\proofpart{Base.}
$\Zero_2 \in \img\phi{\Nats_1}$:
Imediato pois $\phi(\Zero_1) = \Zero_2$.
\proofpart{Passo indutivo.}
Suponha $k \in \img\phi{\Nats_1}$.
Precisamos mostrar que $\Succ_2 k \in \img\phi{\Nats_1}$.
Pela escolha de $k$, tome $k' \in \Nats_1$ tal que
$\phi(k') = k$.
Calculamos:
\compute
\phi(\Succ_1 k')
&= \Succ_2 (\phi(k')) \by {pela def.~$\phi$}
&= \Succ_2 k          \by {pela escolha de $k'$}
\endcompute
ou seja, $\Succ_2 k \in \phi[\Nats_1]$.

\endexercise
%%}}}

%%{{{ x: we_do_not_have_recursion_yet 
\exercise.
\label{we_do_not_have_recursion_yet}%
Qual o erro na prova do~\ref{uniqueness_of_nats}?

\hint
O que é uma função em nosso dicionário,
e quem garanta que escrevendo assim do nada duas equações
sobre um certo objeto $F$, isso realmente defina
uma função?

\solution
Não temos provado que dando equações recursivas como na
prova desse teorema podemos realmente definir uma função.
Fazemos isso no~\ref{recursion_theorem}, assim
realmente botando o $\qedsymbol$ no~\ref{uniqueness_of_nats}.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Recursion_theorems 
\section Teoremas de recursão.
\label{Recursion_theorems}%
\iisee{recursão!teorema}{teorema de recursão}%

%%{{{ thm: recursion_theorem 
\theorem Recursão.
\ii{teorema}[de recursão]%
\label{recursion_theorem}%
Sejam $\cal N = \sset \Nats {\Zero, \Succ}$ um sistema Peano,
$A$ conjunto,
$a \in A$,
e $h: A \to A$.
Então existe única função $F : \Nats \to A$ que satisfaz as equações:
$$
\align
F(\Zero)    &= a \tag{1}\\
F(\Succ n)  &= h(F(n)), \quad\text{para todo $n\in\Nats$}.\tag{2}
\endalign
$$
\sketch.
Nosso plano é
\beginil
\item{(i)} construir o objeto $F$ como conjunto;
\item{(ii)} mostrar que $F : \Nats \to A$;
\item{(iii)} mostrar que $F$ satisfaz as (1)--(2);
\item{(iv)} unicidade.
\endil
\endgraf
(i)
Vamos construir o $F$ \emph{bottom-up}, juntando umas das suas aproximações finitas:
funções parciais $f : \Nats\parto E$ onde a idéia é que elas ``concordam'' com a $F$
desejada onde elas estão definidas.
Nem vamos considerar todas elas: para nossa conveniência queremos apenas aquelas
cujo domínio é algum $\finord n$.
Por exemplo, as primeiras aproximações seriam as seguintes:
$$
\align
f_0 &= \emptyset\\
f_1 &= \bigset{ \tup{0,a} }\\
f_2 &= \bigset{ \tup{0,a}, \tup{1,h(a)} }\\
f_3 &= \bigset{ \tup{0,a}, \tup{1,h(a)}, \tup{2,h(h(a))} },\\
    &\eqvdots
\endalign
$$
Definimos o conjunto $\scr A$ de todas as aproximações aceitáveis:
$$
\scr A \defeq \setst {f \in (\Nats\parto E)} {\text{$f$ é aproximação aceitável}}
$$
onde falta descrever com uma fórmula nossa idéia de ``ser aproximação aceitável''
(\ref{acceptable_approximation}).
(Das aproximações acima a $f_0$ não é aceitável.)
Agora podemos já definir o $F$:
$$
F \defeq \Union {\scr A}.
$$
\endgraf
(ii)
Precisamos mostrar a compatibilidade da $\scr A$ e a totalidade da $F$,
ou seja: que não existem conflitos\ii{função!parcial!conflito}{}
(em outras palavras: que a família de funções parciais
$\scr A$ é compatível\ii{função!parcial!compatibilidade});
e que $\dom F = \Nats$.
Esses são os exercícios~\ref{compatibility_of_scrF}~\&~\ref{totality_of_F}
respectivamente.
\endgraf
(iii)
Precisamos verificar a corretude da $F$, que ela atende sua especificação.
Essa parte deve seguir da definição de ``aproximação aceitável''.
Confirmamos isso no~\ref{correctness_of_F}.
\endgraf
(iv)
Para a unicidade da $F$, precisamos mostrar que se $G : \Nats \to A$ tal que
satisfaz as (1)--(2), então $F = G$.  Isso é o~\ref{uniqueness_of_F}, e com
ele terminamos nossa prova.
\qes
\proof.
A prova completa segue do seu esboço junto com os exercícios:
\refn{acceptable_approximation},
\refn{compatibility_of_scrF},
\refn{totality_of_F},
\refn{correctness_of_F}, e
\refn{uniqueness_of_F}.
\qed
%%}}}

%%{{{ x: acceptable_approximation 
\exercise.
\label{acceptable_approximation}%
No contexto do~\ref{recursion_theorem} defina formalmente a afirmação ``$f$ é uma aproximação aceitável''.

\hint
Podemos ``quebrar'' a afirmação nesses partes:
\beginol
\li $f : \Nats \parto A$
\li $\tup{0,a} \in f$
\li Para qualquer $n\in\Nats_{\neq0}$, se $f$ é definida no $n$, então ela também é definida no predecessor de $n$, e o valor dela no $n$ é o correto, ou seja, o valor que ganhamos aplicando a $h$ no valor do predecessor de $n$.
\endol
O único que precisamos formalizar agora é o último.

\endexercise
%%}}}

%%{{{ x: compatibility_of_scrF 
\exercise Compatibilidade.
\label{compatibility_of_scrF}%
No contexto do~\ref{recursion_theorem} mostre que $\scr A$ é compatível.

\endexercise
%%}}}

%%{{{ x: totality_of_F 
\exercise Totalidade da $F$.
\label{totality_of_F}%
No contexto do~\ref{recursion_theorem} mostre que $\dom F = \Nats$.

\hint
Verifique que $\dom F \subset \Nats$.
Agora basta provar que $\dom F = \Nats$, usando o princípio da indução.

\endexercise
%%}}}

%%{{{ x: correctness_of_F 
\exercise Corretude da $F$.
\label{correctness_of_F}%
No contexto do~\ref{recursion_theorem} mostre que $F$ atende sua especificação,
ou seja:
$$
\align
F(\Zero)    &= a \tag{1}\\
F(\Succ n)  &= h(F(n)), \quad\text{para todo $n\in\Nats$}.\tag{2}
\endalign
$$

\endexercise
%%}}}

%%{{{ x: uniqueness_of_F 
\exercise Unicidade da $F$.
\label{uniqueness_of_F}%
No contexto do~\ref{recursion_theorem} prove a unicidade da $F$, ou seja:
se $G : \Nats \to A$ tal que
$$
\align
G(\Zero)    &= a \tag{1}\\
G(\Succ n)  &= h(G(n)), \quad\text{para todo $n\in\Nats$}.\tag{2}
\endalign
$$
então $F = G$.
Em outras palavras, as equações (1)--(2)
\emph{determinam} a função no $\Nats$.

\hint
Seja $X \subset \Nats$ o conjunto onde $F$ e $G$ ``concordam''.
Mostre que $X = \Nats$ usando o princípio da indução.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Consequences of induction and recursion 
\section Conseqüências de indução e recursão.

\blah.
Na~\refn{Nats_formally} definimos recursivamente operações nos naturais.
Graças ao~\ref{recursion_theorem}, ganhamos todas essas operações em qualquer
sistema Peano.  Vamos lembrar como, e também provar que não importa
\emph{em qual} sistema Peano calculamos: os resultados serão os
correspondentes!

%%{{{ note: Operations and order 
\note Operações e ordem.
Para qualquer sistema Peano $\cal N = \sset \Nats {\Zero, \Succ}$,
definimos as operações de adição e de multiplicação
$$
\xxalignat5
&\text{(a1)}  & n + \Zero   &= n          &&& n \ntimes \Zero   &= \Zero                &&\text{(m1)}\\
&\text{(a2)}  & n + \Succ m &= \Succ(n+m) &&& n \ntimes \Succ m &= (n \ntimes m) + n    &&\text{(m2)}
\endxxalignat
$$
e a relação de ordem no $\Nats$
$$
    n \leq m \defiff (\exists k\in\Nats)[n + k = m].
$$
Sejam dois sistemas Peano
$\cal N_1 = \sset {\Nats_1} {\Zero_1, \Succ_1}$ e 
$\cal N_2 = \sset {\Nats_2} {\Zero_2, \Succ_2}$, e
suas operações de adição $+_1$ e $+_2$, e suas relações de ordem $\leq_1$ e $\leq_2$.
Seja $\phi:\Nats_1\bijto\Nats_2$ o isomorfismo definido pelas
$$
\align
    \phi(\Zero_1)   &= \Zero_2           \tag{$\phi$1}\\
    \phi(\Succ_1 n) &= \Succ_2(\phi(n)). \tag{$\phi$2}
\endalign
$$
%%}}}

%%{{{ property: peano_morphism_respects_addition 
\property.
\label{peano_morphism_respects_addition}%
A $\phi$ respeita a adição, ou seja:
$$
\text{para todo $n,m\in\Nats_1$},\ \ 
\phi(n +_1 m) = \phi(n) +_2 \phi(m)
$$
\proof.
Por indução no $m\in\Nats_1$:
\proofpart{Base ($m \asseq \Zero_1$):}
{\proclaimstyle para todo $n\in\Nats_1$, $\phi(n +_1 \Zero_1) = \phi(n) +_1 \phi(\Zero_1)$.}
Seja $n \in \Nats_1$.
Calculamos:
\compute
\phi(n +_1 \Zero_1)
&= \phi(n)                    \by {pela (a1)$_1$}
&= \phi(n) +_2 \Zero_2        \by {pela (a1)$_2$}
&= \phi(n) +_2 \phi(\Zero_1)  \by {pela ($\phi$1)}
\endcompute
\proofpart{Passo indutivo:}
Seja $k \in \Nats_1$ tal que
$$
\text{para todo $n \in \Nats_1$, $\phi(n +_1 k) = \phi(n) +_1 \phi(k)$.} \tag{H.I.}
$$
Vamos provar que
$$
\text{\proclaimstyle{para todo $n \in \Nats_1$, $\phi(n +_1 \Succ_1 k) = \phi(n) +_1 \phi(\Succ_1 k)$.}}
$$
Seja $n \in \Nats_1$.
Calculamos:
\compute
\phi(n +_1 \Succ_1 k)
&= \phi(\Succ_1(n +_1 k))       \by {pela (a1)$_2$}
&= \Succ_2(\phi(n +_1 k))       \by {pela ($\phi$2)}
&= \Succ_2(\phi(n) +_2 \phi(k)) \by {pela (H.I.), com $n\asseq n$}
&= \phi(n) +_2 \Succ_2\phi(k)   \by {pela (a2)$_2$}
&= \phi(n) +_2 \phi(\Succ_1 k)  \by {pela ($\phi$2)}
\endcompute
\qed
%%}}}

%%{{{ x: peano_morphism_respects_multiplication 
\exercise.
\label{peano_morphism_respects_multiplication}%
Mostre que $\phi$ respeita a multiplicação, ou seja:
$$
\text{para todo $n,m\in\Nats_1$},\ \ 
\phi(n \ntimes_1 m) = \phi(n) \ntimes_2 \phi(m).
$$

\hint
Indução no $m\in\Nats_1$.

\endexercise
%%}}}

%%{{{ x: peano_morphism_respects_order 
\exercise.
\label{peano_morphism_respects_order}%
Mostre que $\phi$ respeita a ordem também, no sentido de:
$$
\text{para todo $n,m\in\Nats_1$},\ \ 
n\leq_1 m \iff \phi(n)\leq_2 \phi(m).
$$

\hint
Prove as duas direções da \bidir\ separadamente.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Constructing more numbers 
\section Construindo mais números.
\label{Constructing_more_numbers}%

\blah.
Tendo construido já os naturais,
vamos construir seus parentes também:
os inteiros, os racionais, os reais, e os complexos.

\TODO Os números inteiros (mostrar a construção).

{\def\eqrat{\approx}%
\note Os números racionais.
Essa construção é bem interessante---e simples!---pois usa um conceito nosso que
deve ser familiar já: o conjunto quociente.
Queremos identificar o racional $1/2$ com o par $\tup{1,2}$,
mas não podemos identificar o próprio $\rats$ com o $\ints \times \ints_{\neq0}$,
pois $\tup{1,2} \neq \tup{2,4}$ mesmo que $1/2 = 2/4$.
Duas idéias parecem razoáveis: (1) escolher um representante específico para cada
racional, trabalhando assim num subconjunto próprio do $\ints\times\ints_{\neq0}$;
(2) definir a relação $\eqrat$ de \emph{equivalência} no $\ints\times\ints_{\neq0}$,
e representar os racionais \emph{não como} membros desse conjunto,
mas \emph{sim como} classes de equivalência, ou seja, membros do conjunto quociente
$\quoset {\ints\times\ints_{\neq0}} {\eqrat}$.
Vamos seguir essa segunda idéia, pois é mais símples e elegante.

%%{{{ df: eqrat
\definition Números racionais.
Seja $Q = \ints\times\ints_{\neq0}$.
Defina no $Q$ a relação $\eqrat$ pela
$$
\tup{a,b} \eqrat \tup{c,d}
\defiff
ad = bc.
$$
Sendo uma relação de equivalência (\ref{eqrat_is_an_eqrel}),
defina
$$
\Rats
\defeq
\quoset Q {\eqrat}.
$$
%%}}}

%%{{{ x: eqrat_is_an_eqrel 
\exercise.
\label{eqrat_is_an_eqrel}%
Mostre que $\eqrat$ é uma relação de equivalência.

\endexercise
%%}}}

%%{{{ x: addition_multiplication_of_Rats 
\exercise.
\label{addition_multiplication_of_Rats}%
Defina formalmente a adição e multiplicação no $\Rats$.

\endexercise
%%}}}

\TODO Construir os racionais.

}

%%{{{ The real numbers (Dedekind cuts) 
\note Os números reais (Dedekind cuts).
\label{Constructing_the_reals}%
%%}}}

\TODO Escrever.

\blah.
Uma abordagem alternativa de construir os reais é mostrada
no~\ref{construct_reals_as_cauchy}.

%%{{{ x: construct_complex 
\exercise.
\label{construct_complex}%
Mostre como construir os complexos.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Problems intermission 
\problems Intervalo de problemas.

%%{{{ prob: multiset_formally_defined 
\problem Multisets.
\label{multiset_formally_defined}%
\ii{multiset}%
Alguém te deu a seguinte especificação de multiset
e tu queres implementá-la dentro da teoria de conjuntos.
(Veja também \ref{Multisets} no \ref{Sets}.)
\endgraf
\noindent
{\bf ``Definição''.}
Lembre (\ref{Multisets}) que um \dterm{multiset} (ou \dterm{bag})
$M$ é como um conjunto onde um elemento pode pertencer ao $M$ mais que
uma vez (mas não uma infinidade de vezes).
Ou seja, a ordem não importa (como nos conjuntos),
mas a ``multiplicidade'' importa sim.
\endgraf
Queremos tres operações em multisets, exemplificadas assim:
$$
\align
    \bag{ x, y, y, z, z, z, w } \bagunion
    \bag{ x, y, z, z, u, v, v } &=
    \bag{ x, y, y, z, z, z, u, v, v, w }\\
    \bag{ x, y, y, z, z, z, w } \baginter
    \bag{ x, y, z, z, u, v, v } &=
    \bag{ x, y, z, z }\\
    \bag{ x, y, y, z, z, z, w } \bagplus
    \bag{ x, y, z, z, u, v, v } &=
    \bag{ x, x, y, y, y, z, z, z, z, z, u, v, v, w }
\endalign
$$
Também queremos um predicado de ``pertencer'' $\inbag$
e uma relação de ``submultiset'' $\subbag$ tais que:
$$
\xalignat2
x&{}\inbag \bag{ x, y, y, z, z, z, w }           &\bag{ x, y, z, z }&{}\subbag    \bag{ x, x, y, y, z, z }            \\
z&{}\inbag \bag{ x, y, y, z, z, z, w }           &\bag{ x, y, z, z }&{}\notsubbag \bag{ x, x, y, y, z }               \\
u&{}\notinbag \bag{ x, y, y, z, z, z, w }        &\bag{ x, y, z, z }&{}\subbag    \bag{ x, y, z, z }                  \\
x&{}\notinbag \emptybag \quad\text{para todo $x$}&M                 &{}\subbag    M \quad\text{para todo multiset $M$}\\
 &                                               &\emptybag         &{}\subbag    M \quad\text{para todo multiset $M$}. 
\endxalignat
$$
(MS1) Para os multisets $A$ e $B$ temos $A = B$ sse eles tem os mesmos membro
com as mesmas multiplicidades.
Por exemplo,
$$
\bag{x, y, z, z, y} = \bag{x, y, y, z, z} \neq \bag{x,y,z}.
$$
(MS2) Para cada conjunto $A$, a classe
$$
\classt M {$M$ é multiset e $\forall x(x \inbag M \limplies x \in A)$}
$$
de todos os multisets formados por membros de $A$ é um conjunto.
\item{(i)}
Defina formalmente (em teoria de conjuntos) o termo ``multiset'' e mostre
(como exemplos) como são representados os multisets seguintes:
$$
\emptybag
\qqqquad
\bag{0, 1, 2, 2, 1}
\qqqquad
\bag{1, 2, 2, 3, 3, 3, 4, 4, 4, 4, \dotsc }.
$$
\item{(ii)}
Defina as operações de multisets ($\bagunion, \baginter, \bagplus$)
e os predicados ($\inbag$, $\subbag$).
\item{(iii)}
Prove pelos axiomas ZF que tua definição satisfaz as (MS1)--(MS2).

\hint
Para representar a multiplicidade, use uma função com codomínio o $\nats_{>0}$.

\solution
(i)
Um \dterm{multiset} é uma tupla $\cal M = \tup{ M ; f }$
onde $M$ é um conjunto e $f : M \to \nats_{>0}$.
$$
\align
\emptybag                       &= \tup{ \emptyset ; \emptyset }\\
\bag{0, 1, 2, 2, 1}             &= \tup{ \set{0,1,2} ; f }\\
\bag{1, 2, 2, 3, 3, 3, \dotsc}  &= \tup{ \nats_{>0} ; \idof {\nats_{>0}} }\\
\endalign
$$
onde $f : \set{0,1,2} \to \nats_{>0}$ é a função definida pela
$$
f(n) = \knuthcases{
    1,  &se $n = 0$\cr
    2,  &se $n = 1$\cr
    2,  &se $n = 2$.
}
$$
\endgraf
(ii)
$$
\align
\tup{A;\alpha} \bagunion \tup{B;\beta}&\defeq\tup{A\union B \;;\; \lambda x. \max\set{\alpha(x),\beta(x)}}\\
\tup{A;\alpha} \baginter \tup{B;\beta}&\defeq\tup{A\inter B \;;\; \lambda x. \max\set{\alpha(x),\beta(x)}}\\
\tup{A;\alpha} \bagplus  \tup{B;\beta}&\defeq\tup{A\union B \;;\; \lambda x. (\alpha(x) + \beta(x))}\\
x \inbag \tup{A;\alpha} &\defiff x \in A\\
\tup{A;\alpha} \subbag \tup{B;\beta} &\defiff A\subset B \mland (\forall x \in A)[ \alpha(x) \leq \beta(x)]
\endalign
$$
\endgraf
(iii)
A (MS1) é obviamente satisfeita graças à nossa definição de múltiset como tupla
de conjunto e função: ganhamos assim a (MS1) pelas definições de $=$ nos três
tipos envolvidos: conjunto; tupla; função.
Vamos verificar a (MS2).
Seja $A$ conjunto.
O arbitrário multiset $\cal M$ com membros de $A$ tem a forma
$\cal M = \tup{X , f}$ para algum $X\subset A$ e $f : X \to\nats_{>0}$.
Então $\cal M \in \pset A \times (A \parto \nats_{>0})$ e construimos o conjunto
de todos os multisets com membros de $A$ usando o ZF4:
$$
\namedop{Multisets}(A) \defeq
    \set{
        \cal M\in \pset A \times (A \parto \nats_{>0})
        \st
        \text{$\cal M$ é um multiset}.
    }
$$
Para mostrar que o $\pset A \times (A \parto \nats\setminus\set{0})$ é um conjunto,
precisamos os operadores $\pset$, $\times$, $\parto$, $\setminus$, e o próprio $\nats$, que já temos construido pelos ZF1--ZF7.

\endproblem
%%}}}

\endproblems
%%}}}

%%{{{ More axioms 
\section Mais axiomas.

%%{{{ Credits 
\note Créditos.
\label{fol_filter_by_fraenkel_and_skolem}%
Todos os axiomas que temos visto até agora são essencialmente os axiomas
de Zermelo\Zermelo{}, e falta apenas um dos seus axiomas originais
(o axioma da escolha que encontramos na~\refn{Axioms_of_choice}).
Sobre o axioma Separation~(\axref{separation}), Zermelo usou o termo
``propriedade definitiva'', que temos usado também sobre o ``filtro'',
mas foram \Fraenkel{}Fraenkel~e~\Skolem{}Skolem que consideraram definir isso
como uma fórmula da linguagem da FOL com $=$ e $\in$.
%%}}}

%%{{{ A letter from Fraenkel to Zermelo 
\note Uma carta de Fraenkel para Zermelo.
\Fraenkel{}Fraenkel percebeu (e comunicou no \yearof{1921} para Zermelo) que
com os seus axiomas não é possível provar a existência duns certos
conjuntos interessantes, como por exemplo o
$$
\bigset{
\Nats, \pset\Nats, \pset\pset\Nats, \pset\pset\pset\Nats, \dotsc
}.
$$
Sim, podemos construir cada um dos seus elementos, mas não a
colecção deles como conjunto!
%%}}}

%%{{{ ax: replacement 
\axiom Replacement (schema).
\tdefined{axioma}[Replacement (schema)]%
\label{replacement}%
{\rm Para cada função-classe $\Phi(\dhole)$, o seguinte:}
Para todo conjunto $a$, a classe
$
\classimg \Phi a \defeq \class {\Phi(x)} {x \in a}
$
é um conjunto.
$$
\forall a
\exists b
\forall y
\bigparen{
    y \in b
    \liff
    \lexists {x \in a} {\Phi(x) = y}
}
\axtaglabel{ZF8}{replacement}
$$
%%}}}

%%{{{ x: powersingleton_without_powerset 
\exercise.
\label{powersingleton_without_powerset}%
Resolve o~\ref{powersingleton} sem usar o~Powerset~(\axref{powerset}).

\hint
Qual operador $\Phi(\dhole)$ tu podes definir para aplicá-lo no $a$?

\solution
Definimos o operador $\Phi(\dhole)$ assim:
$$
\Phi(x) \defeq \set x.
$$
Facilmente, pelo Replacement~(\axref{replacement}) aplicado no $a$ com
esse $\Phi$ temos que
$\classimg \Phi a$
é um conjunto: o conjunto que procuramos!

\endexercise
%%}}}

%%{{{ A mortal game 
\note Um jogo mortal.
Teu oponente escolha um conjunto (e ele não participa mais no jogo):
esse é o ``conjunto da mesa''.
Em cada rodada do jogo tu tem que escolher um dos membros do conjunto da mesa,
e ele se vira o novo conjunto da mesa.
O objectivo é simples: \emph{continuar jogando pra sempre}.
(Imagine que se o jogo acabar, tu morre---e que tu queres viver---ou algo desse tipo.)
Então uma partida onde o oponente escolheu o conjunto
$$
\set{ \emptyset, \fsset{\emptyset}, \fsset{\emptyset, \fsset{\emptyset}},
\set{ \emptyset, \fsset{\emptyset}, \fsset{\emptyset, \fsset{\emptyset}}}}
$$
seria a seguinte
(sublinhamos as escolhas do jogador onde possível):
$$
\matrix
\format
\c\quad & \c\quad & \c \\
\text{Rodada} & \text{Conjunto} & \text{Movimento}\\
1 & \bigset{ \emptyset, \ \fsset{\emptyset}, \ \underline{\fsset{\emptyset, \fsset{\emptyset}}}, \ \fsset{ \emptyset, \fsset{\emptyset}, \fsset{\emptyset, \fsset{\emptyset}} } } & \fsset{\emptyset, \fsset{\emptyset}}\\
2 & \bigset{\emptyset, \underline{\fsset{\emptyset}}} & \fsset{\emptyset} \\
3 & \bigset{\underline{\emptyset}} & \emptyset\\
4 & \emptyset & \boohoo
\endmatrix
$$
Talvez esse jogador não foi o mais esperto, mas facilmente confirmamos
que qualquer possível estratégia dele é condenada com morte certa depois
dum finito número de rodadas.
\emph{E se o próprio jogador começa escolhendo qual é o conjunto da mesa inicial?}
Qual conjunto tu escolheria?
Pode \emph{imaginar} algum conjunto que seria uma boa opção que porderia garantir
vitória?
\spoiler.
%%}}}

%%{{{ x: how_to_win_the_wf_game 
\exercise.
\label{how_to_win_the_wf_game}%
Considere os conjuntos da mesa seguintes:
\beginil
\item{(1)} o conjunto $x$, onde
$$
x = \bigset{ \emptyset, \ \Nats, \ \set{ \emptyset, \set{\set{\emptyset}}}, \ x };
$$
\item{(2)} o conjunto $a$, onde
$$
\xalignat3
a &= \bigset{ \emptyset, \ b } &
b &= \bigset{ \set{\emptyset}, \ c } &
c &= \bigset{ \set{\emptyset}, \ \set{ \set{a}, \set{\set{\set{\emptyset}}}}};
\endxalignat
$$
\item{(3)} o conjunto $\Omega$, onde
$$
\Omega = \bigset{ \Omega }.
$$
\endil
Como tu jogaria nesses jogos?

\endexercise
%%}}}

%%{{{ Can we win? 
\note Podemos ganhar?.
Talvez.  Nossos axiomas não garantam a existência de nenhum conjunto
que nos permitaria ganhar; no outro lado, nem garantam a ausência de
conjuntos como os $x,a,b,c,\Omega$ do~\ref{how_to_win_the_wf_game}.
O axioma seguinte resolve essa questão, afirmando que qualquer partida
desse jogo seria realmente mortal.
%%}}}

%%{{{ ax: foundation 
\axiom Foundation.
\tdefined{axioma}[Foundation]%
\label{foundation}%
Todo conjunto não vazio tem membro disjunto com ele mesmo.
$$
\pforall {a\neq\emptyset}
\lexists {z \in a} {z\inter a = \emptyset}
\axtaglabel{ZF9}{foundation}
$$
%%}}}

\blah.
Vamos agora pesquisar umas conseqüências desse axioma, também conhecido como
\dterm{Regularity}\iisee{axioma}[Regularity]{Foundation}.

%%{{{ x: x_notin_x 
\exercise.
\label{x_notin_x}%
Prove diretamente que para todo conjunto $x$, $x\notin x$.
Quais axiomas tu precisou?

\hint
Seja $x$ conjunto.
Não podemos aplicar o~\refn{foundation} diretamente no $x$,
pois talvez $x = \emptyset$.
Uma abordagem seria separar casos.
Ao inves disso, aplique o~\refn{foundation} no conjunto $\set x$.

\endexercise
%%}}}

%%{{{ cor: univ_not_in_univ 
\corollary.
\label{unit_not_in_univ}%
$\Univ\notin\Univ$, ou seja, $\Univ$ não é um conjunto.
%%}}}

%%{{{ x: x_y_cannot_belong_to_each_other 
\exercise.
\label{x_y_cannot_belong_to_each_other}%
Prove que é impossível para dois conjuntos $x,y$ ter
$x \in y$ e também $y \in x$.

\endexercise
%%}}}

%%{{{ x: no_infinite_in_descending_chain_of_sets 
\exercise.
\label{no_infinite_in_descending_chain_of_sets}%
Prove que não existe seqüência infinita de conjuntos
$$
x_0 \ni x_1 \ni x_2 \ni x_3 \ni \dotsb
$$
e mostre que assim ganhamos os
exercícios~\refn{x_notin_x}~\&~\refn{x_y_cannot_belong_to_each_other}
como corolários.

\endexercise
%%}}}

%%{{{ x: spooky_pair_becomes_good_pair 
\exercise Spooky pair agora.
\label{spooky_pair_becomes_good_pair}%
Prove que com o axioma Foundation podemos sim usar a operação
do~\ref{spooky_pair}
$$
\tup{x,y} \defeq \bigset{ x, \set{x, y} }
$$
como uma implementação de par ordenado.

\endexercise
%%}}}

\endsection
%%}}}

%%{{{ Axioms of choice 
\section Axiomas de escolha.
\label{Axioms_of_choice}%

\blah.
Finalmente encontramos aqui o último axioma de Zermelo,
o mais infame, seu \emph{axioma de escolha}.
Mas, primeiramente, umas definições.

%%{{{ df: choice_set 
\definition Conjunto-escolha.
\label{choice_set}%
\tdefined{conjunto-escolha}%
Seja $\scr A$ uma família de conjuntos.
Chamamos o $E$ um \dterm{conjunto-escolha} da $\scr A$ sse
(1) $E \subset \union \scr A$, e
(2) para todo $A \in \scr A$, a intersecção $E \inter A$ é um singleton.
%%}}}

%%{{{ eg: choice_sets 
\example.
\label{choice_sets}%
Aqui umas famílias de conjuntos e um exemplo de conjunto-escolha para cada uma:
$$
\xalignat2
\scr A_1 &= \set{ [0,2], [1,4], [3,5] }
&&{\set{ 0, \,5/2, \,5 }}\\
\scr A_2 &= \set{ \set{a,b}, \set{b,c}, \set{d} }
&&{\set{a,c,d}}\\
\scr A_3 &= \set{ \set{a,b}, \set{b,c}, \set{c,a} }
&&\text{não tem conjunto-escolha}\\
\scr A_4 &= \set{ \emptyset, \set{\emptyset}, \set{\set{\emptyset}}, \set{\set{\set{\emptyset}}}, \set{\set{\set{\set{\emptyset}}}}, \dots }
&&\text{não tem conjunto-escolha}\\
\scr A_5 &= \set{            \set{\emptyset}, \set{\set{\emptyset}}, \set{\set{\set{\emptyset}}}, \set{\set{\set{\set{\emptyset}}}}, \dots }
&&\scr A_4\\
\scr A_6 &= \set{ \finord 1, \finord 2, \finord 3, \dotsc }
&&\text{não tem conjunto-escolha}
\endxalignat
$$
\endexample
%%}}}

%%{{{ df: choice_function 
\definition Função-escolha.
\label{choice_function}%
\tdefined{função-escolha}[de conjunto]%
\tdefined{função-escolha}[de família]%
Seja $A$ conjunto.
Chamamos a $\epsilon : \pset A \setminus \set{\emptyset} \to A$
uma \dterm{função-escolha do conjunto} $A$ sse $\epsilon(X) \in X$ para todo $X\in\dom\epsilon$.
\endgraf
Seja $\scr A$ família de conjuntos.
Chamamos a $\epsilon : \scr A \to \Union \scr A$ uma
\dterm{função-escolha da família de conjuntos} $\scr A$ sse
$\epsilon(A) \in A$ para todo $A\in \scr A$.
%%}}}

%%{{{ ax: choice_ac 
\axiom Choice (AC).
\tdefined{axioma}[Choice (AC)]%
\label{choice_ac}%
Seja $\scr A$ família de conjuntos não vazios.
Então
$$
\gathered
\text{
existe
$\epsilon : \scr A \to \Union \scr A$,
tal que
}\\
\text{
para todo $A\in\scr A$,
$\epsilon(A) \in A$.
}
\endgathered
\axtaglabel{AC}{ac}
$$
%%}}}

%%{{{ ax: choice_ac_disjoint 
\axiom Choice (forma disjunta).
\label{choice_ac_disjoint}%
Seja $\scr D$ família disjunta de conjuntos não vazios.
Então
$$
\gathered
\text{
existe
$\epsilon : \scr D \to \Union \scr D$,
tal que
}\\
\text{
para todo $D\in\scr D$,
$\epsilon(D) \in D$.
}
\endgathered
\axtaglabel{ACdis}{acdisj}
$$
%%}}}

%%{{{ ax: choice_ac_pset 
\axiom Choice (forma powerset).
\label{choice_ac_powerset}%
Seja $M$ conjunto não vazio.
Então
$$
\gathered
\text{
existe
$\epsilon : \pset M\setminus\set{\emptyset} \to M$,
tal que
}\\
\text{
para todo
$\emptyset\neq A\subset M$,
$\epsilon(A) \in A$.
}
\endgathered
\axtaglabel{AC$\pset$}{acpset}
$$
%%}}}

%%{{{ x: first_ac_equivalences 
\exercise.
\label{first_ac_equivalences}%
Todas as ``formas'' do axioma de escolha (AC) que vimos até agora
são logicamente equivalentes.
Prove isso seguindo o ``round-robin'' seguinte:
$$
\axref{ac}
\implies \axref{acdisj}
\implies \axref{acpset}
\implies \axref{ac}.
$$

\endexercise
%%}}}

\blah.
Depois vamos encontrar mais teoremas (assumindo o \axref{ac}),
que na verdade são equivalentes com ele.

\endsection
%%}}}

%%{{{ Desired and controversial consequences 
\section Conseqüências desejáveis e controversiais.

%%{{{ thm: banach_tarski 
\theorem Banach--Tarski.
\label{banach_tarski}%
\Banach{}\Tarski{}%
\ii{teorema}[Banach--Tarski]%
Podemos decompor a bola sólida unária
$$
B = \set{\tup{x,y,z} \in \reals^3 \st x^2 + y^2 + z^2 \leq 1}
$$
em $5$ subconjuntos
$\sym 1, \sym 2, \sym 3, \sym 4, \sym 5 \subset S$,
rodar e transladar eles, criando duas cópias sólidas de $B$.
%%}}}

%%{{{ thm: wellordering_thm 
\theorem Bem-ordenação (Zermelo).
\label{wellordering_thm}%
\ii{teorema}[da bem-ordenação]
Todo conjunto $A$ pode ser bem ordenado.
%%}}}

%%{{{ thm: cardinal_comparability_thm 
\theorem Comparabilidade de cardinais.
\label{cardinal_comparability_thm}%
Para todos conjuntos $A,B$, temos $A\leqc B$ ou $B \leqc A$.
%%}}}

\endsection
%%}}}

%%{{{ Weaker choices 
\section Escolhas mais fracas.

\endsection
%%}}}

%%{{{ Other set theories 
\section Outras teorias de conjuntos.

\endsection
%%}}}

%%{{{ Other foundations 
\section Outras fundações.

\endsection
%%}}}

%%{{{ Problems 
\problems.

%%{{{ three_classes_are_sets_problem 
\problem.
\label{three_classes_are_sets_problem}%
Seja $a$ conjunto.
\emph{Sem usar} o Separation~(\axref{separation}),
mostre pelo resto dos axiomas que as classes seguintes são conjuntos:
$$
\xalignat3
    E &= \setlst {\set{x, \Union x,\pset x}} {x\in a} ;&
    F &= \setlst x {x\subsetneq a}                    ;&
    G &= \setst  x {x\neq\emptyset \land x = \Inter x}.
\endxalignat
$$

\endproblem
%%}}}

%%{{{ replacement_replaces_separation 
\problem Replacement is the new Separation---or is it?.
\label{replacement_replaces_separation}%
Podemos tirar o Separation scheme~(\axref{separation})
dos nossos axiomas ``sem perder nada'', se temos o
Replacement scheme~(\axref{replacement}) no lugar dele?

\hint
Tente achar uma class-function $\Phi$ tal que aplicada
nos elementos dum conjunto $A$, vai ``identificar'' todos
aqueles que \emph{não} tem a propriedade $\phi(\dhole)$,
mas mesmo assim sendo injetora quando restrita naqueles
que satisfazem a.

\hint
Alem de tudo isso, os ``originais'' $a\in A$ tem que ser
recuperáveis pelas suas imagens atraves da $\Phi$.

\solution
Seja $A$ conjunto e $\phi(x)$ fórmula.
Definimos a class-function
$$
\Phi(x) =
\knuthcases{
    \set {x},   &se $\phi(x)$\cr
    \emptyset,  &se não.
}
$$
Agora aplicamos o Replacement com essa class-function no conjunto $A$,
ganhando assim como conjunto o $\classimg\Phi A$, cujos elementos são exatamente os
\emph{singletons} $\set{a}$ de todos os $a\in A$ que satisfazem a $\phi(a)$,
e o $\emptyset$.
Usando o ZF6 chegamos no $\Union \classimg\Phi A$ que realmente é o desejado
conjunto
$\set { a \in A \st \phi(a) }$.

\endproblem
%%}}}

%%{{{ replacement_replaces_pairset 
\problem Replacement is the new Pairset---or is it?.
\label{replacement_replaces_pairset}%
Podemos tirar o Pairset~(\axref{pairset}) dos
nossos axiomas ``sem perder nada'', se temos o
Replacement scheme~(\axref{replacement}) no lugar dele?

\hint
Podemos sim.
Dados \emph{objetos} $a,b$, mostre que existe o conjunto
$\set{a,b}$ que consiste em exatamente esses objetos.

\hint
Tente achar uma class-function $\Phi$ tal que aplicada
nos elementos dum conjunto suficientemente grande,
vai ter como imagem o desejado $\set{a,b}$.

\solution
Sejam $a,b$ objetos.
Considere a class-function
$$
\Phi (x) \asseq 
\knuthcases{
    a, &se $x=\emptyset$\cr
    b, &se $x\neq\emptyset$.
}
$$
Agora precisamos apenas construir um conjunto $S$ tal que:
$\emptyset \in S$, e $|S| \geq 2$.
Pelo Emptyset, temos o $\emptyset$.
Pelo Powerset aplicado no $\emptyset$ ganhamos o $\set{\emptyset}$, e aplicando mais uma vez o Powerset chegamos no $\set{\emptyset, \set{\emptyset}}$.
Usando o Replacement com a $\Phi(x)$ nesse conjunto, construimos o desejado $\set{a,b}$.
\endgraf
Em forma de árvore:
$$
\AxiomC{}
\RightLabel{Empty}
\UnaryInfC{$\emptyset$}
\RightLabel{Power}
\UnaryInfC{$\set{\emptyset}$}
\RightLabel{Power}
\UnaryInfC{$\set{\emptyset, \set{\emptyset}}$}
\RightLabel{Repl; $\Phi$}
\UnaryInfC{$\set{a, b}$}
\DisplayProof
$$

\endproblem
%%}}}

%%{{{ find_the_crime_of_foundation 
\problem.
\label{find_the_crime_of_foundation}%
Na resolução do~\ref{bad_pair}, tem um roubo.
Ache e explique.

\endproblem
%%}}}

%%{{{ spooky_pair_problem 
\problem.
\label{spooky_pair_problem}%
No~\ref{spooky_pair} provaste que a operação binária definida pela
$$
\tup{x,y} \defeq \bigset{ x, \set{x,y} }
$$
satisfaz a propriedade~\ref{spec_tup2}.
Depois, no~\ref{spooky_pair_becomes_good_pair}, usando o \axref{foundation}
conseguimos provar que satisfaz a propriedade~\ref{spec_tup1} também.
Mostre que o~\axref{foundation} é necessário para conseguir isso,
mostrando um contraexemplo: conjuntos $a,b,a',b'$ tais que
$$
\tup{a,b} = \tup{a',b'}
$$
mas mesmo assim pelo menos uma das $a = a'$ e $b = b'$ não é válida.

\hint
Obviamente, teu contraexemplo tem que utilizar conjuntos mal-fundamentados.

\hint
Considere conjuntos $x,y,o$ com a propriedade
$$
x = \set { o, \set{x,y} }
$$
onde $o \neq y$.

\hint
Calcule o
$$
\tup{ \set{x,y}, o }
$$
e ache que ele é igual com um par ordenado diferente.
(Tem que provar que é difernete mesmo!)

\solution
Considere um $x$ mal-fundamentado, que satisfaz a
$$
x = \set { o, \set{x,y} }
$$
para alguns $y,o$ onde $o \neq y$.
Calculamos o
$$
\align
\tup{ \set{x,y}, o }
&= \set{ \set{x,y}, \set{ \set{x,y}, o } } \\
&= \set{ \set{x,y}, x } \\
&= \tup{ x , y }
\endalign
$$
mesmo com $o \neq y$, ou seja, achamos um contraexemplo mesmo.

\endproblem
%%}}}

%%{{{ choice_rel_problem 
\problem.
\label{choice_rel_problem}%
Mostre que o Choice~\axref{ac} é equivalente com o seguinte axioma:
\endgraf
\noindent
{\bf Choice (Rel).}
{\proclaimstyle
Se uma relação $R \in \relspace{A,B}$ tem a propriedade de totalidade,
então existe função $f : A\to B$ com $x \rel R f(x)$ para todo $x\in A$.
}
$$
\bigparen{
R \in \relspace{A,B}
\land
\dom R = A
}
\limplies
\bigparen{
\pexists {f : A \to B}
\lforall {x\in A} {x \mathrel R f(x)}
}
\axtaglabel{ACrel}{acrel}
$$

\endproblem
%%}}}

%%{{{ prob: construct_reals_as_cauchy 
\problem Reais como seqüências Cauchy.
\label{construct_reals_as_cauchy}%
\TODO Enunciar o problema.

\endproblem
%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite{fromfregetogodel},
\cite{halmosnaive},
\cite{ynmnst},
\cite{kunenfoundations}.
\cite{kunen2011},
\cite{cohensetch},
\cite{kunen1980},
\cite{jechset}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Well-orderings and transfinite induction 
\chapter Bem-ordens e indução transfinita.
\label{Wellorderings_and_transfinite_induction}%

%%{{{ intro 
\chapintro
O termo \emph{wellorder} (ou \emph{well-order}) de inglês tem sido traduzido
como \emph{boa ordem} em português.  Aqui eu uso o termo \emph{bem-ordem}.
Além de ficar mais perto no termo internacional, a palavra ``bem'' tem
um significado \emph{bem} mais usado em português do que em inglês,
onde não é muito \emph{well} known, exemplificado aqui:%
\footnote{e com certeza \emph{well} beyond nossos interesses aqui}
\endgraf\smallskip
Uma ordem é uma relação legal.\endgraf
Uma \emph{bem}-ordem é uma relação \emph{bem}~legal---vamos descobrir isso neste capítulo.
%%}}}

%%{{{ df: woset 
\definition Bem-ordem.
\label{woset}%
\tdefined{woset}%
\iisee{conjunto}[bem-ordenado]{woset}%
Seja $\sset A <$ um conjunto totalmente ordenado.
Sua ordem $<$ é uma \dterm{bem-ordem}, sse
\emph{cada subconjunto $S\subset A$ possui um elemento mínimo}.
Nesse caso chamamos o $A$ \dterm{bem-ordenado} ou \dterm{woset}
(de \dterm{well-ordered set}).
%%}}}

%%{{{ Transfinite induction 
\section Indução transfinita.

\endsection
%%}}}

%%{{{ Transfinite recursion 
\section Recursão transfinita.

\endsection
%%}}}

%%{{{ Problems 
\problems.

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite{goldreisets},
\cite{ynmnst}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Ordinal arithmetic 
\chapter Aritmética ordinal.
\label{Ordinal_arithmetic}%

%%{{{ x: omegaomega_plus_one_is_well_ordered 
\exercise.
\label{omegaomega_plus_one_is_well_ordered}%
O $\omega^2+1$ é bem ordenado.

\hint
Lembre-se que usamos a ordem (anti)lexicográfica nos produtos.
Tome $A$ tal que $\emptyset\neq A \subset \omega^2 + 1$ e ache se u mínimo.
Separe casos dependendo se $A=\set{\top}$ ou não,
onde $\top$ o máximo elemento do $\omega^2+1$.

\solution
Seja $A\subset \omega^2 + 1$ com $A\neq\emptyset$.
Temos a seguinte ordem no $\omega^2 + 1$:
$$
\munderbrace{
 \munderbrace{\tup{0,0} < \tup{1,0} < \tup{2,0} < \dotsb}{\dsize\omega} 
 <
 \munderbrace{\tup{0,1} < \tup{1,1} < \tup{2,1} < \dotsb}{\dsize\omega} 
 <
 \dotsb
}{\dsize\omega^2}
<
\set\top.
$$
\case{Caso $A = \set {\top}$}:
$\min A = \top$.
\endgraf
\case{Caso $A \neq \set {\top}$}:
Como $A\neq \emptyset$, concluimos que $A\inter \omega^2 \neq \emptyset$.
Sejam:
$$
\align
y_0 &\asseq \min\set{ y\in\nats \st \lexists {x\in\nats}{\tup{x,y}\in A}}\\
x_0 &\asseq \min\set{ x\in\nats \st \tup{x,y_0}\in A}
\endalign
$$
onde os dois mínima existem graças ao PBO dos naturais.
Facilmente, $\min A = \tup{x_0,y_0}$.

\endexercise
%%}}}

%%{{{ x: solving_for_ordinals 
\exercise.
\label{solving_for_ordinals}%
O que podes concluir sobre os ordinais $\alpha$ e $\beta$ se\dots:
$$
\xxalignat3
\text{(i)}~&\omega + \alpha = \omega & \text{(iii)}~& \omega \cdot \alpha = \omega & \text{(v)}~& \alpha +     \beta = \omega\\
\text{(ii)}~&\alpha + \omega = \omega & \text{(iv)}~& \alpha \cdot \omega = \omega & \text{(vi)}~& \alpha \cdot \beta = \omega
\endxxalignat
$$

\solution
\item{(i)}   $\alpha = 0$
\item{(ii)}  $\alpha$ é finito
\item{(iii)} $\alpha=1$
\item{(iv)}  $\alpha$ finíto \& $\alpha\neq 0$
\item{(v)}   $\text{ou}\,\leftbrace{\aligned&\text{$\alpha$ finíto      \& $\beta=\omega$}\\&\text{$\alpha=\omega$ \& $\beta=0$}\endaligned}$
\item{(vi)}  $\text{ou}\,\leftbrace{\aligned&\text{$1\leq\alpha<\omega$ \& $\beta=\omega$}\\&\text{$\alpha=\omega$ \& $\beta=1$}\endaligned}$

\endexercise
%%}}}

%%{{{ Problems 
\problems.

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite{goldreisets},
\cite{ynmnst},
\cite{kunen2011}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Denotational semantics 
\chapter Semântica denotacional.
\label{Denotational_semantics}%

%TODO: Check http://pages.cs.wisc.edu/~horwitz/CS704-NOTES/

%%{{{ A language of binary numerals 
\section Uma linguagem de numerais binários.

\endsection
%%}}}

%%{{{ A little programming language 
\section Uma pequena linguagem de programação.

\endsection
%%}}}

%%{{{ Domain theory 
\section Teoria de domínios.

\endsection
%%}}}

%%{{{ Problems 
\problems.

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite{stoysemantics},
\cite{tennent1976},
\cite{tennentsemantics}.

\cite{streicherdomainsfp}.

\cite{lpbook}.

\cite{winskelsemantics},
\cite{guntersemantics}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Universal algebra 
\chapter Álgebra universal.
\label{Universal_algebra}%

%%{{{ Problems 
\problems.

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Category theory 
\chapter Teoria das categorias.
\label{Category_theory}%

%%{{{ Problems 
\problems.

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite{babylawvere},
\cite{arbibmanesarrows},
\cite{papalawvere}.

\cite{goldblatttopoi}.

\cite{awodeycats},
\cite{barrwellscatscs},
\cite{joyofcats},
\cite{borceuxhandbook1}.

\cite{riehlcats},
\cite{maclanecats}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Intuitionistic logic 
\chapter Lógica intuicionista.
\label{Intuitionistic_logic}%

%%{{{ Problems 
\problems.

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite{heytingintuitionism}.
\cite{dummettintuitionism}.
\cite{proofsandtypes}.
\cite{lecturesch}.
\cite{bishopfca}~\&~\cite{bishopbridgesconstructive}.
\cite{girardblindspot}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Proof theory 
\chapter Teoria de provas.
\label{Proof_theory}%

%%{{{ Systems à la Hilbert 
\section Sistemas à la Hilbert.

\endsection
%%}}}

%%{{{ Dedução natural 
\section Natural deduction.

\endsection
%%}}}

%%{{{ Sequent calculus 
\section Sequent calculus.

\endsection
%%}}}

%%{{{ Problems 
\problems.

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite{vonplatoelements},
\cite{bimboproof},
\cite{negrivonplatospt},
\cite{takeuti},
\cite{prawitz},
\cite{proofsandtypes},
\cite{olthdem},
\cite{kleeneIM}.
\cite{lecturesch}.
\cite{girardblindspot}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Linear logic 
\chapter Lógica linear.
\label{Linear_logic}%

%%{{{ Problems 
\problems.

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite{girardllss}.
\cite{girardblindspot}.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Type theory 
\chapter Teoria dos tipos.
\label{Type_theory}%

%%{{{ Problems 
\problems.

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite{nederpeltgeuvers}.
\cite{proofsandtypes}.
\cite{programmingmltt}.
\cite{piercetapl}.
\cite{hott}.

\endfurther
%%}}}

\endchapter
%%}}}

